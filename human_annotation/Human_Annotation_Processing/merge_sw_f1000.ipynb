{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_suggestion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "days_to_submit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "llm_llamaV3-2_length_effort",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_lexical_diversity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_questions_raised",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_citation_usage",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_llamaV3-2_sentiment_polarity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_llamaV3-2_politeness",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_llamaV3-2_hedging",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_llamaV3-2_specificity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_llamaV3-2_domain_terms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_relevance_alignment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_readability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_overall_quality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_overall_score_100",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "6bb7b3a9-4f75-407f-8bd0-28cf1f871cca",
       "rows": [
        [
         "0",
         "Daniel A Nation",
         "19 Jan 2023",
         "Approved",
         "345",
         "Assessing the role of vascular risk factors in dementia: Mendelian randomization meta-analysis and comparison with observational estimates",
         "Background:  Although observational studies demonstrate that higher levels of vascular risk factors are associated with an increased risk of dementia, these associations might be explained by confounding or other biases. Mendelian randomization (MR) uses genetic instruments to test causal relationships in observational data. We sought to determine if genetically predicted modifiable risk factors (type 2 diabetes mellitus, low density lipoprotein cholesterol, high density lipoprotein cholesterol, total cholesterol, triglycerides, systolic blood pressure, diastolic blood pressure, body mass index, and circulating glucose) are associated with dementia by meta-analysing published MR studies. Secondary objectives were to identify heterogeneity in effect estimates across primary MR studies and to compare meta-analysis results with observational studies. Methods: MR studies were identified by systematic search of Web of Science, OVID and Scopus. We selected primary MR studies investigating the modifiable risk factors of interest. Only one study from each cohort per risk factor was included. A quality assessment tool was developed to primarily assess the three assumptions of MR for each MR study. Data were extracted on study characteristics, exposure and outcome, effect estimates per unit increase, and measures of variation. Effect estimates were pooled to generate an overall estimate, I2 and Cochrane Q values using fixed-effect model. Results: We screened 5211 studies and included 12 primary MR studies after applying inclusion and exclusion criteria. Higher genetically predicted body mass index was associated with a higher odds of dementia (OR 1.03 [1.01, 1.05] per 5 kg/m2 increase, one study, p=0.00285). Fewer hypothesized vascular risk factors were supported by estimates from MR studies than estimates from meta-analyses of observational studies.  Conclusion: Genetically predicted body mass index was associated with an increase in risk of dementia.",
         "240",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This is a meta-analysis of mendelian randomization studies and a comparison of this meta-analysis with observational study estimates, to evaluate the potential causal nature of observed associations between 9 vascular risk factors and dementia. The authors conducted a thorough search and identified 12 out of 5211 studies meeting criteria for inclusion in the analysis. Findings indicated higher genetically predicted BMI is associated with slightly higher odds of dementia. Furthermore, fewer vascular risk factors were associated with dementia in mendelian randomization studies than in observational studies. The question of a causal role for modifiable vascular risk factors for dementia is critical to efforts to treat and prevent cognitive impairment, making the topic of this article particularly important. Strengths of the present study include examination of MR which may allow for causal inference, meta-analysis of MR studies in this area which is novel, and comparison with observational studies. The methods appear to be rigorous. Unfortunately, very little can be concluded from the study due to limitations of available data within MR studies themselves and across studies. Although the authors extensively outline these limitations in excellent detail, the limits curtail the ultimate impact of this study. Nevertheless, it was well written and perhaps serves as an initial step forward or a snapshot of field as it currently stands, including the many remaining questions.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         "0.787",
         "1",
         "0",
         "0.1430803571428571",
         "0.1695",
         "0.9657244682312012",
         "17.03",
         "15.9",
         "16.35",
         "16.3",
         "16.1",
         "95",
         "0",
         "2",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "3",
         "4.0",
         "4.0",
         "5.0",
         "90.0",
         "90"
        ],
        [
         "1",
         "Ahmet Turan Isik",
         "27 Sep 2024",
         "Approved With Reservations",
         "250",
         "Assessing the role of vascular risk factors in dementia: Mendelian randomization meta-analysis and comparison with observational estimates",
         "Background:  Although observational studies demonstrate that higher levels of vascular risk factors are associated with an increased risk of dementia, these associations might be explained by confounding or other biases. Mendelian randomization (MR) uses genetic instruments to test causal relationships in observational data. We sought to determine if genetically predicted modifiable risk factors (type 2 diabetes mellitus, low density lipoprotein cholesterol, high density lipoprotein cholesterol, total cholesterol, triglycerides, systolic blood pressure, diastolic blood pressure, body mass index, and circulating glucose) are associated with dementia by meta-analysing published MR studies. Secondary objectives were to identify heterogeneity in effect estimates across primary MR studies and to compare meta-analysis results with observational studies. Methods: MR studies were identified by systematic search of Web of Science, OVID and Scopus. We selected primary MR studies investigating the modifiable risk factors of interest. Only one study from each cohort per risk factor was included. A quality assessment tool was developed to primarily assess the three assumptions of MR for each MR study. Data were extracted on study characteristics, exposure and outcome, effect estimates per unit increase, and measures of variation. Effect estimates were pooled to generate an overall estimate, I2 and Cochrane Q values using fixed-effect model. Results: We screened 5211 studies and included 12 primary MR studies after applying inclusion and exclusion criteria. Higher genetically predicted body mass index was associated with a higher odds of dementia (OR 1.03 [1.01, 1.05] per 5 kg/m2 increase, one study, p=0.00285). Fewer hypothesized vascular risk factors were supported by estimates from MR studies than estimates from meta-analyses of observational studies.  Conclusion: Genetically predicted body mass index was associated with an increase in risk of dementia.",
         "857",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  I have reviewed the manuscript \"Assessing the role of vascular risk factors in dementia: Mendelian randomization meta-analysis and comparison with observational estimates\" with interest. The paper needs to reconsider a few flaws. The background and purpose of the study should be emphasized more clearly. The authors should explain the effects of any potential overlap between the cohorts on the results. It would be better for a statistician to recheck the results because I am not good enough at this topic. No competing interests were disclosed  Are the rationale for, and objectives of, the Systematic Review clearly stated? No  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are the conclusions drawn adequately supported by the results presented in the review? Yes  If this is a Living Systematic Review, is the ‘living’ method appropriate and is the search schedule clearly defined and justified? (‘Living Systematic Review’ or a variation of this term should be included in the title.) Not applicable",
         "0.7836",
         "1",
         "0",
         "0.1358695652173913",
         "0.1953",
         "0.9290751218795776",
         "27.93",
         "13.8",
         "15.0",
         "14.8",
         "14.1",
         "92",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "3",
         "4.0",
         "5.0",
         "4.0",
         "80.0",
         "84"
        ],
        [
         "2",
         "Mansoor Rahman",
         "23 Dec 2024",
         "Approved With Reservations",
         "227",
         "Impact of yoga on the central and peripheral vascular function among desk-based workers: A single-centered trial study",
         "Background The aim of this study was to observe and analyze vascular function in ‘prolonged sitting’, followed by a yoga asana routine and pranayama intervention. Participants in this study include those who work from desks in offices. The study required the participants to attend on three separate days at random, and they had to finish a computerized test on each day. On the first day, participants were required to complete a computer test while sitting still for four hours (with the exception of washroom breaks). The next day, they underwent a computerized test along with a pranayama intervention. Finally, on the last day, they underwent a computerized test along with a yoga asana intervention. At the start of the study and after two and four hours, we measured the diameter and velocity of the common carotid artery (CCA) and superficial femoral artery (SFA).  Methods The study was a within-subjects prospective single-center trial conducted in the Department of Radio-Diagnosis and Imaging, Kasturba Medical Hospital, Manipal, India, between September 2022 and January 2023. Participants were asked to do one of the following ‘activities’ over successive weeks: Week 1 – Prolonged sitting; Week 2 – Pranayama intervention; and Week 3 – Yoga asana intervention during prolonged sitting. The baseline and follow-up variables of pulse velocity, endothelial thickness, and shear rate were assessed for normality through a Shapiro-Wilk Test.  Results Our sample included 11 participants with moderate physical activity, five with high physical activity and one with low physical activity. Yoga asana intervention comprised participants sitting continuously for four hours, with a yoga asana intervention being provided every hour, lasting for 10 minutes.  Conclusions Yoga asana improves vascular functions in prolonged sitting conditions. This routine can promote the concept of interrupted sitting and ways to reduce it with efficient yoga asana practice without changing the work culture and provide better physical relief.  Trial registration Clinical Trials Registry – India ( CTRI/2022/09/045628), date of registration: 19/09/2022(CTRI/2022/9/045628)https://ctri.nic.in/Clinicaltrials/main1.php?EncHid=16349.27799,",
         "227",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Is the work clearly and accurately presented and does it cite the current literature? - There is mismatch in discussion references with duration of this study intervention with the existing evidences chosen to agree the study findings. Are all the source data underlying the results available to ensure full reproducibility? - Intervention procedures and descriptions were not mentioned in detail. Are the conclusions drawn adequately supported by the results? - With single session to conclude requires a strong evidences with theoretical background.  Is the work clearly and accurately presented and does it cite the current literature? No  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? No  Are the conclusions drawn adequately supported by the results? Partly",
         "0.776",
         "1",
         "0",
         "0.1989370748299319",
         "0.0999",
         "0.6949097514152527",
         "20.18",
         "14.7",
         "14.74",
         "15.3",
         "14.8",
         "101",
         "0",
         "0",
         "0",
         "0",
         "2.0",
         "3.0",
         "4.0",
         "False",
         "neutral",
         "neutral",
         "Moderate",
         "neutral",
         "2.0",
         "3.0",
         "4.0",
         "60.0",
         "70"
        ],
        [
         "3",
         "Dr. Talal Shihayb",
         "04 Nov 2024",
         "Approved With Reservations",
         "1197",
         "Do more pregnancies increase the risk of periodontal disease?",
         "Background Hormonal changes in pregnancy and their induced effect on periodontal health are well documented. The present study is aimed at the potential repercussions of multiple pregnancies on periodontal health.  Materials and methods Our study utilized data from key sections of the NHANES. All the pertaining and relevant data for the study is collected. Our exposure variable was the number of pregnancies, and the outcome variable was periodontal disease. The number of pregnancies is classified as one, two, three, four, or more. Age, gender, race/ethnicity, education, poverty/income ratio, marital status, and other variables. Multiple logistic regression models were employed to assess the impact of multiple pregnancies on periodontal disease.  Result The crude and multiple logistic regression analyses revealed that none of the variables were significantly associated with the prevalence of periodontitis. In univariate analysis, patients with one or two pregnancies had higher odds of experiencing periodontitis (OR 1.154, 95% CI 0.748-1.779), (OR 1.464, 95% CI 0.864-2.483) respectively. However, these associations did not reach statistical significance.  Conclusion Within the limitation of the study, there is no significant relationship between parity and the prevalence of periodontitis, the longitudinal study may be warranted to delve deeper into any potential associations.",
         "19",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors assessed the effects of number of pregnancies on periodontitis. Studying pregnancy outcomes in relation to oral health is crucial. However, I have some comments on the paper: Introduction No comments. Methods Can the authors explain why they only selected the 2011-2012 and 2013-2014 cycles of NHANES? The authors excluded edentulous participants from their study. Dealing with edentulous patients is tricky and not straight forward. If the reason for being edentulous was due to periodontal disease, the perhaps edentulous participants may be considered as the most severe form of periodontitis (since the authors are studying prevalent periodontitis and not incident periodontitis). Given that the authors are studying the accumulated exposure of pregnancy on periodontal disease, the results could be different had edentulous participants due to periodontal disease been included in the analysis, I suggest the authors add edentulous as a separate category or at least justify/discuss excluding edentulous participants from the study in the methods/discussion section. If by edentulous participants, the authors meant without any teeth, then any person with 1 tooth is automatically classified as mild periodontitis or no periodontitis and cannot be classified as moderate or severe. However, all included participants should have the chance to be in group of periodontitis, which is unfortunately prevented including participants with just 1 tooth. The authors perhaps may have already included those with at least 2 permanent teeth and if so, should make this clear. If not, then inclusion of participants with at least 2 teeth (if authors are still excluding edentulous participants) in the study or at least discussion of the impact of this aspect on the result is important. The authors defined the exposure as the number of pregnancies. Did the authors include all pregnancies whether completed or not? Providing more details on this aspect would make the paper more clear. Furthermore, the authors used it as a categorical variable instead of a continuous exposure. Unfortunately, this results in loss of information. I suggest the authors add this to the discussion section. The authors have defined the outcome of chronic periodontitis according to CDC/AAP. I suggest replacing the word periodontal disease with chronic periodontitis in the manuscript as the term periodontal disease is an umbrella term that includes multiple conditions. I suggest adding more details on how smoking and alcohol were classified or at least cite their webpages if the authors classified them as NHANES originally did. The authors wrote the following under statistical analysis: “To ensure unbiased point estimates and accurate variance estimation, considering the complex sampling design of NHANES, we applied proper sampling weights and utilized a licensed version of SAS survey procedures, following the recommendations of the National Centre for Health Statistics and the Centres for Disease Control and Prevention.” I think using clustering variables to correctly estimate standard errors should be added as both sampling weights and clustering are need to correctly estimate point estimates and standard errors, respectively. The authors have pointed out the covariates that they included in their study and mentioned the following under statistical analysis: “The multiple regression model included age, sex, race, income, and education level as explanatory variables. The selection of these potential confounders was based on either current literature evidence or their association with insurance and dental care utilization variables observed in bivariate analysis. The significance level was set at p ≤ 0.05, ensuring a rigorous evaluation of the relationships within the study.” Determining how the confounding variables were selected is very crucial in order to estimate the causal effect of multiple pregnancies on chronic periodontitis. In this study, the authors rightly determined age, sex, race, income, and education level as confounding variables based on previous knowledge and literature. However, the following on insurance and dental visit was not clear: “their association with insurance and dental care utilization variables observed in bivariate analysis.” Furthermore, assessing associations or confounding variables based on p-values should be avoided (please check [1],[2]) As a point related to the one above and based on the criteria the authors went with for determining confounding variables, unfortunately, smoking and diabetes (well-known confounding variables) were left out of the multivariable logistic regression model. Therefore, residual confounding exists in the result. I suggest adding them to the model or at least discuss how the residual confounding of these would impact the odds ratio of number of pregnancies on periodontitis. Results The authors did not elaborate on any missing data. Authors should show the frequency and % of missing data for each variables. In addition, authors should describe how they dealt with any missing data in their analysis and discuss its implications on the results. The authors mentioned that they have included the following covariates: “age, gender, race/ethnicity, education, poverty/income ratio, marital status, occupation, smoking habits, alcohol consumption, dental insurance coverage, dental visit frequency, and body mass index (BMI)” Although marital, status and occupation were mentioned in table 4, they along with smoking habits were not mentioned in table 1. Smoking habits was not even mentioned in any table. Authors should add these. In table 5, patients wrote: “Patients with dental visits in the 1-2 year range had greater odds (OR 1.129, 95% CI 0.772-1.651) of having periodontitis, but this association was not statistically significant (p > 0.05) (see Table 5).” The odds ratios of the confounding variables are of no interest to the authors in the study as they are do not correctly estimate their causal effect. This phenomena is well-known as Table 2 fallacy (3). Kindly just report the odds ratios of main variable of interest (number of pregnancies) and remove the other from text or table. Please round the odds of pregnancy on periodontitis to 2 digits as 3 digits adds nothing and just complicates reading the results. I suggest removing displaying/discussing the results in text as significant or non-significant and instead focus on the point estimates as well as their precision (please check [1]and[2]) Discussion and conclusion The authors wrote in the limitations: “Additionally, being a retrospective cross-sectional study, our investigation relied on data from a study not specifically designed to address our hypothesis, potentially introducing clinical variations in the disease process.” The word retrospective should be removed as this was a cross-sectional study. Authors should further discuss the impact of no-temporality, pregnancy misclassification likelihood and effect, missing data, and leaving out important confounding variables.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7794",
         "2",
         "4",
         "0.0548054587688734",
         "0.4272",
         "0.8617962002754211",
         "24.88",
         "15.0",
         "13.69",
         "16.2",
         "16.1",
         "97",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "3.0",
         "11.0",
         "no",
         "neutral",
         "neutral",
         "Moderate",
         "2",
         "4.0",
         "3.0",
         "4.0",
         "80.0",
         "83"
        ],
        [
         "4",
         "Nancy Ajwa",
         "26 Dec 2024",
         "Approved",
         "362",
         "Do more pregnancies increase the risk of periodontal disease?",
         "Background Hormonal changes in pregnancy and their induced effect on periodontal health are well documented. The present study is aimed at the potential repercussions of multiple pregnancies on periodontal health.  Materials and methods Our study utilized data from key sections of the NHANES. All the pertaining and relevant data for the study is collected. Our exposure variable was the number of pregnancies, and the outcome variable was periodontal disease. The number of pregnancies is classified as one, two, three, four, or more. Age, gender, race/ethnicity, education, poverty/income ratio, marital status, and other variables. Multiple logistic regression models were employed to assess the impact of multiple pregnancies on periodontal disease.  Result The crude and multiple logistic regression analyses revealed that none of the variables were significantly associated with the prevalence of periodontitis. In univariate analysis, patients with one or two pregnancies had higher odds of experiencing periodontitis (OR 1.154, 95% CI 0.748-1.779), (OR 1.464, 95% CI 0.864-2.483) respectively. However, these associations did not reach statistical significance.  Conclusion Within the limitation of the study, there is no significant relationship between parity and the prevalence of periodontitis, the longitudinal study may be warranted to delve deeper into any potential associations.",
         "71",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The current structure provides a good foundation for the research paper. I have a few minor comments on the paper, which I am splitting in the headings so that authors can easily identify and improve the respective sections. Introduction: -Consider moving some of the detailed descriptions of the hormonal mechanism to later paragraphs for better flow. -Add a brief sentence early in the introduction highlighting why studying multiple pregnancies (versus single pregnancy) is particularly important -Consider mentioning any geographical or population-specific gaps in current knowledge that this study helps address Methods: -Clarify the definition of pregnancy exposure (whether it includes completed pregnancies only or all pregnancies) -Add information about how missing data was handled in the analysis Results: -Round the odds ratios to 2 decimal places instead of 3 for better readability -Include smoking status data in Table 1, as it's an important variable that was mentioned in the methods but not shown in the results Discussion: -Add a brief discussion of the limitations of using pregnancy as a categorical rather than continuous variable -Include a short paragraph acknowledging the potential impact of excluding edentulous participants on the study findings These modifications would improve the manuscript while maintaining its overall scientific merit and indexing. The core findings and conclusions remain sound, and these suggested changes are minor in nature.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7954",
         "1",
         "0",
         "0.1485978835978836",
         "0.1953",
         "0.7777637243270874",
         "15.44",
         "18.6",
         "20.7",
         "19.1",
         "20.7",
         "104",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "3",
         "4.0",
         "5.0",
         "5.0",
         "90.0",
         "92"
        ],
        [
         "5",
         "Marwa Emam",
         "18 Sep 2024",
         "Approved With Reservations",
         "644",
         "The effect of surface treatments on the bond strength of polyetheretherketone posts: a systematic review protocol",
         "Abstract* Background Polyetheretherketone (PEEK) is widely used in the biomedical field due to its outstanding biological and mechanical properties. Originally employed as a temporary abutment in implantology, recent research has expanded its indications for more definitive applications, such as frameworks and dental post and core. This shift requires a thorough assessment of PEEK’s adhesion and mechanical characteristics. However, PEEK’s inert properties and intricate chemistry create difficulties in surface treatment, resulting in reduced surface energy and inadequate adhesion. Inducing specific physical and chemical changes aims to overcome these challenges and enhance adhesion for PEEK. Despite its numerous clinical trials, standardized protocols remain lacking. This systematic review aims to assess the impact of surface treatments on the bonding performance of PEEK posts.  Methods A detailed search of the literature will be conducted across several databases including PubMed, Scopus and clinical trial registries. Additional databases such as Cochrane Central, EMBASE, Web of Science and EBSCO will also be included. The search strategy will target controlled randomized studies and non-randomized clinical trials evaluating the impact of surface treatments on PEEK post adhesion strength. The Newcastle-Ottawa Scale (NOS) will be used to assess bias in non-randomized studies, while the Cochrane Risk of Bias (ROB II) tool will be employed for evaluating randomized controlled trials. Data extraction will focus on study design, treatment methods, outcomes and results. This systematic review protocol will adhere to the guidelines for systematic reviews outlined in the Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA).  Discussion The discussion will explore the implications of findings on clinical practice, highlighting the importance of enhancing PEEK’s bioactivity and surface energy to improve bonding efficacy in dental procedures. Moreover, it will suggest areas for future research to advance dental materials science, aiming to optimize the utilization of PEEK in dental applications  Systematic review registration PROSPERO: CRD42024529783 (Registered on 08/04/2024).",
         "27",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Review report for the submitted manuscript “The effect of surface treatments on the bond strength of polyetheretherketone posts: a systematic review protocol” I would like to thank the authors for submitting their protocol for review. The use of PEEK posts in dental applications is a developing subject, so a systematic assessment of surface treatment procedures is extremely important. PEEK's biocompatibility and mechanical strength make it excellent for dental posts, but the inert surface makes bonding challenging. This review could fill a crucial gap in clinical practice. Overall, the language is clear, but minor editing of English language might be required in the final submitted review. Author might want to explore options for refining their text to improve its flow and readability. This can make their article more engaging and clear. 1. Title: -  Approved as is. 2. Abstract: Kindly give a hint on the different surface treatment techniques of PEEK for the reader.  3. Introduction: -I think the introduction is a bit shallow. I would prefer the introduction to begin with PEEK material (history, chemical composition and properties) as it is the main objective of the study. Then going through the different applications quickly and concentrating on the endodontically treated teeth and post indications and PEEK post (ready & custom made) as one of the options available for clinicians. Finally, stating PEEK adhesion properties as a weakness that different surface treatments aim to improve. -Kindly connect short paragraphs into paragraphs of 6-7 lines paragraphs. -Kindly add references to the second & third paragraph. - The authors could elaborate on the therapeutic relevance of PEEK's bond strength as compared to conventional materials like metal, zirconia or fiber posts. 4. Methods: -The protocol is well-structured and follows known principles for systematic reviews (PRISMA). The use of numerous databases (e.g., PubMed, Scopus, Cochrane Central) will ensure a thorough literature review. The intended use of risk-of-bias tools (ROB II and NOS) and data extraction procedures demonstrates a commitment to evidence of excellent quality synthesis. Intervention types: There is no mention of the surface treatments of PEEK aimed for exploration. Only 2 examples were mentioned so kindly give more details regarding treatments to be studied. Outcomes: More precise definitions would be useful in the outcomes section. While bond strength and retention are indicated, it is unclear how they would be tested. Providing additional details on the anticipated outcomes and their clinical significance could enhance the protocol. Evaluation of methodological quality and risk of bias: -The protocol’s description of bias assessment tools (ROB II and NOS) is good, but how will studies with unclear risks of bias be handled in the analysis? Also kindly give more details regarding the “standardized tools” you have mentioned as means of evaluation. Meta analysis: While the authors highlight the possibility of meta-analysis, it would be interesting to describe how they intend to deal with possible heterogeneity among studies (e.g., differences in surface treatments, study designs). 5. Conclusions: Although this protocol presents a well-designed systematic review that is expected to yield useful information about the surface treatments of PEEK posts in dental applications, it would be strengthened by adding the details addressed in the comments above for further enhancement.  Is the rationale for, and objectives of, the study clearly described? Yes  Is the study design appropriate for the research question? Yes  Are sufficient details of the methods provided to allow replication by others? Yes  Are the datasets clearly presented in a useable and accessible format? Yes",
         "0.8128",
         "7",
         "0",
         "0.209901738473167",
         "0.7839",
         "0.9337135553359984",
         "35.98",
         "12.8",
         "13.7",
         "14.5",
         "14.5",
         "96",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "3.0",
         "1.0",
         "True",
         "neutral",
         "polite",
         "Moderate",
         "2",
         "4.0",
         "3.0",
         "3.0",
         "83.0",
         "83"
        ],
        [
         "6",
         "Natalia Szejko",
         "28 Oct 2024",
         "Approved With Reservations",
         "468",
         "The use of medicinal marijuana for treating Cerebral Palsy: a literature review",
         "Background Recent studies have established that Medicinal Marijuana (MM) is beneficial in the treatment of spasms, sleep, and pain in adult patients with varying medical diagnoses and symptoms. However, MM has rarely been used for the treatment of Cerebral Palsy (CP) complications in adults. The aim of this systematic literature review was to explore MM interventions globally, with a focus on identifying the best practice with MM for the treatment of complications of CP.  Methods A systematic literature search was performed using keywords and synonyms related to MM treatment and CP complications. Inclusions and exclusions were scoped to scholarly peer reviewed academic literature published 2019 to 2021 located in the Deakin Library collection. A screening process confirmed criteria adherence and identified additional papers in referencing. The papers were appraised and evaluated to ensure selections do not have perceived or actual bias.  Results From 409 publications, 27 papers were selected for review because they investigated the benefits of MM treatment for patients with sleep, pain, and spasm complications. There was no literature found on the use of MM for adults with CP.  Discussion Recent research has demonstrated that with an informed understanding of MM treatment adult patients with varying medical diagnoses and symptoms can use MM to manage sleep disruption and improve relaxation. Therefore, there are potential benefits for the use of MM in treating spasticity, pain, sleep, quality of life, and social and emotional wellbeing in adult patients with CP. No funding was sort or provided for this review and the results are specific to adults with CP, so they are not to be generalized to other populations.",
         "97",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Thank you for providing me the opportunity to review this interesting paper that concerns an interesting topic of CP and use of cannabis based medicine. Overall the paper is interesting and relevant to the field. However, I have some small suggestions that could be considered before the paper will be indexed. It is not clear to me why there is a separate paragraph entitled introduction, which is followed by the one entitled background. In my understanding they are essentially the same? Please provide more information, maybe consider merging both? I also think that there should be more emphasis on the treatment of spasticity with CBM in the introduction. Pain is important of course, but this is crucial in CP also. Also, a brief mention of previous studies about CBM and CP should be discussed at least mentioning the areas where it was used, are these basic science studies or clinical? Are there any RCTs or meta analyses? As the authors clearly describe in the methodology, this is a systematic review, which should be stated in the title. Please add. Although I really like the Tables and Figures that the authors prepared, I suggest to put also a descriptive part in the results – are the studies included RCTs, case reports, retrospective studies? What are the main results? If CBM is effective to treat pain, which CBM specifically? At which dose? Any side effects? The same goes for other symptoms, please describe in more detail. This is now part of the discussion, but I would suggest to move it to results section instead. I would also not say that one treats quality of life, but would rather name it as improvement of quality of life. Could the authors also clarify the abbreviation SEWB? Could the authors also clarify why only studies in adults were included? Are there no such studies in children?  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes  If this is a Living Systematic Review, is the ‘living’ method appropriate and is the search schedule clearly defined and justified? (‘Living Systematic Review’ or a variation of this term should be included in the title.) Yes",
         "0.7683",
         "2",
         "0",
         "0.1559523809523809",
         "0.8801",
         "0.8741981983184814",
         "46.67",
         "10.7",
         "11.92",
         "12.9",
         "10.9",
         "104",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "85.0",
         "85"
        ],
        [
         "7",
         "Mê-Linh Lê",
         "14 Nov 2024",
         "Not Approved",
         "845",
         "The use of medicinal marijuana for treating Cerebral Palsy: a literature review",
         "Background Recent studies have established that Medicinal Marijuana (MM) is beneficial in the treatment of spasms, sleep, and pain in adult patients with varying medical diagnoses and symptoms. However, MM has rarely been used for the treatment of Cerebral Palsy (CP) complications in adults. The aim of this systematic literature review was to explore MM interventions globally, with a focus on identifying the best practice with MM for the treatment of complications of CP.  Methods A systematic literature search was performed using keywords and synonyms related to MM treatment and CP complications. Inclusions and exclusions were scoped to scholarly peer reviewed academic literature published 2019 to 2021 located in the Deakin Library collection. A screening process confirmed criteria adherence and identified additional papers in referencing. The papers were appraised and evaluated to ensure selections do not have perceived or actual bias.  Results From 409 publications, 27 papers were selected for review because they investigated the benefits of MM treatment for patients with sleep, pain, and spasm complications. There was no literature found on the use of MM for adults with CP.  Discussion Recent research has demonstrated that with an informed understanding of MM treatment adult patients with varying medical diagnoses and symptoms can use MM to manage sleep disruption and improve relaxation. Therefore, there are potential benefits for the use of MM in treating spasticity, pain, sleep, quality of life, and social and emotional wellbeing in adult patients with CP. No funding was sort or provided for this review and the results are specific to adults with CP, so they are not to be generalized to other populations.",
         "114",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  As an information professional, I have limited my comments below to those relating to the methodology and citations of the paper.  Methods While the title of this article says it is a literature review, throughout the text the terms used is systematic review (SR), and several practices (e.g., use of a PRISMA flow chart, PRISMA checklist) suggest the authors attempted some aspects of a SR. However, the methods as outlined here are not those of a systematic review and should not be written as such.  In brief, some of the issues are: 1. An extremely limited time frame of 2 years and the authors included only material available in their specific library collection. This is not how SRs are completed as they must locate ALL evidence on a specific topic. 2. Lack of use of any subject terms specific to individual databases, such as MESH or CINAHL search terms 3. Lack of any reproducible search strategy for any database (although really all databases search strategies should be provided). Listing only the keywords is not sufficient. A quick search in MEDLINE using more advanced search terms quickly found several papers that would have been relevant to this article. 4. The authors write “The first and second named authors of this paper both individually completed the entire search and screening process concluding with the same outcome.”. This is not how systematic reviews are completed. There is one search done, and then at least two authors need to conduct screening individually, and then come together at the end to resolve conflicts. 5. The inclusion or exclusion criteria listed are not appropriate in that they do not focus on the studies themselves. They are just focused on study type, but not what the study is about. Also what is listed in the text for inclusion (e.g., must have a keyword) is not what is talked about in Table 3. 6. The screening process was not conducted according to SR suggested processes. The authors indicate that they used the presence of a keyword in specific lines or parts of a paper to decide whether to include or not include. Again, this doesn’t align with their stated inclusion criteria and is not correct SR screening methodology. 7. The authors note that their study is unique in that is focused on an adult population. This is not strictly true, but the authors still could have included content or summaries now what the research on medical marijuana on children with cerebral palsy suggests 8. While I did not conduct an examination of every reference cited, there were several written in the text that are not accurate. For example, the authors write “Even though cannabis is the most commonly used illicit drug in the world today (Zhand & Milin, 2018), […]. However, that article does not actually report that finding. Zhang & Milin instead link out to a different study. I would also argue that both of these articles are outdated (2018 and 2015 respectively), especially in light of recent legislative changes to cannabis in places like the US, Canada, and Australia. The authors should look for more updated references for their content. 9. There are numerical errors in the PRISMA flow chart. I also note that there are grammatical and spelling errors throughout the text. — Ultimately, I think this article needs to be more clearly reclassified as a literature review. All instances of the word ‘systematic’ should be removed so as not to give casual readers a false sense of what they are looking at, and so as not to confuse indexing procedures. I would also urge the authors to both broaden their years (2-3 years is not even sufficient for a literature review) and where they are searching. The fact that they found no literature on the topic strongly suggests that they need to adjust their search parameters. I applaud the authors for attempting to use a more transparent and comprehensive process for their search but as it was conducted it is not sufficient or exhaustive enough for either a systematic review or a comprehensive literature review.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? No  Is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are the conclusions drawn adequately supported by the results presented in the review? No  If this is a Living Systematic Review, is the ‘living’ method appropriate and is the search schedule clearly defined and justified? (‘Living Systematic Review’ or a variation of this term should be included in the title.) Not applicable",
         "0.7885",
         "7",
         "0",
         "0.101311249137336",
         "0.0977",
         "0.7260770797729492",
         "44.03",
         "11.8",
         "12.43",
         "13.6",
         "11.8",
         "102",
         "0",
         "0",
         "0",
         "0",
         "2.0",
         "1.0",
         "11.0",
         "no",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "3.0",
         "2.0",
         "4.0",
         "20.0",
         "50"
        ],
        [
         "8",
         "Godwin Justus Wilson",
         "25 Nov 2024",
         "Approved",
         "223",
         "“Unmasking the Uncommon”: A case series of multi-drug resistant Elizabethkingia meningoseptica causing late-onset sepsis and meningitis in preterm neonates",
         "Elizabethkingia meningoseptica is an uncommon nosocomial pathogen that causes meningitis, pneumonia, and sepsis in neonates and in immunocompromised individuals. It exhibits resistance to many commonly employed first-line antibiotics used to treat gram-negative pathogens. Herein, we present three cases of late-onset sepsis with multi-drug resistant (MDR) Elizabethkingia meningoseptica in high-risk neonates. Case 1 was a one-day-old preterm low-birth-weight infant who presented with respiratory distress syndrome and septic shock. The patient was intubated and administered empirical broad-spectrum antibiotics and antifungal agents. Blood culture grew Candida krusei, hence Amphotericin B was initiated. Repeat blood culture on day 27 showed gram-negative bacilli, identified as Elizabethkingia meningoseptica by MALDI-TOF . Antibiotic susceptibility testing (AST) revealed resistance to Piperacillin/Tazobactam, but sensitivity to Vancomycin, Levofloxacin, and Minocycline. IV Vancomycin was administered, which resulted in clinical improvement and negative blood culture results. Case 2 was an eleven-day-old preterm, low-birth-weight baby who presented with fever. Initial investigations revealed normal complete blood counts (CBC) parameters and elevated CRP levels. Blood and CSF cultures isolated Elizabethkingia meningoseptica with a similar AST pattern. Intravenous Ciprofloxacin was initiated with clinical improvement and negative follow-up blood cultures. Case 3 was a one-day-old preterm baby, appropriate-to-gestational age, presenting with respiratory distress syndrome. The infant was intubated and started on inotropic support and intravenous antibiotics. Blood cultures on day 4 showed Elizabethkingia meningoseptica and Vancomycin was started. Follow-up cultures on days 6 and 14 grew Acinetobacter baumannii. A combination of Levofloxacin and Colistin was added, and blood cultures were negative after seven days, with clinical improvement. Elizabethkingia meningoseptica is a significant cause of hospital-acquired infections, especially in Neonatal Intensive Care Unit (NICU), leading to outbreaks. Clinicians must have a high degree of suspicion of E. meningoseptica for gram-negative bacilli causing sepsis and meningitis in high-risk patients. Recent technological advances have enabled accurate speciation to guide therapy and reduce morbidity and mortality rates.",
         "10",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This article provides an insight into Elizabethkingia meningoseptica infections, particularly in neonates, emphasizing their rare occurrence but severe implications, especially in immunocompromised or premature infants. The case studies presented offer valuable real-world examples of late-onset sepsis and meningitis caused by this pathogen, highlighting its multi-drug-resistant (MDR) nature and the challenges clinicians face due to the lack of standardized treatment guidelines. Overall, the article provides valuable clinical insights and emphasizes the need for prompt detection, tailored treatment, and robust infection control to improve outcomes for neonates affected by this challenging pathogen.  Is the background of the cases’ history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Yes  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Yes  Is the conclusion balanced and justified on the basis of the findings? Yes",
         "0.8317",
         "1",
         "0",
         "0.0941666666666666",
         "0.0999",
         "0.9090203046798706",
         "9.32",
         "18.9",
         "21.56",
         "19.7",
         "21.9",
         "90",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "5.0",
         "4.0",
         "4.0",
         "92.0",
         "92"
        ],
        [
         "9",
         "Mark Fahmy",
         "22 Jan 2025",
         "Approved With Reservations",
         "749",
         "“Unmasking the Uncommon”: A case series of multi-drug resistant Elizabethkingia meningoseptica causing late-onset sepsis and meningitis in preterm neonates",
         "Elizabethkingia meningoseptica is an uncommon nosocomial pathogen that causes meningitis, pneumonia, and sepsis in neonates and in immunocompromised individuals. It exhibits resistance to many commonly employed first-line antibiotics used to treat gram-negative pathogens. Herein, we present three cases of late-onset sepsis with multi-drug resistant (MDR) Elizabethkingia meningoseptica in high-risk neonates. Case 1 was a one-day-old preterm low-birth-weight infant who presented with respiratory distress syndrome and septic shock. The patient was intubated and administered empirical broad-spectrum antibiotics and antifungal agents. Blood culture grew Candida krusei, hence Amphotericin B was initiated. Repeat blood culture on day 27 showed gram-negative bacilli, identified as Elizabethkingia meningoseptica by MALDI-TOF . Antibiotic susceptibility testing (AST) revealed resistance to Piperacillin/Tazobactam, but sensitivity to Vancomycin, Levofloxacin, and Minocycline. IV Vancomycin was administered, which resulted in clinical improvement and negative blood culture results. Case 2 was an eleven-day-old preterm, low-birth-weight baby who presented with fever. Initial investigations revealed normal complete blood counts (CBC) parameters and elevated CRP levels. Blood and CSF cultures isolated Elizabethkingia meningoseptica with a similar AST pattern. Intravenous Ciprofloxacin was initiated with clinical improvement and negative follow-up blood cultures. Case 3 was a one-day-old preterm baby, appropriate-to-gestational age, presenting with respiratory distress syndrome. The infant was intubated and started on inotropic support and intravenous antibiotics. Blood cultures on day 4 showed Elizabethkingia meningoseptica and Vancomycin was started. Follow-up cultures on days 6 and 14 grew Acinetobacter baumannii. A combination of Levofloxacin and Colistin was added, and blood cultures were negative after seven days, with clinical improvement. Elizabethkingia meningoseptica is a significant cause of hospital-acquired infections, especially in Neonatal Intensive Care Unit (NICU), leading to outbreaks. Clinicians must have a high degree of suspicion of E. meningoseptica for gram-negative bacilli causing sepsis and meningitis in high-risk patients. Recent technological advances have enabled accurate speciation to guide therapy and reduce morbidity and mortality rates.",
         "68",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors have written an interesting summary of three cases of Elizabethkingia meningioseptica BSI in pre-term infants.  Major comments: In the discussion section \"wide range of antimicrobials including β-lactams...\" - would argue that some strains retain susceptibility to piperacillin - tazobactam (accepting none in this series were susceptible, which itself is interesting and worth discussing/evaluating in the context of existing literature). However, other published literature has reported susceptibility and clinical success with piperacillin-tazobactam  (e.g. Burnard D et al. 2020 (Ref 1) Comba IY, et al. 2022 (Ref 2) In the discussion section \" Uniquely, it is susceptible to antibiotics used to treat gram-positive infections such as Vancomycin, Clindamycin and Rifampicin...\" I think that the role of vancomycin and rifampicin for treatment of Elizabethkingia BSI is more uncertain than this discussion suggests, and while it might be reasonable to consider use in severe infections/as part of a multi-drug regimen in complex infections, there is a dearth of evidence suggesting the strong conclusion made by the authors \" a combination of vancomycin and ciprofloxacin, linezolid, or rifampicin has demonstrated high cure rates in the treatment of E. meningoseptica meningitis and bacteremia\" Further discussion about the ambiguities and gaps in the literature regarding these therapies for Elizabethkingia would allow for more nuanced recommendations.  In particular, it can be noted that 1) In adult patients, there have been documented rates of failure with vancomycin therapy as details here: Jean SS, et al., 2017 (Ref 3) 2) There is a high prevalence of VanW gene in Elizabethkingia isolates in Australia (and this has been demonstrated elsewhere as well). This gene has also been found to confer a VanB type phenotype in other organisms.  Stewart AG, et al., 2023 (Ref 4) 3) There is overall limited data for the use of rifampicin in gram negative infections.  Drapeau CM, et al., 2010 (Ref 5) Minor comments: In case 1 (and subsequent cases) susceptibility testing is described as use of VITEK-2 + E-test for susceptibility testing. \"antibiotic susceptibility testing (AST) performed using VITEK 2 Compact (BiomerieuxTM). Vancomycin susceptibility was tested by using an E-strip.\" There could be better description of the interpretive criteria used to determine susceptibility. In particular, what breakpoints were used- I assume CLSI non-enterobacterales breakpoints for more traditional agents (e.g. piperacillin, levofloxacin) but there would not be calibrated breakpoints for vancomycin- reporting what the MIC result would be more accurate. Minocycline sensitivity can be inferred from doxycycline or tetracycline susceptibility- was this done or was a minocycline disc/etest performed?  I think the comments about control of environmental sources is very interesting. \" It is also important to periodically repair, clean, super chlorinate, and replace sink taps\" and \"We hypothesized that our cases were nosocomial infections; however, environmental screening failed to identify the source of infection.\" I agree that a nosocomial infection is likely if all three cases were acquired around the same time - it may be worth mentioning that more clearly in the case histories to emphasize this point. However some additional information may be interesting and make the discussion more applicable to a wider audience- 1) Was sequencing considered or done on the isolates from the patients to see if there was close relationship and potentially establish common epidemiological link? 2) How was environmental sampling done- e.g. what was sampled, what methods were used to try and isolate Elizabethkingia sp. There are a variety of published methods for environmental sampling/isolation, none of them specific for Elizabethkingia > our laboratory uses these guidelines for sampling and isolation (https://www.health.vic.gov.au/infectious-diseases/victorian-guideline-on-environmental-sampling-for-cpe) Otherwise the authors have prepared an interesting summary of three cases of this rare but important pathogen, including a good description of a variety of risk factors and clinical outcomes.  Is the background of the cases’ history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Partly  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Partly  Is the conclusion balanced and justified on the basis of the findings? Partly",
         "0.8038",
         "4",
         "1",
         "0.1650421245421245",
         "0.0857",
         "0.8993908166885376",
         "24.58",
         "15.1",
         "14.96",
         "16.0",
         "17.1",
         "94",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "10.0",
         "True",
         "neutral",
         "polite",
         "Minimal",
         "3",
         "4.0",
         "4.0",
         "3.0",
         "68.0",
         "68"
        ],
        [
         "10",
         "Lorraine Du Toit-Prinsloo",
         "22 Feb 2024",
         "Approved With Reservations",
         "368",
         "Epidemiological profiles and causes of sudden deaths of various ages in Ethiopia: an autopsy-based study",
         "Background Sudden death is an important global public health issue. An autopsy is an important source of epidemiological data, as the considerable causes of sudden death remain hermetic until postmortem examination. This study is devoted to evaluating the sociodemographic, behavioral, clinical and pathological characteristics of sudden deaths of various ages in Ethiopia.  Methods This is an observational, prospective, descriptive study that included all sudden deaths observed over 1 year at St. Paul’s Hospital and Millennium Medical College, Addis Ababa, Ethiopia.  Results Sudden death (n = 568) accounted for 11.5% of all autopsied cases. There were 482 males and 86 females (M:F ratio of 5.6:1) and a mean age of 44.81±17.349. The peak age group was the fourth and fifth decades, accounting for 43.9% of the cases. Chronic substance abuse and a history of prior illness were declared in 40.1% and 38% of victims of sudden death, respectively. Cardiovascular (36.1%), respiratory (32.6%), and gastrointestinal system (19.5%) pathologies were the most common causes. The leading underlying causes of sudden death were ischemic heart disease and pneumonia. Most (86.6%) sudden deaths occurred outside of a hospital setting.  Conclusions Most of the causes of sudden death in Ethiopia can be prevented and treated. The majority of sudden deaths are silent without preexisting symptoms. Therefore, it is vital to develop public health measures that will help educate the community about the importance of recognizing the manifestation of various clinical conditions and the need to seek immediate clinical help. Furthermore, efforts should be made to make healthcare facilities accessible and affordable with adequate diagnostic and management capacity. Documentation of autopsy-based data could provide important epidemiological information to guide medical services, prevention efforts, and control measures.",
         "107",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  I am of the opinion that this article provides a good overview of the sudden deaths admitted to a Forensic Medicine Department.  The following comments are to be addressed by the authors: Replace the word victims with deceased / decedents throughout the manuscript  Methods: - \" Autopsied specimens (whole organs or organ pieces) were fixed in 10% formalin for histopathological examination. Multiple sections with thicknesses of 4-5 mm were taken. The tissues were processed, subjected to paraffin sectioning at a thickness of 4 micrometers and then stained using hematoxylin and eosin staining.\" - replace this with ancillary investigations included whole organ retention, histological examination of tissue slides (were there any additional investigations such as microbiology or toxicology done?) Circumstances of death - The statement referring to 36 victims died instantaneously should be further explained in the context - there are only a few causes of death in the forensic setting in my opinion where we can indicate that the death occurred instantaneously. Some of the references pertaining to similar studies reporting on sudden death are more than 10 years old and it would be important to obtain more recent articles if available.  It would also be interesting to expand on the nature of these investigations - a full post-mortem examination was conducted, but expanding on the types of ancillary investigations will add value.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7954",
         "1",
         "0",
         "0.1843749999999999",
         "0.1631",
         "0.7953115105628967",
         "21.63",
         "16.2",
         "17.51",
         "17.2",
         "17.5",
         "102",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "8.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "76.0",
         "76"
        ],
        [
         "11",
         "Martina Modena",
         "10 Jun 2024",
         "Approved With Reservations",
         "516",
         "Epidemiological profiles and causes of sudden deaths of various ages in Ethiopia: an autopsy-based study",
         "Background Sudden death is an important global public health issue. An autopsy is an important source of epidemiological data, as the considerable causes of sudden death remain hermetic until postmortem examination. This study is devoted to evaluating the sociodemographic, behavioral, clinical and pathological characteristics of sudden deaths of various ages in Ethiopia.  Methods This is an observational, prospective, descriptive study that included all sudden deaths observed over 1 year at St. Paul’s Hospital and Millennium Medical College, Addis Ababa, Ethiopia.  Results Sudden death (n = 568) accounted for 11.5% of all autopsied cases. There were 482 males and 86 females (M:F ratio of 5.6:1) and a mean age of 44.81±17.349. The peak age group was the fourth and fifth decades, accounting for 43.9% of the cases. Chronic substance abuse and a history of prior illness were declared in 40.1% and 38% of victims of sudden death, respectively. Cardiovascular (36.1%), respiratory (32.6%), and gastrointestinal system (19.5%) pathologies were the most common causes. The leading underlying causes of sudden death were ischemic heart disease and pneumonia. Most (86.6%) sudden deaths occurred outside of a hospital setting.  Conclusions Most of the causes of sudden death in Ethiopia can be prevented and treated. The majority of sudden deaths are silent without preexisting symptoms. Therefore, it is vital to develop public health measures that will help educate the community about the importance of recognizing the manifestation of various clinical conditions and the need to seek immediate clinical help. Furthermore, efforts should be made to make healthcare facilities accessible and affordable with adequate diagnostic and management capacity. Documentation of autopsy-based data could provide important epidemiological information to guide medical services, prevention efforts, and control measures.",
         "216",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This article addresses a major health problem such as sudden death, which has a dramatic impact on families and society. The authors provide an interesting descriptive study on sudden death in Ethiopia. The authors should address the following comments: Methods: -  “Full postmortem examinations were carried out in each instance using the Letulle evisceration procedure […] Organs were dissected, examined and checked for signs of gross pathological changes and violence. Autopsied specimens (whole organs or organ pieces) were fixed in 10% formalin for histopathological examination. Multiple sections with thicknesses of 4-5 mm were taken. The tissues were processed, subjected to paraffin sectioning at a thickness of 4 micrometers and then stained using hematoxylin and eosin staining.”  The authors can provide more details on full postmortem examinations carried out? e.g. body weight and height have been collected? Concerning the histological analysis: was only the hematoxylin-eosin staining performed? the toxicology analysis was performed? The authors could include a small paragraph on heart analysis: e.g. pericardium, heart cavities, valves and coronary arteries have been checked? -  Considering the growing importance of molecular autopsy, have any EDTA blood or frozen tissue samples been kept for possible future analysis? Results: Causes of sudden unexpected deaths -  “Cardiovascular system diseases (CVS) were the leading causes of SD, accounting for 36.1% of all SD cases. This was followed by respiratory and gastrointestinal system pathologies, accounting for 32.6% and 19.5%, respectively. Central nervous system (CNS) and genitourinary system (GUS) pathologies were the least prevalent causes of death, accounting for 10.6% and 1.2%, respectively.” All described cases of sudden death are explained after autopsy by reaching a certain cause of death. This is surprising considering that in literature the cause of death remains in doubt even after an exhaustive autopsy in several sudden deaths. So, there is usually a proportion of cases remaining \"unexplained\". I suggest to authors to review the literature and guidelines (some references are more than 10 years old) and to review the results to be sure that all cases have been explained by autopsy. Do all cases have a definite diagnosis at autopsy? Particularly among cases of cardiac death, no probable arrhythmic death was found? Did all cases of sudden cardiovascular death have structural cardiac changes?  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7761",
         "2",
         "0",
         "0.1155284043441938",
         "0.0904",
         "0.8414130806922913",
         "30.36",
         "12.9",
         "13.7",
         "14.2",
         "13.6",
         "103",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "4.0",
         "80.0",
         "84"
        ],
        [
         "12",
         "Joseph Westaby",
         "14 Jun 2024",
         "Approved With Reservations",
         "735",
         "Epidemiological profiles and causes of sudden deaths of various ages in Ethiopia: an autopsy-based study",
         "Background Sudden death is an important global public health issue. An autopsy is an important source of epidemiological data, as the considerable causes of sudden death remain hermetic until postmortem examination. This study is devoted to evaluating the sociodemographic, behavioral, clinical and pathological characteristics of sudden deaths of various ages in Ethiopia.  Methods This is an observational, prospective, descriptive study that included all sudden deaths observed over 1 year at St. Paul’s Hospital and Millennium Medical College, Addis Ababa, Ethiopia.  Results Sudden death (n = 568) accounted for 11.5% of all autopsied cases. There were 482 males and 86 females (M:F ratio of 5.6:1) and a mean age of 44.81±17.349. The peak age group was the fourth and fifth decades, accounting for 43.9% of the cases. Chronic substance abuse and a history of prior illness were declared in 40.1% and 38% of victims of sudden death, respectively. Cardiovascular (36.1%), respiratory (32.6%), and gastrointestinal system (19.5%) pathologies were the most common causes. The leading underlying causes of sudden death were ischemic heart disease and pneumonia. Most (86.6%) sudden deaths occurred outside of a hospital setting.  Conclusions Most of the causes of sudden death in Ethiopia can be prevented and treated. The majority of sudden deaths are silent without preexisting symptoms. Therefore, it is vital to develop public health measures that will help educate the community about the importance of recognizing the manifestation of various clinical conditions and the need to seek immediate clinical help. Furthermore, efforts should be made to make healthcare facilities accessible and affordable with adequate diagnostic and management capacity. Documentation of autopsy-based data could provide important epidemiological information to guide medical services, prevention efforts, and control measures.",
         "220",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The article by Lema et al, is an observational study characterising all sudden deaths observed at a single forensic centre in Ethiopia. They report sudden death was 11.5% of all cases autopsied with 5.6 times as many males than females and a mean age of 45. Cardiovascular causes were most common with ischaemic heart disease as the leading cause. They highlight the importance of epidemiological data derived from autopsy studies to inform provision of medical services. This is a study that adds to the literature on sudden death showing its causes from Ethiopia. There are a number of improvements that I recommend that the authors make and I would be happy to re-review the paper following their emendations. Methods Individuals who died but were not confined to their homes, health facilities, or other related institutions due to illness for more than 24 hours before death were not considered unexpected deaths and were not included. Do the authors mean not? Results Figure 1: It would be best not to display the last three bars labelled as total as it does not allow you to appreciate the differences between the decades of age There was a statistically significant difference between the residence of the victims and sex (p<0.001). It is not made clear which sex lived more commonly where. Did males more frequently live in the city or the country? There was a statistically significant relationship between substance abuse and sex (p<0.001) and residence (p=0.004). A different distribution was observed for chronic alcohol use and sex (p<0.001). It is not made clear what these relationships are? Was it more common in males and in the city? Was alcohol more common in males or females? There was a statistically significant relationship between the presence of a prior chronic illness and sex (p=0.022). Were males or females more likely to have prior chronic illness? Table 3: It would be useful to put percentages for each sex for each cause so the differences between males and females are readily appreciable. There was a statistically significant difference between the CVS causes and sex (p=0.019). Was it more common males? Discussion The findings revealed a mean age of 44.8117.349 years. Giving the mean age as a whole number would be more appropriate Of 224 sudden death cases, men (n = 482/586) were predominant over women (n = 86/586), with a ratio of 5.6:1. This finding is consistent with many similar studies.1,3,4,11,14,15 Only two of these studies have a ratio of 5:1, most of these have ratios of 2:1 male:female which is more usual in the literature. Could the authors please speculate as to why they have such a high male to female ratio. Are females autopsied less than males? What percentage of the 4,942 medicolegal autopsies were female? The occurrence of SD in males outnumbers females in all systems except GUS. Our findings coincided with those of the studies conducted in Tukey.4,15 Turkey is spelt wrong. They may wish to use its new name “Türkiye”. Reference four is from Libya not Turkey. Our findings coincided with the results of the United Kingdom.3,10,16 Refences are for two studies from Nigeria and one from Spain. None are from the UK. They should include references from the UK. Cardiomyopathy was the second most common COD in the cardiovascular system, accounting for 5.3% of all sudden deaths. This agrees with the result achieved in Libya.4 It would be important to say that the cardiomyopathies may be inherited and therefore it is important to screen surviving blood relatives for these conditions. (Reference-1)  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? No  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.756",
         "1",
         "0",
         "0.1417936183666521",
         "0.3237",
         "0.8760992288589478",
         "48.4",
         "10.1",
         "10.89",
         "12.2",
         "10.3",
         "98",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "8.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "5.0",
         "85.0",
         "85.0"
        ],
        [
         "13",
         "Baranidharan Subburayan",
         "26 Aug 2024",
         "Approved With Reservations",
         "694",
         "The dynamics of financial performance and market performance in the context of Indian banking industry",
         "Background This study aims to gain insight into the effect of banks’ financial performance on their market performance. We conceptualized the research subject on the assumption that the financial performance of an organization is the most important criterion for triggering movement in its stock price. We explored various models and parameters to evaluate financial performance of banks and found CAMELS being one of the most comprehensive and appropriate model. We considered share price growth of banks to measure their stock market performance  Methods We collected financial and stock market data pertaining to 32 listed Indian banks for the period 2018 to 2022. The study has employed multiple linear regression analysis of panel data for evaluating the relationship between independent and dependent variables. We adopted panel regression for data analysis and used the Prais- Winsten regression with panel corrected standard errors, as the data suffers from contemporaneous cross-sectional correlation.  Results The results show that net non-performing assets, net interest margins, and return on capital have a significant negative impact on share price growth. The capital adequacy ratio and the current and savings account deposit ratios have a positive insignificant impact. The liquid asset-to-total asset ratio has a negative, insignificant impact. The coefficient of determination indicates that the share price growth of banks is more dependent on other factors which are not included in the regression analysis of this study.  Conclusion This study helps investors and bankers understand the limited impact of financial parameters on banks’stock prices and to look for other parameters which explain the stock price movement better.",
         "69",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Summary of the Article  - The dynamics of financial performance and market performance in the context of Indian banking industry The article examines the intricate relationship between financial performance and market performance in the Indian banking industry. By analyzing various financial metrics such as profitability, liquidity, and capital adequacy, alongside market indicators like stock prices and market capitalization, the authors aim to understand how these factors interact and influence each other. The findings suggest that financial performance significantly impacts market performance, with implications for both investors and banking institutions. Strengths of the Article Comprehensive Coverage  The article covers a wide range of financial metrics, providing a holistic view of the banking industry’s financial health and its impact on market performance. This comprehensive approach adds depth to the analysis. Novelty and Relevance  The study addresses a relevant and timely issue in the Indian banking sector, which is crucial given the ongoing changes and challenges in the industry. The focus on the dynamics between financial and market performance adds a fresh perspective to the existing literature. Methodological Rigor  The methodology is sound, with clear articulation of the data collection process, analytical techniques, and statistical methods used. The use of appropriate models to analyze the relationship between financial and market performance enhances the study’s credibility. Weaknesses of the Article Literature Review One of the significant weaknesses of the article is the literature review, which relies on research up to 2021. While the literature review is thorough, it lacks the inclusion of more recent studies that could provide updated insights and strengthen the foundation of the research. The use of present tense in some parts of the literature review is inconsistent with academic writing norms, where past tense is typically used to discuss previous research. This inconsistency may detract from the article’s professionalism and clarity. Implications for Practice and Research  The article would benefit from a more explicit discussion of the implications of the findings for both practitioners in the banking industry and future researchers. Adding this section before the conclusion would help to contextualize the findings and provide actionable insights.  Constructive Suggestions for Improvement Update the Literature Review The authors should consider including more recent studies, particularly those published after 2021. This would make the research more relevant and ensure that it reflects the latest trends and developments in the field. Consistency in Tense Usage Revising the literature review to ensure consistent use of past tense when referring to previous studies will improve the article’s readability and adherence to academic standards. Implications Section Introducing a section that discusses the managerial and research implications of the findings would greatly enhance the article. This would provide practical insights for industry professionals and highlight areas where further research is needed. The article makes a valuable contribution to the understanding of how financial performance influences market performance in the Indian banking industry. The comprehensive analysis and novel focus on this dynamic relationship are commendable. However, the inclusion of more recent literature, consistent tense usage, and a discussion of the practical and research implications would significantly strengthen the paper. The decision to approve the article with reservations is appropriate, given the need for these improvements. The suggestions provided here are intended to help the authors refine their work and ensure that it meets the highest academic standards.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7705",
         "1",
         "0",
         "0.1222602739726027",
         "0.1041",
         "0.9378840923309326",
         "15.61",
         "16.5",
         "15.66",
         "17.7",
         "17.5",
         "104",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "3.0",
         "60.0",
         "62"
        ],
        [
         "14",
         "Rizky Yudaruddin",
         "18 Nov 2024",
         "Not Approved",
         "372",
         "The dynamics of financial performance and market performance in the context of Indian banking industry",
         "Background This study aims to gain insight into the effect of banks’ financial performance on their market performance. We conceptualized the research subject on the assumption that the financial performance of an organization is the most important criterion for triggering movement in its stock price. We explored various models and parameters to evaluate financial performance of banks and found CAMELS being one of the most comprehensive and appropriate model. We considered share price growth of banks to measure their stock market performance  Methods We collected financial and stock market data pertaining to 32 listed Indian banks for the period 2018 to 2022. The study has employed multiple linear regression analysis of panel data for evaluating the relationship between independent and dependent variables. We adopted panel regression for data analysis and used the Prais- Winsten regression with panel corrected standard errors, as the data suffers from contemporaneous cross-sectional correlation.  Results The results show that net non-performing assets, net interest margins, and return on capital have a significant negative impact on share price growth. The capital adequacy ratio and the current and savings account deposit ratios have a positive insignificant impact. The liquid asset-to-total asset ratio has a negative, insignificant impact. The coefficient of determination indicates that the share price growth of banks is more dependent on other factors which are not included in the regression analysis of this study.  Conclusion This study helps investors and bankers understand the limited impact of financial parameters on banks’stock prices and to look for other parameters which explain the stock price movement better.",
         "153",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Summary of the Article This study aims to understand the effect of banks' financial performance on their market performance, based on the assumption that financial performance is a key driver of stock price movement. Using the CAMELS model to assess financial performance, the study analyses financial and market data from 32 listed Indian banks over the period 2018 to 2022 through multiple linear regression on panel data. Strengths of the Article The strength of this article lies in the use of the CAMELS model to measure the impact of financial performance on stock price movements in the Indian banking industry. Weaknesses of the Article 1. Important variables such as the health crisis (COVID-19) have been ignored by the author 2. Endogeneity problem 3. Using stock performance measurements with the percentage growth in share price over the last year's price, completely ignores the dynamics of stock price fluctuations. Constructive Suggestions for Improvement 1. The research period 2018-2022, is the period before and during COVID-19. The author needs to involve control variables such as COVID-19. 2. The author needs to explain the existence of Endogeneity problems and how to overcome them 3. The author needs to use daily data 4. The author needs to do a robustness check 5. The author needs to prepare a clear statement about the contribution of this study  Dharani, M. et al., 2023 (Ref 1)  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? No  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7311",
         "3",
         "0",
         "0.128030303030303",
         "0.0999",
         "0.9381874799728394",
         "36.59",
         "12.6",
         "13.42",
         "14.5",
         "13.0",
         "101",
         "1",
         "0",
         "0",
         "0",
         "2.0",
         "4.0",
         "6.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "2.0",
         "3.0",
         "4.0",
         "50.0",
         "50"
        ],
        [
         "15",
         "Cacik Rut Damayanti",
         "03 Dec 2024",
         "Approved With Reservations",
         "820",
         "The dynamics of financial performance and market performance in the context of Indian banking industry",
         "Background This study aims to gain insight into the effect of banks’ financial performance on their market performance. We conceptualized the research subject on the assumption that the financial performance of an organization is the most important criterion for triggering movement in its stock price. We explored various models and parameters to evaluate financial performance of banks and found CAMELS being one of the most comprehensive and appropriate model. We considered share price growth of banks to measure their stock market performance  Methods We collected financial and stock market data pertaining to 32 listed Indian banks for the period 2018 to 2022. The study has employed multiple linear regression analysis of panel data for evaluating the relationship between independent and dependent variables. We adopted panel regression for data analysis and used the Prais- Winsten regression with panel corrected standard errors, as the data suffers from contemporaneous cross-sectional correlation.  Results The results show that net non-performing assets, net interest margins, and return on capital have a significant negative impact on share price growth. The capital adequacy ratio and the current and savings account deposit ratios have a positive insignificant impact. The liquid asset-to-total asset ratio has a negative, insignificant impact. The coefficient of determination indicates that the share price growth of banks is more dependent on other factors which are not included in the regression analysis of this study.  Conclusion This study helps investors and bankers understand the limited impact of financial parameters on banks’stock prices and to look for other parameters which explain the stock price movement better.",
         "168",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Introduction: The paragraph should have references, especially when the authors describe data in the banking sector. The introduction should clearly describe the research problem in India, whether India has an issue with financial and market performance, to justify the importance of conducting research in this country. The research gaps and novelty of this research should be illustrated in the introduction, such as how the CAMELS model has been under utilized for market performance analysis in the Indian banking sector. While the abstract mentions the CAMELS model as a tool for assessing financial performance, it needs to justify why this model is particularly suitable for the study or how it stands out compared to other approaches. Avoid generalizations, such as \"Indian banking stocks have defied global trends,\" without providing data or citations to support these claims. Literature Review The review needs a more precise thematic structure. Discussions on financial performance, market performance, and the CAMELS model are scattered, making it hard for readers to follow the logical progression. I suggest organizing the literature review into clearly defined themes, such as: (a) Financial performance metrics. (b) Market performance and stock price determinants. (c) Prior studies using the CAMELS model. (d) Studies specific to the Indian banking sector. The author should discuss the CAMELS model and how its application in past studies has been explored in depth. The review mentions the model but needs to evaluate its application across various contexts or its limitations critically and provides a detailed analysis of how the CAMELS model has been used in different studies to assess financial performance and market behavior. Highlight its strengths, weaknesses, and gaps in its application, especially in the Indian context. The literature review primarily summarizes prior studies without critically analyzing their methodologies, findings, or relevance to the current research. The review relies heavily on generalized studies, with limited inclusion of studies specific to the Indian banking sector or stock market. Methods The chapter briefly mentions the data sources (e.g., NSE and BSE websites) but does not provide enough detail on verifying the data’s accuracy or completeness. There is also no mention of handling potential biases in the data. I suggest including a detailed discussion of data quality assurance, such as cross-checking data across multiple sources or handling missing or outlier data points.  I recommend conducting robustness checks, such as using alternative models (e.g., fixed effects, random effects, or dynamic panel models) or testing the results on different time frames or subsets of data to assess the reliability of the findings. While the CAMELS model is central to the study, the chapter needs to adequately justify why specific variables (e.g., NNPA, ROCE) were selected or how they align with the study objectives. The chapter mentions 32 listed banks as the sample but needs to discuss their representativeness or provide details about sample characteristics (e.g., public vs. private banks, size, regional focus). Result While the statistical significance of variables (e.g., NNPA, ROCE, and NIM) is discussed, the meaning of these findings in the context of the Indian banking sector is minimally interpreted. Variables such as CAR, CASA, and LATA are found to be statistically insignificant, but their implications are not adequately explored. The results are not compared with findings from previous studies, making it hard to contextualize the significance of the current study. The chapter reports significance levels (p-values) but does not discuss their thresholds, the potential for Type I or Type II errors (e.g., 0.05 or 0.10), and the likelihood of false positives or negatives. The chapter focuses on statistical findings but needs to discuss their practical implications for stakeholders like investors, policymakers, or bankers. Summarize the results in the context of the hypotheses (e.g., \"H0 is rejected for NNPA and NIM but not for CAR\"). The negative impact of ROCE and NIM is surprising but should be discussed in more detail. I suggest discussing unexpected findings thoroughly, including potential reasons and their implications for the banking sector. The chapter does not acknowledge any limitations in the results, such as potential biases, omitted variables or model restrictions.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7859",
         "1",
         "0",
         "0.0540143964562569",
         "0.2025",
         "0.9059380292892456",
         "28.03",
         "13.8",
         "13.22",
         "14.6",
         "14.2",
         "101",
         "0",
         "0",
         "1",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "False",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "4.0",
         "73.0",
         "73"
        ],
        [
         "16",
         "shaimaa Mohamed Amin",
         "29 Jul 2024",
         "Approved With Reservations",
         "1557",
         "Estimating the efficacy of Newborn-Communication, Health, Feeding and Swallowing Education Program (N-CHFSEP) for primiparous mothers",
         "Background Primiparous mothers face diverse challenges during pregnancy and post-childbirth. There is a lack of comprehensive educational programs for primiparous mothers on maternal functioning and newborn care. This study aimed to explore the efficacy of a developed educational program on the attitude of primiparous mothers towards newborn communication, general health, feeding and swallowing. The objectives were (1) to develop an attitude questionnaire (AQ), a parent education program, and a feedback questionnaire (FQ); and (2) to estimate the efficacy of the education program pre- and post-delivery.  Methods Ninety-eight primiparous mothers without any obstetric history, proficient in English or Kannada, and delivering healthy newborns were recruited for the study. Phase 1 involved the development and validation of AQ, the parent education program [Newborn Communication, Health, Feeding and Swallowing Education Program (N-CHFSEP)], and FQ; while Phase 2 comprised of administering them on the mothers. Both quantitative (descriptive statistics, paired t-test, and chi-square test) and qualitative analysis were done on the parameters of interest.  Results The results of the study demonstrated a notable increase in the number of mothers (not all) reporting heightened confidence levels following receiving the N-CHFSEP (which was observed in all the domains). This observed change (pre and post) was statistically significant as per paired t-test analysis (p <0.05) indicating a significant increase in confidence levels post-N-CHFSEP intervention, as well as recognizing warning signs related to the same. Sociodemographic factors such as age, education, occupation, and family type were reported to have a significant effect (p <0.05) on maternal confidence levels before and after N-CHFSEP administration. Feedback from participants highlighted the effectiveness of the program in enhancing knowledge and awareness, while also suggesting areas for improvement.  Conclusions This study demonstrates the effectiveness of N-CHFSEP in enhancing primiparous mothers' confidence in newborn care, thereby improving maternal and infant health.",
         "20",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Dear [editor ], I hope this message finds you well. I wanted to extend my sincere gratitude to you for sending me the article for review. I truly appreciate the opportunity to contribute to the process and offer my insights. I've gone through the article and I have some constructive feedback that I believe could enhance the overall quality and impact of the piece. Title: Your research title is clear and informative, but it can be made more concise and engaging. Here are a few suggestions to refine and enhance the title: Evaluating the Efficacy of the Newborn Communication, Health, Feeding, and Swallowing Education Program (N-CHFSEP) for First-Time Mothers  Assessing the Impact of the N-CHFSEP on Newborn Care Among Primiparous Mothers Effectiveness of the N-CHFSEP in Enhancing Newborn Care Skills for Primiparous Mothers  Abstract  Background: The background section effectively outlines the problem that primiparous mothers face challenges during pregnancy and post-childbirth. However, the statement \"There is a lack of comprehensive educational programs for primiparous mothers on maternal functioning and newborn care\" could benefit from citation of existing literature to support this claim. Additionally, specifying what aspects of \"maternal functioning\" are included could provide clarity. Objectives: The objectives are clearly stated and logically divided into two main goals: development of tools (attitude questionnaire, education program, feedback questionnaire) and evaluation of the program's efficacy. This separation is clear and helpful for readers to understand the study’s aims. Methods: The methods section is concise but detailed enough to understand the study design. However, it could be improved by specifying the inclusion criteria more precisely (e.g., \"primiparous mothers without any obstetric history\" could specify what kind of history excludes participants). Additionally, mentioning the duration of the study and the specific content covered in the N-CHFSEP could provide more context. Results: The results section effectively communicates the main findings, highlighting the statistically significant increase in maternal confidence levels post-intervention. The use of both quantitative and qualitative analysis is a strength. However, the phrase \"a notable increase in the number of mothers (not all)\" is vague and could be more precise. For example, specifying the percentage of mothers who reported increased confidence would provide more concrete data. Additionally, discussing the specific sociodemographic factors in more detail would enhance understanding of their impact. Conclusions: The conclusions succinctly summarize the study's implications, emphasizing the program's effectiveness in enhancing maternal confidence. However, it would be beneficial to briefly mention any limitations of the study or suggest directions for future research to provide a more balanced view. Keywords: The keywords are relevant and cover the main topics of the study. However, adding keywords like \"confidence,\" \"maternal education,\" and \"program evaluation\" might improve the searchability of the study.  Introduction: The introduction provides a comprehensive overview of the challenges faced by primiparous mothers and underscores the importance of educational programs to support them. Here are some suggestions to refine and strengthen the introduction:  Clarity and Focus: The introduction covers a broad range of issues and studies, which can make it somewhat dense. Consider focusing more sharply on the main problem and the gap your study aims to fill. For example: Highlight the specific challenges primiparous mothers face and how these impact newborn care. Clearly state the need for a comprehensive educational program that addresses these challenges.  Structure: First Paragraph: Introduce the general context of pregnancy and childbirth, emphasizing the unique challenges for primiparous mothers. Second Paragraph: Discuss the importance of maternal confidence, knowledge, and attitudes, and their impact on newborn care. Third Paragraph: Present the specific gaps in current educational programs, citing key studies that demonstrate the need for comprehensive support. Fourth Paragraph: Highlight existing educational programs and their limitations, particularly focusing on the need for a holistic approach. Fifth Paragraph: Conclude by summarizing the need for your study and its objectives.  Citations and Evidence: Ensure all claims are supported by citations. For example, when discussing the impact of maternal confidence or the effectiveness of various programs, provide specific references. Use consistent and current references to strengthen the credibility of your argument.  Flow and Readability: Improve readability by breaking long sentences into shorter, more concise ones. Use transition phrases to connect ideas and ensure a smooth flow from one paragraph to the next.  Specific Suggestions: Opening Sentence: \"Pregnancy and childbirth represent significant milestones in a woman's life, permanently altering her identity and way of living in a continuous and dynamic manner.\" Second Sentence: \"Primiparous mothers (first-time mothers) face a wide range of emotions including joy, excitement, and anxiety, alongside overwhelming and stressful experiences such as routine newborn care, breastfeeding difficulties, lack of sleep, and physically taxing household duties.\" Importance of Maternal Confidence: \"Reduced levels of confidence in primiparous mothers compared to multiparous mothers negatively impact their ability to provide infant care.\" Developmental Milestones: \"Effective identification of developmental milestones by caregivers facilitates early interventions, improving overall health outcomes.\" Educational Programs: \"Although numerous educational programs exist, there is a lack of a holistic approach that comprehensively addresses newborn communication, feeding, swallowing, and general health.\"  Conclusion of Introduction: Summarize Gaps and Objectives: \"Despite the availability of various educational initiatives, there is a noticeable gap in comprehensive programs that address all critical areas of newborn development. This study aims to develop and validate a comprehensive educational program and assess its efficacy in enhancing maternal confidence and knowledge among primiparous mothers.\"  Methods  Study Design and Ethics: Clarity: This section is clear and provides essential information about the study design and ethical approvals. Detail: Including the registration number and ethical approval details adds credibility. Mentioning the adherence to the CONSORT checklist and Declaration of Helsinki is crucial. Participants: Clarity: The paragraph provides detailed demographic data which is good for understanding the sample population. Structure: Breaking this into two paragraphs might enhance readability - one for sample size calculation and the other for demographic details. Detail: Including the sample size formula and demographic breakdown is thorough and helpful. Inclusion and Exclusion Criteria: Clarity: The criteria are clearly listed, which helps in understanding the participant selection process. Structure: The criteria are clearly separated into inclusion and exclusion, making it easy to follow. Detail: Including the proficiency in English or Kannada is important for understanding participant communication abilities. Procedure: The present study was conducted in 2 phases. Phase 1 included the development of an (a) attitude questionnaire, (b) parent education program, and (3) feedback questionnaire; while Phase 2 included the administration of the questionnaires and the education program on the participants, followed by data analysis of the retrieved data. Clarity: The procedure is outlined, indicating a clear structure to the study. Detail: Describing the phases helps in understanding the study's flow. Development of Tools: a) Attitude questionnaire (AQ): Clarity: The development process of the AQ is well-explained, detailing the domains and types of questions. Detail: Including specific item numbers and their domains adds precision. b) Parent Education Program : Clarity: The development process of the N-CHFSEP is described in detail. Detail: Mentioning the consultation with experts adds credibility. c) Feedback Questionnaire (FQ): Clarity: The development process of the FQ is clear and detailed. Detail: Including the types of questions adds precision. Discussion  The discussion section of this study provides a comprehensive analysis of the impact of the Newborn Communication, Hearing, Feeding, and Swallowing Education Program (N-CHFSEP) on the confidence levels of primiparous mothers, emphasizing key areas such as communication, feeding-swallowing skills, and newborn health. While the study effectively highlights the statistical significance of increased confidence post-intervention and relates these findings to previous research, it could benefit from a more concise presentation. The detailed breakdown of influencing variables (age, education, family type, and occupation) is insightful, yet the narrative occasionally becomes repetitive, potentially diluting the focus. Additionally, the discussion extensively references existing literature to contextualize findings, which is commendable, but a more balanced approach with critical reflections on the study's limitations, such as the lack of a control group and the short-term assessment of the intervention's impact, would enhance the overall analysis. The feedback from mothers and the suggestion for practical demonstrations underscore the need for a hands-on approach in educational programs, a point that could be more prominently integrated into the discussion. Overall, while the discussion is thorough and well-supported by data, a more streamlined and critically reflective narrative would strengthen its impact Please address conclusion,  limitations & implications  of the study  Once again, thank you for entrusting me with this task. I look forward to our continued collaboration and to seeing the final version of the article. Warm regards, Shaimaa Mohamed Amin  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? No",
         "0.7872",
         "1",
         "0",
         "0.1835304054054053",
         "0.9542",
         "0.9364086389541626",
         "17.44",
         "15.8",
         "13.86",
         "16.9",
         "17.6",
         "102",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "4.0",
         "3.0",
         "True",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "4.0",
         "3.0",
         "83.0",
         "83"
        ],
        [
         "17",
         "Amogh Verma",
         "03 Sep 2024",
         "Approved With Reservations",
         "653",
         "Estimating the efficacy of Newborn-Communication, Health, Feeding and Swallowing Education Program (N-CHFSEP) for primiparous mothers",
         "Background Primiparous mothers face diverse challenges during pregnancy and post-childbirth. There is a lack of comprehensive educational programs for primiparous mothers on maternal functioning and newborn care. This study aimed to explore the efficacy of a developed educational program on the attitude of primiparous mothers towards newborn communication, general health, feeding and swallowing. The objectives were (1) to develop an attitude questionnaire (AQ), a parent education program, and a feedback questionnaire (FQ); and (2) to estimate the efficacy of the education program pre- and post-delivery.  Methods Ninety-eight primiparous mothers without any obstetric history, proficient in English or Kannada, and delivering healthy newborns were recruited for the study. Phase 1 involved the development and validation of AQ, the parent education program [Newborn Communication, Health, Feeding and Swallowing Education Program (N-CHFSEP)], and FQ; while Phase 2 comprised of administering them on the mothers. Both quantitative (descriptive statistics, paired t-test, and chi-square test) and qualitative analysis were done on the parameters of interest.  Results The results of the study demonstrated a notable increase in the number of mothers (not all) reporting heightened confidence levels following receiving the N-CHFSEP (which was observed in all the domains). This observed change (pre and post) was statistically significant as per paired t-test analysis (p <0.05) indicating a significant increase in confidence levels post-N-CHFSEP intervention, as well as recognizing warning signs related to the same. Sociodemographic factors such as age, education, occupation, and family type were reported to have a significant effect (p <0.05) on maternal confidence levels before and after N-CHFSEP administration. Feedback from participants highlighted the effectiveness of the program in enhancing knowledge and awareness, while also suggesting areas for improvement.  Conclusions This study demonstrates the effectiveness of N-CHFSEP in enhancing primiparous mothers' confidence in newborn care, thereby improving maternal and infant health.",
         "56",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study evaluates the effectiveness of a tailored educational program, the Newborn-Communication, Health, Feeding, and Swallowing Education Program (N-CHFSEP), in enhancing the confidence of primiparous mothers in newborn care. The research addresses a significant gap in maternal education, particularly in the context of first-time mothers who face unique challenges in caring for their newborns. Strengths: Relevance and Impact: The study addresses a highly relevant topic in maternal and child health. The focus on primiparous mothers and the development of a comprehensive educational program is commendable, particularly in regions where such resources may be limited. Methodological Rigor: The development and validation of the study tools (Attitude Questionnaire, Feedback Questionnaire, and N-CHFSEP) are well-detailed and supported by content validation from experts in pediatrics and speech-language pathology. Statistically Significant Findings: The study presents statistically significant improvements in maternal confidence levels across communication, feeding-swallowing, and general health domains, which suggests that the N-CHFSEP is an effective intervention. Practical Implications: The study provides valuable insights for healthcare providers and policymakers, highlighting the importance of structured educational programs for new mothers. Weaknesses: Study Design: The absence of a control group limits the ability to attribute the observed improvements in confidence levels solely to the N-CHFSEP intervention. This is a significant limitation that should be addressed in future studies. The single-arm pre-post study design, while valid for exploratory research, does not provide the level of rigor necessary to establish causality. Generalizability: The sample is limited to primiparous mothers in a specific region, and the exclusion of multiparous mothers may limit the generalizability of the findings to the broader population. Expanding the sample to include a more diverse demographic would strengthen the study. Short-term Assessment: The study measures outcomes immediately post-intervention, leaving questions about the long-term retention of knowledge and skills. A follow-up assessment at 6 months or beyond would provide a more comprehensive understanding of the program's sustained impact. Limited Qualitative Data: While quantitative data is well-represented, the qualitative feedback from participants is not fully explored. Incorporating more qualitative insights could provide a richer context to the statistical findings and highlight areas for improvement in the program. Recommendations for Publication: Revisions: I recommend that the authors address the limitations in their discussion section by clearly acknowledging the absence of a control group and the implications for the study's findings. Additionally, suggestions for future research should be included, particularly regarding long-term follow-up and expanding the sample population. Potential for Improvement: The study would benefit from a more in-depth analysis of the qualitative data collected, as this could provide valuable insights into the participants' experiences and the practical application of the program. Additionally, including recommendations for enhancing the program, such as integrating practical demonstrations, would be beneficial. Suitability for Indexing: Despite its limitations, the study contributes valuable insights into maternal education and has practical implications for improving maternal and infant health. I believe the manuscript is suitable for indexing with revisions. However, the authors should emphasize that this is a preliminary study, laying the groundwork for more rigorous future research.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7955",
         "1",
         "0",
         "0.2008718133718133",
         "0.2025",
         "0.920393705368042",
         "8.47",
         "17.1",
         "15.88",
         "17.2",
         "18.5",
         "88",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "4.0",
         "2.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "84.0",
         "84.0"
        ],
        [
         "18",
         "Micaela Carvajal Alcaraz",
         "14 Dec 2024",
         "Approved With Reservations",
         "485",
         "Biological properties of Moringa oleifera: A systematic review of the last decade",
         "Background The growing incidence of chronic diseases such as cancer and the emergence of drug-resistant microorganisms constitute one of the greatest health challenges of the 21st century. Therefore, it is critical to search for new therapeutic alternatives. Moringa oleifera is a plant well known for the properties of its phytocomponents and its role has been analyzed in a variety of fields, from medicine to biotechnology.  Methods In this work, the biological activity of Moringa oleifera in human health was explored through a review of 129 original articles published between 2010 and 2021 related to antitumor activity and its potential uses against chronic and infectious diseases.  Results Moringa oleifera extracts showed antioxidant, hypoglycemic, antihypertensive and cytoprotective properties at neuronal, hepatic, renal and cardiac levels. Besides, cytotoxic effects, apoptotic and antiploriferative activity against several cancer cell lines has been demonstrated. On the other hand, the antimicrobial potential of M. oleifera was also evidenced, especially against multidrug-resistant strains.  Conclusions Hence, it is supported that there is a wide range of clinical entities in which Moringa oleifera exhibits significant biological activity that could contribute to counteracting metabolic, infectious and chronic diseases in a similar or improved way to the drugs traditionally used.",
         "25",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This work reviews the biological activities of Moringa oleifera, highlighting its antitumor, antimicrobial, and protective effects against metabolic, infectious, and chronic diseases, based on evidence from 129 studies published between 2010 and 2021. The review explores Moringa oleifera across various fields, including medicine and biotechnology, highlighting its versatility and addressing a wide range of bioactivities, including antioxidant, antitumor, antimicrobial, and organ-protective effects, underscoring its therapeutic potential. The reviewed findings open avenues for further exploration into drug development and integrative health strategies involving Moringa oleifera. POINTS 2.- I have notice that there are some other reviews already published with similar subject: SJ Stohs, MJ Hartman. Review of the Safety and Efficacy of Moringa oleifera- Phytotherapy Research, 2015 (Ref-1) - Wiley Online Library KT Mahmood, T Mugal, IU Haq. Moringa oleifera: a natural gift-A review- Journal of Pharmaceutical …, 2010 NZ Abd Rani, K Husain, E Kumolosasi. Moringa Genus: A Review of Phytochemistry and Pharmacology. - Frontiers in pharmacology, 2018 (Ref-2) - frontiersin.org L Gopalakrishnan, K Doriya, DS Kumar. Moringa oleifera: A review on nutritive importance and its medicinal application.- Food science and human …, 2016 (Ref-3) - Elsevier Therefore, the novelty of this actual one should be highlight and clearly establish the added value and relevance compared to previous works. I suggest the following: -Highlight that your review specifically examines the dual potential of Moringa oleifera in tackling both cancer and antimicrobial resistance—two critical and globally relevant health challenges. Also that it integrates data from diverse fields such as medicine, biotechnology, and phytotherapy, offering a broader perspective than reviews focused solely on one discipline. -The review should highlight any newly identified mechanisms, pathways, or potential clinical applications of Moringa oleifera that may not have been discussed extensively in prior reviews. 2.- The conclusions might overstate the potential of Moringa oleifera without sufficient caution about its limitations, such as possible toxicity, variability in efficacy, or challenges in standardizing extracts. This fact should be implemented in discussion or conclusions.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Not applicable  Are the conclusions drawn adequately supported by the results presented in the review? Yes  If this is a Living Systematic Review, is the ‘living’ method appropriate and is the search schedule clearly defined and justified? (‘Living Systematic Review’ or a variation of this term should be included in the title.) Not applicable",
         "0.8453",
         "1",
         "0",
         "0.0688257575757575",
         "0.3011",
         "0.9415368437767028",
         "16.52",
         "16.1",
         "16.92",
         "16.9",
         "18.0",
         "90",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "2",
         "4.0",
         "5.0",
         "3.0",
         "80.0",
         "85"
        ],
        [
         "19",
         "Francisco Osorio-Acosta",
         "16 Jan 2025",
         "Approved",
         "293",
         "Biological properties of Moringa oleifera: A systematic review of the last decade",
         "Background The growing incidence of chronic diseases such as cancer and the emergence of drug-resistant microorganisms constitute one of the greatest health challenges of the 21st century. Therefore, it is critical to search for new therapeutic alternatives. Moringa oleifera is a plant well known for the properties of its phytocomponents and its role has been analyzed in a variety of fields, from medicine to biotechnology.  Methods In this work, the biological activity of Moringa oleifera in human health was explored through a review of 129 original articles published between 2010 and 2021 related to antitumor activity and its potential uses against chronic and infectious diseases.  Results Moringa oleifera extracts showed antioxidant, hypoglycemic, antihypertensive and cytoprotective properties at neuronal, hepatic, renal and cardiac levels. Besides, cytotoxic effects, apoptotic and antiploriferative activity against several cancer cell lines has been demonstrated. On the other hand, the antimicrobial potential of M. oleifera was also evidenced, especially against multidrug-resistant strains.  Conclusions Hence, it is supported that there is a wide range of clinical entities in which Moringa oleifera exhibits significant biological activity that could contribute to counteracting metabolic, infectious and chronic diseases in a similar or improved way to the drugs traditionally used.",
         "58",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The paper has an extensive review and explained properly, however it is necessary an English redaction review. The first paragraph in introduction require connection between ideas. Some scientific names are no correctly written (italics are not used), They used a lot of abbreviations, however they don't use or are used just once (MO), furthermore, there are abbreviations that mean the same but are different (MOLE and MOLEE as an example). It is necessary to review all. Page 4. Figure 1 is cited in the text, however does no correspond with the information present, should be placed in other paragraph. Page 4, 1.3. They don't include bibliography in a paragraph. Page 7. 3.2 Correct Atalas, and correct redaction (The seeds of Moringa oleifera seeds have also shown potential...) It should be expected that authors propose better future perspectives.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Not applicable  Are the conclusions drawn adequately supported by the results presented in the review? Partly  If this is a Living Systematic Review, is the ‘living’ method appropriate and is the search schedule clearly defined and justified? (‘Living Systematic Review’ or a variation of this term should be included in the title.) Yes",
         "0.7832",
         "4",
         "0",
         "0.0899193548387096",
         "0.0999",
         "0.6949644088745117",
         "35.98",
         "12.8",
         "14.69",
         "14.8",
         "13.6",
         "102",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "4.0",
         "1.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "3.0",
         "80.0",
         "85"
        ],
        [
         "20",
         "Pradeep Singh",
         "30 Jan 2025",
         "Approved",
         "496",
         "Biological properties of Moringa oleifera: A systematic review of the last decade",
         "Background The growing incidence of chronic diseases such as cancer and the emergence of drug-resistant microorganisms constitute one of the greatest health challenges of the 21st century. Therefore, it is critical to search for new therapeutic alternatives. Moringa oleifera is a plant well known for the properties of its phytocomponents and its role has been analyzed in a variety of fields, from medicine to biotechnology.  Methods In this work, the biological activity of Moringa oleifera in human health was explored through a review of 129 original articles published between 2010 and 2021 related to antitumor activity and its potential uses against chronic and infectious diseases.  Results Moringa oleifera extracts showed antioxidant, hypoglycemic, antihypertensive and cytoprotective properties at neuronal, hepatic, renal and cardiac levels. Besides, cytotoxic effects, apoptotic and antiploriferative activity against several cancer cell lines has been demonstrated. On the other hand, the antimicrobial potential of M. oleifera was also evidenced, especially against multidrug-resistant strains.  Conclusions Hence, it is supported that there is a wide range of clinical entities in which Moringa oleifera exhibits significant biological activity that could contribute to counteracting metabolic, infectious and chronic diseases in a similar or improved way to the drugs traditionally used.",
         "72",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Biological properties of Moringa oleifera: A systematic review of the last decade This review examines original research papers on Moringa oleifera published from 2010 to 2021. The papers focus on biological properties, especially antitumor activity and possible uses against chronic and infectious diseases. The authors gave in-depth pharmacognostical descriptions and phytochemicals from different parts of Moringa oleifera. They also talked about the plant's traditional uses, antioxidant effects, and potential to fight cancer. activity. The systematic review is compiled by collecting original research articles from various databases like PubMed, Scopus, and Google Scholar. The method used to put this together was very detailed. First, 2700 publications were found in databases. These were then screened to find 410 articles that met certain criteria, such as having to do with Moringa oleifera, chronic diseases, infectious diseases, biological activity, human cancer, antitumor biological activity, in vivo and in vitro activity, and anticancer properties. Finally, 129 (134 listed in reference section) publications were chosen to be included in the final draft of the systematic review. This compilation excludes previously published reviews, editorials, and articles published in languages other than English and Spanish. Suggestions Abbreviations like MO, MOE, and MOSE for Moringa oleifera should be used wisely, and uniformity must be maintained throughout the article. Authors can use an abbreviation once at the beginning of the article with a full description, and then only use the abbreviation for further references. The numbers of publications used for this compilation should be the same. Please check 129 publications mentioned in the abstract, 112 written in the second paragraph of the method section, and a total of 134 references listed under the reference section. Authors must review English grammar and sentence construction.  As mentioned below, recheck references for duplication. 129. Soto AJ, Gomez AC, Vasquez BM, et al.: A Biological properties of Moringa oleifera: a review in the last decade.Publisher Full Text 134. Soto JA, Gomez AC, Vásquez BM, et al.: Data for Biological properties of Moringa oleifera: a review in last decade. Dataset. figshare. 2024. Publisher Full Text  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Not applicable  Are the conclusions drawn adequately supported by the results presented in the review? Yes  If this is a Living Systematic Review, is the ‘living’ method appropriate and is the search schedule clearly defined and justified? (‘Living Systematic Review’ or a variation of this term should be included in the title.) No",
         "0.7697",
         "6",
         "0",
         "0.1201587301587301",
         "0.1376",
         "0.8812143802642822",
         "28.13",
         "13.7",
         "12.89",
         "14.9",
         "14.6",
         "93",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "positive",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "80.0",
         "84"
        ],
        [
         "21",
         "Saja Muhsin",
         "04 Oct 2024",
         "Approved",
         "581",
         "Clinical Outcomes of Polyetheretherketone (PEEK) Hybrid Prosthesis in All-on-Four Rehabilitation: A Systematic Review Protocol",
         "Background The “all-on-four” concept represents a significant advancement in dental implantology. particularly beneficial in cases of extensive jaw bone loss where invasive bone regeneration procedures are typically required. However, the successful implementation of this technique necessitates meticulous planning concerning implant selection, materials, and prosthesis design. The recent introduction of PEEK (Polyetheretherketone) in dentistry, especially in all-on-four prosthetics, prompts questions regarding its clinical efficacy and comparative biomechanical and biological advantages over conventional materials such as titanium and zirconia. While some studies have compared PEEK with other materials, systematic reviews evaluating its efficacy are scarce. This systematic review protocol intends to assess the evidence regarding the viability of PEEK as a potential alternative within the all-on-four approach in dental implantology.  Methods This systematic review protocol will adhere to the Cochrane Handbook for Systematic Review of Interventions and align with the Methodological Expectations of the Cochrane Intervention Reviews (MECIR) guidelines. Utilizing a comprehensive search strategy, multiple databases, including PubMed, EMBASE, Scopus, EBSCO, Web of Science, Cochrane Central, and registries of clinical trials, will be explored. The search aims to identify randomized controlled trials and non-randomized studies investigating the application of PEEK in the all-on-four approach for dental procedures. Emphasizing clinically relevant outcomes such as implant survival, prosthesis success, peri-implant complications, and patient satisfaction, this review aims to provide insights into the effectiveness and potential benefits of using PEEK in all-on-four prosthetics. Non-randomized studies will be assessed for bias using ROBINS-I, while randomized controlled trials will undergo evaluation with the Cochrane Risk of Bias assessment tool, ROB II.  Discussion The outcomes derived from this systematic review hold great significance for dental practitioners exploring the all-on-four concept. Understanding PEEK’s advantages and limitations compared to titanium and zirconia facilitates tailored treatment plans, enhancing success and satisfaction, ultimately improving dental care quality.  Systematic review registration PROSPERO: CRD42024531175 (Registered on 13/04/2024).",
         "140",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Summary; Two independent reviewers will use the Cochrane Risk of Bias Tool and the Newcastle-Ottawa Scale to assess studies, addressing discrepancies through discussion or a third reviewer to ensure a comprehensive evaluation of bias. Data extraction will be performed independently, with differences resolved similarly. Descriptive statistics and narrative synthesis will summarize findings, with subgroup and sensitivity analyses enhancing robustness. If feasible, a random-effects meta-analysis will be conducted, using Chi-squared, Tau-squared, and I-squared tests to assess heterogeneity. Funnel plots and the Egger test will evaluate publication bias, aiming for objective and reliable results. To ensure the article is scientifically sound, the authors should focus on the following specific points: 1. Bias Assessment Tools: Justify the choice of the Cochrane Risk of Bias Tool (ROBII) and the Newcastle-Ottawa Scale (NOS) for assessing bias. Explain how these tools complement each other and their relevance to the study design. 2. Discrepancy Resolution: Provide detailed procedures for resolving discrepancies between reviewers. Specify criteria for involving a third reviewer and how to achieve consensus to enhance transparency. 3. Data Extraction Template: Include a comprehensive description of the data extraction template and the pilot phase evaluation. This ensures the template's effectiveness and reliability in capturing relevant data. 4. Unpublished/Missing Data: Outline the specific steps and methods for contacting study authors to obtain unpublished or missing data. Clarify how these data will be integrated into the analysis and the impact on overall findings. 5. Statistical Analyses: Elaborate on the statistical methods, including how descriptive statistics, frequencies, and proportions will be calculated. Provide clear definitions and justifications for the measures of dispersion used. 6. Subgroup and Sensitivity Analyses: Detail the criteria for conducting subgroup analyses and the factors considered in sensitivity analyses. Explain how these analyses will contribute to understanding the robustness and generalizability of the findings. 7. Meta-Analysis Criteria: Specify the criteria for including studies in the meta-analysis, particularly the definitions of methodological and outcome homogeneity. Justify the use of random-effects models and provide a rationale for the selected tests (Chi-squared, Tau-squared, and I-squared) to assess heterogeneity. 8. Heterogeneity Categorization: Clearly define the categories of heterogeneity (low, high, severe) and explain the thresholds or criteria used to classify them. This aids in interpreting the variability among included studies. 9. Publication Bias: Provide a detailed methodology for creating and interpreting the funnel plot and using the Egger test. Explain the rationale for grouping studies in sets of ten and how symmetry will be assessed to identify publication bias. 10. Visualization of Results: Ensure that the forest plot and any other visualizations are clearly described and justified. Explain how these visual tools will aid in the interpretation and presentation of the combined study effects. By addressing these points, the authors can strengthen the methodological rigour and scientific validity of their study, making it more robust and reliable.  Is the rationale for, and objectives of, the study clearly described? Yes  Is the study design appropriate for the research question? Yes  Are sufficient details of the methods provided to allow replication by others? Yes  Are the datasets clearly presented in a useable and accessible format? Yes",
         "0.7951",
         "10",
         "0",
         "0.1165079365079364",
         "0.088",
         "0.6480745077133179",
         "19.16",
         "15.1",
         "15.34",
         "16.1",
         "16.3",
         "96",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "3.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "85.0",
         "92"
        ],
        [
         "22",
         "Marwa Emam",
         "17 Jan 2025",
         "Approved With Reservations",
         "335",
         "Clinical Outcomes of Polyetheretherketone (PEEK) Hybrid Prosthesis in All-on-Four Rehabilitation: A Systematic Review Protocol",
         "Background The “all-on-four” concept represents a significant advancement in dental implantology. particularly beneficial in cases of extensive jaw bone loss where invasive bone regeneration procedures are typically required. However, the successful implementation of this technique necessitates meticulous planning concerning implant selection, materials, and prosthesis design. The recent introduction of PEEK (Polyetheretherketone) in dentistry, especially in all-on-four prosthetics, prompts questions regarding its clinical efficacy and comparative biomechanical and biological advantages over conventional materials such as titanium and zirconia. While some studies have compared PEEK with other materials, systematic reviews evaluating its efficacy are scarce. This systematic review protocol intends to assess the evidence regarding the viability of PEEK as a potential alternative within the all-on-four approach in dental implantology.  Methods This systematic review protocol will adhere to the Cochrane Handbook for Systematic Review of Interventions and align with the Methodological Expectations of the Cochrane Intervention Reviews (MECIR) guidelines. Utilizing a comprehensive search strategy, multiple databases, including PubMed, EMBASE, Scopus, EBSCO, Web of Science, Cochrane Central, and registries of clinical trials, will be explored. The search aims to identify randomized controlled trials and non-randomized studies investigating the application of PEEK in the all-on-four approach for dental procedures. Emphasizing clinically relevant outcomes such as implant survival, prosthesis success, peri-implant complications, and patient satisfaction, this review aims to provide insights into the effectiveness and potential benefits of using PEEK in all-on-four prosthetics. Non-randomized studies will be assessed for bias using ROBINS-I, while randomized controlled trials will undergo evaluation with the Cochrane Risk of Bias assessment tool, ROB II.  Discussion The outcomes derived from this systematic review hold great significance for dental practitioners exploring the all-on-four concept. Understanding PEEK’s advantages and limitations compared to titanium and zirconia facilitates tailored treatment plans, enhancing success and satisfaction, ultimately improving dental care quality.  Systematic review registration PROSPERO: CRD42024531175 (Registered on 13/04/2024).",
         "245",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The report contains minor issues regarding the clarity of its English language. Editing is required to improve the flow and enhance the understandability of the sentences. Introduction Section: It is unclear whether only in vivo studies will be included, as outcomes cannot be effectively investigated through in vitro studies. The first sentences of the introduction should focus on implant dentistry or the available dental materials for CAD/CAM manufacturing, rather than 3D printing manufacturing. There is no need to mention PEKK since it will not be included in the review. Additionally, abbreviations should only be used after the full term has been introduced. A brief mention of the material’s composition and its related properties should be included here. PMMA is primarily a provisional material, so comparing it with PEEK is somewhat inappropriate. Instead, titanium and Co-Cr should be highlighted as they are considered the gold standard. Mention the advantages zirconia and PEEK bring to clinical outcomes.  Objectives (Primary Objectives): Have you considered including base metals? How will each outcome be measured, and will aesthetic success be evaluated?  Eligibility Criteria: There is a significant difference between “success” and “survival.” The report should specify the measured outcomes, and the terms should not be used interchangeably.  Measures of Effect: The methods used to assess all parameters should be clearly defined and explicitly stated.  Is the rationale for, and objectives of, the study clearly described? Partly  Is the study design appropriate for the research question? Partly  Are sufficient details of the methods provided to allow replication by others? Yes  Are the datasets clearly presented in a useable and accessible format? Yes",
         "0.7852",
         "1",
         "0",
         "0.1356770833333333",
         "0.1163",
         "0.898667573928833",
         "29.04",
         "13.4",
         "14.84",
         "14.6",
         "14.0",
         "100",
         "0",
         "1",
         "1",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "3.0",
         "70.0",
         "70"
        ],
        [
         "23",
         "Eiji Yamamura",
         "11 Dec 2024",
         "Approved With Reservations",
         "959",
         "The Hidden Toll: Investigating the influence of Corruption on Persistent Suicide in the Americas",
         "Background Corruption, a multifaceted governance issue, impacts public well-being globally. The recent trends reveal a rise in suicide rates across the Americas, while all other regions show declines over twenty years of time. This study investigates corruption’s effect on suicide in 26 American countries, considering moderating factors of unemployment, inflation, and economic growth.  Methods This study analysed latest two decades of available data, using stepwise panel regression method to investigate the effects of corruption and economic variables on suicide across income levels. Data were sourced from Transparency International, World Bank and the World Health Organization. Initially, unit root tests and CUSUM plots were used to ensure the stability and stationarity of the dataset, and model specification were validated through F test, LM test and Hausman test to select the ideal econometric model - POLS, REM, or FEM for the study.  Results A strong suicide rate persistence revealed, particularly in high-income countries, where the lagged suicide variable showed a coefficient of 0.8063 (p < 0.001). Corruption significantly impacted suicide rates in upper-middle-income countries (coefficient = -0.0268, p < 0.05), with higher corruption perceptions scores correlating with lower suicide rates. Additionally, unemployment acted as a significant moderator, intensifying the corruption’s adverse impact on suicide with a coefficient of 0.0022 (p < 0.001) in upper-middle income nations. Economic growth demonstrated a minor protective effect, particularly in high-income regions, with an interaction coefficient of -0.0005 (p < 0.1), suggesting slight suicide reduction linked to economic stability.  Conclusion This study found that corruption, unemployment, and economic growth significantly influence suicide rates across the Americas. Corruption exacerbates suicide risks in upper-middle-income countries, while unemployment amplifies this effect. Economic growth offers a slight protective effect, particularly in high-income regions, suggesting that economic stability may help mitigate suicide rates.",
         "15",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Report on  ‘The Hidden Toll: Investigating the influence of Corruption on Persistent Suicide in the Americas The aim of the study is to examine correlation between government corruption and occurrence of suicide in countries in north, central and south America by considering economic condition. As widely known, hyper-inflation occurred in Venezuera. The outcome of inflation in countries in America is valuable to be addressed.  However, readers would be confused due to puzzling definition of Corruption. Further, in some parts, interpretation of estimation results is not appropriate or not sufficiently provided. Further, estimation biases seem to occur. Authors should consider suggestions to improve the current version of manuscript.  Major issues: 1.  Corruption index might lead readers to misunderstand estimation results because the definition is opposed to intuition.  According to Table 2,  \"Corruption Perception Index (0-100)\" was defined by Transparency International. Ordinary saying, larger the value, the more corrupted the government is. However, in the text, to take an example of interpretation for corruption index, \"As key observations, Argentina improved from 35 to 45, indicating a decrease in corruption,\"(p.11).  This shows that smaller value of “corruption” is more corrupted. This is opposed to reader’s intuition. Probably, authors follow the definition of the data source. However, I strongly request to modify the definition to be suitable to reader’s intuition. Instead of it, in Table 2, authors explained that the definition is changed from that of “Transparency International” for convenience of reader’s interpretation. 2.  By definition of variable, values of COR, SUI, and UNEMP must not be negative. I am not familiar with Violin plots in Figure 5. However, sharded area of these values covered negative area. What does it mean? Authors just mechanically illustrated the Figure 5, but was not informative unless authors carefully and appropriately explain importance of Violin plots. Figure 5 of current version is very curious and might lead readers to be confused. In my view, it is enough to just show mean value and 95% CI in Figure.  3.  In results Fixed effects model in Table 5, estimation results of constant are shown. Basically, different from OLS, constant is not calculated in Fixed effects model because constant is completely captured by unobservable time invariant factors (Fixed effects). What does constant mean in Table 5?  4.  In Table 5, Lagged dependent variable is included as independent variable.  In this model, the dynamic panel model is preferred, where Arellano-bond is the basic model although various types of dynamic model have been developed. Especially, time points is relatively long (20 years) and so the dynamic model is appropriated. Most of independent variables seems to be endogenous, that should be mitigated. Fortunately, the Dynamic model mechanically enables authors to deal with the issue of endogenous bias.  5.  In conclusion, influence of lagged suicide variables is shown as below, “The lagged suicide variable repeatedly showed an overwhelmingly substantial positive association with current suicide rates, implying that once suicide rates rise in a country, they likely continue to be elevated over time.” (p.20). Their argument is too strong to be supported by the estimation results. In Fixed effects estimation results of Table 5, coefficient of lagged suicide variable is smaller than 1, despite being statistical significant positive sign. Suicide rate will converge among countries in the long run if the value is smaller than 1.  That is, their argument is supported only if the value is statistically positive and larger than 1. Authors hardly interpret values of coefficients, which lead to misinterpretation.  6.  In table 5, coefficient of CORR is not interpreted as effect of corruption because there are interaction terms between CORR and other variables.  Authors should additionally report results including INFL, UNEMP, and EG, but excluding interaction term. 7.  Authors only interpret statistical significance of independent variables in Table 5. Authors should more carefully value of coefficients to indicate degree of impact of variables (see also Comment 5). 8.  Author’s interpretation about results of Table 5 is ambiguous, and not so informative for readers. For instance,  “corruption combined with increased unemployment rates increases suicide rates in middle-income countries.”  This is interpretation about “CORR×UNEMP” showing 0.0022 (coef) with 1 % level (***).  Actually, authors interpretation above is meaningless. Indicate more clearly and meaningfully interpretation and implication of results. I request authors to show, In the definition of CORR in the paper, large value of CORR show less corrupted government. Hence, in my interpretation, positive value of “CORR×UNEMP” means that less corrupted government reduces the negative effect of unemployment on citizen’s mental health, and so suicide rate. Is it true? To argue as above, negative sign of “UNEMP”  should be shown  However, actually, authors did not indicate results of “UNEMP” in this estimation. So, authors should indicate not only interaction terms but also independent “UNEMP”. Further, how do authors interpret 0.0022 by considering scale of CRR and Unemployment? Apart from it, authors should interpret estimation results in more detail.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? No  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? No",
         "0.7617",
         "9",
         "0",
         "0.0626597967250141",
         "0.0376",
         "0.9343749284744264",
         "30.67",
         "12.8",
         "11.68",
         "14.4",
         "12.9",
         "93",
         "0",
         "1",
         "1",
         "0",
         "4.0",
         "3.0",
         "7.0",
         "False",
         "negative",
         "neutral",
         "Moderate",
         "somewhat specific",
         "4.0",
         "3.0",
         "3.0",
         "60.0",
         "60.0"
        ],
        [
         "24",
         "Febby Mutiara Nelson",
         "08 Jan 2025",
         "Approved With Reservations",
         "459",
         "The Hidden Toll: Investigating the influence of Corruption on Persistent Suicide in the Americas",
         "Background Corruption, a multifaceted governance issue, impacts public well-being globally. The recent trends reveal a rise in suicide rates across the Americas, while all other regions show declines over twenty years of time. This study investigates corruption’s effect on suicide in 26 American countries, considering moderating factors of unemployment, inflation, and economic growth.  Methods This study analysed latest two decades of available data, using stepwise panel regression method to investigate the effects of corruption and economic variables on suicide across income levels. Data were sourced from Transparency International, World Bank and the World Health Organization. Initially, unit root tests and CUSUM plots were used to ensure the stability and stationarity of the dataset, and model specification were validated through F test, LM test and Hausman test to select the ideal econometric model - POLS, REM, or FEM for the study.  Results A strong suicide rate persistence revealed, particularly in high-income countries, where the lagged suicide variable showed a coefficient of 0.8063 (p < 0.001). Corruption significantly impacted suicide rates in upper-middle-income countries (coefficient = -0.0268, p < 0.05), with higher corruption perceptions scores correlating with lower suicide rates. Additionally, unemployment acted as a significant moderator, intensifying the corruption’s adverse impact on suicide with a coefficient of 0.0022 (p < 0.001) in upper-middle income nations. Economic growth demonstrated a minor protective effect, particularly in high-income regions, with an interaction coefficient of -0.0005 (p < 0.1), suggesting slight suicide reduction linked to economic stability.  Conclusion This study found that corruption, unemployment, and economic growth significantly influence suicide rates across the Americas. Corruption exacerbates suicide risks in upper-middle-income countries, while unemployment amplifies this effect. Economic growth offers a slight protective effect, particularly in high-income regions, suggesting that economic stability may help mitigate suicide rates.",
         "43",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Review Strenghts  The study addresses a critical and understudied intersection of corruption and suicide rates in the Americas. By filling a gap in literature that lacks comprehensive regional analyses, it offers significant value for public health and governance discourse. The research employs a robust framework to explore moderating variables like unemployment, inflation, and economic growth, effectively contributing to a nuanced understanding of the socio-economic determinants of suicide.  Areas for Improvement: Clarification of causal direction: The article implies a causal link between corruption and suicide but provides limited discussion of reverse causality or potential bidirectional influences. Policy Context: Although the article discusses policy implications, it could better integrate real-world examples or case studies where similar strategies have succeeded or failed. Methodological Review Variable Definitions and Justification: The rationale for using specific metrics like the Corruption Perceptions Index (CPI) needs more explicit justification regarding its relevance and limitations in capturing nuanced governance issues. Modeling of Interaction Terms: The interaction effects involving corruption, unemployment, and inflation need more theoretical grounding to explain why specific relationships are anticipated. Theoritical Review The literature review connects corruption to mental health through trust erosion and institutional failures, aligning well with existing governance theories Areas for Improvement: Theoretical Integration: The theoretical framework could be enriched by incorporating more psychological theories linking economic stressors directly to mental health outcomes. References to Durkheim’s theory of anomie or contemporary socio-political models would add depth. Conceptual Clarity: The term \"persistence\" of suicide rates is used frequently but could be defined more clearly, perhaps linking it to theories of path dependency in social outcomes. Overall Recommendations Strengthen the theoretical foundation by integrating more detailed explanations for the mechanisms connecting corruption, economic conditions, and mental health. Expand on policy recommendations by providing examples or scenarios demonstrating the impact of governance reforms on suicide rates. Consider alternative data sources or indices to triangulate findings on corruption and governance quality.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Partly",
         "0.8468",
         "1",
         "0",
         "0.1552560646900269",
         "0.0999",
         "0.9523454904556274",
         "-2.64",
         "19.3",
         "19.92",
         "19.5",
         "20.5",
         "98",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "3",
         "4.0",
         "5.0",
         "3.0",
         "80.0",
         "80"
        ],
        [
         "25",
         "Essam S Soliman",
         "26 Dec 2024",
         "Approved With Reservations",
         "685",
         "Implementation of mycotoxin binders to enhance immune response and large intestine histopathology against Newcastle disease in vaccinated broiler chickens fed naturally contaminated diet with mixed mycotoxins",
         "Background In broiler farming, vaccination against Newcastle disease (ND) is essential. Nonetheless, during the post-vaccination phase, production may be negatively impacted by mycotoxin contamination in feed. This study aimed to evaluate the effect of toxin binders on antibody titer and large intestine histopathology after ND vaccination in broiler with aflatoxin B1 (AFB1) and ochratoxin A (OTA) toxication.  Methods A total of 20 broilers were randomly assigned into 4 groups with 5 replications i.e. (C-) broiler groups with basal feed, (C+) broiler groups with AFB1 and OTA feed contamination, (T1) and (T2) broiler groups with exposed AFB1, OTA, and toxin binders as feed additives with dose 1.1 g/kg and 1.6 g/kg feed, respectively. ND vaccination was carried out on day 7 and 21. Antibody titers were evaluated from serum samples of broiler on days 14, 28, and 35 for further hemagglutination inhibition (HI) test. Histopathology of the cecum and colon organs was evaluated using HE staining on day 36. HI test and histological scoring were analyzed using the One-Way ANOVA, followed by Duncan’s test with a p < 0.05 in SPSS v.26 software (IBM Corp., Armonk, NY).  Results As a result, histopathological improvement of the cecum and colon was reported based on mucosal rupture, hemorrhage and necrosis on day 35. An increase in the mean antibody titer compared to days 14 and 28 was observed on day 35, with significant changes observed in serum samples based on the C+ group, which was significantly different from the C- and T2 groups (p < 0.05).  Conclusions This study revealed that toxin binder dose of 1.6 g/kg can increase antibody titer and histopathology of cecum and colon in broiler chickens after ND vaccination fed with mycotoxin-contaminated feed.",
         "13",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Manuscript F1KR00CDE F1R-VER173650-R entitled “Implementation of mycotoxin binders to enhance immune response and large intestine histopathology against Newcastle disease in vaccinated broiler chickens fed naturally contaminated diet with mixed mycotoxins”. Please notice the following: General view: The manuscript highlighted that a toxin binder dose of 1.6 g/kg can increase antibody titer and histopathology of cecum and colon in broiler chickens after ND vaccination fed with mycotoxin-contaminated feed. The manuscript was expressed using moderate English and grammar. A certain degree of copyediting & proofreading, proper display of the introduction, and declaring some explanations of the materials and methods have to be made to achieve better readability & understanding, and publication value. Title: Very long. Preferred to be modified for clarity and simplification into “Mycotoxin Immune and Intestinal Histopathology Ameliorations Against Newcastle Disease in Vaccinated Broilers”. Abstract: Please notice the following: 1. Clear to a great extent. 2. Some modifications must be made to enhance the readability and understanding of the text. Keywords: Re-arrange in alphabetical order as follows: “Aflatoxin, Antibody titer, Broilers, Food production, Ochratoxin, Toxin binders”. Introduction: Please notice the following: Improperly arranged into four paragraphs. The introduction has to be re-arranged into three paragraphs only i.e. 1. Introduction 2. Significance of the study, and 3. Aim of the study. Some modifications must be made to enhance the readability and understanding of the text. The aim: Clear to a certain extent. Some modifications must be made to enhance the readability and understanding of the text. Materials and methods: Please notice the following: 1. MUST provide details on the microclimatic conditions used for rearing the experimental broilers such as ambient temperature, relative humidity, feeding system (manual/automated), watering system (mechanism and source & type of water), lighting program (Color, duration, and intensity), ventilation system, rodentproof, flyproof, cleaning procedures (Provide the active principle of the detergent used), disinfection protocol (Provide the active principle of the disinfectant used), and treatment applied if any. 2. Provide the total number of blood samples collected by the end of the study and specify their types (With or without anticoagulant). 3. Provide a reference for the Euthanasia technique used in broilers. 4. Explain how the carcasses were disposed of hygienically after sampling. 5. Specify the number of the histopathological samples collected. 6. Provide the statistical model exhausted in the statistical analysis. 7. Some modifications must be made to enhance the readability and understanding of the text. Results: Please notice the following: 1. MUST not list the P-value for the non-significant results. 2. Do not list the details of the treatment groups all over and use the symbols instead. 3. Reduce the illustration of numbers as much as possible as they are listed in tables and express them in your own words. 4. Some modifications must be made to enhance the readability and understanding of the text. Discussion: Please notice the following: 1. Clear to a certain extent. 2. A moderate degree of speculation and comparison was used. 3. Some modifications must be made to enhance the readability and understanding of the text. Conclusion: Clear and concise. Authors’ contributions: Clear. Acknowledgment: Clear. References: Sufficient as 62.1% (23 out of 37) were published in the last five years. Tables: Properly designed and well organized. Figures: Properly designed and well organized.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? No  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7667",
         "18",
         "0",
         "0.1118724778046812",
         "0.3698",
         "0.8730815649032593",
         "31.68",
         "12.4",
         "12.19",
         "13.8",
         "13.3",
         "82",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "No Hedging",
         "somewhat specific",
         "3.0",
         "4.0",
         "3.0",
         "84.0",
         "84"
        ],
        [
         "26",
         "Agung Irawan",
         "06 Jan 2025",
         "Approved With Reservations",
         "926",
         "Implementation of mycotoxin binders to enhance immune response and large intestine histopathology against Newcastle disease in vaccinated broiler chickens fed naturally contaminated diet with mixed mycotoxins",
         "Background In broiler farming, vaccination against Newcastle disease (ND) is essential. Nonetheless, during the post-vaccination phase, production may be negatively impacted by mycotoxin contamination in feed. This study aimed to evaluate the effect of toxin binders on antibody titer and large intestine histopathology after ND vaccination in broiler with aflatoxin B1 (AFB1) and ochratoxin A (OTA) toxication.  Methods A total of 20 broilers were randomly assigned into 4 groups with 5 replications i.e. (C-) broiler groups with basal feed, (C+) broiler groups with AFB1 and OTA feed contamination, (T1) and (T2) broiler groups with exposed AFB1, OTA, and toxin binders as feed additives with dose 1.1 g/kg and 1.6 g/kg feed, respectively. ND vaccination was carried out on day 7 and 21. Antibody titers were evaluated from serum samples of broiler on days 14, 28, and 35 for further hemagglutination inhibition (HI) test. Histopathology of the cecum and colon organs was evaluated using HE staining on day 36. HI test and histological scoring were analyzed using the One-Way ANOVA, followed by Duncan’s test with a p < 0.05 in SPSS v.26 software (IBM Corp., Armonk, NY).  Results As a result, histopathological improvement of the cecum and colon was reported based on mucosal rupture, hemorrhage and necrosis on day 35. An increase in the mean antibody titer compared to days 14 and 28 was observed on day 35, with significant changes observed in serum samples based on the C+ group, which was significantly different from the C- and T2 groups (p < 0.05).  Conclusions This study revealed that toxin binder dose of 1.6 g/kg can increase antibody titer and histopathology of cecum and colon in broiler chickens after ND vaccination fed with mycotoxin-contaminated feed.",
         "24",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Overall Assessment: The authors evaluated the efficacy of mycotoxin binders on immunity and histopathology of broilers chickens. The topic of the manuscript is interesting and highly relevant to be disseminated. However, I found that in the current form, the manuscript requires substantial revision. Thorough the manuscript, it is poorly written, with significant issues in language, grammar, and coherence. Additionally, the scientific content is not presented in a manner consistent with standard academic practices, which undermines its clarity and impact. Here are some major issues for authors’ attention: The introduction lacks a logical structure for hypothesis formulation. There is a lack of coherence between sentences. The narrative is disjointed, making it difficult to follow the authors' rationale. The results section contains many unnecessary descriptions that obscure the main findings. A more concise and focused presentation of the data is required. The discussion is poorly structured and hard to follow. The findings are not effectively described, and there is a lack of chronological organization. Critical interpretations are not adequately supported by references. The authors mention a \"hypothesis\" in the conclusion but fail to clearly state it in the introduction. The manuscript does not adequately discuss or revisit the hypothesis in the discussion section.  For more detailed review, please see below comments: #Introduction The introduction is not systematically written, there are too many issues with languages and grammar. Authors need to substantially revise the introduction both grammatically and scientific soundness. Between sentences’ connection is lacking in many parts of paragraphs, some unnecessary information is also found. Some information requires more clarity, such as: 72% samples tested positive for…. -> please indicate what samples? It is not clear! Are the mycotoxin combination that has been shown to have high toxicity -> please be more specific on the toxicity effects and indicate whether the study was in humans or animals (specify the animal) There are some issues with the coherences of sentences in the first paragraph, making the reader a bit confused with the main idea of the paragraph. For instance, authors explain some molecular pathways associated with toxicity of AFB1 and OTA, and then jumped to failure of vaccination program etc. A large portion of the paragraph discuss ND vaccination issue while the importance of mycotoxin exposure issues is lost. Although they are relatable, but it is not written systematically. Please review and rewrite this part to be easier to understand. At the end of 2nd paragraph: plant goods -> what does that mean? I was unfortunately unable to understand. Can the authors please clarify? The statement of the first sentence of 3rd paragraph is not correct. Fiber digestion in poultry occurs primarily in the gizzard (mechanistic digestion) and only very little portion of the fiber is digested in the large intestine and this does not supply much energy for the bird. Please review this part and rewrite… The statement of mycotoxicosis in person is not relevant in this part. In the last paragraph, I do not see how the hypothesis was built, there is missing connection between the scientific background, gap of knowledge, and the objective being pursued in this study. Also, Trichosporon mycotoxinivorans is mentioned with no reason!  #Materials and Methods Rpm should be converted into g to be more standardized. In statistical analysis part, first sentence: followed -> analyzed. Authors mentioned Kruskal Wallis and Mann Whitney tests as well in this part, which one was actually used for the data analysis? Why Mann Whitney was used?  #Results Please rewrite the results to be more concise. At the present form, there are many unnecessary descriptions. It would be better to consult with other experts or to copyedit the manuscript. Some examples are given below: Please remove “as a result” in the first sentence of the section. “Based on Figure 1, presents the HI test” -> Figure 1 (A) depicts Paragraph 3: The investigation of 35-day-old broiler chickens’ antibody titers revealed statistically different results, with a p-value of 0.010 (p < 0.05). The fact that the value of p < 0.05 suggests that the administration of a mycotoxin binders agent has an impact on the antibody titer after ND vaccination -> Please change to “Antibody titers of broilers on day 35 differed (p = 0.010) between groups, suggesting an effect of mycotoxin binder on ND antibody titers establishment”.  #Discussion The discussion is hard to follow. Some terms are not specified such as “organism enter the growth phase….” -> it is ambiguous what organism did the authors mean, whether bird or antigen? - This paper may be useful as a reference: Putra RP et al. (2024 [Ref-1]) https://link.springer.com/article/10.1007/s11259-023-10199-7  #Conclusion: Authors mentioned the “hypothesis” but never stated their hypothesis in the introduction and never discussed it.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7794",
         "1",
         "1",
         "0.0850227625635234",
         "0.2",
         "0.7859644293785095",
         "39.03",
         "11.6",
         "11.8",
         "13.7",
         "12.5",
         "95",
         "0",
         "0",
         "0",
         "0",
         "2.0",
         "4.0",
         "8.0",
         "False",
         "negative",
         "neutral",
         "5",
         "3",
         "2.0",
         "4.0",
         "2.0",
         "50.0",
         "60"
        ],
        [
         "27",
         "Africa Borges",
         "12 Sep 2024",
         "Approved",
         "243",
         "Impact of distress and anxiety due to COVID-19 on digital addictions in university students in the third wave period",
         "Abstract*  Background Digital addictions are a major problem worldwide, which has increased considerably during the COVID-19 pandemic. In this scenario, two important impact factors to explain this problem are stress and anxiety because of COVID-19. The objective of this research was to determine the impact of distress and anxiety due to COVID-19 on digital addictions.  Methods cross-sectional, explanatory study. A total of 802 students from public and private universities residing in the city of Lima and Callao (Peru), with a mean age of 21.68 (SD = 3.11), selected by convenience sampling, participated in the study. The MULTICAGE CAD-4 questionnaire, the distress scale, and the COVID-19 worry scale were applied.  Results two models examined with structural equation modeling showed good fit indices (CFI and TLI > .95, RMSEA and SRMR < .06). The first model shows that the latent variables distress and anxiety due to COVID-19 have direct effects on digital addictions as a general construct (R2 = 22%). The second model shows that the exogenous latent variables (stress and anxiety) have direct effects of different magnitudes on each digital technology, so the variance explained on smartphone addiction was higher (R2 = 25%) with respect to internet (R2 = 19%) and video game addiction (R2 = 6%). It was also found that for every male, there are two females with high levels of distress and anxiety. Regarding the problematic use of smartphones and internet, there is a prevalence of 40% regardless of sex; but as for the problematic use of video games, there is a marked difference between males (18.8%) and females (2.7%).  Conclusion the distress and anxiety caused by COVID-19 have a direct impact in aggravating digital addictions.",
         "7",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The article proposed for indexing has, in my view, sufficient value for this purpose. On the one hand, the subject is of great relevance, since the pandemic has been a turning point in life, both at the level of the various strata of society and from an international perspective. It has been a hard experience, but it is important to develop what we have been able to learn from it. In this sense, this study provides an important approach, relating additions that may have developed during the pandemic. The thoroughness of the analysis leaves no doubt as to its relevance.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7624",
         "1",
         "0",
         "0.1916666666666666",
         "0.157",
         "0.6700870990753174",
         "33.95",
         "13.6",
         "15.86",
         "15.6",
         "13.8",
         "99",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "85.0",
         "84"
        ],
        [
         "28",
         "Georgina Eugenia Bazán Riverón",
         "05 Dec 2024",
         "Approved",
         "246",
         "Impact of distress and anxiety due to COVID-19 on digital addictions in university students in the third wave period",
         "Abstract*  Background Digital addictions are a major problem worldwide, which has increased considerably during the COVID-19 pandemic. In this scenario, two important impact factors to explain this problem are stress and anxiety because of COVID-19. The objective of this research was to determine the impact of distress and anxiety due to COVID-19 on digital addictions.  Methods cross-sectional, explanatory study. A total of 802 students from public and private universities residing in the city of Lima and Callao (Peru), with a mean age of 21.68 (SD = 3.11), selected by convenience sampling, participated in the study. The MULTICAGE CAD-4 questionnaire, the distress scale, and the COVID-19 worry scale were applied.  Results two models examined with structural equation modeling showed good fit indices (CFI and TLI > .95, RMSEA and SRMR < .06). The first model shows that the latent variables distress and anxiety due to COVID-19 have direct effects on digital addictions as a general construct (R2 = 22%). The second model shows that the exogenous latent variables (stress and anxiety) have direct effects of different magnitudes on each digital technology, so the variance explained on smartphone addiction was higher (R2 = 25%) with respect to internet (R2 = 19%) and video game addiction (R2 = 6%). It was also found that for every male, there are two females with high levels of distress and anxiety. Regarding the problematic use of smartphones and internet, there is a prevalence of 40% regardless of sex; but as for the problematic use of video games, there is a marked difference between males (18.8%) and females (2.7%).  Conclusion the distress and anxiety caused by COVID-19 have a direct impact in aggravating digital addictions.",
         "91",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The article meets the requirements. I only suggest a few recommendations: - The title refers to stress and anxiety. In the summary and in the method section it names another variable (worry) and it does not speak of anxiety, but rather worry. They are not the same. It is suggested that variables are always named the same way. - It seems to me that the problem statement can be more specific, detailing the relationship between variables. - In the results, a detailed description of the dimensions of the instruments would help to a deeper understanding. - Review punctuation and spaces in the text  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7368",
         "1",
         "0",
         "0.1663461538461538",
         "0.1695",
         "0.7772457599639893",
         "37.0",
         "12.4",
         "14.69",
         "14.6",
         "12.9",
         "102",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "85.0",
         "85"
        ],
        [
         "29",
         "Octaviano Garcia Robelo",
         "12 Dec 2024",
         "Approved",
         "340",
         "Impact of distress and anxiety due to COVID-19 on digital addictions in university students in the third wave period",
         "Abstract*  Background Digital addictions are a major problem worldwide, which has increased considerably during the COVID-19 pandemic. In this scenario, two important impact factors to explain this problem are stress and anxiety because of COVID-19. The objective of this research was to determine the impact of distress and anxiety due to COVID-19 on digital addictions.  Methods cross-sectional, explanatory study. A total of 802 students from public and private universities residing in the city of Lima and Callao (Peru), with a mean age of 21.68 (SD = 3.11), selected by convenience sampling, participated in the study. The MULTICAGE CAD-4 questionnaire, the distress scale, and the COVID-19 worry scale were applied.  Results two models examined with structural equation modeling showed good fit indices (CFI and TLI > .95, RMSEA and SRMR < .06). The first model shows that the latent variables distress and anxiety due to COVID-19 have direct effects on digital addictions as a general construct (R2 = 22%). The second model shows that the exogenous latent variables (stress and anxiety) have direct effects of different magnitudes on each digital technology, so the variance explained on smartphone addiction was higher (R2 = 25%) with respect to internet (R2 = 19%) and video game addiction (R2 = 6%). It was also found that for every male, there are two females with high levels of distress and anxiety. Regarding the problematic use of smartphones and internet, there is a prevalence of 40% regardless of sex; but as for the problematic use of video games, there is a marked difference between males (18.8%) and females (2.7%).  Conclusion the distress and anxiety caused by COVID-19 have a direct impact in aggravating digital addictions.",
         "98",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The article can be approved: No minor changes are required. The article analyzes and statistically explains the effects of anxiety and stress factors on digital addictions in university students. Its theoretical framework helps to theoretically substantiate the existence of stress and anxiety in more than a quarter and about half young college students in various countries around the world, which are shown and substantiated in their research reports. Also, it presents and details the digital additions, mainly cell phone and video games, in young people, which increased as a result of the Pandemic COVID_19. The methodology for both the data collection and the use of structural equations, allows confirming and explaining with precision the statistically significant influence of the two models shown. This methodology can be replicated for other investigations. The results contribute to substantiate the consequences in mental health brought about by the COVID_19 pandemic in university students in Peru. This phenomenon, which undoubtedly occurred and occurs in other countries of the world, should be addressed and investigated for the prevention of major consequences, such as suicide, low performance and dropping out of their studies. The references are updated and totally related to her research topic.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7626",
         "1",
         "0",
         "0.1167763157894736",
         "0.0999",
         "0.9009323716163636",
         "24.48",
         "15.1",
         "16.87",
         "16.4",
         "16.1",
         "101",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "3.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "very specific",
         "5.0",
         "4.0",
         "3.0",
         "90.0",
         "90"
        ],
        [
         "30",
         "Ooi Kok Loang",
         "04 Dec 2024",
         "Approved With Reservations",
         "331",
         "Evaluation of the fintech era on the performance of Moroccan banks: analysis through non-performing loans",
         "Background This study aims to contribute to a better understanding of the impact of the financial technologies (fintech) era on the performance in the banking sector, measured through non-performing loans (NPL) and their coverage by provisions for NPL. It is a question of knowing whether banking investment in fintech makes it possible to better evaluate the granting of credits, and therefore makes it possible to reduce overdue credits.  Methods To this end, the method used consists of using a regression analysis and a Pearson correlation applied to the financial data of Moroccan banks observed during two distinct periods, namely 2007-2014, considered pre-fintech, and the period 2015-2022, considered as the fintech period.  Results With the emergence of the fintech era, the Moroccan banking situation improved slightly compared to the pre-fintech period: bad debts did not increase despite the significant increase in net banking income and the size of banking assets during the fintech era.  Conclusions The implementation of fintech has improved customer relationship management, credit risk analysis and loan monitoring services, which ultimately reduces non-performing loans and improves the coverage of non-performing loans by provisions. The main implication of the results allows us to deduce that the implementation of fintech makes it possible to have a positive impact on overdue credits, and they are also likely to serve as a lever for the inclusion of those excluded from banking services.",
         "20",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Thank you for submitting the paper. Kindly refer to my comments below: 1.  The introduction should include the reasons for conducting this study. Why do we need this study? Is it important, and what are the novelty contributions? 2.  There are some grammatical, formatting and structure errors. Please do proper proofreading before the next submission (if available). 3.  The literature review and underlying theories are missing. A letter should critically examine what previous studies have done and the gaps found that lead to the necessity of the study. 4.  The source of the data and sampling should be explained. Why select the 2015-2022, and why focus on Moroccan banks? All these have to be explained clearly.  5.  A robustness test should be added in order to increase the credibility of the study. 6.  The study has involved 11 variables in a regression, which is quite a high number. Have the author(s) examined the potential correlation between variables? Granger causality? 7.  Comparison analysis with previous studies is not available.  8.  Theoretical, managerial and policy implications are missing. Similarly, limitations and recommendations for future studies are not presented.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7556",
         "8",
         "0",
         "0.1208796296296296",
         "0.8461",
         "0.8050601482391357",
         "41.16",
         "10.8",
         "13.01",
         "13.2",
         "11.3",
         "99",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "7.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "64.0",
         "64"
        ],
        [
         "31",
         "Anas Ahmad Bani Atta",
         "23 Dec 2024",
         "Approved With Reservations",
         "474",
         "Evaluation of the fintech era on the performance of Moroccan banks: analysis through non-performing loans",
         "Background This study aims to contribute to a better understanding of the impact of the financial technologies (fintech) era on the performance in the banking sector, measured through non-performing loans (NPL) and their coverage by provisions for NPL. It is a question of knowing whether banking investment in fintech makes it possible to better evaluate the granting of credits, and therefore makes it possible to reduce overdue credits.  Methods To this end, the method used consists of using a regression analysis and a Pearson correlation applied to the financial data of Moroccan banks observed during two distinct periods, namely 2007-2014, considered pre-fintech, and the period 2015-2022, considered as the fintech period.  Results With the emergence of the fintech era, the Moroccan banking situation improved slightly compared to the pre-fintech period: bad debts did not increase despite the significant increase in net banking income and the size of banking assets during the fintech era.  Conclusions The implementation of fintech has improved customer relationship management, credit risk analysis and loan monitoring services, which ultimately reduces non-performing loans and improves the coverage of non-performing loans by provisions. The main implication of the results allows us to deduce that the implementation of fintech makes it possible to have a positive impact on overdue credits, and they are also likely to serve as a lever for the inclusion of those excluded from banking services.",
         "39",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  General Suggestions 1. Language and Proofreading: The manuscript has several grammatical and formatting issues that should be corrected. 2. Novelty and Contribution: The study needs to make a stronger case for its novelty and contribution to the literature. This could be by add more recent studies (i.e. 2024 studies). 3. Statistical Rigor: If can add robustness tests and address potential methodological issues like multicollinearity and endogeneity. Title and Abstract 1. Title: The title is clear and indicates the research focus. 2. Abstract: The abstract summarizes the study well but lacks specificity regarding the novelty of the findings. Including a clearer statement of the research gap and main contribution would strengthen it. Introduction 1. The introduction does not clearly articulate the research gap or the novelty of the study. Why is it important to study Moroccan banks during the fintech era? This should be emphasized more explicitly. 2. While the background is informative, it lacks critical engagement with recent prior literature. Literature Review 1. The literature review provides a broad overview of fintech and banking performance. 2. Key gaps in existing research and how this study addresses those gaps are not explicitly outlined. Additionally, theoretical frameworks supporting the relationship between fintech and banking performance could be better developed. 3. update the  references look at the references below  Methodology 1. The justification for dividing the study period into pre- and post-fintech eras needs more clarity, especially why 2015 is chosen as the start of the fintech era in Morocco. 2. While the selection of variables is explained, the rationale for their inclusion could be stronger, with references to relevant studies. 3. No mention of robustness checks or tests for multicollinearity, which are critical given the number of variables used in the regression analysis. Results and Analysis 1. The results are well-structured, but there is a lack of critical discussion comparing these findings with prior studies especially the recent studies. 2. Some correlations are reported as significant without discussing their practical implications.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7872",
         "12",
         "0",
         "0.1591312056737588",
         "0.072",
         "0.8576239943504333",
         "30.57",
         "12.8",
         "13.71",
         "14.4",
         "13.2",
         "91",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "3.0",
         "82.0",
         "82"
        ],
        [
         "32",
         "Rupesh Kumar",
         "08 Feb 2025",
         "Approved With Reservations",
         "363",
         "Heavy Metal Contamination: Sources, Health Impacts, and Sustainable Mitigation Strategies with Insights from Nigerian Case Studies",
         "Heavy metal contamination has gradually become a very much important significant global issue due to its continual existence in the environment and bioaccumulation in the ecosystems, posing deleterious risks to human health. This review aims to investigate the sources, pathways, and toxicological impacts of heavy metals such as cadmium, lead, mercury, and arsenic, elucidating their health consequences and plausible mitigation strategies. Furthermore, the review explores the dual origins of heavy metal contamination; natural geological processes and anthropogenic activities such as industrial emissions, mining, and agricultural practices. These heavy metals sip into soil, water, and food chains, leading to bioaccumulation, bio-magnification and causing significant health risks, including cardiovascular diseases, neurological disorders, and reproductive toxicity. Additionally, the addition of indigenous case studies from Nigeria, such as lead poisoning in Zamfara State and contamination in the Great Kwa River of Cross Rivers State underscores the disproportionate impact of heavy metal pollution in developing nations. These case studies reveal the socio-economic and environmental dimensions of the issue, providing a contextual understanding of region-specific vulnerabilities and health outcomes. To address these problems, the review evaluates already existing mitigation strategies, including chelation therapy and phytoremediation, while proposing sustainable, cost-effective solutions for reducing exposure and mitigating impacts. It emphasizes the importance of integrative approaches involving policy, community engagement, and technological innovations to fight heavy metal contamination effectively. In conclusion, this seminar contributes to the understanding of heavy metal toxicity, giving and showcasing very much important insights into the sources and health implications of contamination. By integrating theoretical perspectives with practical solutions, this review provides a robust framework for informing policy makers and advancing sustainable environmental management practices.",
         "12",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Few important observations needs to be addressed for improving the quality of work: 1) What is the novelty of study? Is there any existing work supporting or motivating to do this study? Please explain in Introduction part. 2) Author should also mention some other existing technologies may be considered or used instead of AI predictive. 3) I unable to see the research gaps and objectives. Please include latest references which will give you an idea of work in different sectors. Few important papers needs to be added: i. Kumar R et al. (2014 [Ref-1])  ii. Rajani R et al. (2022 [Ref-2]) iii. Kumar R (2017 [Ref-3])  4) Methodology: Please check for proper citation of figures and tables in the text. In addition, there is no source given for figure and tables. If it is self then author should cite as “Source: Author Composition” or similar. 5) Implications should be added in this (Political, Practical and Social if any). 6) Conclusion part is written in very short. Compare your study with other authors and write in conclusion and extend a bit more. 7) Limitations and future work should be included as a separate heading or may be a part of conclusion also in the last para. 8) Please make a proper structure of your manuscript like aligning with Introduction, LR, Gaps, Objectives, Methods and Materials, Analysis, Results and Discussion, Implications, Conclusion, Limitations and Future Scope and References. 9) Authors may proof read before submitting the revision.  Is the topic of the review discussed comprehensively in the context of the current literature? Yes  Are all factual statements correct and adequately supported by citations? Yes  Is the review written in accessible language? Yes  Are the conclusions drawn appropriate in the context of the current research literature? Yes",
         "0.8067",
         "4",
         "0",
         "0.0912037037037037",
         "0.4218",
         "0.6904819011688232",
         "48.3",
         "10.1",
         "12.08",
         "13.0",
         "10.7",
         "101",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "4.0",
         "2.0",
         "True",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "72.0",
         "72"
        ],
        [
         "33",
         "Alysa Pomer",
         "09 Oct 2024",
         "Approved With Reservations",
         "950",
         "Psychometric properties of an instrument measuring monkeypox knowledge, perception, and beliefs of health threat in health science students in a middle-income country",
         "Objective This study aimed to establish the factor structure and reliability of the evaluation instrument measuring monkeypox (Mpox) knowledge, perception and beliefs of health threat in students of the health area in two universities of Peru during 2022.  Methods The methodology used was psychometric in nature. The study variable on knowledge of monkeypox was based on the instrument made by Ricco et al., carried out with health professionals, adjusted to Peru and administered to 416 students.  Results The results showed adequate goodness-of-fit indicators with RMSEA and SRMR coefficients lower than 0.08 and a TLI lower than 0.90 and adequate reliability values for knowledge of monkeypox (KR20=0.70 and α=0.73), with the perception of health threats being the one with the highest reliability (α=0.88 and Ω=0.89).  Conclusions Having instruments that accurately reflect the knowledge, perception and beliefs of health students will make it possible to contribute significantly to the prevention, control and management of this disease and, at the same time, be prepared to address other challenges of public health in the future.",
         "119",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Summary: In this study, the authors seek to validate a psychometric instrument measuring mpox knowledge, perceptions, and beliefs of health threats in a new context—namely, among healthcare students at two universities in Peru. This is a valuable contribution in Peru (and potentially other Spanish-speaking populations of the Americas) where mpox rates have been high. Understanding the knowledge base and biases of medical trainees around this disease can help ensure education of those future medical providers is adapted so mpox patients are getting the best care possible. The methods should be expanded to ensure replication is possible. This should include information about the specific items included as well as the translation procedures. The specific statistical analyses used are outside of my area of familiarity, so I can’t comment on the statistical analyses specifically. However, some information does seem to be missing from the tables that would have made it easier for me to understand these analyses. My greatest concern with this manuscript is that the specific results of this study are not clearly shown in the Results, which means the Discussion does not have a thorough exploration of what this particular study found in relation to other studies, leading to a vague Conclusion that doesn’t say anything specific about this study. If the Results can be more clearly and thoroughly explained, I believe this would cascade to a more robust Discussion section and clear, concise Conclusion. It is worth noting that the nomenclature around this disease changed fairly recently; I strongly suggest changing “monkeypox” to “mpox” throughout the manuscript. The literature is otherwise current. Finally, the manuscript would benefit from proofreading for grammar and syntax.  General comments: 1. I strongly suggest changing “monkeypox” to “mpox” to align with updated WHO nomenclature guidelines (https://www.who.int/news/item/28-11-2022-who-recommends-new-name-for-monkeypox-disease and https://www.ncbi.nlm.nih.gov/pmc/articles/PMC9901940/). Introduction: 2. Update your first sentence to note that “monkeypox” is the previous name for the disease that is currently known as “mpox” and that this disease is caused by the monkeypox virus (MPXV). 3. Did the last outbreak start in May 2022 in the UK, or was it confined to May 2022 in the UK? The current language makes it sound like the latter, but that’s contradicted in the following line when it’s stated that a PHE was declared two months later. Please clarify. 4. Compared to 2022…”—is this referring to case rates in 2023 being compared to 2022 case rates? Please clarify. Methods: 5. Population: I suggest presenting the inclusion criteria rather than the exclusion criteria. 6. Variables and instruments: “The study variable on knowledge of [mpox] was taken from the instrument…and carried out with health professionals.” How are the health professionals involved with the survey? I understood the survey to be conducted online and given to students. Please clarify. 7. Variables and instruments: Which 17 knowledge items and 11 perception/belief items were included? Why were these items included but not the others? Consider including the survey used in this study as a supplementary file (Spanish and English translations). 8. Variables and instruments: Considering the importance of translation in the validation of survey instruments in new contexts, the information about the translation procedure should be expanded. For example, what does it mean that the instrument was “translated by professionals and evaluated by expert judgment”? How many people translated the survey? Were the translators from the medical field? Were any of the translators part of the study team? Did a second set of translators back-translate? 9. Procedure: “Irrelevant” would be a more accurate word than “impertinent” in the first sentence. Results: 10. A table showing the knowledge items, correct answer, and response distribution for each item would be helpful (similar to table A3 in the Ricco et al., 2022, paper). 11. The results of the perception and belief of health threats variables should also be presented in a table. Discussion: 12. Clarification—If the first sentence is referring to the 2020s, this is actually the third decade of the 21st century (2000s is the first decade, 2010s is the second decade, 2020s is the third decade). Conclusions: 13. This is a very vague statement that doesn’t say anything about what this particular study actually found. Clarify the findings through the Results and Discussion sections to create a more specific Conclusions section. References: 14. #14 is an incomplete reference and should be as follows: [ ref 1 ] Tables: 15. Table 1 should include the total number of participants. 16. Tables 2 and 3 include “D1, D2, D3” in the header but don’t define what these mean. Please define this terminology as a footnote in the tables and consider adding the information to the text. 17. Table 3 shows RMSEA with bracketed ranges, but no other indicators show these ranges. Please explain what these ranges are and why the other indicators do not include ranges.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7491",
         "20",
         "2",
         "0.085995062989445",
         "0.1638",
         "0.8828500509262085",
         "36.39",
         "12.6",
         "12.35",
         "14.2",
         "13.7",
         "94",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "3.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "80.0",
         "83"
        ],
        [
         "34",
         "Mona Gamal Mohamed",
         "14 Nov 2024",
         "Not Approved",
         "369",
         "Psychometric properties of an instrument measuring monkeypox knowledge, perception, and beliefs of health threat in health science students in a middle-income country",
         "Objective This study aimed to establish the factor structure and reliability of the evaluation instrument measuring monkeypox (Mpox) knowledge, perception and beliefs of health threat in students of the health area in two universities of Peru during 2022.  Methods The methodology used was psychometric in nature. The study variable on knowledge of monkeypox was based on the instrument made by Ricco et al., carried out with health professionals, adjusted to Peru and administered to 416 students.  Results The results showed adequate goodness-of-fit indicators with RMSEA and SRMR coefficients lower than 0.08 and a TLI lower than 0.90 and adequate reliability values for knowledge of monkeypox (KR20=0.70 and α=0.73), with the perception of health threats being the one with the highest reliability (α=0.88 and Ω=0.89).  Conclusions Having instruments that accurately reflect the knowledge, perception and beliefs of health students will make it possible to contribute significantly to the prevention, control and management of this disease and, at the same time, be prepared to address other challenges of public health in the future.",
         "155",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Introduction: The introduction lacks a comprehensive discussion of the psychometric framework and the significance of the study. While the disease context is briefly mentioned, the foundational importance of this work in advancing measurement science is not adequately addressed. Contrary to the claim of limited research in this area, a substantial body of literature exists, providing critical insights into similar psychometric developments. These references should be acknowledged to contextualize the study and highlight its relevance within the broader research landscape. Methods: The methodology section is underdeveloped and lacks clarity, making it difficult to follow the process. Only one reference is cited for the instrument's development, despite the wealth of existing literature on similar psychometric tools, which I have included in the included citations. Furthermore, the translation process is entirely omitted, and the critical phases of tool validation—such as content validation, construct validation, and reliability testing—are not detailed. These omissions significantly undermine the credibility and reproducibility of the study. Results: The results section requires substantial improvement through advanced statistical analysis. The current presentation appears overly simplistic, offering only a fundamental analysis that does not provide a nuanced understanding of the tool's psychometric properties. Enhanced analysis is necessary to give the reader a clearer and more comprehensive perspective on the validity and reliability of the instrument. Such improvements would significantly elevate the quality and usefulness of the findings.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? No  Are sufficient details of methods and analysis provided to allow replication by others? No  If applicable, is the statistical analysis and its interpretation appropriate? No  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7794",
         "1",
         "0",
         "0.0983821733821734",
         "0.1262",
         "0.7725992798805237",
         "9.48",
         "16.8",
         "17.41",
         "17.2",
         "17.3",
         "101",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "2.0",
         "3.0",
         "False",
         "negative",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "4.0",
         "3.0",
         "64.0",
         "64"
        ],
        [
         "35",
         "Anne Eudes Jean Baptiste",
         "01 Oct 2024",
         "Approved With Reservations",
         "194",
         "Zero-dose children in Latin America: analysis of the problem and possible solutions",
         "Introduction Zero-dose children (ZDC) are defined as those that have never been reached by routine immunization services. In Latin America, almost 2.7 million infants younger than 1 year of age, have incomplete vaccination schedules, and vaccine preventable diseases such as measles or polio have increase worldwide. ZDC are reported to reside in high risk and fragile settings, including remote-rural areas, urban slums, and conflict-affected areas. Identifying the problem and settings in each country is mandatory to propose possible solutions to the immunization coverage situation.  Areas covered In November 2023, a group of experts of the Latin America Society of Pediatric Infectious Diseases (SLIPE) analyzed the global and regional reality of ZDC, and present in this document an updated reality of the Latin American region and the weight of the possible interventions to overcome this problem.  Expert commentary Communication is a key element to improve vaccination coverage, as it is quality and use of vaccination data. Campaigns that deliver targeted and effective messages to communities and families, provide education about vaccination, avoid missed vaccination opportunities, and coordinate efforts across different sectors and communities, among other strategies, could improve the current immunization situation.",
         "14",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  To strengthen the article, several key areas require attention: 1- More quantitative data on immunization coverage rates, ZDC prevalence, and relevant metrics would enhance the analysis and identification of specific areas of concern. 2- Acknowledging limitations, such as potential bias in data analysis, and outlining areas for future research is essential. This will enhance the article's credibility. 3- Emphasizing in the conclusion the importance of political will and commitment is critical.  Is the topic of the opinion article discussed accurately in the context of the current literature? Yes  Are all factual statements correct and adequately supported by citations? Partly  Are arguments sufficiently supported by evidence from the published literature? Yes  Are the conclusions drawn balanced and justified on the basis of the presented arguments? Partly",
         "0.7789",
         "1",
         "0",
         "0.107",
         "0.0999",
         "0.8609498739242554",
         "15.71",
         "16.4",
         "19.16",
         "18.2",
         "17.4",
         "95",
         "0",
         "0",
         "0",
         "1",
         "4.0",
         "3.0",
         "1.0",
         "no",
         "positive",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "74.0",
         "74"
        ],
        [
         "36",
         "Chelsea Marie",
         "10 Oct 2024",
         "Approved With Reservations",
         "838",
         "Zero-dose children in Latin America: analysis of the problem and possible solutions",
         "Introduction Zero-dose children (ZDC) are defined as those that have never been reached by routine immunization services. In Latin America, almost 2.7 million infants younger than 1 year of age, have incomplete vaccination schedules, and vaccine preventable diseases such as measles or polio have increase worldwide. ZDC are reported to reside in high risk and fragile settings, including remote-rural areas, urban slums, and conflict-affected areas. Identifying the problem and settings in each country is mandatory to propose possible solutions to the immunization coverage situation.  Areas covered In November 2023, a group of experts of the Latin America Society of Pediatric Infectious Diseases (SLIPE) analyzed the global and regional reality of ZDC, and present in this document an updated reality of the Latin American region and the weight of the possible interventions to overcome this problem.  Expert commentary Communication is a key element to improve vaccination coverage, as it is quality and use of vaccination data. Campaigns that deliver targeted and effective messages to communities and families, provide education about vaccination, avoid missed vaccination opportunities, and coordinate efforts across different sectors and communities, among other strategies, could improve the current immunization situation.",
         "23",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This review entitled \"Zero-dose children in Latin America: analysis of the problem and possible solutions\" seeks to describe the problem of Zero Dose Children (defined as those that have never been reached by routine immunization services), describe how interventions can be targeted, and suggest solutions. The review also includes a discussion on the importance and role of National Immunization Technical Advisory Groups (NITAGs). The topic is highly significant as ZDC are vulnerable to preventable diseases and the number of ZDC in a country is a key indicator of barriers to vaccination. Analysis of vaccination is particularly topical in the wake of the covid-19 pandemic which resulted in structural barriers to vaccination as well as an increase in vaccine hesitancy in some populations.  While the title suggests an analysis of ZDC in Latin America the content presented herein is more editorial in nature, with a mixture of global, regional and country-wide statistics presented throughout that while illustrative of some specific points, do not leave the reader with a comprehensive understanding of the problem or it's associated impacts.  If within the scope, I believe this review has the unique opportunity to include such an analysis by including an analysis of ZDC in Latin America in a country by country manner from the WHO and UNICEF Estimates of National Immunization Coverage (WUENIC), 2023 revision report. . Approaching the evaluation of ZDC in Latin America in the way could highlight not only the countries where interventions are most needed, but also highlight countries that have effectively reduced the proportion of ZDC which could in turn suggest or inform the section on possible solutions. While the estimates in this report come with limitations, the authors appear to be well-qualified to offer an expert interpretation and discussion of such limitations.  The prevalence of vaccine preventable diseases in Latin America is mentioned in several places throughout the review and similar to the comment above, including a comprehensive analysis of prevalence estimates of vaccine preventable diseases would strengthen this review and offers the opportunity to examine how ZDC rates and vaccine preventable disease rates intersect.  In the section entitled \"Risk focus evaluation of decision-making interventions for dose-zero children in Latin America\". I believe the goal of this section is to summarize how data can be used to prioritize and target interventions for ZDC across Latin America. I agree that the discussion of drop-out is very important and a key factor beyond ZDC that should be included. This could be analyzed by looking at the rates DPT1 and DPT3 by country in the WUENIC report and would be a fascinating adjunct that has the potential to highlight distinct barriers by country.  There is a brief mention of the impact of the covid-19 pandemic on vaccination rates, that is also apparent in the data on vaccine rates. It would be interesting to discuss the impact in terms the decrease in vaccination rates during the pandemic, as well as the rate of catch-up by country. The important topic of vaccine hesitancy is also mentioned and is interesting as it contradicts the assumption that ZDC is largely driven by lack of access. Is vaccine hesitancy thought to be a driver of ZDC in Latin America?  The authors highlight the key role of Advances in National Immunization Technical Advisory Groups (NITAGs) in Latin America. As well as barriers faced by NITAGs. This is an important topic and offers useful information. This section could be strengthened by including more detailed information on the countries with and without NITAGs, as well as include references for some of the statements in this section.  The final section highlights broad recommendations of the SLIPE  to improve immunization rates and decrease the number of ZDC in Latin America. These recommendations are fairly common-sense and apply to vaccination efforts throughout the world. This impact of this section could be increased by placing these recommendations in the context of the existing landscape of ZDC in Latin America  and highlighting region specific or country specific barriers.  Overall, this review offers information on a crucial public health issue of ZDC in Latin America. My recommendations for approval would be to include a more comprehensive analysis of the problem leveraging the UNCEIF and WHO data and to provide more focused  recommendations on the particular barriers facing Latin American countries.  Is the topic of the opinion article discussed accurately in the context of the current literature? Partly  Are all factual statements correct and adequately supported by citations? No  Are arguments sufficiently supported by evidence from the published literature? Partly  Are the conclusions drawn balanced and justified on the basis of the presented arguments? Partly",
         "0.763",
         "2",
         "0",
         "0.1611886724386724",
         "0.2025",
         "0.9255359768867492",
         "27.15",
         "16.2",
         "15.48",
         "17.3",
         "17.7",
         "99",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "4.0",
         "6.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "3",
         "3.0",
         "4.0",
         "4.0",
         "64.0",
         "64"
        ],
        [
         "37",
         "Yoesoep Edhie Rachmad",
         "27 Nov 2024",
         "Approved",
         "1273",
         "Does Brand Attitude Complement Influencer Credibility in Shaping Purchase Intention of Indian GenZ Consumers?",
         "Introduction The social media landscape has undergone radical changes and has revolutionized consumer perspectives, purchasing habits, and behaviors. Amidst this emerging trend is the rise of influencer marketing and its impact on the purchase intentions of followers. The objective is to explore the characteristics of influencers that contribute to their credibility. This research aims to explore the role of consumers’ attitude toward brands on their intention to adopt brands endorsed by influencers.  Methods This cross-sectional research was undertaken among GenZ in the urban landscape of India. Data collected was analyzed using SmartPLS4 software.  Findings Trust, expertise, and similarity were the significant antecedents of the formation of influencer credibility. Attractiveness did not have a significant influence on influencer credibility. A complementary partial mediation of Attitude towards a brand is observed in the association between influencer credibility and the purchase intention of followers. Attitude towards the video also had a significant positive influence on purchase intention.  Conclusion The study found that Gen Z places little importance on an influencer’s attractiveness, as it has no significant impact on credibility. However, attitude toward the brand strongly influenced purchase intention and partially mediated the relationship between influencer credibility and purchase intention.",
         "19",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Submission ID  : 2024_IJWOE-237645 Title  :  Does Brand Attitude Complement Influencer Credibility in Shaping Purchase Intention of Indian GenZ Consumers? Authors  :  Pranav Vilas Chavare, Smitha Nayak, Ramona Birau, Varalakshmi Alapati. Journal  : F1000Research 2024, 13:1343 Last updated: 13 NOV 2024 Dear Authors,  Thank you for your submission of the manuscript titled \"Does Brand Attitude Complement Influencer Credibility in Shaping Purchase Intention of Indian GenZ Consumers?\" This study offers a valuable and timely contribution to the field of influencer marketing, particularly in the context of Generation Z consumers in India. The research methodology, findings, and theoretical implications are well-articulated. However, I would like to suggest a few areas for improvement to further enhance the manuscript’s clarity, impact, and contribution. Feedback and Suggestions Clarity in Presentation Detailed Explanations: While the methodology section is robust, additional explanations regarding the choice of a five-point Likert scale and its appropriateness in this context would enhance understanding. Consider including a justification for its use over other scales. Figures and Tables: Some figures and tables, such as the structural model and hypothesis testing results, could benefit from clearer captions or legends. For example, explicitly defining significance levels (e.g., p values) directly in the table or figure notes would improve readability. Data Accessibility and Reproducibility Data Sharing: It is commendable that the dataset is available on Figshare under a Creative Commons license. However, it may be beneficial to provide an appendix or a supplementary section with detailed instructions on how to access and use the dataset for replication studies. Discussion and Implications Comparative Context: The discussion section could be expanded to include comparisons with similar studies in other regions or demographic groups. This would contextualize the findings and highlight their generalizability. Practical Applications: Including examples of how brands or marketers can apply these findings to develop effective influencer strategies would increase the manuscript's practical utility. Future Research Directions Content and Product Categories: The study would benefit from a clearer acknowledgment of its limitations regarding generalizations across different content types or product categories. Suggestions for future research in these areas could provide valuable guidance for subsequent studies. Minor Corrections Consistency in Terms: Ensure all technical terms are consistently defined throughout the manuscript. For instance, maintaining uniform terminology for constructs like “trust,” “expertise,” and “credibility” will aid comprehension. Grammar and Typographical Errors: A few minor typographical errors were noted. A careful review of the manuscript will help ensure overall accuracy and readability. Overall, this manuscript represents a significant contribution to the literature on influencer marketing and consumer behavior. The innovative approach and detailed analysis are commendable, and I am confident that with these refinements, the paper will achieve even greater impact. Thank you for the opportunity to review this work. I look forward to the revised version. Best regards, Prof. Dr. Yoesoep Edhie Rachmad Reviewer Submission ID  : 2024_IJWOE-237645 Title  :  Does Brand Attitude Complement Influencer Credibility in Shaping Purchase Intention of Indian GenZ Consumers? Authors  :  Pranav Vilas Chavare, Smitha Nayak, Ramona Birau, Varalakshmi Alapati. Journal  : F1000Research 2024, 13:1343 Last updated: 13 NOV 2024  Dear Editor,  The manuscript titled \"Does Brand Attitude Complement Influencer Credibility in Shaping Purchase Intention of Indian GenZ Consumers?\" presents a compelling study that contributes significantly to the growing field of influencer marketing and its impact on consumer behavior, specifically within the context of Generation Z in India. While the research demonstrates robust methodology and meaningful findings, there are a few areas that I would recommend addressing to enhance the overall clarity and impact of the manuscript: Key Points for Consideration Clarity and Accessibility in Methodology: The study employs PLS-SEM to test hypotheses effectively. However, for a broader audience, providing additional context or illustrative examples regarding the structural model and key metrics (e.g., significance thresholds) would increase clarity and accessibility.  Data Availability and Reproducibility: While the authors commendably provide access to the dataset on Figshare, it may be beneficial to suggest including explicit guidance or links in an appendix to facilitate easier replication by future researchers.  Discussion of Findings and Generalizability: The discussion section could be expanded to compare the findings with similar research across different demographics or industries. Highlighting potential applications of the study's insights in other regions or sectors would underscore its broader relevance.  Practical Implications: The paper makes significant theoretical contributions. To balance this, elaborating on how brands can implement these findings to design effective influencer campaigns could enhance the manuscript’s practical utility.  Future Research Directions: The limitations section briefly mentions opportunities for future work. However, more detailed suggestions, such as examining content types or distinguishing between macro- and micro-influencers, would provide valuable guidance for subsequent research in this field. Overall Recommendation The manuscript offers a valuable addition to the literature on influencer marketing and consumer behavior. Addressing the points above through minor revisions would further strengthen its impact and readability. Thank you for the opportunity to review this manuscript. I look forward to seeing its refined version. Best regards, Prof. Dr. Yoesoep Edhie Rachmad Reviewer  Submission ID  : 2024_IJWOE-237645 Title  :  Does Brand Attitude Complement Influencer Credibility in Shaping Purchase Intention of Indian GenZ Consumers? Authors  :  Pranav Vilas Chavare, Smitha Nayak, Ramona Birau, Varalakshmi Alapati. Journal  : F1000Research 2024, 13:1343 Last updated: 13 NOV 2024  I recommend Minor Revisions for the manuscript titled \" Does Brand Attitude Complement Influencer Credibility in Shaping Purchase Intention of Indian GenZ Consumers?\". Justification for Recommendation:  Innovative Approach: The manuscript provides an insightful examination of influencer credibility and its impact on purchase intention, particularly in the context of Generation Z in India. The integration of trust, expertise, and similarity in assessing influencer credibility adds a significant contribution to the literature on consumer behavior.  Clarity and Detail: The study uses advanced methodologies such as PLS-SEM, which are well-documented. However, the manuscript would benefit from additional intuitive examples or explanations for readers less familiar with this approach. Adding more visuals or diagrams, particularly in the methodology section, could enhance clarity.  Data Accessibility: While the dataset is made publicly available through Figshare, the authors should provide additional guidance or references for accessing and utilizing the data to support reproducibility.  Discussion and Practical Implications: The discussion section is thorough but could be expanded with a stronger emphasis on practical applications. For instance, the authors could elaborate on how brands can leverage the findings to design effective influencer marketing campaigns.  Minor Corrections: Some typographical errors and inconsistencies in the use of technical terms were noted. Ensuring uniformity in terminology and addressing these minor errors will improve the manuscript's readability. Conclusion: This manuscript is a valuable contribution to the understanding of influencer marketing and consumer behavior. The proposed revisions are minor and intended to enhance the manuscript's clarity, practical relevance, and broader impact. I look forward to reviewing the revised version. Best regards, Prof. Dr. Yoesoep Edhie Rachmad Reviewer  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.8516",
         "1",
         "0",
         "0.1733818770226536",
         "0.8769",
         "0.8670296669006348",
         "10.91",
         "16.2",
         "13.17",
         "17.0",
         "17.3",
         "81",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "4.0",
         "3.0",
         "yes",
         "positive",
         "polite",
         "2",
         "4",
         "4.0",
         "5.0",
         "5.0",
         "82.0",
         "82"
        ],
        [
         "38",
         "Meenakshi Sharma",
         "17 Dec 2024",
         "Approved",
         "451",
         "Does Brand Attitude Complement Influencer Credibility in Shaping Purchase Intention of Indian GenZ Consumers?",
         "Introduction The social media landscape has undergone radical changes and has revolutionized consumer perspectives, purchasing habits, and behaviors. Amidst this emerging trend is the rise of influencer marketing and its impact on the purchase intentions of followers. The objective is to explore the characteristics of influencers that contribute to their credibility. This research aims to explore the role of consumers’ attitude toward brands on their intention to adopt brands endorsed by influencers.  Methods This cross-sectional research was undertaken among GenZ in the urban landscape of India. Data collected was analyzed using SmartPLS4 software.  Findings Trust, expertise, and similarity were the significant antecedents of the formation of influencer credibility. Attractiveness did not have a significant influence on influencer credibility. A complementary partial mediation of Attitude towards a brand is observed in the association between influencer credibility and the purchase intention of followers. Attitude towards the video also had a significant positive influence on purchase intention.  Conclusion The study found that Gen Z places little importance on an influencer’s attractiveness, as it has no significant impact on credibility. However, attitude toward the brand strongly influenced purchase intention and partially mediated the relationship between influencer credibility and purchase intention.",
         "39",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Detailed Explanation: The narrative style of the paper is scientific. The paper has a high degree of clarity and is focused. It contributes to the body of knowledge in the marketing domain, especially in the context of GenZ. It has been clearly articulated. Figures and Tables: All figures and tables are in order and have an intext mentioned at appropriate places. Consistent with the paper's objective, the tables provide an overview of major findings. Methodology: The methodology section is well drafted and captures the process appropriately. However, the authors are advised to explain the sample size estimation process in detail. This will strengthen the methodology section. There appears to be an error in the data measurement section. Relook at the “5-5 point likert scale”. In the pilot testing section “Similarity with the Influencer was below the threshold value of 0.7. In social science research, a construct with a Cronbach alpha above 0.6 in a pilot study could be retained as it is expected the increase with an increment in sample size. Hence the research team decided to retain the construct and explore it further during the final data analysis phase.” Authors are advised to include a  citation for this. Data sharing: data is shared on Figshare and incorporated in the manuscript. Discussion and Directions for future direction: The discussion section is well drafted and provides a comparison to previously published literature at appropriate places. A few grammatical errors are observed, Authors are advised to relook and incorporate corrections. Eg.. A sentence starts with “To address ……..”; Typo errors like 3.6….Cronbach alpha of all constructs of the study was above o.7 etc. Authors are advised to take a relook at the paper and incorporate the suggestions presented above. The paper maybe accepted for indexing as it is written well and contributes to the body of knowledge of management science.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7312",
         "1",
         "0",
         "0.1452350427350427",
         "0.0999",
         "0.7688331604003906",
         "39.84",
         "11.3",
         "11.93",
         "12.5",
         "11.4",
         "99",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "5.0",
         "3.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "4.0",
         "5.0",
         "85.0",
         "85"
        ],
        [
         "39",
         "Mohammad Rakibul Islam Bhuiyan",
         "04 Feb 2025",
         "Approved With Reservations",
         "717",
         "An extension of Trust and TAM model with TPB in the adoption of digital payment: An empirical study in Vietnam",
         "Background Digital payment systems are pivotal in the digital economy, relying on the interplay between internet technology and e-vendors. This study seeks to explore acceptance behaviors regarding digital payments by employing an extended version of the Trust and Technology Acceptance Model (TAM) and incorporating the Theory of Planned Behavior (TPB).  Methods We conducted a qualitative analysis using interview data from 509 respondents and applied Structural Equation Modeling (SEM) to evaluate the relationships between key variables. The extended model allows for a comprehensive examination of both technological and trust-related factors influencing adoption.  Results Our analysis revealed that all standardized path coefficients were positively significant, except for the path from perceived usefulness (PU) to attitude (ATT). The findings confirm that while digital payments are primarily driven by Internet and communication technologies, addressing trust-related issues is essential for enhancing user adoption. The TAM identifies perceived usefulness and perceived ease of use, alongside trust, as critical factors affecting behavioral intention. In the TPB framework, trust significantly impacts digital payment adoption through mediators such as attitude, perceived behavioral control, and subjective norm.  Conclusions This study enhances our understanding of the factors influencing digital payment adoption, emphasizing the need to address both technological and trust issues. The insights gained provide valuable recommendations for increasing the use of digital payment systems, particularly in the Northern mountainous regions of Vietnam, thereby fostering greater financial inclusion and economic growth.",
         "8",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  1. Overall Evaluation: The paper titled \"An extension of Trust and TAM model with TPB in the adoption of digital payment: An empirical study in Vietnam\" presents a timely and relevant study on digital payment adoption, with a particular focus on Vietnam. The study contributes to the body of knowledge by integrating the Trust Model, the Technology Acceptance Model (TAM), and the Theory of Planned Behavior (TPB) in a comprehensive framework. However, there are several areas where revisions are needed to improve the clarity, depth, and completeness of the research. 2. Clarity and Precision of the Presentation: The paper is generally well-written but could benefit from further refinement in some sections, particularly in the literature review and the interpretation of results. The connection between the theoretical models (Trust, TAM, TPB) could be more clearly articulated, specifically how they complement each other in the context of digital payment adoption. The introduction could also be expanded to better emphasize the research gap and the study’s contribution to the field. 3. Literature Review and Citations: While the paper cites some foundational studies, it is noticeably lacking in recent references (2022-2025). The literature review should be updated to include more recent research on digital payment adoption, especially considering the rapidly evolving nature of the digital payment landscape. Relevant studies on the impact of trust, technology acceptance, and behavioral intentions in digital finance should be integrated to strengthen the paper’s theoretical foundation. 4. Methodology and Analysis: The methodology is generally sound, but more detail is needed to clarify certain aspects of the research design. For example, the sampling process and sample size justification should be provided more thoroughly. Additionally, the survey instrument used to collect data could benefit from a more detailed explanation of its validation process. The use of structural equation modeling (SEM) is appropriate, but the model could be more thoroughly explained, particularly with regard to the measurement model and the path coefficients. 5. Statistical Analysis: The statistical analysis is partly addressed, but there are areas for improvement. It would be helpful to provide more detailed explanations of how the validity and reliability of the constructs were assessed. Additionally, further discussion of the model fit indices and how they support the hypotheses would strengthen the analysis. A clearer discussion of the limitations of the model would also be beneficial. 6. Contribution to the Field: The paper makes a solid contribution to understanding digital payment adoption in Vietnam, but the proposed model’s novelty and value would be more apparent with some improvements in the literature review, methodology, and analysis sections. Once these issues are addressed, this paper could provide important insights into how trust, technology acceptance, and behavioral intentions influence digital payment adoption in emerging economies like Vietnam. 7. Recommendations for Revision: Literature Update: Add more recent citations (2022-2025) to reflect the latest developments in the digital payment domain. Methodology: Provide more details on the sampling procedure, sample size justification, and survey instrument validation. Statistical Analysis: Clarify the SEM approach, provide more details on model fit indices, and discuss how the statistical findings relate to the hypotheses. Theoretical Framework: Strengthen the explanation of how the integrated model (Trust, TAM, and TPB) contributes to the field of digital payment adoption, and clarify the relationships between the constructs. Once the above points are addressed, this paper has the potential to contribute significantly to the literature on digital payment adoption, particularly in the context of developing countries like Vietnam.  Is the work clearly and accurately presented and does it cite the current literature? No  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7779",
         "7",
         "0",
         "0.1981292517006803",
         "0.0999",
         "0.9557458758354188",
         "14.9",
         "16.7",
         "15.49",
         "17.4",
         "17.4",
         "98",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "2.0",
         "62.0",
         "62"
        ],
        [
         "40",
         "Harry R. Yucra-Condori",
         "13 Jan 2025",
         "Approved With Reservations",
         "606",
         "Assessment of heavy metal contamination in fish, fruits, and vegetables in Southwest Nigeria: A systematic review",
         "Background The aim of this systematic review was to investigate the prevalence of heavy metal contamination in fish, fruits, and vegetables in Southwest Nigeria. The review focused on studies published over a ten-year period, between 2014 and 2024.  Methods Articles used for the study were obtained by conducting a comprehensive literature search using several databases, including ResearchGate, Scopus, Google Scholar, ScienceDirect, and PubMed using Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRISMA). To identify relevant studies, a plethora of keywords were utilized to search for articles in the selected databases, including. Articles reporting heavy metal contamination in specified food products within the last decade were included.  Results Of the 10,212 initially identified articles, 64 met the inclusion criteria after thorough screening. The selected studies were predominantly conducted in Lagos (30), Ondo (8), and Ogun (7) states, with few studies in Oyo, Ekiti, and Osun states. The majority of the research focused on fish (40 studies), followed by vegetables (20) and fruits (4). The commonly studied fish species were observed to be Tilapia zilli, Chrysichthys nigrodigitatus, Clarias gariepinus, and Oreochromis niloticus, with heavy metal concentrations frequently exceeded WHO limits.  Conclusions Therefore, this review highlights the significant risks posed by the presence of heavy metals in food products and underscores the importance of stringent environmental monitoring and the adoption of appropriate regulatory mechanisms for health and environmental risk mitigation. This could help in the formulation of appropriate policy implementation strategies geared towards mitigating heavy metal contamination in the region’s food supply.",
         "48",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Report Systematic Review of Heavy Metal Contamination in Fish, Fruits, and Vegetables in Southwestern Nigeria (2014-2024) Abstract This comprehensive systematic review meticulously examines heavy metal contamination in fish, fruits, and vegetables in southwestern Nigeria over the decade spanning 2014-2024. The researchers conducted an exhaustive search across multiple scientific databases, rigorously selecting 64 studies that met specific inclusion criteria. Key Findings The analysis reveals alarming levels of contamination, particularly by lead, cadmium, chromium, and zinc, in various fish species and some vegetables, frequently exceeding the limits established by the World Health Organization (WHO). Although less extensively studied, fruits also exhibited a degree of contamination. Methodology Enhancement Recommendations Research Foundation and Objectives Formulate specific objectives and clear research questions. Provide a detailed justification for the selection of the 2014-2024 study period. Methodological Approach and Data Analysis Delineate the complete search strategy for at least one database. Specify the study selection process, including the number of reviewers at each stage. Describe data extraction and synthesis methodologies. Incorporate a quality assessment or risk of bias evaluation for included studies. Conclusion Formulation Explicitly link conclusions to the presented data. Discuss the quality and consistency of the evidence. Address limitations of both included studies and the review itself. Additional Considerations Health Risk Assessment: Conduct a more rigorous analysis considering exposure levels and consumption patterns, utilizing guidance from articles such as: Román-Ochoa Y, et al., 2021 (Ref 1) Choquenaira-Quispe C, et al., 2022 (Ref 2)  Inter-Study Variability: Discuss potential reasons for observed discrepancies. Practical Implications: Address consequences for consumers and public health authorities. Sensitivity Analysis: Consider including an assessment of evidence certainty (e.g., using GRADE methodology). Keywords: Review relevance to facilitate web-based identification of the review. Figure 1: Include a brief justification for selection criteria and the number of participating reviewers. Cereal Inclusion: Justify the exclusion of cereals, considering their importance in local diets as evidenced by studies such as: Sowunmi F, et al., 2020 (Ref 3) Ikudayisi A, 2020 (Ref 4) Otemuyiwa IO, et al., 2012 (Ref 5)  Results Presentation Uniformity: Standardize the presentation of concentration data across all sections (fish, vegetables, and fruits). Table Structure: Uniformize format, including units, complete row numbering, WHO maximum values, and justify the absence of references in some rows. Legends and Abbreviations: Include explanations for BDL, ND, and clarify terms such as \"Si\" and \"exceeds limit\" in the WHO limits column. Geographic Information: Add a column in tables identifying the specific study region. Data Format: Standardize the number of decimal places and metal nomenclature (acronyms or full names). Article Accessibility: Identify the quantity of open access and subscription articles utilized. It is suggested to provide quantitative summaries of contamination levels by food type and metal (ranges, medians).  Are the rationale for, and objectives of, the Systematic Review clearly stated? Partly  Are sufficient details of the methods and analysis provided to allow replication by others? Partly  Is the statistical analysis and its interpretation appropriate? Not applicable  Are the conclusions drawn adequately supported by the results presented in the review? Partly  If this is a Living Systematic Review, is the ‘living’ method appropriate and is the search schedule clearly defined and justified? (‘Living Systematic Review’ or a variation of this term should be included in the title.) Not applicable",
         "0.8323",
         "1",
         "0",
         "0.0758333333333333",
         "0.0999",
         "0.954321026802063",
         "12.53",
         "15.6",
         "16.06",
         "16.3",
         "16.2",
         "90",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "1.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "2.0",
         "72.0",
         "72"
        ],
        [
         "41",
         "Saad Salih Hussein",
         "03 Feb 2025",
         "Approved",
         "534",
         "Artificial Intelligence and Finance: A bibliometric review on the Trends, Influences, and Research Directions",
         "Background This bibliometric study examines the intersection of artificial intelligence (AI) and finance, providing a comprehensive analysis of its evolution, central themes, and avenues for further exploration. The study aims to uncover the theoretical foundations, methodological approaches, and practical implications of AI in financial contexts.  Methods The research employs bibliometric techniques, using 607 Web of Science (WoS) indexed papers. The Theory-Context-Characteristics-Methodology (TCCM) framework guides the analysis, focusing on thematic mapping to explore key topics. Core areas such as risk management, market efficiency, and innovation are analyzed, alongside emerging themes like ethical AI, finance applications, and factors influencing AI-driven financial decision-making.  Results The findings reveal critical gaps in interdisciplinary methods, ethical considerations, and methodological advancements necessary to develop robust and transparent AI systems. Thematic mapping highlights the increasing importance of ethical AI practices and the influence of AI on financial decision-making processes. Emerging research areas emphasize the need for innovative frameworks and solutions to address current challenges.  Conclusions This study provides valuable insights for academics, industry practitioners, and policymakers to harness transformative potential of AI in finance. This research offers a foundation for future studies and practical applications by addressing key gaps and promoting interdisciplinary and ethical approaches in a rapidly evolving field.",
         "11",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This article discusses a new aspect of the relationships between Artificial intelligence and finance, it gives, therefore, a rule of thump to the literature on accounting and finance, the researchers have used a sufficient amount of background articles to support their argument to prove the relationship between the main variables of this study, it is thus, this article has written carefully in the right path with all supported evidence to complete the paper argument. Summary of the Article The article provides a comprehensive bibliometric analysis of the intersection of artificial intelligence and finance, shedding light on its evolution, central themes, and potential research avenues which is welcoming. The study uses 607 Web of Science indexed papers and follows the Theory-Context-Characteristics-Methodology (TCCM) framework which is commendable. The research highlights key themes such as risk management, market efficiency, innovation, and emerging areas like ethical AI and AI-driven financial decision-making. The findings emphasize critical gaps in interdisciplinary methodologies, ethical considerations, and the need for more transparent AI systems in financial applications. Strengths of the Article Comprehensive Scope – The study successfully maps the evolution of AI in finance, providing a well-structured thematic analysis. Robust Methodology – The use of bibliometric techniques and the TCCM framework adds rigor to the research, ensuring a systematic approach. Relevance to Academia and Industry – The findings are valuable for researchers, practitioners, and policymakers, offering insights into the transformative role of AI in finance. Identification of Key Gaps – The study highlights crucial research gaps, particularly in ethical AI and methodological advancements, making it a strong foundation for future research. Major Points for Improvement 1. Expanding Practical Implications through empirical research– The findings highlight key trends in AI adoption within finance; however, further elaboration on the direct industry applications of these insights would enhance the study’s practical relevance. Providing specific examples of AI’s role in areas such as credit risk assessment, fraud detection, portfolio management, and regulatory compliance could help bridge the gap between research and practice. Minor Points for Improvement 1. Incorporating Recent Literature – The study is well-grounded in existing research; however, integrating more recent publications (2023–2025) would further enhance its timeliness. Including the latest studies on AI applications in finance, particularly in ethical AI and regulatory advancements, would ensure the findings remain current and relevant. Nevertheless, the article can be accepted for indexing in bibliographic databases.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7996",
         "1",
         "0",
         "0.125159632034632",
         "0.0999",
         "0.9665930271148682",
         "14.29",
         "17.0",
         "17.82",
         "18.1",
         "18.9",
         "101",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "5.0",
         "4.0",
         "3.0",
         "86.0",
         "86"
        ],
        [
         "42",
         "Rajeev Semwal",
         "04 Feb 2025",
         "Approved",
         "1204",
         "Artificial Intelligence and Finance: A bibliometric review on the Trends, Influences, and Research Directions",
         "Background This bibliometric study examines the intersection of artificial intelligence (AI) and finance, providing a comprehensive analysis of its evolution, central themes, and avenues for further exploration. The study aims to uncover the theoretical foundations, methodological approaches, and practical implications of AI in financial contexts.  Methods The research employs bibliometric techniques, using 607 Web of Science (WoS) indexed papers. The Theory-Context-Characteristics-Methodology (TCCM) framework guides the analysis, focusing on thematic mapping to explore key topics. Core areas such as risk management, market efficiency, and innovation are analyzed, alongside emerging themes like ethical AI, finance applications, and factors influencing AI-driven financial decision-making.  Results The findings reveal critical gaps in interdisciplinary methods, ethical considerations, and methodological advancements necessary to develop robust and transparent AI systems. Thematic mapping highlights the increasing importance of ethical AI practices and the influence of AI on financial decision-making processes. Emerging research areas emphasize the need for innovative frameworks and solutions to address current challenges.  Conclusions This study provides valuable insights for academics, industry practitioners, and policymakers to harness transformative potential of AI in finance. This research offers a foundation for future studies and practical applications by addressing key gaps and promoting interdisciplinary and ethical approaches in a rapidly evolving field.",
         "12",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  1. Is the work clearly and accurately presented and does it cite the current literature? Response: Yes Explanation: The paper is well-structured and provides a comprehensive review of the intersection between artificial intelligence (AI) and finance. The presentation follows a logical flow, beginning with an introduction to AI's impact on finance, a review of relevant literature, a detailed discussion of the bibliometric methodology, and a structured analysis using the TCCM framework. The paper effectively conveys its objectives, research questions, and findings without excessive complexity. The citations include a mix of foundational theories (e.g., Efficient Market Hypothesis, Decision Theory) and contemporary research, ensuring that the literature review remains current and relevant. The use of bibliometric tools such as VOSviewer and Bibliometrix further strengthens the credibility of the study, providing a systematic analysis of publication trends, key authors, and influential works. Recommendation: The clarity of the paper is commendable, and no major revisions are needed in terms of structure or citation quality. However, the introduction could benefit from a more concise summary of the key bibliometric trends identified, helping readers quickly grasp the significance of the study. Additionally, while the literature cited is extensive, the authors could briefly acknowledge any limitations related to potential publication bias, particularly the exclusion of non-English and non-Web of Science indexed studies. 2. Is the study design appropriate and is the work technically sound? Response: Yes Explanation: The study employs a robust bibliometric approach, which is a widely accepted method for identifying research trends and knowledge gaps in a given domain. The authors use a well-defined process for data collection, screening, and analysis, ensuring methodological rigor. The adoption of the TCCM framework provides a structured way to categorize existing research based on theoretical perspectives, contextual applications, methodological approaches, and key characteristics. This framework enhances the study’s depth by not only mapping existing literature but also proposing future research directions. The reliance on the Web of Science (WoS) database ensures access to high-impact, peer-reviewed publications, lending credibility to the findings. The use of bibliometric tools (Bibliometrix and VOSviewer) for co-citation analysis, keyword mapping, and research impact assessment adds further technical validity. Recommendation: While the study design is appropriate, the authors could briefly discuss any potential biases associated with bibliometric analysis. For example, the exclusion of conference papers and preprints could mean that some emerging research trends are not captured. Additionally, acknowledging any limitations related to the reliance on citation metrics (which can be influenced by journal impact factors rather than intrinsic research quality) would enhance transparency. 3. Are sufficient details of methods and analysis provided to allow replication by others? Response: Partly Explanation: The paper outlines the methodology in a structured manner, detailing the data collection process, the use of specific bibliometric tools, and the screening process for relevant articles. The inclusion of a three-step selection process (identification, screening, and final inclusion) ensures clarity in how studies were chosen. However, some critical details are missing that could impact replication. For instance, the exact parameters used in VOSviewer for network visualization (e.g., clustering thresholds, link strength criteria) are not mentioned. Similarly, while the TCCM framework is referenced, it is unclear how the classification of studies into its four components was conducted—was it manually coded, or was a software-assisted text analysis used? Recommendation: The authors should provide additional methodological details to enhance replicability. Specifically, they should: Include a more detailed description of how bibliometric data was cleaned and processed. Specify the exact search terms and filters used in Web of Science.  4. If applicable, is the statistical analysis and its interpretation appropriate? Response: Yes Explanation: The statistical analysis used in the paper is appropriate for a bibliometric review. The study effectively utilizes co-citation networks, citation count analysis, and research trend evaluations to identify influential works and key research domains. The thematic evolution analysis, which traces how AI and finance research has developed over time, is particularly useful in highlighting emerging research trends. The authors also provide a Sankey diagram to illustrate shifts in research focus, adding a strong visual representation of the field’s progression. The citation-based benchmarking approach used to identify high-impact studies is an established method in bibliometrics, and the interpretation of these results aligns well with broader trends in AI and finance. Recommendation: No major revisions are required for the statistical analysis. However, the authors could improve the discussion by briefly addressing potential limitations of citation-based impact metrics. For example, some highly cited papers might be review articles rather than empirical studies, and self-citations could also influence citation counts. Including a short paragraph on such limitations would add nuance to the discussion. 5. Are all the source data underlying the results available to ensure full reproducibility? Response: Yes Explanation: The study ensures transparency by making its dataset publicly available on Zenodo, with a provided DOI link. This allows other researchers to access the raw bibliometric data used in the analysis, facilitating reproducibility. The inclusion of citation details, thematic mappings, and network visualizations further supports the integrity of the study. Additionally, the authors utilize widely accepted bibliometric tools (VOSviewer and Bibliometrix) for analysis, making it easier for others to replicate their methodology. The structured approach to data selection, processing, and screening ensures that all source materials are well-documented. Recommendation: While data accessibility is well-addressed, the authors could enhance reproducibility by Providing a step-by-step guide or supplementary material outlining how to replicate the analysis using the shared dataset. Clarifying whether any pre-processing scripts or software configurations (e.g., parameter settings in VOSviewer) are included in the repository. 6. Are the conclusions drawn adequately supported by the results? Response: Partly Explanation: The conclusions summarize the study’s key findings well and highlight important research gaps. The identification of future research directions is particularly useful, as it provides a roadmap for scholars interested in AI and finance. However, while the paper discusses research gaps and trends, it does not sufficiently address practical implications for financial institutions, policymakers, or industry practitioners. Given the relevance of AI in real-world financial applications, a discussion on how financial institutions can use these insights would enhance the paper’s impact. Additionally, the ethical implications of AI in finance—such as bias in AI-driven decision-making and the risks of algorithmic trading—are briefly mentioned but not explored in depth. Recommendation: Expand the discussion on practical implications for financial decision-makers and policymakers. Provide a clearer link between the identified research gaps and potential industry applications.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.8177",
         "6",
         "0",
         "0.1332148962148962",
         "0.0999",
         "0.945265293121338",
         "18.86",
         "15.2",
         "13.61",
         "16.3",
         "17.2",
         "97",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "5.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "No Hedging",
         "somewhat specific",
         "4.0",
         "3.0",
         "4.0",
         "80.0",
         "90"
        ],
        [
         "43",
         "Camille Paynter",
         "23 Mar 2024",
         "Approved With Reservations",
         "1044",
         "'It’s become a theatre’: relational experiences of family carers and people with Amyotrophic lateral sclerosis (ALS) after cognitive impairment emerges",
         "Background:  Amyotrophic lateral sclerosis (ALS) can lead to emotional and psychological distress between patients and their family carers. Many people with ALS develop cognitive impairment, which limits their ability to process complex information, interact, and communicate. This cognitive decline adds to caregiver burden. Few studies have explored interpersonal relations between people with ALS and their carers. Aim:  To better understand how ALS-associated cognitive impairment influences close relations. Methods:  Individual semi-structured in-depth, interviews were conducted once, with four patients and four family carers. Thematic analysis was used. Results:  Increased distance of close relations was identified as the core theme. Differences and similarities within the data were identified according to the subthemes, (1) Everyday life together but apart: a demanding role to play, and (2) Coping with a lost future: living in the ‘normal’ present and searching for hope through a well-lived life. Conclusions and significance:  Cognitive impairment following ALS can lead to increased relational distance between patients and their family carers. To ease their burden, professionals should recognize patients’ and carers’ relational issues and grief at an early stage. Focusing on their occupational identity and highly valued occupations that are still-accessible may help patients and carers regain meaning in everyday life.",
         "204",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Thank you for the opportunity to review this manuscript. The authors present important work in the area of ALS, and how people living with ALS and their family carers react to cognitive change. This is important work especially in the context of clinical advances in understanding the cognitive sequalae of ALS and the impact it has for those affected by ALS. The manuscript presents interesting, qualitative research. The manuscript would benefit from some minor written/typographical refinement or reorganisation, clarification and/or revision in relation to the methodology, a review of the results section to provide data to support findings and support the development of themes. The Discussion section is lengthy and would benefit from editing and revision. Suggestions are provided. General Authors may wish to consider their use of “patients”. “People living with ALS” is ‘person-first’ language and is recognised as a recommended way to speak about people with or about disability. Both “carers” and “family carers” are used throughout; consistent terminology would improve readability. Introduction The authors present a succinct introduction to the topic and provide a rationale for their study. The third paragraph would benefit from revision to improve clarity. The first sentence presents as slightly contradictory (starting with ‘unclear’ evidence although quite a lot has been published in the area of carer burden as the authors have referenced). The last two sentences require revising to clarify the authors’ intended meaning. Methods Design The authors are commended for reflecting on the paradigm underpinning their research. The reference #34 should be attributed to the qualitative design and not occupational science. Data analysis The authors report they used TA as set out by Braun and Clarke 2006. The authors may wish to consider reviewing Braun and Clarke’s more recent publications. Since the inaugural 2006 paper, Braun and Clarke have published a number of papers and book chapters to guide researchers in producing methodologically coherent TA and reflexive TA. I believe it will strengthen your paper if your approach to analysis more closely aligns with your theoretical positioning. The authors report the data analysis undertaken allowed “theoretical and epidemiological” flexibility, and describe that theory was connected to the data. This information relates to the study’s epistemology and methodology and would be appropriate to include in the ‘design’ section. However, an epidemiological approach does not seem congruent with Goffman. This reviewer is unfamiliar with Goffman and was unable to obtain the texts referenced, therefore this comment is based on brief online information available and I acknowledge may not be completely accurate. Regardless, not all readers will be familiar with Goffman therefore some clarification on the approach may be helpful for readers. The authors report the three topic areas of the interview and provide the interview guide as supplementary material which is always helpful for other researchers. It would be helpful to understand why the data regarding “healthcare in the early phases” is not included in your findings. Findings The Findings section would benefit from inclusion of more data (ie., rich descriptions) to support your findings. Often the findings are generalised to all participants and contain, what appears to be, interpretation of participants’ feelings (eg., describing participants as sad, rather than reporting what the participants said). The authors present thick information in the two themes which may benefit from the inclusion of sub-themes to improve readability. At times there is inconsistent emphasis given to examples. The second theme would benefit from further work to justify how the theme was developed from the data. It was difficult to identifying information related to ‘searching for hope through a well-lived life’. Discussion The authors have written a lengthy discussion which would benefit from editing and revision. It may be helpful to focus on three areas in the first instance. Firstly, the discussion introduces new information and topics regarding the findings from the interviews. Typically, a discussion focuses on explaining, evaluating and interpreting results and how they relate to the literature review, and do not introduce new information. Secondly, there seems to be an epistemological incongruity; the authors’ integration and evaluation of results using ‘epidemiology flexibility’ together with the anthropological and sociological stance of Goffman does not seem consistent and would benefit from explanation/clarification. The reviewer has already declared a lack of knowledge of Goffman however the reported views of disability as a ‘stigma’ does not appear (on face value) consistent with current opinions of inclusion. The link to the stated occupational therapy paradigm (ref Hitch et al 2014) in the methodology was not clear in the discussion. Lastly, the clinical symptoms of ALS, and the associated cognitive impairments described in the introduction were not clearly integrated in the discussion. I would also direct the authors to papers written by Paynter, Mathers, Gregory, Vogel & Cruice (2019-2022) [1] who explored the impact of communication and cognitive impairment on healthcare involvement for people living with MND and carers. Methodological considerations The reflexive information provided in this section may be more appropriate to include in the methods section. The strengths and limitations of the current study would be clearer for the reader. The authors may wish to consider editing the second last sentence to report “perspectives from people with ALS with cognitive impairment and carers” to more accurately reflect extant literature. Conclusions The authors’ report helpful clinical recommendations for allied health professionals. Congratulations to the authors for focusing on an important topic which may have application beyond ALS.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7839",
         "1",
         "1",
         "0.1408896658896659",
         "0.8817",
         "0.8645050525665283",
         "27.22",
         "14.1",
         "13.77",
         "15.4",
         "14.9",
         "101",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "3.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "92.0",
         "92"
        ],
        [
         "44",
         "Nicolò Zarotti",
         "12 Jun 2024",
         "Not Approved",
         "523",
         "'It’s become a theatre’: relational experiences of family carers and people with Amyotrophic lateral sclerosis (ALS) after cognitive impairment emerges",
         "Background:  Amyotrophic lateral sclerosis (ALS) can lead to emotional and psychological distress between patients and their family carers. Many people with ALS develop cognitive impairment, which limits their ability to process complex information, interact, and communicate. This cognitive decline adds to caregiver burden. Few studies have explored interpersonal relations between people with ALS and their carers. Aim:  To better understand how ALS-associated cognitive impairment influences close relations. Methods:  Individual semi-structured in-depth, interviews were conducted once, with four patients and four family carers. Thematic analysis was used. Results:  Increased distance of close relations was identified as the core theme. Differences and similarities within the data were identified according to the subthemes, (1) Everyday life together but apart: a demanding role to play, and (2) Coping with a lost future: living in the ‘normal’ present and searching for hope through a well-lived life. Conclusions and significance:  Cognitive impairment following ALS can lead to increased relational distance between patients and their family carers. To ease their burden, professionals should recognize patients’ and carers’ relational issues and grief at an early stage. Focusing on their occupational identity and highly valued occupations that are still-accessible may help patients and carers regain meaning in everyday life.",
         "285",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Thank you for asking me to review this article on relational experiences of family caregivers and people with ALS who experience cognitive impairments. The article would potentially be of interest for the field and the readership of the journal. However, I believe a number of major issues prevent it from being indexed at this stage: - The sample size is very limited. While large sample sizes are normally not required in thematic analysis, this study only enrolled 4 participants for each type (people with ALS and caregivers) to explore a construct (relational experiences) which is arguably conveyed fully only by dyadic data. In other words, the effective total sample size of this study is only of 4 'relational participants’, which is very unlikely to be sufficient to obtain data saturation or, in the authors' words, \"thick descriptions of individual experiences to reach an in-depth understanding of the participants’ situation\". Indeed, no actual justification or rationale is provided in favour of this sample size, apart from a vague sentence mentioning \"rich and detailed interview data\" before the data are even presented.  - The authors spend almost an entire page to describe how their analysis was carried out inductively, only to add a whole series of theoretical underpinnings in step five (i.e., Goffmans and DPM) which clearly made at least part of the analysis deductive. While TA allows for both inductive and deductive approaches to be carried out simultaneously, a significant lack of clarity (and potentially methodological understanding) transpires from the Methods section.  - Despite what the authors claimed, their data are in fact not rich. The Findings section is barely two pages long, covering only one overarching theme split into two sub-themes. If this is really all that emerged from the interviews, it is hard to believe it was not due to the very limited sample size. - The Discussion section is far longer than the Findings, which makes me wonder how the participants managed to draw so many points from such a limited data set.  Overall, the manuscript cannot be considered for indexing in its current limited form. The authors should carry out further in-depth interviews with additional participants and a more thorough data analysis, thus allowing for a more comprehensive and methodological robust contribution to the literature.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? No  Are sufficient details of methods and analysis provided to allow replication by others? No  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? No",
         "0.8116",
         "1",
         "0",
         "0.079008556547619",
         "0.6574",
         "0.8899228572845459",
         "30.6",
         "14.9",
         "15.91",
         "16.3",
         "16.1",
         "98",
         "0",
         "1",
         "0",
         "1",
         "2.0",
         "3.0",
         "4.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "2.0",
         "3.0",
         "3.0",
         "30.0",
         "34"
        ],
        [
         "45",
         "Keith Ford",
         "05 Feb 2025",
         "Approved",
         "212",
         "A Social Constructionist Influenced Scoping Review of Addictions, Deviance and Crime: Biopsychosocial Perspectives for the Emerging Forensic Mental Health Nursing and Healthcare Services of the Middle East",
         "Background Nurses and healthcare professionals employed in correctional and forensic mental health settings encounter unique challenges in the care of their patients due to custodial and restrictive environments. Regions within the Middle East, such as the United Arab Emirates and the Kingdom of Saudi Arabia, have recently experienced exponential economic and healthcare infrastructure development. Mental health has been prioritized for development by recent legislation and practice that incorporate the development of specialist forensic psychiatry services that mediate the need for specialized nurses and allied healthcare staff. Traditionally, forensic care has been provided by general services. The need to progress specialist forensic services with a focus on multidisciplinary staff that seeks to develop safer communities, enhance care, and support the criminal justice system.  Methods This review article aims to provide a foundation for the nuances of forensic staff through social constructionism. We adopted the framework of Arksey and O’Malley (2005). The use of a scoping review provides a better understanding of the compatibility, content, and outcomes to position the reader to the theoretical construct that society can be seen as existing in both objective and subjective reality.  Discussion This paper argues for the preparedness of thought understood through social constructionism and demonstrates that it is envisaged that any frequently repeated action becomes cast into a pattern that can be reproduced without much effort. The interconnectedness between the themes of addiction, deviance, and crime allows for a holistic overview and improved understanding for care providers and this was achieved through bio-psychosocial model.  Conclusion Through the emergence of these complex forms of knowledge, deviance within the lives of patients can be better understood by the emerging professions employed in the emerging forensic healthcare services within the Middle East. These individuals are carefully and dutifully navigating the cultural complexities of mental illness, addictions, and associated deviant behavior.",
         "14",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This is a thorough and comprehensive study addressing a very important and pertinent area of mental health. The scoping was sufficient and addresses the research question well. The methodology is clearly stated and is replicable for future studies if required and the conclusion draws the together findings nicely. Overall an important contribution to the body of knowledge.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes  If this is a Living Systematic Review, is the ‘living’ method appropriate and is the search schedule clearly defined and justified? (‘Living Systematic Review’ or a variation of this term should be included in the title.) Yes",
         "0.7279",
         "1",
         "0",
         "0.1588636363636364",
         "0.0999",
         "0.7747617959976196",
         "26.51",
         "14.4",
         "15.83",
         "15.7",
         "14.7",
         "102",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "3.0",
         "yes",
         "positive",
         "polite",
         "Moderate",
         "somewhat specific",
         "4.0",
         "5.0",
         "4.0",
         "90.0",
         "92"
        ],
        [
         "46",
         "Wei Feng",
         "07 Feb 2025",
         "Approved With Reservations",
         "484",
         "Magnitude and Factors Associated with Research Misconduct at Public University in Ethiopia: A Cross-Sectional Survey",
         "Background Research integrity, essential for ethical scientific research, has been inadequately addressed in Ethiopia, resulting in gaps in addressing misconduct like plagiarism, falsification and fabrication.  Methods An institutional-based cross-sectional study was conducted on a random sample of researchers. Data were collected via a self-administered, structured questionnaire, which was adapted from a similar study. The collected data were analysed using descriptive, bivariate, and multivariable logistic regression.  Result A total of 244 researchers participated in the study, resulting in an 82% response rate. In our study, 37.7% of participants reported engaging in at least one form of misconduct, 95% CI [31.6%, 44.1%]. Authorship misconduct was the most common form of self-reported misconduct (47.5%), 95% CI [41.1%, 54.0%], followed by fabrication and falsification (40.6%), 95% CI [34.4%, 47.0%]. Publication pressure was significantly associated with research misconduct (AOR = 3.18; 95% CI: [1.02, 9.95]).  Conclusion Research misconduct has profound implications, compromising the validity of scientific findings and eroding public trust in research. Implementing comprehensive education initiatives on responsible research practices, as well as building an all-encompassing institutional policy, can help to reduce the occurrence of misconduct.",
         "18",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Thank you for the opportunity to review this article. This cross-sectional study investigates the extent of research misconduct (RM) among researchers in Ethiopia’s academic and research institutions using a structured questionnaire. Some findings are particularly intriguing, such as the lack of significant statistical correlation between ethics education and RM. However, I have three primary concerns I would like to discuss with the authors. Firstly, the authors examined behavioral influences on responsible conduct in research and explored factors associated with RM composites. While the selected factors appear relevant to RM, the authors do not delve deeply into why these factors may influence RM. This oversight may represent a limitation of the quantitative approach and raises questions for scholars engaged in qualitative research. Therefore, I recommend that the authors provide a more comprehensive explanation of these influencing factors, taking into account the educational and cultural context of Ethiopia, as well as relevant existing theories. Secondly, as noted in the Discussion Sec., the findings from Ethiopia align with those from Kenya and the Middle East. Readers may be interested in understanding the uniqueness and broader applicability of this study. The research's distinctiveness should not be solely attributed to the choice of Ethiopia as the research site. This concern is related to my first point regarding the investigation of established factors influencing RM, as the significance of the research appears less pronounced. I suggest that the authors further explore the uniqueness of this study and its potential broader applicability in future research. Thirdly, the article exhibits certain limitations in research methodology, particularly concerning the formulation of research hypotheses. The manuscript lacks a dedicated literature review section; instead, it briefly presents current research on RM in the Middle East within the Introduction Sec. This approach does not adequately develop research hypotheses by considering existing literature, which should be followed by validation through the questionnaire. I recommend that the authors enhance the methodological rigor of this cross-sectional study by incorporating a more thorough review of relevant literature to inform the formulation of their research hypotheses.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.8029",
         "1",
         "0",
         "0.1547619047619048",
         "0.8817",
         "0.8927220106124878",
         "17.94",
         "15.6",
         "15.69",
         "16.0",
         "16.2",
         "95",
         "0",
         "0",
         "1",
         "0",
         "4.0",
         "3.0",
         "3.0",
         "yes",
         "neutral",
         "neutral",
         "2",
         "3",
         "4.0",
         "4.0",
         "4.0",
         "82.0",
         "92.0"
        ],
        [
         "47",
         "Patrick Okonta",
         "08 Feb 2025",
         "Approved With Reservations",
         "471",
         "Magnitude and Factors Associated with Research Misconduct at Public University in Ethiopia: A Cross-Sectional Survey",
         "Background Research integrity, essential for ethical scientific research, has been inadequately addressed in Ethiopia, resulting in gaps in addressing misconduct like plagiarism, falsification and fabrication.  Methods An institutional-based cross-sectional study was conducted on a random sample of researchers. Data were collected via a self-administered, structured questionnaire, which was adapted from a similar study. The collected data were analysed using descriptive, bivariate, and multivariable logistic regression.  Result A total of 244 researchers participated in the study, resulting in an 82% response rate. In our study, 37.7% of participants reported engaging in at least one form of misconduct, 95% CI [31.6%, 44.1%]. Authorship misconduct was the most common form of self-reported misconduct (47.5%), 95% CI [41.1%, 54.0%], followed by fabrication and falsification (40.6%), 95% CI [34.4%, 47.0%]. Publication pressure was significantly associated with research misconduct (AOR = 3.18; 95% CI: [1.02, 9.95]).  Conclusion Research misconduct has profound implications, compromising the validity of scientific findings and eroding public trust in research. Implementing comprehensive education initiatives on responsible research practices, as well as building an all-encompassing institutional policy, can help to reduce the occurrence of misconduct.",
         "19",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The study has as its objective 'to assess the magnitude of RM – as well as associated attitudes and factors – among faculty researchers conducting biomedical and epidemiological studies involving human participants in an academic institution in Ethiopia.'  The topic is important  especially in the context that it is the first of its kind in Ethiopia. Generally the manuscript is well written and the methods well described to make reproducibility of the study possible. However, the following issues /suggestions need to be addressed 1. Title. I would suggest inserting 'a' in front of 'Public University. 2. Abstract  a) The aim of the study should be included either as a subheading or the second sentence in the Background subheading.  b) The conclusion has to be completely revised as I suggests below 3. Method  a) The variable 'Research experience' was measured by the number of years in an academic post. I wonder why the 'number of publications/scholarly works' was not used as a more appropriate marker for research experience? 4. Results  a) Table 2 is not in the manuscript.  b) Page 8- The sentence, 'A Chi-Square test showed significant associations with a p-value of less than 0.05'  has to be expanded to make it complete and self explanatory. c) I suggest further analysis on Authorship misconduct should be provided to determine which of the 3 types studied was associated with more years of research experience. Conclusion. The conclusion as stated does not derive from this particular study or related to the objective of the study as stated by the Authors. The conclusion is too generic and very broad without any specific link to either the results from this study or the stated objectives of the study. It should be completely re-written. In addition, since there was no significant difference in research misconduct between those that had prior training in ethics and those who did not, I wonder the basis for the recommendation of educational interventions in the conclusion  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? No  Are the conclusions drawn adequately supported by the results? No",
         "0.7774",
         "5",
         "0",
         "0.144875",
         "0.2025",
         "0.9213261008262634",
         "33.85",
         "13.6",
         "14.64",
         "15.4",
         "13.9",
         "98",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "5.0",
         "3.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "4.0",
         "80.0",
         "82"
        ],
        [
         "48",
         "Billy Ogwel",
         "17 May 2024",
         "Approved With Reservations",
         "467",
         "Predicting stunting in Rwanda using artificial neural networks: a demographic health survey 2020 analysis",
         "Background Stunting is a serious public health concern in Rwanda, affecting around 33.3% of children under the age of five in 2020. Several examples of research have employed machine learning algorithms to predict stunting in Rwanda; however, no study used artificial neural networks (ANNs), despite their strong capacity to predict stunting. The purpose of this study was to predict stunting in Rwanda using ANNs and the most recent Demographic and Health Survey (DHS) data from 2020.  Methods We used a multilayer perceptron (MLP) architecture to train and test the ANN model on a subset of the DHS dataset. The input variables for the model included child, parental and socio-demographic’s characteristics. The output variable was a binary indicator of stunting status (stunted vs. not stunted).  Results An overall accuracy of 72.0% on the test set was observed, with an area under the receiver operating characteristic curve (AUC-ROC) of 0.84, indicating the model’s good performance. Several factors appear as important contributors to the probability of stunting among the negative value aspects. First and foremost, the mother’s height is important, as a lower height suggests an increased risk of stunting in children. Positive value characteristics, on the other hand, emphasie elements that reduce the likelihood of stunting. The timing of the initiation of breastfeeding stands out as a crucial factor, showing that early breastfeeding initiation has been linked with a decreased risk of stunting.  Conclusions Our findings suggest that ANNs can be a useful tool for predicting stunting in Rwanda and identifying the most important associated factors for stunting. These insights can inform targeted interventions to reduce the burden of stunting in Rwanda and other low- and middle-income countries.",
         "87",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This manuscript addresses a significant public health challenge and provides valuable insights. To further enhance its impact, the authors may consider the following suggestions: Abstract: -Add detail on the modelling approach in the methods section. - Report 95% CI around the estimates -Be very explicit on the targeted interventions in the conclusion of the abstract. Introduction -More recent estimates of stunting are available 148.1 million as at 2022 (https://www.who.int/data/gho/data/themes/topics/joint-child-malnutrition-estimates-unicef-who-wb) -The authors can add successful implementations of ANNs in the healthcare domain in the paragraph where they talk about the strengths of ANNs. -The authors need to add the justification of their study why it is important to use ANNs to the same dataset that was used by authors in reference 11 in the same setting using SVM, NB, RF, LR, and XGBoost algorithms . Do they aim to achieve a higher predictive accuracy? Methods The authors say the data was partitioned into a training set, a validation set, and a test set. Yet talk only of a 80%:20% split. They could clarify this. Results: -The authors could refer to the TRIPOD checklist on reporting of diagnostic or prognostic prediction studies (Collins GS ,et.al., 2015 [Ref1]) . Specifically, they could : \"Describe the flow of participants through the study, including the number of participants with and without the outcome and, if applicable, a summary of the follow-up time. A diagram may be helpful.\" -They also need to report performance measures (with CIs) for the prediction model according to this guideline. Discussion: The authors could improve the discussion by comparing their results to those of other studies that have used DHS to predict stunting and particularly reference 11 that was done in the same setting using the same data. Did their ANN model improve performance as hypothesized in the background? the authors could also discuss the potential clinical use of the model, highlighting where and when it can be used in the healthcare system  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7669",
         "1",
         "1",
         "0.1721491228070175",
         "0.0999",
         "0.8586709499359131",
         "34.97",
         "13.2",
         "14.37",
         "14.4",
         "14.5",
         "97",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "3.0",
         "5.0",
         "yes",
         "positive",
         "neutral",
         "2",
         "2",
         "4.0",
         "4.0",
         "3.0",
         "75.0",
         "76"
        ],
        [
         "49",
         "Mashfiqul Huq Chowdhury",
         "22 May 2024",
         "Approved With Reservations",
         "958",
         "Predicting stunting in Rwanda using artificial neural networks: a demographic health survey 2020 analysis",
         "Background Stunting is a serious public health concern in Rwanda, affecting around 33.3% of children under the age of five in 2020. Several examples of research have employed machine learning algorithms to predict stunting in Rwanda; however, no study used artificial neural networks (ANNs), despite their strong capacity to predict stunting. The purpose of this study was to predict stunting in Rwanda using ANNs and the most recent Demographic and Health Survey (DHS) data from 2020.  Methods We used a multilayer perceptron (MLP) architecture to train and test the ANN model on a subset of the DHS dataset. The input variables for the model included child, parental and socio-demographic’s characteristics. The output variable was a binary indicator of stunting status (stunted vs. not stunted).  Results An overall accuracy of 72.0% on the test set was observed, with an area under the receiver operating characteristic curve (AUC-ROC) of 0.84, indicating the model’s good performance. Several factors appear as important contributors to the probability of stunting among the negative value aspects. First and foremost, the mother’s height is important, as a lower height suggests an increased risk of stunting in children. Positive value characteristics, on the other hand, emphasie elements that reduce the likelihood of stunting. The timing of the initiation of breastfeeding stands out as a crucial factor, showing that early breastfeeding initiation has been linked with a decreased risk of stunting.  Conclusions Our findings suggest that ANNs can be a useful tool for predicting stunting in Rwanda and identifying the most important associated factors for stunting. These insights can inform targeted interventions to reduce the burden of stunting in Rwanda and other low- and middle-income countries.",
         "92",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study employs a deep learning model to predict stunting status among children under the age of five in Rwanda. The findings are intriguing. However, several improvements are necessary. The comments are detailed below: Title can be modified to: Predicting stunting status among under-5 children in Rwanda using neural network model: Evidence from 2020 Rwanda demographic and health survey In the Abstract, the results section needs improvement. The authors should rewrite the following sentence: Several factors appear as important contributors to the probability of stunting among the negative value aspects. Introduction section: a) Discuss the consequences of stunting and the overall situation of stunting in Rwanda among under-5 children. b) In the second paragraph, the author critically evaluates the linear regression and decision tree models. It is recommended that the author also discuss the logistic regression model. c) This sentence is not relevant to me: \"They can also be parallelised over many processors, increasing computing efficiency.9 ANNs may be used for transfer learning, which involves fine-tuning a pre-trained model for a new task with little data. This is especially important when data is scarce or expensive to collect.\"  d) Spelling mistake: Supportive Vector Machine e) Give a reference to this sentence: ANNs have proven to be highly effective in predicting illnesses. f) The authors need to provide a more detailed description of the motivation behind this study. g) The literature review is very limited. I suggest adding more references to existing studies and relevant literature. h) This sentence is not clear: \"Given the crucial importance of addressing the root causes of stunting for effective treatments and policymaking, the researcher chose to conduct this study on the application of ANNs in the specific context of stunting in Rwanda, using the same dataset as the aforementioned publication. Methods section: a) This section can be split into the following sub-sections: Data Source and Sampling Design, Study Population, and Variables (Explanatory and Outcome Variables). The authors need to discuss the data file used from the DHS website, including information on any missing variables and whether they were discarded or handled in some other way. b) In Table 1, the following changes are recommended: replace \"Baby's age\" with \"Child's age,\" \"Antenatal\" with \"Antenatal care visits,\" and \"Reading\" with \"Media access.\" For variables such as source of drinking water, toilet facilities, and place of delivery, define the categories clearly in the variables sub-section. Specify the definitions for unimproved and improved statuses earlier in the text. Also, clarify which places are considered health facilities. Instead of using mother's height, the authors may consider the mother's BMI variable. c) The variables \"size of a child\" and \"birthweight\" are essentially the same. Should both variables be included? d) The authors need to clarify why the altitude variable is crucial for this analysis. e) Authors can create a new subsection titled \"Experimental Setup\" to systematically outline the experimental procedures. This section should be written in a clear and organized manner to ensure ease of understanding for readers. f) In the section discussing the Artificial Neural Network (ANN) model, it's important to specify the size of the hidden layer and provide justification for this choice, possibly citing relevant references. Additionally, authors should explain how they tuned the hyperparameters of the model. Including a reference for the Adam optimizer would also be beneficial. To improve clarity and prevent redundancy, it's recommended not to repeat the discussion of Scikit-learn, TensorFlow, and Python many times. g) The authors should clarify the context in which they use both standardization methods, Minimax scaler and Standard scaler, in their paper. It's important to explain why each method is chosen and how they are applied to the data. This clarification will help readers understand the rationale behind using different scaling techniques and their impact on the results. i) Use observations instead of instances. j) Figure 1 title needs to be improved. Results section: a) In Figure 2, the x-axis and y-axis titles should be clearly labeled. The legends also need to be improved to indicate \"Training Loss,\" \"Test Loss,\" \"Training Accuracy,\" and \"Test Accuracy.\" Additionally, the main title of the figure should be rewritten for clarity. b) Write a general comment based on Figures 2, 3, 4. Write in 2-3 paragraphs without sub-sections. c) If feasible, conduct a comparison with a machine learning model like logistic regression. This comparative analysis will elucidate which type of model (ML or DL) is best suited for this type of dataset. d) This sentence is not clear to me: \"This study reveals that it is crucial to note that the ROC curve and AUC-ROC should be assessed in conjunction with other assessment measures like accuracy, precision, and recall to provide a thorough picture of the model’s performance and applicability for practical application in stunting prediction, however, this study used only the ROC\". Discussion section: Authors can emphasize identifying similarities or consistency with other existing works.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7973",
         "1",
         "0",
         "0.1136357270180799",
         "0.1695",
         "0.9002885222434998",
         "36.18",
         "12.7",
         "13.42",
         "14.5",
         "13.9",
         "101",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "4.0",
         "1",
         "2",
         "3",
         "2",
         "4",
         "3.0",
         "4.0",
         "3.0",
         "3.0",
         "82"
        ]
       ],
       "shape": {
        "columns": 37,
        "rows": 10174
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_suggestion</th>\n",
       "      <th>length_words</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>days_to_submit</th>\n",
       "      <th>review_text</th>\n",
       "      <th>mattr</th>\n",
       "      <th>question_count</th>\n",
       "      <th>...</th>\n",
       "      <th>llm_llamaV3-2_citation_usage</th>\n",
       "      <th>llm_llamaV3-2_sentiment_polarity</th>\n",
       "      <th>llm_llamaV3-2_politeness</th>\n",
       "      <th>llm_llamaV3-2_hedging</th>\n",
       "      <th>llm_llamaV3-2_specificity</th>\n",
       "      <th>llm_llamaV3-2_domain_terms</th>\n",
       "      <th>llm_llamaV3-2_relevance_alignment</th>\n",
       "      <th>llm_llamaV3-2_readability</th>\n",
       "      <th>llm_llamaV3-2_overall_quality</th>\n",
       "      <th>llm_llamaV3-2_overall_score_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Daniel A Nation</td>\n",
       "      <td>19 Jan 2023</td>\n",
       "      <td>Approved</td>\n",
       "      <td>345</td>\n",
       "      <td>Assessing the role of vascular risk factors in...</td>\n",
       "      <td>Background:  Although observational studies de...</td>\n",
       "      <td>240</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.7870</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Ahmet Turan Isik</td>\n",
       "      <td>27 Sep 2024</td>\n",
       "      <td>Approved With Reservations</td>\n",
       "      <td>250</td>\n",
       "      <td>Assessing the role of vascular risk factors in...</td>\n",
       "      <td>Background:  Although observational studies de...</td>\n",
       "      <td>857</td>\n",
       "      <td>Approved With Reservations  info_outline Along...</td>\n",
       "      <td>0.7836</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mansoor Rahman</td>\n",
       "      <td>23 Dec 2024</td>\n",
       "      <td>Approved With Reservations</td>\n",
       "      <td>227</td>\n",
       "      <td>Impact of yoga on the central and peripheral v...</td>\n",
       "      <td>Background The aim of this study was to observ...</td>\n",
       "      <td>227</td>\n",
       "      <td>Approved With Reservations  info_outline Along...</td>\n",
       "      <td>0.7760</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dr. Talal Shihayb</td>\n",
       "      <td>04 Nov 2024</td>\n",
       "      <td>Approved With Reservations</td>\n",
       "      <td>1197</td>\n",
       "      <td>Do more pregnancies increase the risk of perio...</td>\n",
       "      <td>Background Hormonal changes in pregnancy and t...</td>\n",
       "      <td>19</td>\n",
       "      <td>Approved With Reservations  info_outline Along...</td>\n",
       "      <td>0.7794</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nancy Ajwa</td>\n",
       "      <td>26 Dec 2024</td>\n",
       "      <td>Approved</td>\n",
       "      <td>362</td>\n",
       "      <td>Do more pregnancies increase the risk of perio...</td>\n",
       "      <td>Background Hormonal changes in pregnancy and t...</td>\n",
       "      <td>71</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.7954</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10169</th>\n",
       "      <td>Peter N. Robinson</td>\n",
       "      <td>23 Jul 2012</td>\n",
       "      <td>Approved</td>\n",
       "      <td>733</td>\n",
       "      <td>Low budget analysis of Direct-To-Consumer geno...</td>\n",
       "      <td>Direct-to-consumer (DTC) genetic testing is a ...</td>\n",
       "      <td>7</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.7925</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10170</th>\n",
       "      <td>Christian Gilissen</td>\n",
       "      <td>26 Jul 2012</td>\n",
       "      <td>Approved</td>\n",
       "      <td>499</td>\n",
       "      <td>Low budget analysis of Direct-To-Consumer geno...</td>\n",
       "      <td>Direct-to-consumer (DTC) genetic testing is a ...</td>\n",
       "      <td>10</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.7589</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10171</th>\n",
       "      <td>Suzanne Gaudreault</td>\n",
       "      <td>17 Jul 2012</td>\n",
       "      <td>Approved</td>\n",
       "      <td>337</td>\n",
       "      <td>Knowledge of specific HIV transmission modes i...</td>\n",
       "      <td>Background: In prior research, Africans who kn...</td>\n",
       "      <td>4</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.8052</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10172</th>\n",
       "      <td>Nigel Livesley</td>\n",
       "      <td>27 Jul 2012</td>\n",
       "      <td>Not Approved</td>\n",
       "      <td>701</td>\n",
       "      <td>Knowledge of specific HIV transmission modes i...</td>\n",
       "      <td>Background: In prior research, Africans who kn...</td>\n",
       "      <td>14</td>\n",
       "      <td>Not Approved  info_outline Alongside their rep...</td>\n",
       "      <td>0.7521</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>impolite</td>\n",
       "      <td>impolite</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10173</th>\n",
       "      <td>Carlos Morel</td>\n",
       "      <td>02 Aug 2012</td>\n",
       "      <td>Approved</td>\n",
       "      <td>100</td>\n",
       "      <td>Knowledge of specific HIV transmission modes i...</td>\n",
       "      <td>Background: In prior research, Africans who kn...</td>\n",
       "      <td>20</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.8468</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>74.0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10174 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 reviewer  review_date           review_suggestion  \\\n",
       "0         Daniel A Nation  19 Jan 2023                    Approved   \n",
       "1        Ahmet Turan Isik  27 Sep 2024  Approved With Reservations   \n",
       "2          Mansoor Rahman  23 Dec 2024  Approved With Reservations   \n",
       "3       Dr. Talal Shihayb  04 Nov 2024  Approved With Reservations   \n",
       "4              Nancy Ajwa  26 Dec 2024                    Approved   \n",
       "...                   ...          ...                         ...   \n",
       "10169   Peter N. Robinson  23 Jul 2012                    Approved   \n",
       "10170  Christian Gilissen  26 Jul 2012                    Approved   \n",
       "10171  Suzanne Gaudreault  17 Jul 2012                    Approved   \n",
       "10172      Nigel Livesley  27 Jul 2012                Not Approved   \n",
       "10173        Carlos Morel  02 Aug 2012                    Approved   \n",
       "\n",
       "       length_words                                              title  \\\n",
       "0               345  Assessing the role of vascular risk factors in...   \n",
       "1               250  Assessing the role of vascular risk factors in...   \n",
       "2               227  Impact of yoga on the central and peripheral v...   \n",
       "3              1197  Do more pregnancies increase the risk of perio...   \n",
       "4               362  Do more pregnancies increase the risk of perio...   \n",
       "...             ...                                                ...   \n",
       "10169           733  Low budget analysis of Direct-To-Consumer geno...   \n",
       "10170           499  Low budget analysis of Direct-To-Consumer geno...   \n",
       "10171           337  Knowledge of specific HIV transmission modes i...   \n",
       "10172           701  Knowledge of specific HIV transmission modes i...   \n",
       "10173           100  Knowledge of specific HIV transmission modes i...   \n",
       "\n",
       "                                                abstract  days_to_submit  \\\n",
       "0      Background:  Although observational studies de...             240   \n",
       "1      Background:  Although observational studies de...             857   \n",
       "2      Background The aim of this study was to observ...             227   \n",
       "3      Background Hormonal changes in pregnancy and t...              19   \n",
       "4      Background Hormonal changes in pregnancy and t...              71   \n",
       "...                                                  ...             ...   \n",
       "10169  Direct-to-consumer (DTC) genetic testing is a ...               7   \n",
       "10170  Direct-to-consumer (DTC) genetic testing is a ...              10   \n",
       "10171  Background: In prior research, Africans who kn...               4   \n",
       "10172  Background: In prior research, Africans who kn...              14   \n",
       "10173  Background: In prior research, Africans who kn...              20   \n",
       "\n",
       "                                             review_text   mattr  \\\n",
       "0      Approved  info_outline Alongside their report,...  0.7870   \n",
       "1      Approved With Reservations  info_outline Along...  0.7836   \n",
       "2      Approved With Reservations  info_outline Along...  0.7760   \n",
       "3      Approved With Reservations  info_outline Along...  0.7794   \n",
       "4      Approved  info_outline Alongside their report,...  0.7954   \n",
       "...                                                  ...     ...   \n",
       "10169  Approved  info_outline Alongside their report,...  0.7925   \n",
       "10170  Approved  info_outline Alongside their report,...  0.7589   \n",
       "10171  Approved  info_outline Alongside their report,...  0.8052   \n",
       "10172  Not Approved  info_outline Alongside their rep...  0.7521   \n",
       "10173  Approved  info_outline Alongside their report,...  0.8468   \n",
       "\n",
       "       question_count  ...  llm_llamaV3-2_citation_usage  \\\n",
       "0                   1  ...                           yes   \n",
       "1                   1  ...                            no   \n",
       "2                   1  ...                         False   \n",
       "3                   2  ...                            no   \n",
       "4                   1  ...                           yes   \n",
       "...               ...  ...                           ...   \n",
       "10169               0  ...                           yes   \n",
       "10170               2  ...                          True   \n",
       "10171               1  ...                           yes   \n",
       "10172               2  ...                            no   \n",
       "10173               0  ...                           yes   \n",
       "\n",
       "       llm_llamaV3-2_sentiment_polarity  llm_llamaV3-2_politeness  \\\n",
       "0                               neutral                   neutral   \n",
       "1                               neutral                   neutral   \n",
       "2                               neutral                   neutral   \n",
       "3                               neutral                   neutral   \n",
       "4                               neutral                    polite   \n",
       "...                                 ...                       ...   \n",
       "10169                           neutral                   neutral   \n",
       "10170                           neutral                    polite   \n",
       "10171                           neutral                    polite   \n",
       "10172                          impolite                  impolite   \n",
       "10173                           neutral                    polite   \n",
       "\n",
       "       llm_llamaV3-2_hedging  llm_llamaV3-2_specificity  \\\n",
       "0                    Minimal                          3   \n",
       "1                    Minimal                          3   \n",
       "2                   Moderate                    neutral   \n",
       "3                   Moderate                          2   \n",
       "4                    Minimal                          3   \n",
       "...                      ...                        ...   \n",
       "10169                Minimal                          3   \n",
       "10170                Minimal                          4   \n",
       "10171                Minimal          somewhat specific   \n",
       "10172                  Heavy                          4   \n",
       "10173                Minimal          somewhat specific   \n",
       "\n",
       "       llm_llamaV3-2_domain_terms  llm_llamaV3-2_relevance_alignment  \\\n",
       "0                             4.0                                4.0   \n",
       "1                             4.0                                5.0   \n",
       "2                             2.0                                3.0   \n",
       "3                             4.0                                3.0   \n",
       "4                             4.0                                5.0   \n",
       "...                           ...                                ...   \n",
       "10169                         4.0                                4.0   \n",
       "10170                         4.0                                5.0   \n",
       "10171                         3.0                                4.0   \n",
       "10172                         2.0                                3.0   \n",
       "10173                         4.0                                3.0   \n",
       "\n",
       "       llm_llamaV3-2_readability  llm_llamaV3-2_overall_quality  \\\n",
       "0                            5.0                           90.0   \n",
       "1                            4.0                           80.0   \n",
       "2                            4.0                           60.0   \n",
       "3                            4.0                           80.0   \n",
       "4                            5.0                           90.0   \n",
       "...                          ...                            ...   \n",
       "10169                        5.0                           85.0   \n",
       "10170                        4.0                           60.0   \n",
       "10171                        5.0                           80.0   \n",
       "10172                        1.0                           20.0   \n",
       "10173                        4.0                           74.0   \n",
       "\n",
       "       llm_llamaV3-2_overall_score_100  \n",
       "0                                   90  \n",
       "1                                   84  \n",
       "2                                   70  \n",
       "3                                   83  \n",
       "4                                   92  \n",
       "...                                ...  \n",
       "10169                               85  \n",
       "10170                               60  \n",
       "10171                               83  \n",
       "10172                               20  \n",
       "10173                               74  \n",
       "\n",
       "[10174 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_suggestion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "days_to_submit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "llm_length_effort",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_lexical_diversity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_questions_raised",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_citation_usage",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_sentiment_polarity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_politeness",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_hedging",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_specificity",
         "rawType": "object",
         "type": "unknown"
        },
        {
         "name": "llm_domain_terms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_relevance_alignment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_readability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_overall_quality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_overall_score_100",
         "rawType": "object",
         "type": "unknown"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "b73a6049-eb4b-48cc-bb66-72972b321287",
       "rows": [
        [
         "0",
         "3771-4985",
         "Anonymous",
         "02/Dec/2024",
         "Accept",
         "19",
         "The ANthropological Notation Ontology (ANNO): A core ontology for annotating human bones and deriving phenotypes",
         "The Anthropological Notation Ontology (ANNO) allows the systematic and standardized classiﬁcation of recovered bone ﬁnds into the skeletal system, the description of the skeletal pieces, and the deﬁnition of functions for deriving different phenotypes of humans in forensic and historical anthropology. ANNO consists of two components: ANNOdc, a domain-core ontology providing core entities such as basic anatomical categories, and ANNOds, a domain-speciﬁc ontology used for annotating structures of the human skeleton. ANNO is integrated into AnthroWorks3D, a photogrammetry pipeline and application for the creation and analysis of 3D-models of human skeletal remains. The integration is based on the three-ontology method with the General Formal Ontology as the top-level ontology, ANNOdc as the task ontology and ANNOds as the domain ontology. Thus, AnthroWorks3D only needs to implement access to the entities (classes and properties) of the task ontology, whereas the entities of the corresponding domain ontology are imported dynamically. ANNO supports the analysis of skeletal and bone ﬁnds in forensic and historical anthropology, facilitating the standardization of data annotation and ensuring accurate preservation of information for posterity.",
         "56",
         "After the revision, this paper looks better. I agree that the manuscript is published in the semantic web journal.",
         "0.8947",
         "0",
         "0",
         "0.5",
         "0.2086",
         "0.703601598739624",
         "61.83",
         "7.0",
         "10.12",
         "0.0",
         "7.1",
         "19",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "1.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "3.0",
         "70.0",
         "75"
        ],
        [
         "1",
         "3771-4985",
         "Yuming Shen",
         "16/Dec/2024",
         "Accept",
         "24",
         "The ANthropological Notation Ontology (ANNO): A core ontology for annotating human bones and deriving phenotypes",
         "The Anthropological Notation Ontology (ANNO) allows the systematic and standardized classiﬁcation of recovered bone ﬁnds into the skeletal system, the description of the skeletal pieces, and the deﬁnition of functions for deriving different phenotypes of humans in forensic and historical anthropology. ANNO consists of two components: ANNOdc, a domain-core ontology providing core entities such as basic anatomical categories, and ANNOds, a domain-speciﬁc ontology used for annotating structures of the human skeleton. ANNO is integrated into AnthroWorks3D, a photogrammetry pipeline and application for the creation and analysis of 3D-models of human skeletal remains. The integration is based on the three-ontology method with the General Formal Ontology as the top-level ontology, ANNOdc as the task ontology and ANNOds as the domain ontology. Thus, AnthroWorks3D only needs to implement access to the entities (classes and properties) of the task ontology, whereas the entities of the corresponding domain ontology are imported dynamically. ANNO supports the analysis of skeletal and bone ﬁnds in forensic and historical anthropology, facilitating the standardization of data annotation and ensuring accurate preservation of information for posterity.",
         "70",
         "The revised manuscript has been reviewed thoroughly, and it differs little from the previous version, with only a few minor details having been refined.",
         "0.9167",
         "0",
         "0",
         "-0.1208333333333333",
         "0.1304",
         "0.6797345876693726",
         "38.66",
         "13.8",
         "14.6",
         "0.0",
         "15.9",
         "24",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "95.0",
         "95"
        ],
        [
         "2",
         "3763-4977",
         "Anonymous",
         "08/Oct/2024",
         "Accept",
         "18",
         "Enhancing Ontology Matching: Lexically and Syntactically Standardizing Ontologies Through Customized Lexical Analyzers",
         "Ontology matching systems commonly leverage similarity metrics to establish mappings between entities in the ontologies participating in the process. However, the lack of standardized entity names across these ontologies can cause such metrics to overlook correct mappings. Generally, existing methodologies that focus on standardizing entity names neglect the ongoing matching process, leading to inaccurate results, and fail to address the syntactic standardization of entity names. To address these issues, we introduce a novel approach that standardizes entity names both lexically and syntactically through a customized lexical analyzer tailored to the ontologies participating in the process. We evaluate this approach's efficacy using Alin and AML, ontology matching systems, along with the Anatomy and Conference tracks of OAEI, demonstrating an improvement in matching results.",
         "9",
         "After reviewing the updated manuscript, I find the changes satisfactory, and I now recommend the paper for publication.",
         "0.8333",
         "0",
         "0",
         "0.0",
         "0.1571",
         "0.7408018112182617",
         "27.83",
         "13.9",
         "18.31",
         "0.0",
         "14.3",
         "18",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "0.0",
         "yes",
         "positive",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "90.0",
         "92"
        ],
        [
         "3",
         "3763-4977",
         "Anonymous",
         "09/Jan/2025",
         "Accept",
         "107",
         "Enhancing Ontology Matching: Lexically and Syntactically Standardizing Ontologies Through Customized Lexical Analyzers",
         "Ontology matching systems commonly leverage similarity metrics to establish mappings between entities in the ontologies participating in the process. However, the lack of standardized entity names across these ontologies can cause such metrics to overlook correct mappings. Generally, existing methodologies that focus on standardizing entity names neglect the ongoing matching process, leading to inaccurate results, and fail to address the syntactic standardization of entity names. To address these issues, we introduce a novel approach that standardizes entity names both lexically and syntactically through a customized lexical analyzer tailored to the ontologies participating in the process. We evaluate this approach's efficacy using Alin and AML, ontology matching systems, along with the Anatomy and Conference tracks of OAEI, demonstrating an improvement in matching results.",
         "102",
         "In my initial review, I had concerns around \"(2) significance of the results\", \"(3) quality of writing\", and relevance for the special issue. The authors have addressed all the issues in this revision, and the paper is now a strong contribution to this field. The only remaining issue is that \"ChatGPT\" is used without proper citation and incorrectly defined as a model. ChatGPT is a software, and you have a choice of several LLMs for the software. You need to specify which model you have used. Is it gpt-4o? I would say the model name should also be a parameter defined in parameters.txt to run the code.",
         "0.7149",
         "0",
         "0",
         "0.1317460317460317",
         "0.2476",
         "0.7163301706314087",
         "57.87",
         "8.5",
         "10.22",
         "10.7",
         "7.3",
         "94",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "very specific",
         "4.0",
         "5.0",
         "5.0",
         "95.0",
         "96"
        ],
        [
         "4",
         "3754-4968",
         "Anonymous",
         "14/Dec/2024",
         "Reject",
         "493",
         "Nordic Spatial Humanities: Ups and Downs in LOD Implementation across Humanities’ Digital Spatial Research Infrastructures in the Nordic Countries",
         "The article constitutes a report of a LOD application attempt undertaken within the humanities’ spatial research (SRI)/spatial data infrastructure (SDI) sector. The case study is carried out on the geocoded data, mostly place-names and place-name attestations, of the four chosen Nordic SRIs: Icelandic Saga Map, Mapping Saints, Norse World and Norwegian Place-names. Ontologically, the case study aims at the implementation of Linked Art Data Model across the four resources. Methodologically, the SRIs data went through cleaning, transformation and augmentation stages. The results section demonstrates that the outcomes of the LOD implementation and the test querying have been uneven which is explained partially by the differences between the SRIs as well as by time constrains. In the discussion, the article reflects on possible alternative methodology, technological challenges such as scalability as well as its contribution to the field.",
         "103",
         "The paper discusses the results of two workshops, held in September 2022 and May 2023, conducted under the Nordic Spatial Humanities (NSH) project (2022–2024). The authors present lessons learned and outcomes from these workshops. The paper claims the creation of a functional RDF output derived from three of the four data sources (ISM, NW, and NPN). This output was published through a search portal where the spatial aspect served as the common denominator across the data sources. 1. Quality, Importance, and Impact Quality. The work appears below average in quality. The description of LOD integration requirements, data sources, architecture, and exploitation is minimal. The project involves data augmentation and aggregation of ISM, NW, and NPN datasets with spatial features, but lacks validation of results. The authors admit that time constraints and limited familiarity with certain ontologies negatively influenced outcomes. Importance. The project data, code, and related resources have been available during the project’s lifetime (2022–2024). However, the decision to discontinue the resources post-project suggests the authors implicitly acknowledge that the outcomes have limited importance. Impact. The work’s impact seems to be limited to the NSH project’s participants. The paper does not provide details on workshops number of participants, follow-up activities, or broader influence. Additionally, the decision not to maintain project outputs diminishes its potential long-term impact. 2. Clarity and Readability The paper is challenging to read, with issues in organization and formatting. Furthermore, the paper does not adhere to the recommended SWJ format. 3. Long-Term Stable URL for Resources Not available. In addition, the application lacks a GitHub, Figshare, or Zenodo repository.  Detailed Review - The term “spatial research infrastructures” (SRIs) seems to be coined by the authors. Existing literature in digital humanities already addresses spatial information extensively without using this term. - The paper does not establish how its approach differs from or improves upon similar work. - The three research questions are overly ambitious and cannot be addressed only through insights from two workshops. A more detailed and technical research work would be required. - The concept of a “spatial humanities infrastructure” (p. 15) and its requirements are insufficiently explained. Furthermore, the claim that “showcasing a semantic portal may not have been the most suitable case” is not backed up by evidence. - The claim that the spatial aspect is the main common denominator between datasets requires further data to discard other alternatives. - Detailed data on the size of the input datasets and the resulting integration dataset is missing. - The design of the URI is missing. - It is not clear which parts of the system were developed during which workshop. A timeline would improve clarity. - There is no quantification of time or resources invested and the quality of mappings. The paper should include quality measures and effort required. - The claim of LOD silos requires data supporting it. - The bibliography contains broken links (e.g., https://www3.uu.se), non-standard references (e.g., RDF, RDFS), and duplicate references (RDF and W3C/RDF).",
         "0.7886",
         "5",
         "1",
         "0.0581018518518518",
         "0.1041",
         "0.8946142792701721",
         "41.36",
         "10.7",
         "11.76",
         "13.1",
         "12.5",
         "89",
         "0",
         "0",
         "0",
         "0",
         "2.0",
         "4.0",
         "5.0",
         "no",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "3.0",
         "4.0",
         "2.0",
         "42.0",
         "58"
        ],
        [
         "5",
         "3754-4968",
         "Sarah Rebecca Ondraszek",
         "02/Jan/2025",
         "Major Revision",
         "1101",
         "Nordic Spatial Humanities: Ups and Downs in LOD Implementation across Humanities’ Digital Spatial Research Infrastructures in the Nordic Countries",
         "The article constitutes a report of a LOD application attempt undertaken within the humanities’ spatial research (SRI)/spatial data infrastructure (SDI) sector. The case study is carried out on the geocoded data, mostly place-names and place-name attestations, of the four chosen Nordic SRIs: Icelandic Saga Map, Mapping Saints, Norse World and Norwegian Place-names. Ontologically, the case study aims at the implementation of Linked Art Data Model across the four resources. Methodologically, the SRIs data went through cleaning, transformation and augmentation stages. The results section demonstrates that the outcomes of the LOD implementation and the test querying have been uneven which is explained partially by the differences between the SRIs as well as by time constrains. In the discussion, the article reflects on possible alternative methodology, technological challenges such as scalability as well as its contribution to the field.",
         "122",
         "The submitted application report discusses the Nordic Spatial Humanities project and an integrated case study that evaluates the advantages and disadvantages of applied Linked Open Data (LOD) for infrastructures focusing on geocoded humanities data in the Nordic countries (using exemplary data from the Icelandic Saga Map, Mapping Saints, Norse World, and Norwegian Place-names). To harmonize and link the data across these different Spatial Research Infrastructures (SRIs) and make them queryable simultaneously, the authors propose the creation of a Linked Art Data Model at the ontological level and a standardized methodological approach for data processing. The report provides valuable insight into the current state of SRIs in the field of digital humanities and cultural heritage in Nordic countries. The strengths of the report are its structured methodology for implementing LOD across the four chosen case studies and the clear communication of the advantages and disadvantages of LOD implementations. Additionally, the approach to include several collaborators in workshops proves an understanding of the importance of user involvement in the development process of linked data applications. The application report's significance lies in its provision of insights into interdisciplinary endeavors concerning geospatial data, with a focus on harmonizing diverse sources to enhance interoperability and reusability. The authors adopt a dual approach, incorporating ontological and methodological/pipeline-oriented perspectives on the project, thereby offering a comprehensive and multifaceted examination of the subject matter. The report demonstrates notable self-awareness, as evidenced by its identification of the framework's and ontology's limitations on pages 14 to 16. One area for improvement in this report concerns the inaccessibility of the project’s results. The paper should clearly reference the obtained results, ensuring they are accessible for a review and a better understanding of the value of the contribution (also regarding the aspect of convincing evidence for the impact of this study). This would concern, for example, the ontology. The authors emphasize the significance and impact of the present study by underscoring the role of SRIs and geospatial data in the realm of digital humanities and cultural heritage research. The authors acknowledge the necessity to enhance the existing structures and to establish interconnectivity among resources in view of the growth of available data. They underscore the imperative for sustainability and data reuse to open up future research, a principle that finds application in the FAIR principles and the concept of Open Science. The report indicates a challenge posed by the heterogeneity of infrastructures, attributable to two factors. Firstly, the unique structures of geospatial SRIs in Scandinavia, are characterized by data stemming from diverse sources within the humanities and cultural heritage sectors, such as literary sources, manuscripts, maps, and sound files, etc. Secondly, the report highlights divergent requirements for the usability and objectives of a developed infrastructure, also addressing the need for an improved dialogue between recommended bottom-up approaches, and top-down recommendations, which have so far not been finally formulated. With the Nordic Spatial Humanities, they address both issues equally, with a standardized framework and the engagement of various stakeholders in workshops. They included researchers, governmental agencies, and international initiatives (DARIAH-EU, Google, Open Geospatial Consortium, World Historical Gazetteer project, Australian Time Layered Cultural Map project). In order to enhance the report and demonstrate the study's significance, I would recommend to include quantitative measures for the datasets in the introduction and in the result section. This could include, among others aspects, how many data points are included, what is the size of the dataset, what does the LOD landscape looks like, e.g. the coverage of LOD application in SRIs in Nordic countries, an evaluation of applied semantic technologies (outside of the four observed infrastructures). An example: Evaluate how many of the identifiers from the Wikidata have been used in Mapping Saints, and check how the LOD-ification in the project changed it semantification. This relates to the need of a broader contextualization: I recommend contextualizing the findings within the larger framework of LOD initiatives in the humanities and digital research. This is especially important because initiatives like DARIAH-EU were mentioned. Additionally, the authors should explain why the four SRIs were chosen with a clear rationale. This could include discussing the unique characteristics of each SRI, how they relate to the research questions, and how they represent a range of common challenges in similar projects. Such a rationale could also be used to compare the four SRIs based on their content and results in the discussion section. The choice of CIDOC-CRM and the Linked Art Model is clear. However, the design process of the ontology should be defined in more detail on pages 10 and 11. Instead of introducing RDF, it would be interesting to learn more about the design process behind the choice. For example, was a certain design methodology used? Was user feedback involved? This could be done in the method section, before the description of the data transformation process. The \"What about MS?\" section could be shortened and replaced with a comparative analysis. Additionally, a quantitative evaluation of the results would strengthen the concluding remarks. A comparative analysis of the data before and after the LOD implementation, or the number of successfully converted resources, would be a valuable addition. However, in its current state, the section lacks a comparison against existing frameworks. Equally, the authors should address the state of the art of similar projects, also in terms of ontology design and methodological framework. Overall, the paper is well-written and easily comprehensible. However, there are a few irregularities in the use of acronyms throughout the paper (some acronyms are partially introduced, while others are not introduced, e.g., SSH, GIS, etc.) and missing references for fundamental concepts, such as FAIR or Open Science principles, or mentioned frameworks, like Iconclass. Also, a few headings are consistent in their capitalization. Furthermore, a few sections appear slightly imbalanced and could be shortened accordingly. This concerns the definition of core concepts, such as RDF, and the detailed explanation of the MS use case. These sections could be edited as mentioned in the previous paragraph, replacing parts with a comparative analysis of the use cases. The authors should align the visual representations of the concepts across the projects (pages 5, 6, and 7), as well as the CIDOC and Linked Art model (page 10), to a similar graph style to ensure consistency and clarity in the presentation of information. Finally, the addition of visual aids could potentially enhance clarity for the reader by illustrating the met challenges. For instance, Figure 8 could be expanded to include exemplary data from one use case and then compared to another to highlight the connection (spatial resources) and identify which aspects might require more attention.",
         "0.7784",
         "0",
         "0",
         "0.1242595818815331",
         "0.1262",
         "0.9490644335746764",
         "24.17",
         "15.3",
         "15.36",
         "16.0",
         "16.5",
         "90",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "4.0",
         "85.0",
         "85"
        ],
        [
         "6",
         "3754-4968",
         "Anonymous",
         "07/Jan/2025",
         "Reject",
         "1345",
         "Nordic Spatial Humanities: Ups and Downs in LOD Implementation across Humanities’ Digital Spatial Research Infrastructures in the Nordic Countries",
         "The article constitutes a report of a LOD application attempt undertaken within the humanities’ spatial research (SRI)/spatial data infrastructure (SDI) sector. The case study is carried out on the geocoded data, mostly place-names and place-name attestations, of the four chosen Nordic SRIs: Icelandic Saga Map, Mapping Saints, Norse World and Norwegian Place-names. Ontologically, the case study aims at the implementation of Linked Art Data Model across the four resources. Methodologically, the SRIs data went through cleaning, transformation and augmentation stages. The results section demonstrates that the outcomes of the LOD implementation and the test querying have been uneven which is explained partially by the differences between the SRIs as well as by time constrains. In the discussion, the article reflects on possible alternative methodology, technological challenges such as scalability as well as its contribution to the field.",
         "127",
         "This article presents the results of a project led by Scandinavian researchers to set up a Spatial Research Infrastructure (SRI) based on semantic web technologies. The aim of this infrastructure is to improve the reuse, linking and analysis of data initially available in 4 different infrastructures in order to facilitate research in digital humanities. The datasets considered seem heterogeneous but share the common feature of containing geospatial data. Although the topic is of interest to the community, in my view the article has a number of shortcomings that make it incompatible with the journal requirements. While the article was submitted as an ‘Application Report’, it instead presents a high-level view of the reflections carried out by researchers as part of the Nordic Spatial Humanities project (funded by NordForsk between 2022-2024), particularly those relating to two workshops that were organised. The article does not present in detail the originality and novelty of the infrastructure integrating the 4 existing SRIs, but rather a general overview of these existing SRIs and the directions that have been considered for choosing an ontology to describe the data and for querying them. This choice is directly indicated in the introduction in which 3 research questions that the article attempts to answer are indicated. These are not focused on the application but on an attempt to establish good practices for the use of semantic web technologies in digital humanities projects. The LOD principles are highlighted in the research questions and throughout the article as a strong motivation for the project. However, it is regrettable that the authors do not describe what they consider for these principles. In particular, it would have been interesting to indicate how these principles are to be understood in the context of the digital humanities. The same applies to the FAIR principles. From my point of view, making a resource ‘Findable’ or ‘Reusable’ (etc) does not have the same impact depending on the type of users targeted, particularly when it concerns SSH researchers. Another important point in the tackled questions is the specificity of humanities materials in Nordic countries. This point deserves to be developed, as the article only puts forward general considerations such as the heterogeneity of materials, the variability of place names and the variability of expressions used to locate them. In my opinion, these points are common to a large number of geolocalised data sources. Another shortcoming of the paper is its lack of positioning in relation to the state of the art. On the one hand, this concerns the ontologies used to represent territorial units. Several have been proposed in addition to the 2 considered. -\thttp://data.ign.fr/def/geofla -\thttp://rdf.insee.fr/def/geo -\thttp://data.ordnancesurvey.co.uk/ontology/admingeo/ https://rdfdata.eionet.europa.eu/ramon/ontology.rdf http://rdfs.co/juso/ http://www.geonames.org/ontology -\tHiebel, G., Doerr, M., Eide, Ø.: Crmgeo: A spatiotemporal extension of cidoc-crm. International Journal on Digital Libraries 18(4), 271–279 (2017) -\tKauppinen, T., Henriksson, R., Sinkkilä, R., Lindroos, R., Väätäinen, J., Hyvönen, E.: Ontology-based disambiguation of spatiotemporal locations. In: IRSW (2008) -\tKawtar, Y.D., Hind, L., Dalila, C.: Ontology-based knowledge representation for open government data. International Journal of Intelligent Systems and Applications in Engineering 10(4), 761–766 (2022) -\tBernard, C., Villanova-Oliver, M., Gensel, J., Dao, H.: Modeling changes in territorial partitions over time: Ontologies tsn and tsn-change. In: Proceedings of the 33rd Annual ACM Symposium on Applied Computing Pages (SAC ’18). p. 866–875 (2018) -\tCharles,W., Aussenac-Gilles, Nathalie Hernandez, HHT: An Approach for Representing Temporally-Evolving Historical Territories. ESWC 2023: 419-435 (2023) It would be interesting to discuss why these have not been considered. On the other hand, the temporal aspect linked to the spatial data has not been explored. The approaches mentioned above take account of this dimension, which is important when considering digital human resources. In the introduction, this aspect is mentioned as an objective of the project. However, little information is given on how this aspect is dealt with, in particular how places whose names or locations can have changed over time while being the same entity. What is more, the originality and novelty of the application were not sufficiently appreciated. Even if no finalised application resulted from the project, it might have been interesting to flesh out the recommendations and good practices to be developed beyond the failures reported. The workshops that were held led to the production of video resources, and it would have been interesting to highlight how these video presentations could help other SSH researchers to appropriate the technologies, or how they could be supplemented to make this possible. Finally the application provided did not live up to the SWJ expectations. Long-term stable URLs have been defined for some resources but not for all of them, and it is not possible to access a long-term stable URL for the entire application. This point is pointed out in the cover letter sent by the authors but without it is difficult to evaluate the application. In addition to the points raised above, the formatting and the lack of respect for the format of the bibliography make the document difficult to read. Here are some more detailed comments on the content of the paper. In the introduction what does “token attestations” mean? Examples could be given in order to better explain the difference with “place-names attestations”. This could help understanding the differences between the 4 SRI considered. The figures presenting the data model of the 3 first SRIs could use a common formalism (with UML diagrams for example). As they stand, it is difficult to understand, analyse and compare them. In addition, a paragraph should be added to describe the content of each of them. The 4 different SRIs deal with locations covering different geographical areas and time periods. It would have been interesting to specify the concrete motivation and potential for integrating these data into a single SRI based on use cases before presenting the global approach. For the ISM project, it is stated that “environmental concepts that build on the CIDOC-CRM” are considered. However, these are not highlighted in the figure and their integration into the proposed database is not specified. The authors could also explain how “The great potential to link the ISM geo-spatial data with other comparable datasets … clear from the outset” has been considered in the proposed data model. I have the impression that the temporal aspect is considered for individuals and manuscripts but not for places. For this SRI, are places considered to be timeless? Are they considered to be the same entity that two manuscripts describe, even if they concern a different period? How are the places that contain the modelled place represented? The figure shows “parish, country, etc.”, but how is this aspect managed in practice? For the Mapping Saints project, information could be given on how the data model considers the link with “ data from previous projects and to national authorities”. In Figure 2, it seems that the description of a place is marked in time. What identity criteria are considered when deciding whether to create a new place with the same name? Does each mention of a place over a different period lead to the creation of a new entity? How are thesauri considered in the SRI? The Norse World SRI seems to be dedicated to a place name nomenclature. Has the proposed model been compared with that of other Nomenclatures? Is the temporal aspect of the use of these names taken into account? This does not appear to be the case from Figure 3, although I think this information could be of interest. For the Norwegian Place-names SRI the data model could be given to explain how the different entities are represented. When presenting the framework, for me, the part presenting RDF is not of great interest. More information could be given on the CIDOC-CRM elements considered and in particular their link with the elements already present in the 4 SRIs considered. A description on how the names and the temporal aspect linked to the places can be taken up could be added. Moreover, as Sampo-UI is included, the authors could explain if they have considered the ontologies proposed in the SAMPO project.",
         "0.7726",
         "1",
         "11",
         "0.113707720850578",
         "0.1507",
         "0.9359018802642822",
         "36.28",
         "12.7",
         "12.47",
         "14.6",
         "13.2",
         "99",
         "1",
         "1",
         "0",
         "0",
         "2.0",
         "4.0",
         "8.0",
         "False",
         "neutral",
         "neutral",
         "Moderate",
         "broad",
         "3.0",
         "4.0",
         "2.0",
         "42.0",
         "46"
        ],
        [
         "7",
         "3749-4963",
         "Herminio Garcia-Gonzalez",
         "30/Oct/2024",
         "Reject",
         "375",
         "Lessons Learned in the Pursuit of Production-Readiness: Iterative Evaluation of the Kadaster Knowledge Graph Construction",
         "The application of linked data has played a role in enhancing the accessibility and reusability of data at the Kadaster,\\nthe Dutch National Land Administration and Mapping Agency. Over the past decade, three distinct iterations of linked data\\ncreation, publication, and integration have emerged. The most recent iteration involves the KKG, now published using a nationally standardised model and an enterprise-ready architecture, transitioning it into a production-ready data product. This paper\\nevaluates each iteration, identifies key requirements for production-readiness in a governmental context, and presents lessons\\nlearned to guide other organisations in adopting linked data technologies. A design science methodology is used to perform\\nthe evaluations and the findings reveal the importance of strategic alignment, specialised expertise, and ongoing evaluation in\\nachieving and sustainability of production-readiness in linked data architectures. This research provides valuable insights into\\nthe practical adoption of linked data over a decade-long period, offering a unique longitudinal perspective. The lessons from\\nKadaster’s experience can serve as a roadmap for other institutions aiming to integrate linked data into their operations. Future\\nresearch could expand on these findings to explore the scalability of the approach in different organisational contexts and its\\nimpact on data accessibility and utility.",
         "61",
         "This paper introduces a series of lessons learnt from adopting linked data technologies in the context of the Dutch Kadaster. The paper offers a longitudinal study which can be very interesting for other practitioners, especially in industry, who can benefit from the raised conclusions. Nevertheless, as a whole, I find that the paper lacks a more profound basis and further explanations. Right now, Section 3 reads like an implementation logbook which highlights some of the problems found during its implementation (both technically and at the organisational level) but it is not clear how this differentiates from previous publications on the matter [1-4]. This iteration-based methodology is related as a “design science approach” but this concept is never introduced nor referenced in the paper. In general, this is somehow one of the main problems of the paper, as many of the used concepts are never introduced while at the same time it lacks a lot of essential references in the bibliography (just as an example, RML and Morph-KGC are mentioned but their companion scientific publications are not referenced). In my opinion this paper would greatly benefit from defining the goals of implementing LD technologies in this specific context and establishing some quantifiable indicators beforehand. Then, based on that, each iteration can be analysed and conclusions can be drawn from them in a more structured and expectable manner. Finally, these results can be jointly discussed in Section 4 together with the already existing lessons learnt (which I find interesting but quite generic and applicable to any kind of scenario). Following the guidelines for “Application Report” paper types, one important aspect is the uptake of the proposed solution. Even though the authors comment on the governmental set-up in which this application is being developed. There is no mention of the impact that it has on other government’s services and external users. I would suggest that the authors elaborate on this a bit more and relate it to my previous comments about clearly defining the goals of this implementation. Even though the paper highlights some interesting points, due to the enumerated shortcomings, in its current form, I cannot suggest this paper for publication. Nevertheless, I would encourage the authors to rework this paper and resubmit it in the future.",
         "0.836",
         "0",
         "0",
         "0.1651942355889724",
         "0.11",
         "0.872763454914093",
         "37.64",
         "14.2",
         "15.76",
         "16.0",
         "16.2",
         "101",
         "0",
         "3",
         "0",
         "0",
         "3.0",
         "4.0",
         "6.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "2.0",
         "64.0",
         "73"
        ],
        [
         "8",
         "3749-4963",
         "Anonymous",
         "04/Nov/2024",
         "Reject",
         "1167",
         "Lessons Learned in the Pursuit of Production-Readiness: Iterative Evaluation of the Kadaster Knowledge Graph Construction",
         "The application of linked data has played a role in enhancing the accessibility and reusability of data at the Kadaster,\\nthe Dutch National Land Administration and Mapping Agency. Over the past decade, three distinct iterations of linked data\\ncreation, publication, and integration have emerged. The most recent iteration involves the KKG, now published using a nationally standardised model and an enterprise-ready architecture, transitioning it into a production-ready data product. This paper\\nevaluates each iteration, identifies key requirements for production-readiness in a governmental context, and presents lessons\\nlearned to guide other organisations in adopting linked data technologies. A design science methodology is used to perform\\nthe evaluations and the findings reveal the importance of strategic alignment, specialised expertise, and ongoing evaluation in\\nachieving and sustainability of production-readiness in linked data architectures. This research provides valuable insights into\\nthe practical adoption of linked data over a decade-long period, offering a unique longitudinal perspective. The lessons from\\nKadaster’s experience can serve as a roadmap for other institutions aiming to integrate linked data into their operations. Future\\nresearch could expand on these findings to explore the scalability of the approach in different organisational contexts and its\\nimpact on data accessibility and utility.",
         "66",
         "The article presents a three-step (named iterations in the article) evolution of the Kadaster Knowledge Graph (KG). The article presents each iteration in terms of a model developed, a technological architecture illustrated by a figure and an evaluation. In the evaluation some shortcomings are presented. Regarding the quality, importance, and impact of the described application (convincing evidence must be provided). The quality of the artefact, due to its size, is hard to be evaluated nevertheless, playing a bit with the Kadaster Knowledge Graph it seems to have been a high-quality application in technological terms. The importance and the impact of the Kadaster Knowledge Graph, as any other Kadaster, is clearly relevant. However, the article is about the evolution of this Knowledge Graph and the lessons learnt, and this is important to be considered. The quality, importance and impact of the lessons learnt, as well as the iterations defined is not very high:  •\tThe Kadaster KG is available online, however, the article lacks links to the ontologies and other related artefacts (like SHACL shapes) mentioned in the paper that are relevant to understand and watch the evolution through the different iterations •\tEach iteration presents models, but it is unclear how these models and the Knowledge Graph where developed. •\tThe evaluations sections present some shortcomings. However, it is not clear how these shortcomings are addressed in the next iterations. Also, the article mentions an evaluation for each iteration but does not explain how this evaluation was carried out or what was evaluated. •\tIn general, the reviewer is not able to follow and understand the evolution of the different steps since their explanation is shallow and generic. Regarding the clarity of the article, which the reviewer considers one main drawback of the article. The article is not written in a clear language, particularly the first sections. Several sentences are repeated without providing more information about the contributions of the article. For instance, the evaluation and the iterations are mentioned in the abstract, in the introduction, and in the context. However, no information about the iterations or the evaluation is provided; just that there are three iterations and a design science methodology evaluation. There is no insight in the different sections or more information. This provides to the reviewer the impression of been reading the same text several times without reaching any point further. A reader needs to arrive to section 3 to understand what the authors mean by the iterations and the evaluation.  Following the previous comment, the contribution and the challenges are not clear, and they seem to change depending on the paragraph. They revolve around the iterations and the evaluation but sometimes, it seems the contribution is the definition of those iterations, other times it seems the implementation, other the evaluation as the iteration where already defined. A reader needs to reach section 3 to understand what these iterations stand for since there is no prior explanation about them. In addition, the article has many inaccuracies and sentences that need to be improved, some of them:   - In the abstract the world KKG appears without a previous definition of it, it should appear what this acronym stands for before using it.  - \"Over the past decade, three distinct iterations of linked data creation, publication, and integration have emerged\" iterations do not emerge, they are identified or performed  - \"The most recent iteration involves the KKG\" all iterations involve linked data. Which one is the most recent, the first iteration, the second, the third? is the most recent a fourth iteration? this is not clear.  - \"A design science methodology is used to perform the evaluations and the findings reveal the importance of strategic alignment,\" a punctuation sign is needed after the world \"evaluations\"  - \"The impact of the paper presented in this work is twofold\" sentence is a bit redundant  - \"The transformation of a Web Feature Service (WFS) model to a linked data model involves the alignment of the underlying data schema with semantic web standards. Initially, the WFS model, which is typically structured in a format optimised for geospatial data exchange, is mapped. This mapping process involves translating the elements of the WFS schema—such as feature types, attributes, and relationships—into corresponding classes, properties, and relationships in ontologies based on standards like RDFS, OWL, SHACL and SKOS\" --> The schema of WFS, that is a model, should be developed as an ontology or mapped to an existing one so data expressed with WFS could be expressed in RDF according to such ontology. SHACL is for validation, how is WFS mapped into SHACL. This paragraph needs to be explained in more detailed as now has misleading and (seems) incorrect information.   - \" The ETL begins with the extraction of relational data from the WFS service followed by loading it into a spatially enabled database. This step ensures that geographic features available via the WFS services are standardised into a structure which supports efficient querying and manipulation in the following steps of the ETL\" How this can be ensured? the database and the fact that data is stored ensures that geographic features are standardised into a structure compatible with ETL? which standard is that?  * \"The relational data is then mapped to the model defined and the resultant triples are loaded into an instance of GraphDB during which the SHACL validation step is taken to ensure that the resultant linked data adheres to the linked data model\" Which data model, i.e., ontology ? how those SHACL are developed ?  * \"This architecture is illustrated in Figure 1.\" Figure 1 shows an RDF4J database, the role of this component is not explained.  - \"While this construction iteration resulted in the availability of a high volume of linked data\" What does this mean, how much is high volume? in the figure 1 only one relational database appears.    - \"The Information Model details specific dataset information using the Shapes Constraint Language (SHACL) to ensure internal consistency and maintain recognizability for domain experts. Conversely, the Knowledge Model captures generic, shareable knowledge, facilitating integration with external linked data models through RDF(S), OWL, and SKOS vocabularies for improved reusability and interoperability. A model for each key register and required external source was manually defined.\" Something similar was done in the first iteration, what is the difference now? Also, SHACL defined restrictions, is a bit odd to call it Information Model. How was the SHACL shapes developed? are they available?  - In figure 2 where is the original Relational Database and the WFS services? The reviewer expected an evolution of the previous iteration, but Figure 2 seems a new scenario. In general, the article needs to be improved to explain accurately the evolution of the Kadaster Knowledge Graph. As the article is currently written and ideas presented it seems to have a lot of inaccuracies and the impact of the contribution is not clear. It would be also a good addition to explain how the lessons learnt can be adopted third parties.",
         "0.7388",
         "0",
         "0",
         "0.0774156612618151",
         "0.0751",
         "0.8036122918128967",
         "33.34",
         "13.8",
         "12.37",
         "15.2",
         "14.2",
         "89",
         "0",
         "1",
         "0",
         "0",
         "2.0",
         "3.0",
         "5.0",
         "False",
         "neutral",
         "neutral",
         "Minimal",
         "2",
         "3.0",
         "4.0",
         "3.0",
         "70.0",
         "80"
        ],
        [
         "9",
         "3749-4963",
         "Julian Rojas",
         "04/Nov/2024",
         "Minor Revision",
         "785",
         "Lessons Learned in the Pursuit of Production-Readiness: Iterative Evaluation of the Kadaster Knowledge Graph Construction",
         "The application of linked data has played a role in enhancing the accessibility and reusability of data at the Kadaster,\\nthe Dutch National Land Administration and Mapping Agency. Over the past decade, three distinct iterations of linked data\\ncreation, publication, and integration have emerged. The most recent iteration involves the KKG, now published using a nationally standardised model and an enterprise-ready architecture, transitioning it into a production-ready data product. This paper\\nevaluates each iteration, identifies key requirements for production-readiness in a governmental context, and presents lessons\\nlearned to guide other organisations in adopting linked data technologies. A design science methodology is used to perform\\nthe evaluations and the findings reveal the importance of strategic alignment, specialised expertise, and ongoing evaluation in\\nachieving and sustainability of production-readiness in linked data architectures. This research provides valuable insights into\\nthe practical adoption of linked data over a decade-long period, offering a unique longitudinal perspective. The lessons from\\nKadaster’s experience can serve as a roadmap for other institutions aiming to integrate linked data into their operations. Future\\nresearch could expand on these findings to explore the scalability of the approach in different organisational contexts and its\\nimpact on data accessibility and utility.",
         "66",
         "This Application Report paper describes the process and different stages carried out for the creation and release of the Kadaster Knowledge Graph (KGG) by the Dutch National Land Registry and Mapping Agency (Kadaster). The description covers from the prototyping until production-ready stages for creating the KGG. The KGG constitutes an interoperable and integrated data resource that brings together multiple geospatial data sources mainly managed by Kadaster and known as geospatial key registries. The KGG can be seen as a prominent example of how Semantic Web technologies can be used at large in real organizational contexts to improve data interoperability. The insights provided in the paper are valuable for others organizations wanting to follow similar paths and highlight common challenges that may arise. The use of Semantic Web technologies by Kadaster for managing official and public data assets for the whole country of the Netherlands, constitutes and important impact that can motivate other organizations to follow on their example. The technical and architectural details laid out in the paper are indeed a rare and valuable asset, since most Linked Data-related solution descriptions are usually of the prototype and demonstrator kind. The paper is well written and is easy to follow.  In general terms, I have the following two main remarks: - Is not clear enough for me, how are data updates handled overall (e.g., nightly build, continuous stream, etc) and across the different iterations.  As it is mentioned in the paper, the proper management and implementation of data updates is a crucial aspect, specially for production-ready solutions. I would like to see some more details on this particular aspect in each of the iterations descriptions. - One of the most valuable contributions of this paper is the provision of examples of how Semantic Web standards and well-known specifications can be applied for real-world data publishing and service provision. However, I didn't see any links towards actual examples of the configurations, mapping rules, vocabularies, etc, used for the creation of the KKG. The official website does contain information about how to query the resulting KKG, but examples and documentation on how to accomplish the different steps to arrive to a fully-fledged knowledge graph are what other organizations could use better to follow this path. Next I provide some more specific remarks on the description of the different iterations. ## Iteration 1: - What spatially enabled DB was used? How did the mapping process take place? It would be good to know a bit more about the technical details that allowed you to quickly setup a working prototype, as this is often the first step needed to convince organizations to invest in Semantic Web technologies. - Are the WFS schemas and semantic data models used publicly available? If so please linked them in the paper. It would be interesting to see the correspondence between them as an example for other KG creations that start also from existing WFS interfaces. - How were updates handled (statically mapped or continuous process)?  ## Iteration 2: - Can you provide an example of a CONSTRUCT query used to map data from the key registers? Not necessarily within the paper, a link towards an external resource could also be valuable. - Some additional info on the scale of the data and pipeline performance (e.g., mapping process, SHACL validation, etc) could provide better idea of the deployment costs of this type of solution. ## Iteration 3: - How do you decide where to store the materialized GeoSPARQL relations? In one of the SPARQL endpoints? In both? how do manage synchronization in such case? - Was there any improvement achieved in terms of performance and scalability for the ETL processes at this stage compare with the previous? - Effective versioning is mentioned as crucial for managing updates, how is this handled in the case of the KKG? Are the versioning capabilities already considered in the IMX-GEO model or were they defined externally and if so what vocabularies did you use? ## Section 4, 5 and 6: - Section 4 is called \"Discussion and Future Work\" and Section 5 is again called \"Future Work\". Perhaps Section 4 can be renamed to \"Lessons learned and Discussion\" and the 4.1 header can be removed as there are no other subsections there. - The use of more complex OWL-based classes is mentioned as future work, do you already have some use cases in mind where (complex) reasoning could be useful for KKG? ## Typos: - Abstract: \"...in achieving and sustainability...\" - Page 5, lines 47-48: \"...the ETL process managed [is] managed...\" - Page 8, lines 30 and 33: duplicated statement about the scalability of the process that generates triples - Page 10, line 29: missing parenthesis on acronym \"...(LLMs[)]\"",
         "0.8144",
         "0",
         "0",
         "0.135741341991342",
         "0.4524",
         "0.8736968040466309",
         "44.14",
         "11.7",
         "12.47",
         "14.1",
         "12.8",
         "82",
         "1",
         "1",
         "0",
         "0",
         "3.0",
         "4.0",
         "5.0",
         "yes",
         "positive",
         "neutral",
         "2",
         "3",
         "4.0",
         "3.0",
         "4.0",
         "80.0",
         "84"
        ],
        [
         "10",
         "3749-4963",
         "Paola Espinoza",
         "02/Jan/2025",
         "Minor Revision",
         "924",
         "Lessons Learned in the Pursuit of Production-Readiness: Iterative Evaluation of the Kadaster Knowledge Graph Construction",
         "The application of linked data has played a role in enhancing the accessibility and reusability of data at the Kadaster,\\nthe Dutch National Land Administration and Mapping Agency. Over the past decade, three distinct iterations of linked data\\ncreation, publication, and integration have emerged. The most recent iteration involves the KKG, now published using a nationally standardised model and an enterprise-ready architecture, transitioning it into a production-ready data product. This paper\\nevaluates each iteration, identifies key requirements for production-readiness in a governmental context, and presents lessons\\nlearned to guide other organisations in adopting linked data technologies. A design science methodology is used to perform\\nthe evaluations and the findings reveal the importance of strategic alignment, specialised expertise, and ongoing evaluation in\\nachieving and sustainability of production-readiness in linked data architectures. This research provides valuable insights into\\nthe practical adoption of linked data over a decade-long period, offering a unique longitudinal perspective. The lessons from\\nKadaster’s experience can serve as a roadmap for other institutions aiming to integrate linked data into their operations. Future\\nresearch could expand on these findings to explore the scalability of the approach in different organisational contexts and its\\nimpact on data accessibility and utility.",
         "125",
         "This work highlights the main decisions made and lessons learned during the construction of the Kadaster Knowledge Graph (KKG). This KG enables Kadaster to publish its geospatial data following the linked data principles. The manuscript is a valuable contribution for the Semantic Web community, particularly for newcomers as it summarizes the main steps taken in the KG construction process. It illustrates the stack of technologies used and evaluates which of them worked better based on the organization’s requirements and needs at different points in time. The evolution of the construction process over the years from a “yet another format” stage to a “production environment” effectively captures the KKG’s journey.  This manuscript was submitted as 'Application Report'. ** (1) Quality, importance, and impact of the described application (convincing evidence must be provided) ** The quality of the article is good, and it is relevant for the community. It systematically outlines each iteration of the KG construction and provides detailed insights into the requirements and decisions made throughout the construction, while also summarizing the key lessons learned. The manuscript cites some scientific publications that reflect the work done by Kadaster in recent years, offering evidence of KKG's journey. ** (2) Clarity and readability of the describing paper, which shall convey to the reader the key ideas regarding the application of Semantic Web technologies in the application. ** The manuscript is well-written and easy to follow. Unfortunately, as mentioned by the authors, the manuscript does not yet include an evaluation of the third construction iteration, as it is relatively recent. This evaluation could provide valuable lessons that would enrich the content of the paper and enhance the understanding and relevance of the latest construction iteration for readers. ** (3) Assess the data file provided by the authors under “Long-term stable URL for resources”. In particular, assess: (A) whether the data file is well organized and in particular contains a README file which makes it easy for you to assess the data, (B) whether the provided resources appear to be complete for replication of experiments, and if not, why, (C) wether the chosen repository, if it is not GitHub, Figshare or Zenodo, is appropriate for long-term repository discoverability, and (4) whether the provided data artifacts are complete. *** This assessment is not applicable because the primary focus of this work is to provide a general overview of the Knowledge Graph Construction (KGC) journey, and the key lessons learned. However, it is important to note that the KKG is accessible through a SPARQL endpoint, along with a suite of services offered by the tool that hosts the knowledge graph. Minor comments: - Abstract:   - Meaning of the “KGG” acronym needs to be provided.   - To improve clarity, the definition of data product should be provided in the manuscript. - Section 2, Application Context:   - “Kadaster Knowledge Graph, in short the Graph” -> the term \"Graph\" is used infrequently in the manuscript. To enhance clarity and consistency, I recommend removing this reference and using \"KKG\" as the abbreviation for Kadaster Knowledge Graph, as this is already done in most parts of the manuscript - Section 3.1. Iteration 1: Linked Data as \"Yet Another Format\":   - The meaning of “WFS” (Web Feature Service) should be introduced in this section rather than in  Section 3.1.1. Implementation. This change will provide readers with relevant context at an earlier point in the document. - Section 3.3.1. Implementation:   - Morph-KGC could be appropriately cited, as this KG construction engine is supported by a scientific paper: https://content.iospress.com/articles/semantic-web/sw223135 - Section 3.3.2. Evaluation:   - As the KG is operating in a production environment, it would be useful to provide a detailed evaluation of this construction iteration. For instance, what has been the impact of changes originated by the new model (IMX-Geo) on the use cases supported by the previous model, the benefits and challenges encountered when adopting a mapping rules strategy (using RML or R2RML) for building the KKG, how the governance of the KKG has been improved since the alignment with the Kadaster’s enterprise architecture, etc. Sharing these experiences could greatly enhance the understanding and relevance of the latest construction iteration. - Section 4.1. Lessons Learned Across Construction Iterations:   - Governance of Knowledge Graphs: This lesson is a highly relevant and extensive topic, particularly for large organizations. However, the manuscript lacks further details on how governance is managed within Kadaster. To enhance the reader's understanding, it would be beneficial to include references related to this topic, allowing them to explore further information on, for example, “roles and responsibilities”. A valuable reference could be Section 5.2.4.1, titled “Roles in the KGE Lifecycle,” from the recent Dagstuhl Seminar Report https://drops.dagstuhl.de/storage/04dagstuhl-reports/volume14/issue02/24... which outlines the various individuals involved in the KG construction. - Section 5. Future work:   - Evaluation of LLMs: Similarly to my previous comment, it would be useful to include references related to this topic. (e.g. https://drops.dagstuhl.de/storage/08tgdk/tgdk-vol001/tgdk-vol001-issue00...  )  Typos: - Section 3.2: “publication of concept lists in linked data” -> “publication of concept lists as linked data” - Section 3.2.1:   - In caption of Figure 2, “…the ETL process with Delivers Linked Data” -> “…the ETL process which delivers Linked Data”   - In caption of Figure 3, the format of its reference should align with the style used for other citations throughout the manuscript - Section 4. “Discussion and Future Work” should be renamed as it does not provide information about future work. - Section 4.1: “linked data adoption suffers …” -> “Linked data adoption suffers …” - Section 5: “(LLMs for knowledge graph” -> “(LLMs for knowledge graph)”",
         "0.7708",
         "5",
         "3",
         "0.1456390603931587",
         "0.1969",
         "0.8592510223388672",
         "32.02",
         "14.3",
         "13.93",
         "15.9",
         "17.1",
         "96",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "True",
         "3",
         "4",
         "3",
         "4",
         "3.0",
         "5.0",
         "5.0",
         "90.0",
         "90"
        ],
        [
         "11",
         "3721-4935",
         "Anonymous",
         "15/Oct/2024",
         "Minor Revision",
         "344",
         "EducaWood: a Semantic Web Application for Forestry Education",
         "There are few applications available for educational purposes in the forestry domain. These applications have significant limitations, including not exploiting existing biodiversity datasets, lacking flexible and consistent use of domain concepts, and generating annotations that are not easily shareable or reusable by other applications. In this paper, we introduce EducaWood, a novel Semantic Web application designed for forestry education that overcomes these limitations by leveraging Linked Open Data (LOD). Users can easily create tree annotations through a web form that hides the complexity of Semantic Web technologies. These annotations adhere to the Simple Tree Annotation ontology and are saved in a triplestore, facilitating seamless sharing with other users and applications. Moreover, EducaWood offers scalable and efficient visualization of semantic tree data across various zoom levels on a map interface. Access to LOD is handled through a REST API that allows read and write operations over multiple data sources. An implementation of EducaWood has been successfully tested by almost 500 users, including real students and teachers in a pilot educational experience.",
         "95",
         "Dear Educawood Team, I really liked your work and the idea behind your tool and the story has been comprehensibely described in the paper. I would assume that the addition of the millions of tress that are out there could make this experience really fun. Below you can find a list of my suggestions for improvement: * You are highlightling forestry education but mention Tree Management. I would recommend spending some thoughts creating different personas of User Types and what would be their use cases. I would assume that also Analysis/Layer Topics (e.g. highlighting a big amount of dead trees) would be necessary then. You could select representatives of personas and do lists with user acceptance tests. * User Requirements of Personas should be logically linked with you functional requirements, especially in connection with Challenge 3. You should provide a scientific method to evaluate the quality of the end result. Your current requirments are basically boolean (it works or it does not) or in the case of low latency not very specific. Therefore it is not possible to really grasp the quality of the implementation. * Please define your test cases and design them in a way to evaluate the current boundaries of the application (e.g. generate a Million Trees randomly and see how it effects loading times, render times, visualization quality and usability in different scenarios) * Same thing should go for the performance of the API Calls under stress. As you were highlighting the integration of multiple sources is challenging so you should provide some metrics and gradients depending on loads * In the SPA Model I got confused that classes are named Annotations and subclasses of Annotations when I would personally interpret them as Classes. Especially since the Annotation Property is a part of Ontology Standards. That creates an ambiguity that I would avoid in the model Please think about which of these suggestions are in and out of scope for the current paper. Thank you very much for the nice read and I hope this feedback helps you moving forward.",
         "0.8121",
         "0",
         "0",
         "0.0465384615384615",
         "0.8033",
         "0.7155685424804688",
         "51.28",
         "11.1",
         "13.98",
         "14.1",
         "12.6",
         "96",
         "2",
         "1",
         "0",
         "0",
         "4.0",
         "5.0",
         "3.0",
         "1",
         "2",
         "4",
         "3",
         "3",
         "3.0",
         "2.0",
         "3.0",
         "73.0",
         "83"
        ],
        [
         "12",
         "3721-4935",
         "Anonymous",
         "27/Oct/2024",
         "Major Revision",
         "1111",
         "EducaWood: a Semantic Web Application for Forestry Education",
         "There are few applications available for educational purposes in the forestry domain. These applications have significant limitations, including not exploiting existing biodiversity datasets, lacking flexible and consistent use of domain concepts, and generating annotations that are not easily shareable or reusable by other applications. In this paper, we introduce EducaWood, a novel Semantic Web application designed for forestry education that overcomes these limitations by leveraging Linked Open Data (LOD). Users can easily create tree annotations through a web form that hides the complexity of Semantic Web technologies. These annotations adhere to the Simple Tree Annotation ontology and are saved in a triplestore, facilitating seamless sharing with other users and applications. Moreover, EducaWood offers scalable and efficient visualization of semantic tree data across various zoom levels on a map interface. Access to LOD is handled through a REST API that allows read and write operations over multiple data sources. An implementation of EducaWood has been successfully tested by almost 500 users, including real students and teachers in a pilot educational experience.",
         "107",
         "This manuscript was submitted as 'Application Report' and should be reviewed along the following dimensions: (1) Quality, importance, and impact of the described application (convincing evidence must be provided). (2) Clarity and readability of the describing paper, which shall convey to the reader the key ideas regarding the application of Semantic Web technologies in the application. Please also assess the data file provided by the authors under “Long-term stable URL for resources”. In particular, assess (A) whether the data file is well organized and in particular contains a README file which makes it easy for you to assess the data, (B) whether the provided resources appear to be complete for replication of experiments, and if not, why, (C) whether the chosen repository, if it is not GitHub, Figshare or Zenodo, is appropriate for long-term repository discoverability, and (4) whether the provided data artifacts are complete. Please refer to the reviewer instructions and the FAQ for further information. The paper describes a forestry interface, the EducaWood, that can be used for educational purposes. The code for the application is on the GitHub repository, however, it does not contain the ontology. There is a SPARQL endpoint at https://crossforest.gsic.uva.es/pruebas/sparql  (1) Quality, importance, and impact of the described application  The application found at https://educawood.gsic.uva.es/ shows a well-developed and pleasant to use tool for forestry domain, which preliminary results demonstrate potential impact in forestry education. Although the interface has a polished design, the paper quality is uncertain due to a couple of drawbacks, as listed below.  1. First and foremost, the EducaWood work seems quite similar to Forest Explorer which has been published in previous papers (see references 38, 41, 51 in the paper). However, the paper does not explain how it advances the contributions made in these papers.  2. The related works section does not include past works similar to EducaWood (papers 41 and 51), and only briefly describes previous work done in paper 38. Moreover, this section does not mention how the described literature is relevant to the paper's work, which limitations were imposed, and which parts this paper adapts, and advances compared to the state-of-the-art. Further, Section 2.2 is a mix of different elements (visualizations, REST APIs etc) making it difficult to follow and understand their connection to the paper contributions; I would recommend rewriting this section or spliting it to more sections each with a distinctive content.  3. As the paper focuses on the EducaWood interface, it lacks the clear connection and advancement to the semantic web, especially since the architecture of EducaWood, and the creation of annotations seem very close to those of Forest Explorer. Consequentially, I would recommend clearly stating the differences of the current paper output to previously published works. Also, it would be helpful adding in the Table 2 dependencies related to SW. Moreover, the paper can be benefited of a section describing the underlying ontology and knowledge graph in numbers, and comparing them with state-of-the-art resources and the user-interface connections they provide.  4. I am not sure I understand well Table 1, as I would expect having the namespaces used in the ontology, however I am not certain this is the case as no information is further provided in the text. Moreover, the namespaces used raises concerns about best practices for ontology development as the same namespace (http://educawood.gsic.uva.es) is reused under different prefixes.  5. Highlighting the pedagogical aspect of the special issue, I would expect more details about:  5.1. which aspects of the system and interface are aligned with which pedagogical and learning settings. Currently, the paper's discussion of educational aspects takes place only at the end of the paper (Section 4 and 5). This leads to plenty of unsupported claims, about the applicability of EducaWood in different educational levels, learning objectives, learners interest, interdisciplinary learning, collaborative learning, and logical awareness, because it misses any connection with the EducaWood system and interface.  5.2. Section 4.2, regarding the experiment, such as the students background knowledge checks (if any), students introduction to EducaWood steps, an example of the annotation session and verification, more details about the design and learning objectives of the experiment and the choice of different steps (min 20 trees, forestry management) motivating the usage of SUS questionnaire, what type of teachers feedback was provided, which was the alternative paper-pencil activity and how EducaWood is making thinks better/easier, qualitative analysis and presentation of the students annotations (in comparisson with their scores) and discussion of minor bugs and how they might have affected the UX.  6. Regarding the educational contribution, the results of SUS (75% with s.d. 11.5) seem very similar to Forest Explorer SUS results (75% with s.d. 16 in general. If the two systems are similar (to which degree is left to the revision to be clarified), I would need to see how the EducaWood is better since the SUS results do not demonstrate any potential for statistical significance.  7. Regarding the design of web applications, the paper claims to contribution to the \"good practices\", but it is unclear which are those and how they apply them in EducaWood.  (2) Clarity and readability of the describing paper  The presentation and readability could be improved in most of the sections.  I would recommend having a different 1st paragraph in the Introduction that is more related to the topic.  I would highly encourage restructuring and editing the paper so it clearly explains the problem, proposed solution and contributions of the current work compared to the literature. Minor comments:  - kindly avoid the ...  - adding \"The\" before the namespace:name in the beginning of a sentence  - make footnotes before ; ie ZOOMz;\\footnote{} -> ZOOMz\\footnote{};  - adding limitations to Discussion section  - reformulating the Discussion section to highlight the key findings and contributions of the paper  - adding a separate future work and conclusion section for the summary of the paper  - kindly make the Figure 1 with transparent background, if possible  2 (A) the data file is well organized and in particular contains a README file which makes it easy for you to assess the data  yes  2 (B) whether the provided resources appear to be complete for replication of experiments,  no, the user study data are not provided  2 (C) whether the chosen repository is appropriate for long-term repository discoverability,  yes  (4) whether the provided data artifacts are complete.  There is a GitHub does not connect to the underlying ontology neither to the SPARQL endpoint.  Questions for the authors:  1. In the description of Figure 4b, why is the taxon information obtained from DBpedia and Wikidata, and not the underlying ontology and KG?  2. In Listing 1, why most of the IDs are the same (the \"Neik7P0woiD\")?",
         "0.7516",
         "10",
         "3",
         "0.1315243902439024",
         "0.3825",
         "0.8907488584518433",
         "28.57",
         "15.6",
         "14.82",
         "16.9",
         "17.3",
         "94",
         "0",
         "0",
         "1",
         "0",
         "3.0",
         "4.0",
         "6.0",
         "no",
         "neutral",
         "neutral",
         "Moderate",
         "2",
         "3.0",
         "4.0",
         "5.0",
         "70.0",
         "70"
        ],
        [
         "13",
         "3721-4935",
         "Dalia E Varanka",
         "20/Dec/2024",
         "Accept",
         "157",
         "EducaWood: a Semantic Web Application for Forestry Education",
         "There are few applications available for educational purposes in the forestry domain. These applications have significant limitations, including not exploiting existing biodiversity datasets, lacking flexible and consistent use of domain concepts, and generating annotations that are not easily shareable or reusable by other applications. In this paper, we introduce EducaWood, a novel Semantic Web application designed for forestry education that overcomes these limitations by leveraging Linked Open Data (LOD). Users can easily create tree annotations through a web form that hides the complexity of Semantic Web technologies. These annotations adhere to the Simple Tree Annotation ontology and are saved in a triplestore, facilitating seamless sharing with other users and applications. Moreover, EducaWood offers scalable and efficient visualization of semantic tree data across various zoom levels on a map interface. Access to LOD is handled through a REST API that allows read and write operations over multiple data sources. An implementation of EducaWood has been successfully tested by almost 500 users, including real students and teachers in a pilot educational experience.",
         "161",
         "This manuscript was submitted as 'Application Report' and should be reviewed along the following dimensions: (1) Quality, importance, and impact of the described application (convincing evidence must be provided). (2) Clarity and readability of the describing paper, which shall convey to the reader the key ideas regarding the application of Semantic Web technologies in the application. Please also assess the data file provided by the authors under “Long-term stable URL for resources”. In particular, assess (A) whether the data file is well organized and in particular contains a README file which makes it easy for you to assess the data, (B) whether the provided resources appear to be complete for replication of experiments, and if not, why, (C) whether the chosen repository, if it is not GitHub, Figshare or Zenodo, is appropriate for long-term repository discoverability, and (4) whether the provided data artifacts are complete. Please refer to the reviewer instructions and the FAQ for further information.",
         "0.7316",
         "0",
         "0",
         "0.1106060606060606",
         "0.2893",
         "0.766657829284668",
         "14.22",
         "19.1",
         "20.46",
         "19.3",
         "20.2",
         "94",
         "0",
         "0",
         "1",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "True",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "4.0",
         "80.0",
         "90"
        ],
        [
         "14",
         "3699-4913",
         "Anonymous",
         "22/Jul/2024",
         "Accept",
         "169",
         "Temporal Relevance for Representing Learning over Temporal Knowledge Graphs",
         "Representation learning for link prediction is one of the leading approaches to deal with incompleteness problem of real world knowledge graphs. Such methods are often called knowledge graph embedding models which represent entities and relationships in knowledge graphs in continuous vector spaces. By doing this, semantic relationships and patterns can be captured in the form of compact vectors. In temporal knowledge graphs, the connection of temporal and relational information is crucial for representing facts accurately. Relations provide the semantic context for facts, while timestamps indicate the temporal validity of facts. The importance of time is different for the semantics of different facts. Some relations in some temporal facts are time-insensitive, while others are highly time-dependent. However, existing embedding models often overlook the time sensitivity of different facts in temporal knowledge graphs. These models tend to focus on effectively representing connection between individual components of quadruples, consequently capturing only a fraction of the overall knowledge. Ignoring importance of temporal properties reduces the ability of temporal knowledge graph embedding models in accurately capturing these characteristics. To address these challenges, we propose a novel embedding model based on temporal relevance, which can effectively capture the time sensitivity of semantics and better represent facts. This model operates within a complex space with real and imaginary parts to effectively embed temporal knowledge graphs. Specifically, the real part of the final embedding of our proposed model captures semantic characteristic with temporal sensitivity by learning the relational information and temporal information through transformation and attention mechanism. Simultaneously, the imaginary part of the embeddings learns the connections between different elements in the fact without predefined weights. Our approach is evaluated through extensive experiments on the link prediction task, where it majorly outperforms state-of-the-art models. The proposed model also demonstrates remarkable effectiveness in capturing the complexities of temporal knowledge graphs.",
         "78",
         "The revised paper under review introduces TRKGE, a model that integrates temporal relevance into the temporal knowledge graph completion framework. Utilizing tensor decomposition, TRKGE is distinct in its sensitivity to the temporal attributes of facts, differentiating between transient and permanent relations. The model's innovative construction in the complex space, coupled with rotation matrices and an attention mechanism, seamlessly blends temporal relevance with entity, relation, and timestamp embeddings. The performance, particularly in link prediction accuracy, surpasses existing state-of-the-art systems, marking a significant advancement in the field. The authors have addressed the primary concerns highlighted in my initial review. They have now provided an in-depth discussion on time complexity. Additionally, the authors have improved the paper's reproducibility by sharing the source code. These resources are crucial for validating the model's performance and facilitating its application in further research. In conclusion, the authors have successfully addressed the critical issues raised in the initial review. The paper is ready for publication and is expected to inspire further research and development in this domain.",
         "0.7998",
         "0",
         "0",
         "0.1494791666666666",
         "0.1149",
         "0.9069722890853882",
         "12.02",
         "15.8",
         "17.88",
         "16.5",
         "17.1",
         "84",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "5.0",
         "1.0",
         "True",
         "positive",
         "polite",
         "Minimal",
         "very specific",
         "5.0",
         "5.0",
         "5.0",
         "95.0",
         "95"
        ],
        [
         "15",
         "3699-4913",
         "Anonymous",
         "28/Jul/2024",
         "Accept",
         "60",
         "Temporal Relevance for Representing Learning over Temporal Knowledge Graphs",
         "Representation learning for link prediction is one of the leading approaches to deal with incompleteness problem of real world knowledge graphs. Such methods are often called knowledge graph embedding models which represent entities and relationships in knowledge graphs in continuous vector spaces. By doing this, semantic relationships and patterns can be captured in the form of compact vectors. In temporal knowledge graphs, the connection of temporal and relational information is crucial for representing facts accurately. Relations provide the semantic context for facts, while timestamps indicate the temporal validity of facts. The importance of time is different for the semantics of different facts. Some relations in some temporal facts are time-insensitive, while others are highly time-dependent. However, existing embedding models often overlook the time sensitivity of different facts in temporal knowledge graphs. These models tend to focus on effectively representing connection between individual components of quadruples, consequently capturing only a fraction of the overall knowledge. Ignoring importance of temporal properties reduces the ability of temporal knowledge graph embedding models in accurately capturing these characteristics. To address these challenges, we propose a novel embedding model based on temporal relevance, which can effectively capture the time sensitivity of semantics and better represent facts. This model operates within a complex space with real and imaginary parts to effectively embed temporal knowledge graphs. Specifically, the real part of the final embedding of our proposed model captures semantic characteristic with temporal sensitivity by learning the relational information and temporal information through transformation and attention mechanism. Simultaneously, the imaginary part of the embeddings learns the connections between different elements in the fact without predefined weights. Our approach is evaluated through extensive experiments on the link prediction task, where it majorly outperforms state-of-the-art models. The proposed model also demonstrates remarkable effectiveness in capturing the complexities of temporal knowledge graphs.",
         "84",
         "(1) originality, this paper is novel and considers the interplay between time and relation in terms of knowledge graph completion. (2) significance of the results. Compared with other embedding methods, the experimental results show improvements, especially in the GDELT dataset.  (3) quality of writing. This paper is easy to follow and includes detailed introduction to previous work and extensive experiments.",
         "0.7886",
         "0",
         "0",
         "0.0916666666666666",
         "0.1304",
         "0.8356141448020935",
         "33.92",
         "11.5",
         "15.47",
         "13.3",
         "12.2",
         "60",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "1.0",
         "True",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "4.0",
         "5.0",
         "5.0",
         "95.0",
         "95"
        ],
        [
         "16",
         "3699-4913",
         "Zhangzu Wang",
         "21/Oct/2024",
         "Accept",
         "56",
         "Temporal Relevance for Representing Learning over Temporal Knowledge Graphs",
         "Representation learning for link prediction is one of the leading approaches to deal with incompleteness problem of real world knowledge graphs. Such methods are often called knowledge graph embedding models which represent entities and relationships in knowledge graphs in continuous vector spaces. By doing this, semantic relationships and patterns can be captured in the form of compact vectors. In temporal knowledge graphs, the connection of temporal and relational information is crucial for representing facts accurately. Relations provide the semantic context for facts, while timestamps indicate the temporal validity of facts. The importance of time is different for the semantics of different facts. Some relations in some temporal facts are time-insensitive, while others are highly time-dependent. However, existing embedding models often overlook the time sensitivity of different facts in temporal knowledge graphs. These models tend to focus on effectively representing connection between individual components of quadruples, consequently capturing only a fraction of the overall knowledge. Ignoring importance of temporal properties reduces the ability of temporal knowledge graph embedding models in accurately capturing these characteristics. To address these challenges, we propose a novel embedding model based on temporal relevance, which can effectively capture the time sensitivity of semantics and better represent facts. This model operates within a complex space with real and imaginary parts to effectively embed temporal knowledge graphs. Specifically, the real part of the final embedding of our proposed model captures semantic characteristic with temporal sensitivity by learning the relational information and temporal information through transformation and attention mechanism. Simultaneously, the imaginary part of the embeddings learns the connections between different elements in the fact without predefined weights. Our approach is evaluated through extensive experiments on the link prediction task, where it majorly outperforms state-of-the-art models. The proposed model also demonstrates remarkable effectiveness in capturing the complexities of temporal knowledge graphs.",
         "169",
         "The paper after revision flows better than the original and my questions are mostly addressed. For example, Table 1 gives a clear summary of notations which helps significantly with the overall workflow. Besides, the stable url is also provided. The motivation of the work is justified and experiments show adequate support. Therefore I would recommend acceptance.",
         "0.8367",
         "0",
         "0",
         "0.3229166666666667",
         "0.1655",
         "0.654490053653717",
         "34.73",
         "11.2",
         "15.19",
         "13.0",
         "10.2",
         "56",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "5.0",
         "4.0",
         "4.0",
         "90.0",
         "90"
        ],
        [
         "17",
         "3765-4979",
         "Finn Årup Nielsen",
         "16/Oct/2024",
         "Minor Revision",
         "300",
         "On General and Biomedical Text-to-Graph Large Language Models",
         "Knowledge graphs and ontologies represent symbolic and factual information that can offer structured and interpretable knowledge. Extracting and manipulating this type of information is a crucial step in complex processes. While Large Language Models (LLMs) are known to be useful for extracting and enriching knowledge graphs and ontologies, previous work has largely focused on comparing architecture-specific models (e.g. encoder-decoder only) across benchmarks from similar domains. In this work, we provide a large-scale comparison of the performance of certain LLM features (e.g. model architecture and size) and task learning methods (fine-tuning vs. in-context learning (iCL)) on text-to-graph benchmarks in two domains, namely the general and biomedical ones. Experiments suggest that, in the general domain, small fine-tuned encoder-decoder models and mid-sized decoder-only models used with iCL reach overall comparable performance with high entity and relation recognition and moderate yet encouraging graph completion. Our results further tentatively suggest that, independent of other factors, biomedical knowledge graphs are notably harder to learn and better modelled by small fine-tuned encoder-decoder architectures. Pertaining to iCL, we analyse hallucinating behaviour related to sub-optimal prompt design, suggesting an efficient alternative to prompt engineering and prompt tuning for tasks with structured model output.",
         "16",
         "I thank the authors for feedback to my review. I am mostly satisfy except for my last point with the ordering of the triplets. Consider the WebNLG sentence: \"A.E Dimitra Efxeinoupolis is located in Greece, the capital of which is Athens.\". There are two triplet extracted: <\"A.E_Dimitra_Efxeinoupolis\", \"location\", \"Greece\"> <\"Greece\", \"capital\", \"Athens\"> If we reorder the triples they become <\"Greece\", \"capital\", \"Athens\"> <\"A.E_Dimitra_Efxeinoupolis\", \"location\", \"Greece\"> If we use ROUGE *across* triplets, then we - in the first case - get as one of the two-grams \"Greece, Greece\" and in the second case instead \"Athens, A.E_Dimitra_Efxeinoupolis\". It was not clear to me from the paper and it is still not clear from the reply notes whether the ROUGE metrics are used across triplets, so the object of one triplet is used together with the subject of the following extracted triplet. If that is the case then the metric can be manipulated by reordering the triplets (if there are multiple triplets). Reading Figure 6, Appendix A, I see that the (Ciudad Ayala # country # Mexico) is first in the output while the same triple it in the middle of the list. Would moving that triple to the \"correct\" position result in another ROUGE-2 and ROUGE-L score? As far as can read code the authors use the 'evaluate' Python library for testing with ROUGE. https://github.com/jrcf7/txt2graphLLMs/blob/main/scripts/utils/predictio... But I have not examined with what format of data the 'compute' method is called. In graphs the ordering of the triplets are usually ignored. Therefore if the computation of the ROUGE (-2 and -L) score is order-dependent it is highly unusual and should be noted in the manuscript. As a side note I would like to point out that reviewer 3 points to a Piglou paper but the authors pont to a Kuhn paper, reference [6].",
         "0.7241",
         "1",
         "2",
         "0.0522222222222222",
         "0.7339",
         "0.8167802095413208",
         "52.7",
         "10.5",
         "11.32",
         "12.2",
         "12.4",
         "60",
         "0",
         "0",
         "0",
         "1",
         "4.0",
         "3.0",
         "2.0",
         "no",
         "neutral",
         "neutral",
         "minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "82.0",
         "82"
        ],
        [
         "18",
         "3765-4979",
         "Fidel Jiomekong",
         "16/Nov/2024",
         "Accept",
         "226",
         "On General and Biomedical Text-to-Graph Large Language Models",
         "Knowledge graphs and ontologies represent symbolic and factual information that can offer structured and interpretable knowledge. Extracting and manipulating this type of information is a crucial step in complex processes. While Large Language Models (LLMs) are known to be useful for extracting and enriching knowledge graphs and ontologies, previous work has largely focused on comparing architecture-specific models (e.g. encoder-decoder only) across benchmarks from similar domains. In this work, we provide a large-scale comparison of the performance of certain LLM features (e.g. model architecture and size) and task learning methods (fine-tuning vs. in-context learning (iCL)) on text-to-graph benchmarks in two domains, namely the general and biomedical ones. Experiments suggest that, in the general domain, small fine-tuned encoder-decoder models and mid-sized decoder-only models used with iCL reach overall comparable performance with high entity and relation recognition and moderate yet encouraging graph completion. Our results further tentatively suggest that, independent of other factors, biomedical knowledge graphs are notably harder to learn and better modelled by small fine-tuned encoder-decoder architectures. Pertaining to iCL, we analyse hallucinating behaviour related to sub-optimal prompt design, suggesting an efficient alternative to prompt engineering and prompt tuning for tasks with structured model output.",
         "47",
         "The authors addressed the comments suggested in the previous reviews. The authors should make a proofread of the manuscript to correct grammatical errors and typos. The following comments should also be considered: Page 5: - line 3: Here we discuss -> This section presents - line 7: Given that the authors make reference to datasets, it would be nice if they can present the datasets before this section (but, not an obligation) - line 47: .. (we adopt version 3.0) … -> (we choose version 3.0) may be more appropriate Page 6: - line 1 - 12: it would be nice to illustrate with an example Page 7: - Hugging Face2 ,3 -> check the correct way to put the numbers referring to the footnote Page 8: - … Encoder-decoder architectures are a generic class of transformer models, introduced in [57] … -> Encoder-decoder architectures are generic class of transformer models [57] Page 9: - line 21: is the following correct?: Anther difference consists Page 10: - line 33: it would be nice at this point to highlight the prompt method used by the authors. Of course, the type of prompt used is presented in page 13, line 48, but it is too far for the reader who wants to understand the paper Page 14: - line 37: have a a log-linear -> have a log-linear",
         "0.7474",
         "0",
         "2",
         "0.2256410256410256",
         "0.1303",
         "0.6860838532447815",
         "53.65",
         "12.2",
         "14.03",
         "14.0",
         "14.7",
         "93",
         "0",
         "1",
         "0",
         "2",
         "4.0",
         "5.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "3",
         "4.0",
         "5.0",
         "5.0",
         "92.0",
         "92"
        ],
        [
         "19",
         "3765-4979",
         "Anonymous",
         "05/Dec/2024",
         "Accept",
         "17",
         "On General and Biomedical Text-to-Graph Large Language Models",
         "Knowledge graphs and ontologies represent symbolic and factual information that can offer structured and interpretable knowledge. Extracting and manipulating this type of information is a crucial step in complex processes. While Large Language Models (LLMs) are known to be useful for extracting and enriching knowledge graphs and ontologies, previous work has largely focused on comparing architecture-specific models (e.g. encoder-decoder only) across benchmarks from similar domains. In this work, we provide a large-scale comparison of the performance of certain LLM features (e.g. model architecture and size) and task learning methods (fine-tuning vs. in-context learning (iCL)) on text-to-graph benchmarks in two domains, namely the general and biomedical ones. Experiments suggest that, in the general domain, small fine-tuned encoder-decoder models and mid-sized decoder-only models used with iCL reach overall comparable performance with high entity and relation recognition and moderate yet encouraging graph completion. Our results further tentatively suggest that, independent of other factors, biomedical knowledge graphs are notably harder to learn and better modelled by small fine-tuned encoder-decoder architectures. Pertaining to iCL, we analyse hallucinating behaviour related to sub-optimal prompt design, suggesting an efficient alternative to prompt engineering and prompt tuning for tasks with structured model output.",
         "66",
         "The authors have satisfactorily addressed all my comments. I believe the paper is now ready for acceptance.",
         "0.9412",
         "0",
         "0",
         "0.2",
         "0.2468",
         "0.6267498731613159",
         "54.39",
         "7.8",
         "8.11",
         "0.0",
         "8.0",
         "16",
         "1",
         "0",
         "0",
         "0",
         "5.0",
         "5.0",
         "0.0",
         "True",
         "positive",
         "polite",
         "Minimal",
         "very specific",
         "5.0",
         "4.0",
         "5.0",
         "90.0",
         "92"
        ],
        [
         "20",
         "3757-4971",
         "Christophe Cruz",
         "06/Oct/2024",
         "Accept",
         "452",
         "Constructing Domain-Specific Knowledge Graphs From Text: A Case Study on Subprime Mortgage Crisis",
         "This research paper details a novel methodology for constructing a domain-specific Knowledge Graph (KG) from unstructured text data, exemplified by a case study on the subprime mortgage crisis. The authors present a five-phase approach – specification, conceptualization, formalization, integration, and augmentation – to transform unstructured financial news articles from the MEANTIME corpus into a structured KG. This framework enables the extraction of valuable insights, revealing trends, correlations, and complex relationships among companies, market movements, and economic indicators. The KG's efficacy is demonstrated through its ability to answer complex queries related to the subprime mortgage crisis, highlighting its potential as a powerful tool for knowledge representation and decision-making in the financial domain.   ",
         "27",
         "The paper \"Constructing Domain-Specific Knowledge Graphs From Text: A Case Study on Subprime Mortgage Crisis\" presents an innovative approach to constructing domain-specific knowledge graphs from textual data. The authors have chosen to focus on the subprime mortgage crisis as their case study, which provides a compelling and complex real-world application for their methodology. In terms of originality, the paper offers a fresh perspective on extracting and structuring knowledge from complex financial texts. The methodology described appears novel in its application to this specific domain, potentially opening new avenues for research in other complex fields. The significance of the results is evident in several aspects. The paper provides a methodology for creating domain-specific knowledge graphs and demonstrates its practical application to a high-impact scenario. The subprime mortgage crisis is a topic of considerable importance in the field of finance and economics, and the creation of a knowledge graph in this domain could serve as a valuable resource for researchers and practitioners alike. Furthermore, the methodology presented has the potential to be applied to other complex domains, extending its impact beyond the immediate case study. The quality of writing in the paper is commendable. The authors have presented their ideas clearly and coherently, making the complex subject matter accessible to readers. The structure of the paper appears to be well-organized, allowing for a logical flow of ideas from the introduction of the methodology to its application in the case study. Regarding the data file assessment, the authors have provided a GitHub repository with full details about the implementation and usage. This choice of platform is appropriate for long-term discoverability, as GitHub is widely used for code sharing and version control, making it easily accessible to other researchers. The provision of implementation details and usage instructions should facilitate reproducibility of the experiments described in the paper. While a thorough assessment of the README file's clarity and completeness would require direct examination, the fact that the authors have included \"full details\" suggests a commitment to transparency and reproducibility. This is a significant strength of the paper, as it allows other researchers to build upon and verify the work presented. The combination of a novel methodology, a relevant and impactful case study, and accessible resources makes this paper a significant and interesting contribution to the community. In conclusion, this paper presents a valuable contribution to the field by providing a methodology for constructing domain-specific knowledge graphs and applying it to the complex domain of the subprime mortgage crisis. The high-quality writing, novel approach, and provision of resources for replication all contribute to making this a strong and impactful piece of research. Its potential to influence future work in both knowledge graph construction and financial analysis is considerable.",
         "0.791",
         "0",
         "0",
         "0.1064658210007047",
         "0.1041",
         "0.9698132276535034",
         "23.16",
         "15.6",
         "15.85",
         "16.9",
         "17.3",
         "89",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "5.0",
         "2.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "5.0",
         "5.0",
         "5.0",
         "90.0",
         "92"
        ],
        [
         "21",
         "3757-4971",
         "Paul Groth",
         "09/Nov/2024",
         "Major Revision",
         "326",
         "Constructing Domain-Specific Knowledge Graphs From Text: A Case Study on Subprime Mortgage Crisis",
         "This research paper details a novel methodology for constructing a domain-specific Knowledge Graph (KG) from unstructured text data, exemplified by a case study on the subprime mortgage crisis. The authors present a five-phase approach – specification, conceptualization, formalization, integration, and augmentation – to transform unstructured financial news articles from the MEANTIME corpus into a structured KG. This framework enables the extraction of valuable insights, revealing trends, correlations, and complex relationships among companies, market movements, and economic indicators. The KG's efficacy is demonstrated through its ability to answer complex queries related to the subprime mortgage crisis, highlighting its potential as a powerful tool for knowledge representation and decision-making in the financial domain.   ",
         "61",
         "This article proposes a new methodology and system for knowledge graph construction. It provides an implementation of that methodology in a well documented framework. However, the evaluation is case study based and I found it difficult to assess the paper as a research contribution because of the lack of generalisability.  Specifically, the paper claims that \"Existing methodologies to KG construction are predominantly constrained by their domain-specific focus, which limits their flexibility and generalizability for KG construction for other domains.\". However, it then proceeds to analyse the performance of the approach on a single domain in the financial sector. I would have expected to see the methodology applied to multiple domains to address this claim.  Furthermore, I think there are in fact several general approaches to knowledge graph construction, for instance: - Gerhard Weikum, Xin Luna Dong, Simon Razniewski and Fabian Suchanek (2021), \"Machine Knowledge: Creation and Curation of Comprehensive Knowledge Bases\", Foundations and Trends® in Databases: Vol. 10: No. 2-4, pp 108-490. - Hofer, M., Obraczka, D., Saeedi, A., Köpcke, H., & Rahm, E. (2024). Construction of knowledge graphs: current state and challenges. Information, 15(8), 509. - Gytė Tamašauskaitė and Paul Groth. 2023. Defining a Knowledge Graph Development Process Through a Systematic Review. ACM Trans. Softw. Eng. Methodol. 32, 1, Article 27 (January 2023), 40 pages. https://doi.org/10.1145/3522586 - Lingfeng Zhong, Jia Wu, Qian Li, Hao Peng, and Xindong Wu. 2023. A Comprehensive Survey on Automatic Knowledge Graph Construction. ACM Comput. Surv. 56, 4, Article 94 (April 2024), 62 pages. https://doi.org/10.1145/3618295 -  That being said, I think there are interesting elements of the proposed methodology in particular the focus on linguistic analysis. I also appreciated the underlying software text2graphs as a framework and the reflection on the role of KG construction with respect to outputs as property graphs. I think maybe the paper would have been better as a systems paper or application paper rather than a research paper with the key requirement of evidence of generalisation.",
         "0.8295",
         "14",
         "4",
         "0.0535376082251082",
         "0.103",
         "0.8800716996192932",
         "37.5",
         "12.2",
         "13.1",
         "14.0",
         "14.4",
         "99",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "2.0",
         "no",
         "neutral",
         "neutral",
         "minimal",
         "3",
         "4.0",
         "3.0",
         "4.0",
         "70.0",
         "70"
        ],
        [
         "22",
         "3757-4971",
         "Anonymous",
         "12/Dec/2024",
         "Reject",
         "2085",
         "Constructing Domain-Specific Knowledge Graphs From Text: A Case Study on Subprime Mortgage Crisis",
         "This research paper details a novel methodology for constructing a domain-specific Knowledge Graph (KG) from unstructured text data, exemplified by a case study on the subprime mortgage crisis. The authors present a five-phase approach – specification, conceptualization, formalization, integration, and augmentation – to transform unstructured financial news articles from the MEANTIME corpus into a structured KG. This framework enables the extraction of valuable insights, revealing trends, correlations, and complex relationships among companies, market movements, and economic indicators. The KG's efficacy is demonstrated through its ability to answer complex queries related to the subprime mortgage crisis, highlighting its potential as a powerful tool for knowledge representation and decision-making in the financial domain.   ",
         "94",
         "* Summary: The paper presents a methodology for constructing a domain-specific financial/stock market Labeled Property Graph from the MEANTIME corpus (unstructured text data).  The presented results and validations revolve around a financial news article on the subprime mortgage crisis (table #7).  The methodology is based on a generic and well-known five-phase approach.   * Overall Evaluation (ranging from 0-10): [Q]+ Quality: 5 [R]+ Importance/Relevance: 5 [I]+ Impact: 4 [N]+ Novelty: 4 [S]+ Stability: 6 [U]+ Usefulness: 4 [W]+ Clarity, illustration, and readability: 7 [P]+ Impression score: 5 * Dimensions for research contributions (ranging from 0-10): (1) Originality (QRN): 4.7 (2) Significance of the results (ISU): 4.7 (3) Quality of writing (QWP): 5.7 * Overall Impression (1,2,3): 50.3 * Suggested Decision: Reject * General comments: - The paper is easy to read and has a good redaction and articulation of the main ideas. - §2-3 (Background and Related Work) cover appropriate and foundational references about methods, techniques, models, and tools for KG and ontology engineering. - I had a good impression of the paper until §4.  Unfortunately, from §5 onward, my positive impression rapidly decayed. In the end, I was disappointed in the intent of this work. To some extent, it feels like the paper presents a \"cooking recipe\" that only lists the ingredients. - The \"meat\" of the content focuses on a case study about the subprime mortgage crisis: to transform an unstructured financial news article related to the stock market (table #7) from the MEANTIME corpus into a structured KG. - The paper claims to present a \"novel\" five-phase approach.  However, there's no apparent novelty in the proposed methodology since it's the summary of generic and well-known steps from the KG/Ontology Engineering domain:   1) Specification: Ontology Requirement Specification Document—ORSD.   2) Conceptualization: concept map (high-level conceptual representation), intermediate representations: data dictionary.   3) Formalization.   4) Integration: the paper skips this part (§7.4).   5) Augmentation: sub-phases: rule-based enrichments (Entity Typing task and identifying \"triggers\" for events) and refinement. - The presented work is weak and has several issues to address (see further below). - The claimed novelty is poor.  One can read the following in some parts of the manuscript:   - \"a novel methodology for constructing a domain-specific Knowledge Graph (KG) from unstructured text data\".   - \"a novel, domain-agnostic framework for the autonomous construction of Knowledge Graphs from unstructured text\".   - However, the paper fails to show this claimed novelty. - Additionally, this paper seems to overlap extensively with ref [104] (both papers are from the same authors).  [104] has more technical merit than this one.  It seems like the content of this manuscript is a \"rehashed\" version of [104].  If this appreciation is incorrect, the authors should describe how the manuscript differs and adds value compared to [104]. - In general, the presented paper requires major corrections and improvements.   * Specific comments: - pag#05 / §4.1: \"The announcement of the credit crisis came as a shock to the financial world\" --> Not really.  Any \"seasoned financial analyst\" like Bob would known that the \"bubble\" was going to \"burst\" at any time since financial reports from early 2007. - §6: This section introduces an overview of the proposed 2-phase approach and architecture.  It's too broad, and it doesn't go into details. There is no apparent novelty.  There are no details on how the integration of the mentioned tasks/techniques was performed.  (It's like a cooking recipe that only lists the ingredients.) - §7.3 / Fig.#6: The ontology spec, in the form of a turtle serialisation of the OWL2 definitions, should be available in the public repo.  A more detailed concept map of the ontology should be presented instead of a Protégé screenshot. - [pag#17 / §7.5] Define/cite/reference \"TLINK\" and \"CLINK\". - §8.1 has only one sub-section (§8.1.1).  This structure is not adequate.  §8.1.1 should be removed (the title), and the content should be merged with §8.1. - §8.1 refers to Figure #5, which comes directly from [104] (Figure #8).  This should be cited. - §8.2, §8.3: What is the value of these sub-sections? Basically, they only state that the KG will be used to answer the competency questions. - Table #6: The intent of the \"Contexts\" and \"Arguments\" is unclear.  Also, there are some typos and missing information:   - [row 1, Arguments]: Shouldn't it be \"ARG1: [Market, StockMarketIndexMovement]\"?   - [row 2, Arguments]: Why there's an ARG2? What does it mean?   - [rows 4 & 6, Arguments]: Why there's no ARG0? What does it mean? - [pag#20 / §8.5] The proposed validation process is a set of queries based on Competency Questions. Did they involve any financial experts to corroborate the query output and KG structure? - [pag#21 / §8.5.2]   - \"... and Lehman Brothers mentioned in the news\"; \"Lehman Brothers\" doesn't even appear in the case study! (link from Table #7).   - \"... statements from CEOs...\"; the article does not include any statement from any CEO! (link from Table #7).   - How can the authors make such statements when the case study that was used clearly doesn't mention many entities?   - This sub-section, along with §4.1, describes a \"fairy tale\" about \"Bob\" and nothing else.  There's no evidence of any of those results.  Where are they in the repo? Where are the queries and the results presented in the repo?   - This is highly disappointing.  Many things don't make any sense with the content presented in this section.   * Questions: - Why a Labeled Property Graph (LPG)?   - The implementation uses Neo4j's proprietary technologies (graph database and Cypher query language).  The generated KG is an LPG, and it's not represented as an RDF-based KG.   - [pag#03 / §3] \"... RDF presents several limitations... in the context of complex textual data. It often results in sparse graphs with limited structural detail, particularly when handling intricate relationships within diverse real-world scenarios\".  The authors developed an ontology as the KG schema; shouldn't this give a proper backbone structure for the KG?   - What about FAIR principles (https://www.go-fair.org/fair-principles/) if the KG is not based on Open Standards such as W3C's Semantic Web technologies? Are those principles not relevant to this proposed \"framework\"?   - The authors should make a more substantial justification for why their implementation is not based on Open Standards. - Figures #1,2,3:   - Figure #1: It's too generic and resembles the NeoN Ontology Engineering Methodology.   - Are these figures significant contributions? The diagrams summarise well-known steps and techniques in Information Extraction, Computational Linguistics (NLP) tasks, and KG engineering.   - The claimed novelty is unclear.  Additionally, these figures are not clearly aligned with the software artefact in the repo (see feedback below about Figure 5). - §5:   1) Specification: Ontology Requirement Specification Document—ORSD.  Where is the ORSD for this case study?   2) Conceptualization: concept map (high-level conceptual representation), intermediate representations: data dictionary.  Where is the concept map and data dictionary?   3) Formalization.  Where is the OWL ontology file in the repo? - [pag#07 / §5.4] Why you didn't include Wikidata in the \"established knowledge graphs\" spectrum list? - [pag#08 / §5.4] Shouldn't be mapping entities from the formalised model into these external sources (the other way around)?  (this corresponds to the Named-Entity Linking —NEL— task) - [pag#10 / §6.3.1] What is \"text genre\"? - [pag#16 / §7.4] Define \"R2ML\". - Figure #5: This figure should depict the mapping of how each component (Python script, Docker service, etc.) from the software artefact repo is used in each one of those boxes.  What is the purpose of this diagram? Basically, there's no difference between this figure and figures 1-3: they are too broad and vague.  The value of this figure is unclear. - [pag#18 / §8.1.1] The presented validation results of Phase 1 raise many questions:   - What is the \"ground truth\" used to evaluate the performance of all the tasks (entity extraction, recognition of numeric values, temporal expression detection, etc.)?  It is unclear and requires more explanations.   - \"event recall (F1 score of 0.719)\"; the recall metric has an F1 score?! This must be a typo, right? F1 is the harmonic mean of precision and recall; hence, recall can't have an F1 score.   - \"precision in entity instances (F1 score of 0.550)\"; same as above!   - The authors should include a detailed table of the results: the P, R, and F1 for all the tasks (similar to what you did in [104 / Table 3]).  The evaluations should be included in the repo. - [pag#19 / §8.4.2] Where is the *Domain Dictionary* located in the repo? - [§8.4.1 / Table #5, §8.4.3 / Table #6] How the rules are applied? The algorithms are missing.  A diagram depicting these \"enrichments\" should clarify the expected output after applying these rules. - [pag#22-23 / Table #9]   - What kind of id is \"cb.id = 'Central banks across the world'\"?  Is \"RegulatoryBody\" a class in the ontology?  Unclear.   - \"(ec:EconomicCrisis)-[r {type:'ARG0'}]->(e:TEvent)\", why only \"ARG0\"? What about \"ARG1\" and \"ARG2\"?  Unclear.   - \"... made by Bank of America Home Loans...\" The entity doesn't even exist in the news article! (Link from Table #7).   - In the last query, why \"Federal_Reserve\" and not: \"FederalReserve\" or \"Federal Reserve\" or any other variation?  Unclear. - [pag#21 / §8.5.4] How the P, R, and F1 metrics were calculated? What is the \"ground truth\" for the KG enrichment process (NER, events, and temporal expressions)?  Unclear.  Did you manually build another KG from the article and run the same queries? How did you measure the \"relevancy\" of the retrieved results? This requires a detailed explanation. - [pag#23 / Figure #7] Shouldn't the *MarketMovement* event \"fell\" be unique in the graph? Why are there many \"fell\" bubbles? Explanation required. - [pag#24 / Figure #8]   - Why \"ARG1\" and not \"ARG0\"? What is the difference between \"Frame\" and \"PublicStatement\"?   - Why are \"FrameArguments\" modelled as entities and not literal values?   - Explanation required. - [pag#24 / §9] From this section, it seems that the proposed framework only works for the specific stock market case study.  So why are there claims about its generalisability, robustness, and versatility? - After reviewing the paper, I have the final observations regarding the first two stated \"significant contributions to KG construction and semantic modelling\" of this work (pag#02 / §1): 1) Robust stock market ontology.   - There's no evidence of this.  As indicated above, the ontology spec (OWL file) doesn't exist in the repo. 2) Formalization method utilising Labeled Property Graphs (LPGs) to capture complex semantic relationships.   - How is the method formalised? There's little evidence in what is described in §6.   * About the companion resources: (“Long-term stable URL for resources”) — Title of the attached files: \"Materials for mapping study: structured data to RDF\". (A) The repo resources are well organised.  The content is clear and easy to understand. (B) The provided resources appear to be complete.  To some extent, one could replicate the presented case study. (C) The chosen repository is appropriate for long-term repository discoverability. (D) The provided artifacts (companion documents for the study in place) are incomplete.  There are missing artefacts such as the ontology spec, concept map, data dictionary, etc. * Observations: - There's an error in the following Jupyter notebook  * Minor corrections: pag#03 / §3: \"IE\" is used but has not been defined (\"Information Extraction\"). pag#04 / §3: \"semantic role labeling (SRL) (Shi & Lin, 2019)\" --> Modify the reference following the format (a number). pag#05 / §4.1: \"Let’s assume, Bob is a seasoned financial analyst...\" --> \"Let’s assume, Bob, a seasoned financial analyst...\" pag#07~08 / §5.3~5.4: Missing citation/reference/link about OWL, Description Logic, Framenets, RDFS, RDF. pag#08 / §5.5: The two-phase listing should be \"a)\" and \"b)\". pag#09 / Fig.#2:  (Phase 1): \"baed\"; the caption is too small --> should be enlarged.  (All the table and figure captions should be enlarged). pag#10 / §7.1.1: \"IPOs\" is used but has not been defined (\"Initial Public Offerings\"); it's defined in Table #2. pag#13 / Table #2; pag#19 / Table #5: Move it to the next page. pag#14 / Table #2: \"Chronicles chronological\" pag#15 / Table #4: The \"Domain Label Types\" should be in bold --> \"FinancialIndicator\", \"EconomicActivity\", etc. Table #5-6: they are not referenced in the text/content. pag#20 / §8.5.1: The listing should start from \"a)\". pag#21 / §8.5.2: \"Table 7-3\" does not exist.  Shouldn't be Table #9? Figure #7-8: they are not referenced in the text/content. pag#25~ / Ref: \t- Many references are incomplete ([25], [49], [64], [71]...).  See [48] as a complete example for arXiv ([25]). \t- Add DOI/link and year to all. \t- Equivalent references: [79]===[85]. \t- [91] \"M. Fernández, A. Gómez-Pérez\".",
         "0.7841",
         "12",
         "15",
         "0.0242332728545963",
         "0.0363",
         "0.9152600169181824",
         "51.24",
         "9.0",
         "8.75",
         "11.5",
         "11.1",
         "68",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "8.0",
         "no",
         "negative",
         "neutral",
         "Moderate",
         "2",
         "4.0",
         "3.0",
         "3.0",
         "60.0",
         "62"
        ],
        [
         "23",
         "3750-4964",
         "Antonello Meloni",
         "26/Oct/2024",
         "Accept",
         "239",
         "From Manuscripts to Knowledge Graphs: Automating the Semantic Representation of Tafsir al-Tabari",
         "Tafsir, the exegesis of the Quran, constitutes a fundamental pillar of Islamic knowledge, providing critical insights into the interpretation and application of Quranic teachings. Rooted in the teachings of Prophet Muhammad and early Islamic scholars, Tafsir elucidates the Quranic verses through historical, linguistic, and jurisprudential lenses. Despite its profound significance, systematic semantic modelling and digital representation of Tafsir literature remain unexplored.\\nThis paper presents the design, development, and implementation of a SemanticTafsir ontology and knowledge graph, focusing on the comprehensive exegesis by Muhammad Ibn Jarir al-Tabari. Following established ontology engineering methodologies, we define the SemanticTafsir ontology to capture and interlink key concepts within Tafsir literature.  By leveraging existing ontologies such as SemanticHadith, Schema.org, and DBpedia, our approach ensures semantic coherence and interoperability.\\nThe core contribution of this work lies in the automation of the semantic representation of Tafsir literature. We develop a pipeline that automates the conversion of TEI format manuscripts of Tafsir into an RDF-based knowledge graph, integrating Quranic verses, hadith, commentaries, and thematic connections. This automation facilitates enhanced accessibility and analysis of Tafsir literature. The evaluation encompasses logical consistency, competency question resolution, and semantic fidelity, validating the ontology's robustness and applicability.\\nThe SemanticTafsir framework supports SPARQL queries, enabling both technical and non-technical users to explore and derive insights from the interconnected layers of Quranic exegesis. This research contributes to Islamic knowledge engineering by advancing digital preservation, accessibility, and scholarly engagement with Tafsir literature, thereby enriching the global understanding of Islamic knowledge.\\nThe SemanticTafsir ontology and knowledge graph are freely accessible at https://github.com/A-Kamran/SemanticTafsir.",
         "56",
         "1. Originality The manuscript presents an original contribution by automating the transformation of TEI-encoded Tafsir manuscripts into a knowledge graph (KG), a novel approach within Islamic studies and digital humanities. This effort to create a SemanticTafsir ontology enhances accessibility and understanding of the Tafsir literature, filling a gap in digital knowledge representation for Quranic exegesis. 2. Significance of Results The results are highly significant as they enable semantic search and exploration of interconnected concepts within Tafsir literature. The approach could advance both Islamic scholarship and digital preservation efforts, broadening accessibility and understanding of these texts. 3. Quality of Writing The paper is clearly and meticulously written, with well-structured explanations of the KG development process and challenges. The authors outline their methodology comprehensively, ensuring readers can follow the procedural steps and reasoning behind the ontology’s design and evaluation. Data File Assessment A. Organization: The data file is generally well-organized but lacks full accessibility due to non-working links in the README. B. Completeness for Replication: The broken links to the SPARQL endpoint and documentation hinder full replication. C. Repository Choice: The repository on GitHub is appropriate for long-term accessibility and discoverability. D. Completeness of Artifacts: Aside from the link issues, the artifacts appear complete and sufficiently described. Suggestions for Improvement To strengthen the reproducibility and usability of the framework, I recommend the authors ensure all links, particularly the SPARQL endpoint and documentation in the GitHub repository, are active and correctly referenced.",
         "0.7989",
         "4",
         "0",
         "0.0817708333333333",
         "0.1262",
         "0.9559870958328248",
         "0.52",
         "18.1",
         "18.0",
         "17.5",
         "18.7",
         "88",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "3.0",
         "yes",
         "positive",
         "neutral",
         "No Hedging",
         "4",
         "4.0",
         "5.0",
         "4.0",
         "92.0",
         "92"
        ],
        [
         "24",
         "3750-4964",
         "Anonymous",
         "14/Nov/2024",
         "Reject",
         "822",
         "From Manuscripts to Knowledge Graphs: Automating the Semantic Representation of Tafsir al-Tabari",
         "Tafsir, the exegesis of the Quran, constitutes a fundamental pillar of Islamic knowledge, providing critical insights into the interpretation and application of Quranic teachings. Rooted in the teachings of Prophet Muhammad and early Islamic scholars, Tafsir elucidates the Quranic verses through historical, linguistic, and jurisprudential lenses. Despite its profound significance, systematic semantic modelling and digital representation of Tafsir literature remain unexplored.\\nThis paper presents the design, development, and implementation of a SemanticTafsir ontology and knowledge graph, focusing on the comprehensive exegesis by Muhammad Ibn Jarir al-Tabari. Following established ontology engineering methodologies, we define the SemanticTafsir ontology to capture and interlink key concepts within Tafsir literature.  By leveraging existing ontologies such as SemanticHadith, Schema.org, and DBpedia, our approach ensures semantic coherence and interoperability.\\nThe core contribution of this work lies in the automation of the semantic representation of Tafsir literature. We develop a pipeline that automates the conversion of TEI format manuscripts of Tafsir into an RDF-based knowledge graph, integrating Quranic verses, hadith, commentaries, and thematic connections. This automation facilitates enhanced accessibility and analysis of Tafsir literature. The evaluation encompasses logical consistency, competency question resolution, and semantic fidelity, validating the ontology's robustness and applicability.\\nThe SemanticTafsir framework supports SPARQL queries, enabling both technical and non-technical users to explore and derive insights from the interconnected layers of Quranic exegesis. This research contributes to Islamic knowledge engineering by advancing digital preservation, accessibility, and scholarly engagement with Tafsir literature, thereby enriching the global understanding of Islamic knowledge.\\nThe SemanticTafsir ontology and knowledge graph are freely accessible at https://github.com/A-Kamran/SemanticTafsir.",
         "75",
         "This paper presents the construction of an ontology and a knowledge graph representing Tafsir al-Tabari. A Tafsir is a body of commentary and explication, aimed at explaining the meanings of the Qur'an. Muhammad ibn Jarir al-Tabari is a Persian scholar. This work is the continuation of a work published in the Semantic Web journal on the construction of a knowledge graph representing the hadith corpus. A hadith is an action of the prophet Mohammed, reported by a chain of narrators. In general, the paper is well written and pedagogically presented and its content fits in well with the topics of the journal and the produced KG is interesting for cultural heritage. However the paper presents several major shortcomings: First, there is a lot of repetition and generalities in the article. The content could be presented in a much shorter paper. Second, there is an overlap with the paper previously published by the authors in the SWJ on the SemanticHadith KG. There is for sure a delta but it is unclear, e.g. the new ontology comprises terms from the previous one, some competency questions are the same, the general structure of the papers and positioning are very similar. Third, I could not access the SPARQL endpoint (nor that of the SemanticHadith). And I do not find the KG on GitHub. Fourth, the SPARQL queries implementing the competency questions are not discussed in the paper (nor in the previous paper). There is no evaluation of the produced KG (nor of the SemanticHadith KG, which is left for future work in the published paper). Detailed comments: Introduction P2 line 6-7, there shoud not be a distinction here between Linked data application and KG application, medecine should go in the list of domains line 4. Background This section presents some redundancies with the introduction, in particular sub-section 2.4. Merging both sections would avoid it. SemanticTafsir Ontology The positioning wrt the Semantic Hadith ontology is unclear. P5 line 48 a namespace should be chosen (whatever the prefix), which is not given in the paper. The ontology should be published, with dereferenceable URIs. P6 The overlap between competency questions that can be answered on the SemanticHadith and those specific to the Semantic Tafsir should be clearly stated. P8 “concept classes” is not correct, nor “object type properties”, and a class does not comprise properties. P9 Modelling decisions: similar to that of the previous paper. access to ref 62 and 63 dates back to 2022. The references are not complete and the date is not correct. The modelling choice is very debatable, in my view there should be 3 subclasses of Narrator, and narrator individuals should be declared as instances of them or of the superclass Narrator. P10 Figure 3 does not reflect the n-ary patterns: there should be a refersTo relation between a ThematicVerseFragmentReference and a VerseFragment, and property hasSubTheme should be hasTheme. Also in my view the model lacks a thesaurus for special individuals: hadith, narrators, etc. Methodology The text lines 27-44 is far too long, describing obvious notions for SWJ readers. Subsection 4.1 should go in section 3 P11 lines 23-26 the text is redundant with what is already detailed in sections 1 and 2. Section 4.2 is redundant with what is already descrubed in section 3. P12-13 data class, concept class, object class do not make sense, nor a class equipped with properties. Section 4.3 should be shortened. Technical staff should not be described. Obvious things should just be deleted, e.g. subsection 4.3.1 and most of 4.3.2. Subsection is not precise enough, which tools have been used? Who are the experts? 4.4 are generalities on GitHub that can be avoided. Results and Discussion Subsection 5.1 are technical details that are not challenges to be discussed What is described in subsection 5.1 is not an evaluation, it is usual staff in ontology engineering that should not be described in a SWJ paper. The statistics on the KG in Table 2 should go in Section 4. In this table, 3 millions of axioms must be a typo. The table should report the numbers of links between classes and between individuals (with a clear distinction). A presentation of the SPARQL queries implementing the competency questions and a discussion on their results are missing. The paper would benefit from a presentation of interesting outputs in the field of Islamic studies produced by querying the KG. There are many assertions which are not precise enough, e.g. “significant advancement”: what are the KPI which enable to measure it? “revealing underlying patterns in the Tafsir’s interpretative framework”: which are they? How the visualisations were created from the KG is not discussed. The text in subsection 5.4 before and at the beginning of subsection 5.4.1 is far too general, redundant with the first sections. Conclusion I disagree with the assertion that a “rigorous evaluation” was presented. In my view, the paper is better suited to a publication in a journal in Digital Humanities.",
         "0.7121",
         "2",
         "0",
         "0.0759825700615174",
         "0.0448",
         "0.8572394847869873",
         "56.86",
         "8.9",
         "10.09",
         "12.3",
         "9.9",
         "93",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "6.0",
         "no",
         "negative",
         "impolite",
         "Heavy",
         "very broad",
         "3.0",
         "2.0",
         "2.0",
         "42.0",
         "72"
        ],
        [
         "25",
         "3750-4964",
         "Bruno Almeida",
         "21/Nov/2024",
         "Reject",
         "579",
         "From Manuscripts to Knowledge Graphs: Automating the Semantic Representation of Tafsir al-Tabari",
         "Tafsir, the exegesis of the Quran, constitutes a fundamental pillar of Islamic knowledge, providing critical insights into the interpretation and application of Quranic teachings. Rooted in the teachings of Prophet Muhammad and early Islamic scholars, Tafsir elucidates the Quranic verses through historical, linguistic, and jurisprudential lenses. Despite its profound significance, systematic semantic modelling and digital representation of Tafsir literature remain unexplored.\\nThis paper presents the design, development, and implementation of a SemanticTafsir ontology and knowledge graph, focusing on the comprehensive exegesis by Muhammad Ibn Jarir al-Tabari. Following established ontology engineering methodologies, we define the SemanticTafsir ontology to capture and interlink key concepts within Tafsir literature.  By leveraging existing ontologies such as SemanticHadith, Schema.org, and DBpedia, our approach ensures semantic coherence and interoperability.\\nThe core contribution of this work lies in the automation of the semantic representation of Tafsir literature. We develop a pipeline that automates the conversion of TEI format manuscripts of Tafsir into an RDF-based knowledge graph, integrating Quranic verses, hadith, commentaries, and thematic connections. This automation facilitates enhanced accessibility and analysis of Tafsir literature. The evaluation encompasses logical consistency, competency question resolution, and semantic fidelity, validating the ontology's robustness and applicability.\\nThe SemanticTafsir framework supports SPARQL queries, enabling both technical and non-technical users to explore and derive insights from the interconnected layers of Quranic exegesis. This research contributes to Islamic knowledge engineering by advancing digital preservation, accessibility, and scholarly engagement with Tafsir literature, thereby enriching the global understanding of Islamic knowledge.\\nThe SemanticTafsir ontology and knowledge graph are freely accessible at https://github.com/A-Kamran/SemanticTafsir.",
         "82",
         "This manuscript describes the creation of a knowledge graph of Tafsir literature based on an ontology and on a TEI dataset of texts. The underlying topic is contextualized, and the work carried has great significance for digital humanities and Islamic studies. Unfortunately, while the OWL file of the ontology described in the manuscript is made available through the project’s GitHub repository, the knowledge graph itself is not, contrary to what is stated in the Section “Data availability”: “Ontology, Knowledge Graph, ontology documentation, SPARQL Queries corresponding to Competency Questionstions, MIRO report are available at https://github.com/A-Kamran/SemanticTafsir” (p. 20). Somewhat confusingly, the data and code made available through the GitHub repository is referred earlier in the text to as a “reference implementation”: “The resultant ontology and knowledge graph are hosted in a persistent public data repository, ensuring accessibility and facilitating future development. A reference implementation is available in a public GitHub repository, serving as a platform for issue tracking and community engagement” (p. 13). The provided link to the documentation within the Github repository (https://a-kamran.github.io/SemanticTafsir/) returns a 404 error, so there is no available documentation. There is no further information about the Python and Jupyter Notebook files available in the GitHub repository beyond a ‘readme’ file instructing to change a couple of variables in the config.py file, but the main notebook file still throws several errors about missing files/incorrect paths. In any case, the manuscript does not even mention the code or how to reproduce the results presented in Section 5. There are also several issues regarding the provided OWL file that lead me to believe that the ontology described in the manuscript is a different version from that which is made available through the GitHub repository. For example, the ontology metrics mentioned in Section 3.6 (p. 8) and presented in Table 2 (p. 16) do not match the information presented in Protegé for the provided ontology file. For example, Section 3.6 refers to “36 concept classes, comprising 40 object type properties and 18 datatype properties” (p. 8), but the ontology file actually has 31 classes and 37 object properties. In the manuscript, there is mention of “facets” regarding the data properties: “The data properties of the ontology have different facets. These facets consist of data type, restrictions, cardinality, and other features of values for the properties” (p. 9). Yet the declared data properties have no description whatsoever beyond being subproperties of owl:topDataProperty. In Section 3.7 , the modeling decision of “Values as sets of individuals” is described: “We define a class NarratorType, which enumerates the individuals sahabi, rawi, shaykh, and unknown-rawi” (p. 9). No such individuals are declared in the ontology file. In fact, the file does not contains any description of individuals. Furthermore, there are several bad modeling choices with the ontology. For example, the alignment properties of OWL, equivalentClass and equivalentProperty, are declared as annotation properties in the OWL file: owl:equivalentClass rdf:type owl:AnnotationProperty owl:equivalentProperty rdf:type owl:AnnotationProperty The alignments to external classes and properties function in SemanticTafsir as metadata descriptions, with external URI appearing as language typed literals (ex. \"http://schema.org/Place\"@en). This hinders interoperability with external ontologies and datasets, which is a stated objective of the work described in the manuscript. Alignments with Wikidata entities are simply wrong, since they use URL for Wikidata pages (ex. https://www.wikidata.org/wiki/Q215627) rather than entity URI (ex. http://www.wikidata.org/entity/Q215627). Since the results described in the manuscript cannot be reproduced, I cannot recommend the publication of the manuscript, even if the above-mentioned issues with the ontology were corrected.",
         "0.7253",
         "2",
         "5",
         "0.0541666666666666",
         "0.0777",
         "0.9165862798690796",
         "26.51",
         "14.4",
         "13.33",
         "16.1",
         "16.7",
         "87",
         "0",
         "0",
         "0",
         "0",
         "1.0",
         "2.0",
         "3.0",
         "no",
         "negative",
         "impolite",
         "Heavy",
         "very broad",
         "4.0",
         "2.0",
         "3.0",
         "20.0",
         "23"
        ],
        [
         "26",
         "3744-4958",
         "Pano Maria",
         "24/Sep/2024",
         "Accept",
         "367",
         "Declarative construction of knowledge graphs from NETCONF data sources",
         "The knowledge graph paradigm is drawing attention in the network industry as a technology for integrating heterogenous data silos such as model-driven telemetry based on the YANG language. In this sense, declarative mapping languages have emerged as scalable and flexible solutions for constructing knowledge graphs. A prominent mapping language is the Resource Mapping Language (RML), which enables the integration of heterogenous data sources by reusing ontologies that describe access to them. However, when it comes to the network domain, there is a lack of ontologies that describe access to YANG data exposed by network devices. This paper introduces the YANG Server Ontology for describing YANG servers and the interactions with them using network protocols like NETCONF. Additionally, guidelines for reusing the ontology in RML mappings are provided and validated in a use case by extending a reference RML engine.",
         "27",
         "This paper introduces the YANG server ontology as a way to describe YANG servers and to express access to YANG data exposed by them. It leverages existing protocols and describes a binding to these protocols in the ontology. Furthermore, it describes how this ontology can serve as a data source description language for the RDF Mapping Language (RML), such that the YANG data can be used to build knowledge graphs. Finally, the paper shows a use case where the combination of the ontology and an RML processor is used to generate a knowledge graph using the existing YANG catalog and YANG library data. Since the YANG language is being supported by an increasing amount of vendors in the network devices space, this is a significant effort. The paper is clearly written and well presented. The ontology was developed following proven methodologies for ontology management and was also tested against ontology pitfalls and fairness assessors. The paper highlights the key elements in the ontology and describes their meaning and intended usage. Furthermore, the paper describes how the ontology can be combined with the emerging RML ontology to enable knowledge graph creation from network devices. The paper also suggests some points which could be added to the ongoing RML community effort to further support the knowledge graph creation process. One point of improvement, that would make the provided examples on expressing queries using the ontology more clear, would be to add a listing with some example source data which correspond with the query descriptions. This would especially aid in understanding the workings of the ys:SubTreeFilter, which leaves room for interpretation. The YANG server ontology is published via the W3ID service for permanent identifiers on the web, and relevant documentation on the artifacts introduced in the paper is provided via a GitHub repository, where instructions for locally generating the ontology documentation are provided in the README. The latter contains both the ontology, and supporting documentation, and also contains the ontology assessment results from the evaluation tools used. Next to this the RML mappings used for the use case are also available in the repository. Overall this is a very well presented ontology along with a practically useful presented use case.",
         "0.7282",
         "0",
         "0",
         "0.13625",
         "0.143",
         "0.9358946084976196",
         "31.31",
         "14.6",
         "14.83",
         "16.1",
         "15.2",
         "99",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "5.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "5.0",
         "5.0",
         "5.0",
         "95.0",
         "95"
        ],
        [
         "27",
         "3744-4958",
         "Anonymous",
         "28/Sep/2024",
         "Major Revision",
         "1125",
         "Declarative construction of knowledge graphs from NETCONF data sources",
         "The knowledge graph paradigm is drawing attention in the network industry as a technology for integrating heterogenous data silos such as model-driven telemetry based on the YANG language. In this sense, declarative mapping languages have emerged as scalable and flexible solutions for constructing knowledge graphs. A prominent mapping language is the Resource Mapping Language (RML), which enables the integration of heterogenous data sources by reusing ontologies that describe access to them. However, when it comes to the network domain, there is a lack of ontologies that describe access to YANG data exposed by network devices. This paper introduces the YANG Server Ontology for describing YANG servers and the interactions with them using network protocols like NETCONF. Additionally, guidelines for reusing the ontology in RML mappings are provided and validated in a use case by extending a reference RML engine.",
         "31",
         "The authors propose an ontology that enables describing the essential characteristics of YANG servers (i.e. network devices exposing an API compatible with the YANG formalism for configuration and operational data) to facilitate interactions with these servers via a knowledge graph construction pipeline using declarative mapping. In addition to the paper, the implementation of the ontology is available as open source on GitHub. An extension of the BURP tool accompanies this proposal (the merge request has been accepted by the owner of BURP) to validate the approach. Overall, the authors adopt the perspective of network management and monitoring systems by providing the means to construct a knowledge graph based on the description of the network administration layer. The paper is carefully written, and the associated resources (ontology, documentation, mapping examples, tools, BURP contribution) are accessible and of good quality. The contribution is significant in relation to the importance of being able to use knowledge graph technologies for IT Service Management in telecommunications networks at the scale of operator networks. A few corrections and additions in the positioning and explanations of the proposal (see questions and remarks below) will make it a valuable resource for advancing this topic. Questions and remarks: - p. 1 \"support new use cases such as network service assurance [7] or network digital twins [8].\" : why do you only refer to YANG-based works? Why not extend the discussion to other works on cybersecurity and network management that utilize knowledge graphs built from various data sources, whether they describe networks or provide complementary insights on network management? Why not also discuss facilitating the management of YANG models through knowledge graphs? - p. 2 \"YANG data into knowledge graphs is still at an early stage with recent proposals like [9]\" : could you provide additional references? - p. 2 \"Related work\" : the section content looks more like describing the background knowledge on the knowledge graph construction topic rather than a related work analysis. For instance, the paper falls into the 'Ontology Description' category but also emphasizes access to YANG data sources via YANG servers for the purpose of constructing a graph. I understand the significance of the innovation presented in this paper and the inherent complexity of simultaneously addressing the challenge of accessing this data through declarative mapping while proposing an ontology to represent it. However, since you touch on both areas, I suggest addressing both in your analysis. For example, you state, 'there are no ontologies for describing access to YANG data sources that could be reused in RML,' which is a key point for consideration and a crucial element of your proposal, but it is very lightly argued in terms of motivations compared to more 'traditional' solutions that would involve deploying a YANG-compatible ETL pipeline and structuring the data according to ontologies such as DevopsInfra, NORIA-O, or SEAS. - p. 2 \"RML language is currently under development arranged into multiple modules\" : are you referring to the current RML v1.2 standardization effort or the current RML v1.1 'unofficial draft' available at https://rml.io/specs/rml/ ? - p. 3 \"ontological requirements has been conducted over several sprints\" & \"extracted from interviews with experts from the network industry\" : could you provide an overview of the profile of the experts who participated? What are their companies of origin? How many were there? - p. 3 \"derived from the analysis of standard specifications [3, 6, 16, 17]\" : all of these references are RFCs, how did you extracted the requirements from these? What were your criteria? Was it a manual extraction based on expert opinions, an extraction assisted by NLP, or an extraction through parsing associated implementations? You seem to use the Competency Questions method: what patterns of CQs appeared to be useful? More broadly, regarding the specification stage, what key principles and concepts did you identify, and how many? - p. 3 \"basic authentication credentials\" : how do you envision the use of encrypted data or a reference to a vault? why not reuse already existing vocabularies (e.g. http://xmlns.com/foaf/spec/#term_OnlineAccount or the UCO observable:AccountAuthenticationFacet) to maximize the interoperability of a knowledge graph structured by your ontology with other knowledge bases? - Listing 1 \"ys:endpoint\" : I understand that your implementation with a literal makes it easier for BURP to consider the endpoint for establishing the connection. However, as mentioned above with FOAF, why don't you reuse existing vocabularies for this kind of concept (e.g., observable:SocketAddress from UCO)? - Listing 1 \"\" & \"\" : indicates that we have a Datastore, but what do you do with it? is it only for inventory purposes, or do you envision additional use cases? How do you envision tracking state changes over time? - Section \"5. Use case: evolution of the YANG Catalog\" : It seems to me that the narrative around the experimentation is somewhat limited and resembles more of a test than an evaluation. Indeed, what conclusions do you draw from the execution of the pipeline and the resulting graph? What challenges did you encounter? What is the size of the input dataset? What is the size of the resulting graph? How did you test the compliance of the graph? Does the ontology ultimately meet the specifications and competency questions? How? - p. 8 \"the metadata can be integrated with data related to the network topology [24]\" : same remark as for the \"Related work\" section ... why only focusing on YANG-based data models for the nework topology? - p. 9 : \"referencing the YANG Library Ontology\" : could you provide details about what features you have added in https://github.com/kg-construct/BURP/pull/5 ? - p. 9 : \"unlocking real-time use cases\" : could you provide details about the kind of use cases and ideas about how you will implement these (e.g. leveraging the Streaming MASSIF framework [P. Bonte, ISWC, 2020])? Minor remarks: - p. 3 \"the requirements were captured in the form of natural language statements and stored in a CSV\" : I suggest that you highlight here the https://github.com/candil-data-fabric/yang-server-ontology/tree/main/req... repository. - Section 3.3. Publication : I suggest that you highlight the URL http://w3id.org/yang/server/ directly in the paragraph rather than hiding it in a footnote. - p. 8 \"ii) the semantic layer built with the knowledge [...]\" : I suggest that you reformulate the idea using a \"by facilitating ... thanks to ...\" form. - p. 9 \"The ontology has been developed following a well-known, mature methodology\" : I suggest that you reformulate by \"The ontology has been developed following a well-known knowledge engineering methodology\". - The colors of the listings can be difficult to read when the document is printed in black and white. - Typo in the https://w3id.org/yang/server#ConventionalDatastore documentation, see \"configuration datastores: , , , and .\" - Missing 'examples/cisco-example.ttl' file in https://github.com/candil-data-fabric/yang-server-ontology/tree/main/kno... to fully asses the proposal.",
         "0.7916",
         "2",
         "12",
         "0.1095570969434605",
         "0.9417",
         "0.930033802986145",
         "37.5",
         "12.2",
         "13.51",
         "14.4",
         "14.1",
         "92",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "8.0",
         "False",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "5.0",
         "4.0",
         "85.0",
         "85"
        ],
        [
         "28",
         "3744-4958",
         "Anonymous",
         "18/Oct/2024",
         "Reject",
         "827",
         "Declarative construction of knowledge graphs from NETCONF data sources",
         "The knowledge graph paradigm is drawing attention in the network industry as a technology for integrating heterogenous data silos such as model-driven telemetry based on the YANG language. In this sense, declarative mapping languages have emerged as scalable and flexible solutions for constructing knowledge graphs. A prominent mapping language is the Resource Mapping Language (RML), which enables the integration of heterogenous data sources by reusing ontologies that describe access to them. However, when it comes to the network domain, there is a lack of ontologies that describe access to YANG data exposed by network devices. This paper introduces the YANG Server Ontology for describing YANG servers and the interactions with them using network protocols like NETCONF. Additionally, guidelines for reusing the ontology in RML mappings are provided and validated in a use case by extending a reference RML engine.",
         "51",
         "This manuscript is submitted as 'Ontology Description'. In 10 pages with a total of 26 references only, it introduces the YANG server ontology, which describes the core concepts of the YANG data model and adds extensions to the specific NETCONF protocol which encodes YANG as XML and relies on SSH for interactions between clients and servers. The ontology is developed following the LOT methodology, conceptualized using CHOWLK, the documentation is generated using Widoco, and the ontology+documentation is available at https://w3id.org/yang/server The sources are on github, with a total of 22 requirements listed in a csv document, and converted to SPARQL queries that can be executed through a Jupyter Notebook. An example turtle file is available too. In addition to introducing the ontology, the paper describes how the YANG server ontology can be combined with RML to generate a knowledge graph from the data available at a YANG server. More specifically again, this paper and the implementation focuses on the servers implementing the NETCONF protocol. The combination of this work with RML has been integrated in the reference RML implementation BURP (pull request #5). In my opinion, the article does not meet the quality standards required for publication in the semantic web journal : (1) Although the paper is officially an ontology paper and should therefore be concise (10p would be fine), its actual scope is broader. The title of the paper demonstrates it focuses on its integration in RML-based KG construction.  (2) As an ontology paper, I'd say that it has some shortcomings.  - It is the result of applying well a mature methodology, but many details are missing, including the timeline of the sequence of sprints, number of participants (domain experts, ontology engineers, number of pitfalls and how they were solved, same for FOOPS!, ...), - some statistics about the ontology would be welcome. How many classes, properties, what expressivity, ... - some additional considerations such as modularity: it would have been useful to better separate what's generic (YANG) from what's specific to NETCONF. I guess basic authentication for example is not relevant for all YANG protocols. It would be probably appropriate as well, for a journal paper, to support at least one more YANG protocol such as RESTCONF or gNMI or CORECONF (CORECONF is not mentioned in the paper). - the way the YANG Server Ontology and RML can be combined could be specified using simple alignments, or more formally using SHACL rules.  (3) If I consider the part of the paper that focuses on the construction of knowledge graphs from NETCONF data sources (what's the focus as per the title, and also the most relevant to this special issue): - we're missing a proper validation of the approach. It's a good point that the proposal has been merged in the BURP code base, however this doesn't properly justify the validity of the approach. I would expect some validation through experiments in the paper, with a clear description of the setting (based if I understand well on CESNET/netopeer2). Statistics about KG generation would be relevant,  including the duration, how this duration is shared between the YANG server/network/BURP, including size of the exchanged XML documents, number of triples generated, relevance of having filters on the server, etc. - I miss some discussion about alternative ways to support the conversion of XML data on CORECONF servers. From my understanding of RFC6241, NETCONF must support SSH as a transport protocol (specified further in RFC6242), but other transport protocols could be defined incl. SOAP/HTTP/TLS. So an alternative could be to have data sources in RML send a SOAP request message, and interpret the SOAP response message. An alternative could also be to extend RML with support for SSH connections to some server, then have the logical source element describe what needs to be sent to the server, and how the response must be interpreted ... - I miss some discussion about what would be different for another YANG protocol. What can be reused from the ontology and implementation, and what needs to be added (4) Finally, I believe the paper could use more references or could better choose references. For example, there is a reference for the modular RML as the result of 3yrs of existence of the KGC community group (ISWC 2023 Resource Track). Maybe the following papers are highly related work: - Ismail, H., Hamza, H. S., & Mohamed, S. M. (2018, December). Semantic enhancement for network configuration management. In 2018 IEEE Global Conference on Internet of Things (GCIoT) (pp. 1-5). IEEE. - Sahlmann, K. (2021). Network management with semantic descriptions for interoperability on the Internet of Things (Doctoral dissertation, Universität Potsdam). - Sahlmann, K., Scheffler, T., & Schnor, B. (2018, June). Ontology-driven device descriptions for IoT network management. In 2018 Global Internet of Things Summit (GIoTS) (pp. 1-6). IEEE. The section about related work is really focusing on RML, with only 4 references. If the paper is about the ontology, then related ontologies should be considered.",
         "0.7704",
         "8",
         "2",
         "0.1353243021346469",
         "0.0501",
         "0.905623972415924",
         "40.79",
         "13.0",
         "14.09",
         "15.6",
         "14.7",
         "80",
         "0",
         "0",
         "0",
         "0",
         "2.0",
         "4.0",
         "3.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "2.0",
         "3.0",
         "60.0",
         "60"
        ],
        [
         "29",
         "3744-4958",
         "Edna Ruckhaus",
         "24/Nov/2024",
         "Minor Revision",
         "352",
         "Declarative construction of knowledge graphs from NETCONF data sources",
         "The knowledge graph paradigm is drawing attention in the network industry as a technology for integrating heterogenous data silos such as model-driven telemetry based on the YANG language. In this sense, declarative mapping languages have emerged as scalable and flexible solutions for constructing knowledge graphs. A prominent mapping language is the Resource Mapping Language (RML), which enables the integration of heterogenous data sources by reusing ontologies that describe access to them. However, when it comes to the network domain, there is a lack of ontologies that describe access to YANG data exposed by network devices. This paper introduces the YANG Server Ontology for describing YANG servers and the interactions with them using network protocols like NETCONF. Additionally, guidelines for reusing the ontology in RML mappings are provided and validated in a use case by extending a reference RML engine.",
         "88",
         "- Clarity. + HTML documentation is provided where classes and properties have been defined and the conceptual model diagram is presented and described. + The development of the ontology has followed a well known methodology, LOT, and the steps have been described. - Completeness and correctness + To validate the ontology regarding completeness, competency questions and their corresponding SPARQL queries need to be developed . These must also be published. + The correctness of the ontology can be validated with the results of the evaluation of OOPS and FOOPS tools. These results must be added to the repository. – Extensibility. + The ontology seems extensible to other protocols in quite a simple way: adding a subclass to the yg:YangServer class  and adding specific classes and properties that are related to this subclass. This extensibility is illustrated with the NETCONF protocol. + There is a drawback that should be highlited, regarding the extension of the BURP engine. The extension is specific for the support of the NETCONF protocol. However is is not clear what are the implications on the extension of the engine if a different protocol is required.  (2) Illustration, clarity and readability of the describing paper, which shall convey to the reader the key aspects of the described ontology. + All the related resources are well organized and have been provided in public repositories, except the User stories and the results of the OOPS and FOOPs evaluation which were referred to already in the previous points. + The paper is clear and well written. Some improvements are advisable:   ++ In the introduction, there is a mention of the \"flexibility\" of the YANG language. This could briefly defined, with respect to which requirements?   ++ In the extension proposed for RML, there seems to be a requirement for mapping languages  regarding data sources and mentions that \"filtering out data at the server ... brings multiple benefits\". Clarify if this is in general a requirement of the KG construction community and if it has been considered in other works.   ++ Briefly describe the challenges in your work. You could add them to the Conclusions.",
         "0.6931",
         "2",
         "0",
         "-0.012037037037037",
         "0.4402",
         "0.8886175155639648",
         "38.32",
         "11.9",
         "12.95",
         "14.3",
         "12.0",
         "95",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "1.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "4.0",
         "5.0",
         "5.0",
         "92.0",
         "92"
        ],
        [
         "30",
         "3738-4952",
         "Mario Scrocca",
         "08/Nov/2024",
         "Minor Revision",
         "963",
         "Algebraic Mapping Operators for Knowledge Graph Generation",
         "Recent advancements in declarative knowledge graph generation have led to the development of multiple mapping\\nlanguages, their various versions, and different mapping engines that can interpret these languages and execute the mapping\\nprocess. The field has progressed to the extent that current studies are now more focused on optimizing the knowledge graph\\ngeneration process. Although different mapping engines share the common functionality of generating knowledge graphs from\\nheterogeneous data sources, sharing the various optimization techniques and features of these engines remains challenging due to\\nthe lack of formal operational semantics for the general mapping processes. A set of algebraic mapping operators can provide the\\nnecessary operational semantics for general mapping processes, establish a theoretical foundation for mapping languages, and\\nfacilitate the introduction and evaluation of a compliant implementation, that is capable of interpreting and executing multiple\\nmapping languages. In this paper, we propose such an algebra based on the SPARQL algebra. This allows us to maximally reuse\\nestablished definitions, and further bridge the world of knowledge graph generation with query engines. To evaluate that our\\nwork is not limited to a single specific mapping language, we translated mapping languages ShExML and RML to our mapping\\nplan composed of algebraic mapping operators. The results of our completeness evaluation shows that our algebraic operators\\ncover the operational semantics of RML and partially for ShExML. To fully cover ShExML, further analysis into ShExML’s\\nconcise operational semantics is needed (e.g. for joining data from two input sources). For performance evaluation, our proofof-concept algebraic mapping engine has a consistent memory usage of around 500 MB across the different workloads, and\\nachieved second place in the Knowledge Graph Construction Workshop’s performance challenge. Algebraic mapping operators\\ndecouple mapping engines from the mapping languages, enabling multilingual mapping engines. Furthermore, the mapping\\nplan can incorporate optimization techniques as a separate process from the mapping itself, allowing us to benefit from stateof-the-art mapping process optimizations. The proposed set of algebraic mapping operators will lay the foundation for future\\nstudies on the theoretical analysis of complexity and expressiveness of mapping languages, and will provide consistency in the\\nexecution semantics of mapping engines. Furthermore, the alignment of our algebra with SPARQL will enable further research\\ninto advanced methods such as virtualization, enabling heterogeneous data querying.",
         "86",
         "The manuscript presents a formal description of the declarative mapping process as a set of algebraic mapping operators extending the SPARQL algebra. The objective of this work is to enable a description and the execution of mapping rules independently from the mapping language originally adopted for defining it. This would enable multilingual mapping engines and the definition of mapping plans that can be optimised independently from the mapping itself. The authors also present the implementation of two resources publicly available on GitHub: (i) Algemaploom-rs provides a CLI translator from RML and ShExML to mapping algebra, (ii) RMLWeaver-JS is a Node.js mapping engine based on the reactive paradigm that executes a mapping processes described according to the mapping algebra (e.g., obtained by the Algemaploom-rs tool). The coverage of RML and ShExML is empirically evaluated. Finally, the performance of the RMLWeaver-JS is compared with the one of other RML processors. The provided URL guarantees long-term stability via Zenodo. The DOI is assigned to a single upload referencing the specific versions of the resources considered for this work. The tools presented are available via GitHub and contain the relevant documentation for their usage. The material used for the evaluation is also made available via GitHub. The paper provides a relevant contribution to the field of declarative KG construction by introducing formally defined operational semantics for mapping operators and proves its applicability by presenting related resources. The contribution is novel but builds on existing work and is well-aligned with the state of the art. It could represent an important work for reconciling declarative mapping languages and the approaches for their optimized execution. Overall, the paper is well-written, but some aspects should be addressed to improve the presentation. Comments to be addressed - In the overall paper, the usage of the word \"mapping\" and \"solution mapping\" may be quite confusing for the reader. Indeed, the formalisation of the operators refers to \"mapping\" as the process of binding the input data to a multiset of \"solution mappings\". However, usually the concept of \"mapping\" (e.g., in RML) also entails the operation of transforming the \"solution mappings\" to the target output format (defined as \"serialization\" in the paper). Indeed, also the authors define \"Serialize\" and \"Target\" as \"mapping\" operators. My understanding is that these terms are inherited from other work, therefore, if they cannot be changed, I suggest to add at least a clarification in the preliminaries (section 4.1) to help the reader. - From a formal perspective, would two solution mappings serialized to the same quad pattern generate duplicates in the output or not? I am missing a discussion about the potential duplicates in the solution mappings and in the output while presenting the operators (the deduplication is mentioned only in the evaluation section as something that is not implemented by RMLWeaver-JS). I believe this would be relevant since this is a quite discussed topic in the literature on declarative mapping languages for KG construction. - The fact that ShExML is only partially supported is briefly commented and should be clarified. Is it a problem of \"parsing\" the ShExML specification or a limitation of the proposed algebra? Especially regarding the joins, it is not fully clear from the paper why for RML can be supported and not for ShExML. Moreover, an example for ShExML (mapping + resulting operators) is missing. - The example presented in Section 5 (from RML) is limited to a few operators but is very useful in association with the corresponding diagram of mapping operators (Figure 2). It would be useful to report a couple of examples (e.g., from the considered RML test cases) so that every operator introduced appears at least in one example and corresponding diagram. - It is not clear from the paper how the output of the Algemaploom-rs tool is represented in order to be processed by an engine based on the algebra like RMLWeaver-JS - In my opinion, the performance evaluation discussed from the KGCW challenge does not really prove the claim reported at the end of Section 6 about the efficiency of an algebraic mapping engine. Indeed, the evaluated tool differs in many aspects from the others considered (e.g., reactive programming), and the performance of another potential algebraic mapping engine may be worse depending on how the mapping operators are implemented. I would suggest rephrasing the conclusions of the evaluation and, wherever possible, providing some hints on how the mapping operators have been efficiently implemented in the RMLWeaver-JS.  Typos/Suggestions - I would remove \"500MB across different workloads\" from the abstract since it's a number provider without enough contest of which workloads are considered. - Line 28 pag 2: Statement \"closes the gap between KG materialization and KG virtualization\" not clear and to be better formulated or removed - Line 51 pag 4 \"newvalues\" missing a space - Line 17 page 6 \"mulitsets\" - Line 18 page 18: Add \"is denoted by\" or something similar before the symbol for a multiset of mapping tuples - Section 4.3 Ref. [31] is cited 4 times - Footnote 5: JSONPath can now be cited as a standard https://www.rfc-editor.org/info/rfc9535 - Line 22 pag 9: visualisation problem with \"irify\". Also \"irify\" is used without explanation. - Line 33-34 pag 9 (Definition 8): I do not understand the behavior of the rename operator with an alias string, please rephrase or add an example. Why is the || symbol used here? - Line 20 pag 10: \"copyData\" is used but not explained - Definition 12: sometimes Theta-join is used with the word for Theta and others it is written with the symbol - Section 4.8: serializer expression is defined -> D on line 25 and -> T on line 34 - Line 13 pag 16: \"of of\" - Line 28 pag 19: \"rml:template\" is \"rr:template\" in the Listing 3",
         "0.7462",
         "0",
         "2",
         "0.0376753246753246",
         "0.1481",
         "0.8936411738395691",
         "33.85",
         "13.6",
         "13.66",
         "15.2",
         "14.0",
         "93",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "3.0",
         "True",
         "2",
         "3",
         "1",
         "2",
         "4.0",
         "5.0",
         "3.0",
         "82.0",
         "84"
        ],
        [
         "31",
         "3738-4952",
         "Jose Emilio Labra-Gayo",
         "28/Nov/2024",
         "Major Revision",
         "1623",
         "Algebraic Mapping Operators for Knowledge Graph Generation",
         "Recent advancements in declarative knowledge graph generation have led to the development of multiple mapping\\nlanguages, their various versions, and different mapping engines that can interpret these languages and execute the mapping\\nprocess. The field has progressed to the extent that current studies are now more focused on optimizing the knowledge graph\\ngeneration process. Although different mapping engines share the common functionality of generating knowledge graphs from\\nheterogeneous data sources, sharing the various optimization techniques and features of these engines remains challenging due to\\nthe lack of formal operational semantics for the general mapping processes. A set of algebraic mapping operators can provide the\\nnecessary operational semantics for general mapping processes, establish a theoretical foundation for mapping languages, and\\nfacilitate the introduction and evaluation of a compliant implementation, that is capable of interpreting and executing multiple\\nmapping languages. In this paper, we propose such an algebra based on the SPARQL algebra. This allows us to maximally reuse\\nestablished definitions, and further bridge the world of knowledge graph generation with query engines. To evaluate that our\\nwork is not limited to a single specific mapping language, we translated mapping languages ShExML and RML to our mapping\\nplan composed of algebraic mapping operators. The results of our completeness evaluation shows that our algebraic operators\\ncover the operational semantics of RML and partially for ShExML. To fully cover ShExML, further analysis into ShExML’s\\nconcise operational semantics is needed (e.g. for joining data from two input sources). For performance evaluation, our proofof-concept algebraic mapping engine has a consistent memory usage of around 500 MB across the different workloads, and\\nachieved second place in the Knowledge Graph Construction Workshop’s performance challenge. Algebraic mapping operators\\ndecouple mapping engines from the mapping languages, enabling multilingual mapping engines. Furthermore, the mapping\\nplan can incorporate optimization techniques as a separate process from the mapping itself, allowing us to benefit from stateof-the-art mapping process optimizations. The proposed set of algebraic mapping operators will lay the foundation for future\\nstudies on the theoretical analysis of complexity and expressiveness of mapping languages, and will provide consistency in the\\nexecution semantics of mapping engines. Furthermore, the alignment of our algebra with SPARQL will enable further research\\ninto advanced methods such as virtualization, enabling heterogeneous data querying.",
         "106",
         "The paper presents a proposal for a set of algebraic mapping operators which can be applied for the generation of RDF from other sources of data like CSV, JSON, etc.  The paper presents the definition of the different operators from using a formal notation based on multisets and also presents prototype implementations that convert two different technologies: RML, and ShExML, and generates the mapping operators in Rust , as well as an interpreter of the mapping operators in Javascript. The evaluation takes into account two aspects: expressiveness (or completeness according to the authors) and performance compared with other RML implementations using the results of the knowledge graph construction challenge. Given that the manuscript has been submitted as a full paper, I proceed the review taking into account the 3 dimensions: originality, significance of the results and quality of writing. 1.- Originality. As far as I know the contents presented in the paper are original and I think the idea of providing a set of formal mapping operators is new (although as the authors indicate, the formalization evolves from the formalization of SPARQL, which is OK for me). 2.- Significance of the results. I think the results are significant and can be the basis for a new generation of mapping proposals which can be based on a set of formal abstractions which can be used for optimizing the mapping process. In fact, I think a natural next step for this paper would be to research optimization techniques based on those mappings. 3.- Quality of writing. Although the paper is well written and I think the authors have made an effort to make the paper readable, the current paper still needs to be improved before publication. I would suggest the authors present a good running example which could be used along the paper to present the main topics. Although the authors started with a running example about people and pets in section 4, the example is not followed in section 5 and 6, where the authors present an example about sports without including the data. I think it wouldn’t be difficult for the authors to extend the people/pets example and use it to exemplify the rest of the sections. Specially, section 5 which presents the converter from RML and ShExML could be improved if the authors included the mappings and ShExML file for that people/pets domain, which could be used to exemplify some of the concepts described in that section.  About the availability of the data and code, the authors provide a Zenodo link which I think can be good as a long term stable URI and also provide a .zip file. The contents point to two github repositories which include the Rust implementation algemaploom-rs which translates RML and ShExML to the mapping operators and the RMLWeaver-JS implementation which implements the engine that runs those mapping operators. More specific remarks: - Although the mapping operators are defined along the paper, I think it would make sense to provide an abstract syntax defining the operators indicating what are the parameters that they contain. I think the authors already have that language because they implemented an engine based on it, but it is not explicit in the paper. - Page 2, the sentence that starts by “On the one hand, homogeneous mapping languages…” gives 3 examples: R2RML, TARQL and SML, and explains that R2RML is from relational data to RDF, and TARQL from CSV to RDF…leaving without explaining what SML does. - In section 2.1, the authors consider ShExML as a constraint-based language based on ShEx. I am not so sure about that, because although ShExML was inspired by ShEx in the sense that it uses shapès and a concise syntax, it is not using constraints internally. I think it could also fit in the dedicated mapping language. - Given that most of the operators defined in the paper are taken from SPARQL…I wonder if it would make sense to define a SPARQL-inspired mapping language which could have a more concise syntax than RML but also a more SPARQL-like syntax. In fact, I would like to know if the authors have considered to define an intermediate syntax for the mapping operators. - As I indicated before I would suggest the authors to try to find a single running example to explain most of the operators and concepts. For that, - In figure 1 the inputs seem to be only CSV files or Databases…I think the authors also want to support JSON and XML, right? - Table 1 seems to contain an extra line space between the f_personal row and the f_friends rows…maybe it is intended. - I am not sure that I understand the sentence: “The set of fragments, F, is infinite and pairwise disjoint with the other sets defined in Section 4.1.”. - The choice of the letter xi for mapping tuples (both in lower and in upper case) is a bit unfortunate because it is not a popular greek letter and I think readers can find it difficult. I would suggest t (for mapping tuple) which would probably make the paper more readable. - In my opinion, the source operator is not very well defined and needs some extra definitions. It is defined in terms of Iterators and Fields…but the authors indicate that the work on iterators is currently continued with logical views…I would suggest the authors to try to explain a bit better that part. I also found the definitions of iterators and fields not easy to follow because they are not self-contained, they use subfields without indicating what a subfield is. Maybe with the help of the running example, this part could be more readable. - Definition 5 says: “The extracted data value can have a datatype in the Literal if the datatype can be inferred from the data source.”, how can that datatype be inferred from the data source? I think this definition requires a bit more explanation because it can be important. Is it possible to generate IRIs? And Blank nodes? - What is the concept of default fragment? Is it defined? - Definition 7, expr: \\Omega \\into T an expression statement…what does it mean it is an expression statement? - Example 3, what is irify(_) ? - Definition 12, I found a bit strange that the operands of the \\theta expression are quite small. I think the authors are using some macro, because that happens in other places of the paper. - Definition 15, I didn’t understand well what is \\Psi, maybe add an example? - It is interesting that Serialize can be defined in terms of Project and Extend…which seems that it is probably not a necessary operator as it is not a primitive operator. Is that the case? - Example 9, “...and binds the variable<,>...”, I think that comma is not necessary. - Page 15, the footnote pointing to Apache Kafka is repeated…maybe only one footnote would be enough. - Example 10, it is not clear to me why the result will go to /target/output.nt if it is not specified in the target. - Example 10. The sentence: “If multiple solution mappings exist, the target operator will append the serialized data to the file.”, seems like an implementation detail that could be configured with a different behaviour? - Page 16, “the semantics of ...” - Page 16, the statement “this way we ensure that our approach is language agnostic”, is in my opinion too strong, you could state that you were able to implement in some different languages, but you can not ensure that it is language agnostic. - I found very interesting that the authors are using Rust to convert between RML and ShExML…in fact, at this moment, I am a big fan of Rust…however, the authors didn’t explain why they chose it, and also, why they chose Javascript for the engine…specially as I would probably choose Rust for the engine as in section 6, the authors do a performance comparison between FlexRML which is implemented in C++ and authors’ implementation in Japvascript. I would probably ask the authors to expand a little bit about those decisions…and what they think could happen if the engine was implemented in Rust instead of Javascript. - I found a bit strange the use of “interpreter” for the Rust converter from RML and ShExML to the mapping operators. I would think that an interpreter is something that takes, for example, RML or ShExML code and interprets it, i.e. in my view, what the authors call interpreter, I would call it a converter/translator, while what they call engine, I would probably call it interpreter also. This is not a big issue for me, but I was a bit surprised by that usage. - Sections 5.1 and 5.2 contain a description which is not easy to follow…I may suggest the authors to use a running example of a mapping expressed in RML and to show the output of the conversion, and the same thing using ShExML…in this way, the explanation could be clarified with those examples. - Page 18, “that could be generated from  RML document…” - I would suggest Listing 3 and listing 4 to use the same example based on people/pets. - Page 20 I think the sentence: “For adapted chosen ShExML test cases,” lacks something… - Table 12 is interesting but some of the concepts in the table are not explained in the paper…I would ask the authors to describe the meaning of some concepts and maybe justify why they can not be implemented with their approach. I also think that the table lacks some parts like the push/pop feature of ShExML - Page 22. “The virtual machine has  64 bit architecture” (I think it is “a” instead of “an”)",
         "0.7364",
         "2",
         "0",
         "0.1111075915953964",
         "0.0821",
         "0.918194055557251",
         "48.43",
         "12.1",
         "12.15",
         "13.3",
         "12.8",
         "99",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "4.0",
         "7.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "80.0",
         "80"
        ],
        [
         "32",
         "3687-4901",
         "Daniel Hernandez",
         "03/Nov/2024",
         "Major Revision",
         "656",
         "A Semantic Approach to Reducing GHG Emissions",
         "In the year 2015, 196 countries signed the Paris Agreement, which aims at keeping the rise in mean global temperature below 2◦C above pre-industrial levels. Governments have since launched awareness campaigns and tightened regulations, motivating companies and governmental organizations to reduce their direct greenhouse gas (GHG) emissions and the indirect emissions of their value chains. To monitor and report on GHG emissions, companies follow standardized methodologies which today remain costly, time-consuming, and require extensive human expertise. In this paper, we present a Knowledge Graph (KG) that forms the semantic backbone of an interdisciplinary research project that aims to significantly reduce the time and effort that environmental accounting experts spend gathering relevant data and validating it. To facilitate data gathering, instead of proposing the creation of a new standard, we created ontologies and management tools for three of the most common GHG data formats—ILCD, EcoSpold01, and EcoSpold02—and we propose a bridge ontology to seamlessly query data expressed in either of these formats. To take advantage of already widely-used ontologies, increase interoperability, and integrate expert knowledge, we follow the Simplified Agile Methodology for Ontology Development to create the WISER ontologies, which are part of the proposed KG and have been created to permit automatic responses to requests by environmental scientists and to capture their domain knowledge. To demonstrate the effectivity of our KG-based approach, we present a tool for data gathering that has been validated by environmental accounting experts. The proposed KG aims at decreasing the effort required for GHG emissions reporting while increasing its transparency and reproducibility. It furthermore democratizes access to GHG emissions data for environmental accounting experts, companies, auditing authorities, and regulatory bodies.",
         "198",
         "This paper proposes an ontology for assessing greenhouse gas emissions based on three data formats: ILCD, EcoSpold01, and EcoSpold02. The paper tackles the highly relevant problem of integrating diverse datasets with a uniform ontology. From the beginning, the paper is well-written and easy to follow. However, the description is mostly null when it comes to the central question of this paper: the proposed WISER ontology. The authors describe only two competency questions, and both questions are about identifying (1) the geographic coverage of a dataset and (2) the certainty about the geographic coverage. The central aspect of the description is thus not related to greenhouse gas emissions, nor even to sustainability, but to geolocation. The authors said they describe all the other competency questions in the supplementary material. This excuse is insufficient for the paper because the title and abstract suggest readers will read about creating a unifying ontology for the three data formats they consider. I would recommend rejecting the paper. However, being generous and considering the possible impact of this work, I recommend the paper for a major revision so they can improve the description of the proposed ontology. Questions and issues: Q1. In Section 2.2, the authors enumerate some ontologies that have similar objectives. They claim that the lack of adoption of these ontologies is due to the difficulty of shifting an entire community towards creating new databases based on a new knowledge model. I wonder why, unlike these ontologies, the proposed in this paper will be adopted. Q2. In Section 3, the authors said they “focus” on ILCD, EcoSpold01, and EcoSpold02 to create the WISER knowledge graph. First, the word “focus” suggests that the authors pay more attention to these formats but may also consider other formats. I wonder if they also considered the other two formats mentioned in Section 2.4, and if they do not consider these formats, why not? If these three formats are the only ones used to define the WISER knowledge graph, I suggest replacing the word “focus” with a more precise one. Q3. Section 3.2 describes a mapping to translate the XML files from the existing data formats into RDF. They implement this mapping using a custom algorithm. Why do not use a mapping language like RML to define the mapping from XML to RDF? Q4. Section 3.3 describes the creation of a bridge ontology between the concepts generated from mapping the three data formats to RDF. Please confirm that this bridge ontology consists of axioms A ⊑ B ⊔ C, where A is a bridge concept and B and C are the original concepts, and similarly for properties, or if there is something more. The authors said they based this bridge ontology’s construction on the openLCA project. What is the additional work over the openLCA project contributions? How many of these axioms did you provide? Was this process entirely manual? Q5. On page 6, line 32, the authors mention “equivalent classes.” So, it suggests that some classes are assumed to be equivalent, and thus, it suffices to add an axiom A ≡ B. Please confirm. How many equivalent axioms did you include? Q6. On page 7, line 1, the authors say that Figure 3 shows equivalent properties. However, the example shows properties that are not equivalent but subsumed by a common bridge property. Please clarify this statement. Q7. The scenario in Section 4.1 describes a large international manufacturing company. Is this company fictitious or a real one whose name the authors maintain in secret? Q8. The footnote 10, on page 9, line 4, does not appear. Also, I do not recommend footnotes in the equation environment because one can interpret them as the power of a number. Q9. Please explain the central aspects of the ontology you are proposing. As I already commented, the current description only refers to geolocalizing datasets, and it is mostly null regarding the most specific questions related to greenhouse gas emissions.",
         "0.7603",
         "9",
         "0",
         "0.1306791785450322",
         "0.3134",
         "0.9053943157196044",
         "47.28",
         "10.5",
         "10.73",
         "12.7",
         "10.4",
         "89",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "8.0",
         "no",
         "neutral",
         "neutral",
         "minimal",
         "2",
         "3.0",
         "4.0",
         "3.0",
         "50.0",
         "62"
        ],
        [
         "33",
         "3687-4901",
         "Eva Blomqvist",
         "11/Nov/2024",
         "Major Revision",
         "1395",
         "A Semantic Approach to Reducing GHG Emissions",
         "In the year 2015, 196 countries signed the Paris Agreement, which aims at keeping the rise in mean global temperature below 2◦C above pre-industrial levels. Governments have since launched awareness campaigns and tightened regulations, motivating companies and governmental organizations to reduce their direct greenhouse gas (GHG) emissions and the indirect emissions of their value chains. To monitor and report on GHG emissions, companies follow standardized methodologies which today remain costly, time-consuming, and require extensive human expertise. In this paper, we present a Knowledge Graph (KG) that forms the semantic backbone of an interdisciplinary research project that aims to significantly reduce the time and effort that environmental accounting experts spend gathering relevant data and validating it. To facilitate data gathering, instead of proposing the creation of a new standard, we created ontologies and management tools for three of the most common GHG data formats—ILCD, EcoSpold01, and EcoSpold02—and we propose a bridge ontology to seamlessly query data expressed in either of these formats. To take advantage of already widely-used ontologies, increase interoperability, and integrate expert knowledge, we follow the Simplified Agile Methodology for Ontology Development to create the WISER ontologies, which are part of the proposed KG and have been created to permit automatic responses to requests by environmental scientists and to capture their domain knowledge. To demonstrate the effectivity of our KG-based approach, we present a tool for data gathering that has been validated by environmental accounting experts. The proposed KG aims at decreasing the effort required for GHG emissions reporting while increasing its transparency and reproducibility. It furthermore democratizes access to GHG emissions data for environmental accounting experts, companies, auditing authorities, and regulatory bodies.",
         "206",
         "The paper presents a new ontology, related to describing greenhouse gas emission data, bridging a number of existing formats in the area. The paper addresses an interesting and pressing problem, which is very real for many companies out there, struggling to meet reporting standards and assess their environmental impact to meet regulations and guidelines. While this is a practical contribution, I currently do not see a sufficiently clear research contribution of the paper, including an insufficient dept of both the discussion of state-of-the-art as well as the evaluation of the proposed artefact. Alternatively this could be converted into an ontology paper, shifting the focus from the scientific contributions to a practical, reusable, resource. However, even with that in mind, both the related work and evaluation sections would need considerable improvement.  More specifically, regarding the journal's evaluation criteria (1) originality, I do not see the original research contribution, i.e. the new knowledge that this paper contributes to the community. I think that the ontology architecture presented, i.e. \"bridge\" ontologies as mapping tools for expressing connections and transformations between standards and formats, is slightly novel - not as a proposal (many research efforts claim they will do this), but as an actual completed project, where three different formats have been aligned through such a bridge ontology. However, the paper does not take advantage of this novelty, and simply focuses on the resource itself, rather than what we can learn from this effort.  This brings us to review criteria (2), significance of the results, which is unfortunately also low in the current form. Following from the discussion above, the actual scientific results are minimal (most results are practical, an artefact), hence, the new knowledge gained is not significant and the paper will not significantly help other researchers build on this in the future.   Regarding criteria (3), quality of writing, the paper is reasonably well written, in terms of language and clarity, but it is missing several crucial parts to complete the \"storyline\", as already mentioned. More specifically, starting from the related work section, this section covers a broad range of topics, from datasets for sustainability to data models for LCA. While for each such topic, the discussion is brief, and the account of state of the art work does not seem complete. If a selection has been made, then it is not clear why particular work was included and other work left out. For instance, knowledge graphs for sustainability has been a topic for several years, and many datasets have been published, including efforts from Google and other large organisations, linked governmental data etc. There is also the whole area of linked energy data, which is not even mentioned. Either this section has to be considerably extended, or perhaps the title should be changed - is it really relevant to survey and contrast against all kinds of sustainability efforts? On the other hand some sections seem incomplete, such as the fact that the PACT formats are not even mentioned in this section, while this work is acknowledge in the introduction as the main alternative (although still emerging), i.e. standardisation instead of mapping between many other formats.  Next, from looking at sections 3 and 4 it is quite unclear what WISER is supposed to be. In the title of section 3 it sounds like it is the KG that is called WISER, and then in the title of section 4 it reads as that section will present the ontology of the KG. However, from the content of the sections it seems that the ontology is already described in section 3 (subsection 3.3), which raises the question what section 4 is actually about? Or are they different ontologies? Is it the development methodology and more details of the same ontology described in section 3.3, or are these actually different things? If they are indeed the same things, then I would suggest to start with section 4, describing the methodology, and details of the ontology, and only after that show how this can be used to represent data, and map between the standards. There are also many unclear points in the development process: What is actually the scope of the bridge ontology? And WISER? Is it only bridging the geographical aspects of these formats? Or is the geographical requirements and mappings just an example? Several of the figures illustrating examples are not sufficiently explained, neither in terms of notation (e.g. what do the arrows between classes and properties indicate in Figure 3? Domain and range restrictions? And what about the dashed lines \"mapping\" in Figure 4?) nor in terms of their content. It is also not clear why the notation is different between Figure 1 & 3 and Fig 4 & 5?  In section 3.2 generation of an RDF KG from XML documents is discussed. It is a bit unclear how this fits in with the rest of the paper, which is about the ontology. Does this bring any novelty and scientific contribution, or is it more a part of the use case, i.e. how the ontology can be used? Additionally, the approach is poorly motivated. Why is a translation via Java classes used? Why was mappings, such as using RML, ruled out? And what about other kinds of transformation approaches, such as OTTR/OPPL? If this approach is part of the research contribution, it should also be backed by related work, novelty and generalisability discussed, and choices as the one mentioned above better motivated, as well as results evaluated and discussed. Figure 2 is also not very clear - what do the two arrows mean? The database sends a database to a generic Java class??  Further, sections 3 and 4 need to focus more on the learnings from this work - what are the challenges in creating bridge ontologies? How were they addressed? What are the cases that could not be covered? Why? What other things can we learn from this?  Finally, the main emphasis of the paper should be on the evaluation - this is where we can really learn something, and where the scientific contribution should be grounded. However, for this to be possible, the evaluation should be described in much more detail. The title of the evaluation section 4.2.7 \"Set of queries\" does not really match the content. I would suggest to make this its own section, called “Evaluation\", and then several subsections, e.g. \"Evaluation setup\", \"Evaluation results\", \"Analysis\" etc. While assessing the query performance of the integrated data is an interesting evaluation, actually applying the ontology in its intended use case should also be an essential part. The web application briefly mentioned could be a part of this, but on one hand the description is way too brief, and on the other hand it is not clear whether this has even been used, e.g. in a real use case, by actual users etc. And what can we actually learn from using the ontology for this application? How are we now making reporting or LCA assessment better? What are the gains? In fact, from the paper it is not even clear what the focus of the application is - what does \"data gathering\" mean? Entering new data into the system, or accessing and gathering data from different datasets/databases?  The paper completely lacks an analysis of the results, and a discussion of limitations and implications of the research.  The supplemental material is comprehensive, but not well documented. For instance, the ontologies lack a documentation page for human consumption, and some ontologies even lack documentation (annotations) in the OWL files (e.g. labels and comments). This makes it difficult to assess the quality of the artefacts themselves. Minor issues: - Page 3: \"databases that based on a new\" -> \"that are based on a new\"? - Page 4: \"analizing\" -> \"analyzing\" - Figure 3 - why is one class more orange than the rest? It is also not entirely clear where all the lines go - do they branch out or cross each other? - What do you mean with TBox-data in section 4.2? Normally data is the ABox. - Footnotes are missing on page 9. - Figure 4: What do the different colors mean? Why are some arrows dashed and some not? What does \"mapping\" mean technically? - Don't break the listing 1 on two sides of a figure, and on two separate pages. - Page 11: \"grater\" -> \"greater\"",
         "0.7753",
         "2",
         "0",
         "0.0648243358708474",
         "0.0821",
         "0.9163589477539062",
         "54.83",
         "9.7",
         "10.46",
         "12.6",
         "10.5",
         "102",
         "0",
         "1",
         "0",
         "0",
         "2.0",
         "3.0",
         "5.0",
         "False",
         "negative",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "4.0",
         "70.0",
         "80"
        ],
        [
         "34",
         "3687-4901",
         "Anonymous",
         "05/Dec/2024",
         "Major Revision",
         "1045",
         "A Semantic Approach to Reducing GHG Emissions",
         "In the year 2015, 196 countries signed the Paris Agreement, which aims at keeping the rise in mean global temperature below 2◦C above pre-industrial levels. Governments have since launched awareness campaigns and tightened regulations, motivating companies and governmental organizations to reduce their direct greenhouse gas (GHG) emissions and the indirect emissions of their value chains. To monitor and report on GHG emissions, companies follow standardized methodologies which today remain costly, time-consuming, and require extensive human expertise. In this paper, we present a Knowledge Graph (KG) that forms the semantic backbone of an interdisciplinary research project that aims to significantly reduce the time and effort that environmental accounting experts spend gathering relevant data and validating it. To facilitate data gathering, instead of proposing the creation of a new standard, we created ontologies and management tools for three of the most common GHG data formats—ILCD, EcoSpold01, and EcoSpold02—and we propose a bridge ontology to seamlessly query data expressed in either of these formats. To take advantage of already widely-used ontologies, increase interoperability, and integrate expert knowledge, we follow the Simplified Agile Methodology for Ontology Development to create the WISER ontologies, which are part of the proposed KG and have been created to permit automatic responses to requests by environmental scientists and to capture their domain knowledge. To demonstrate the effectivity of our KG-based approach, we present a tool for data gathering that has been validated by environmental accounting experts. The proposed KG aims at decreasing the effort required for GHG emissions reporting while increasing its transparency and reproducibility. It furthermore democratizes access to GHG emissions data for environmental accounting experts, companies, auditing authorities, and regulatory bodies.",
         "230",
         "Paper Summary The paper discusses an important topic of green house gas (GHG) emissions which is of high significance. The authors introduce a method for translating data from three common XML data formats (ILCD, EcoSpold01, and EcoSpold02) into RDF knowledge graphs and propose ontology mappings (formalised in the Bridge ontology) to enable common query interface across the datasets described using such formats. In addition, authors provide additional semantic links as part of their WISSER ontology (aligned with GeoNames) to enable more granular geospatial search over location metadata recorded as literal values in the emission datasets.  Strengths:  The paper discusses a highly relevant domain with plethora of challenges highly relevant to the semantic web community. I agree with the authors that semantic approach to GHG emission data could have a significant impact and that this is not very frequently discussed in our community.  The article reports on a semantic integration approach for real world datasets described using established data formats.  The narrative is easy to follow and the authors provide the link to GITHUB repository containing datasets used in experiments, ontologies, and the additional supporting code  Weaknesses:  1)\tContributions  Could authors please clarify the main contributions of the article? If it is the KG resulting from parsing existing datasets and described using the bridge ontology, please provide more details on the KG (e.g., size, location, number of datasets integrated, etc.). If it is the method used to integrate the different schemas, could you please extend the description of the process (e.g., how were the experts integrated, how agreement was achieved, etc.). If the main contribution is the Bridge Ontology and the Wisser ontology it feels that there is not sufficient detail in the article at the moment to assess these resources. For example, in https://raw.githubusercontent.com/researchAndMore/swj/refs/heads/main/On... there are a number of classes not discussed in the paper but they also do not have any comments in the actual ontology file.  2)\tModelling Bridge Ontology Only simple straightforward mappings are discussed in the paper with examples, however, more complex cases are not shown. For example, authors write : \"However, even when classes are not equivalent, we were able to bridge objects and data properties based on the openLCA  analysis [16], since some of them provide one-to-one matching, and others denote sufficiently similar properties.\" What is meant by \"sufficiently similar properties\" and how was this reflected in the ontology? It is also not clear how the actual emissions values are modelled which I presume are one of the main results of the search?   Wisser Ontology Authors claim that \"The bridge ontology described in the previous section allows homogeneous querying of heterogeneously described data. However, it is not capable of fulfilling all the practical requirements of environmental accounting experts when gathering data for GHG reporting.\" However, I am not sure it is clear why the bridge ontology is not fulfilling the requirements and what these requirements are.  Section 4.2.3 mentions \"selected\" CQs which gives an impression there are many more in the Github but I have only been able to find four, all focusing on the geospatial aspects (https://github.com/researchAndMore/swj/blob/main/SAMOD/CompetencyQuestio...) Are there more? Are there any CQs for the bridge ontology?  re:Geospatial concepts in WISSER I am not entirely sure whether the WISSER concepts are really needed as even the properties like :bGeographyParent mirror the properties in the Geonames vocabulary. Could authors please motivate in more detail why should, for example, :bGeography property not have a range gn:Feature and then just use gn:alternateName for the labels?  Please see [1] (missing from the related work and probably relevant) where the observations are linked directly to geonames.  Evaluation: The evaluation is based on query performance which is hardware dependant but hardware specs are not reported. It is also not clear how the evaluation datasets were created. I am personally not very sure how suitable is this form of evaluation without further context (e.g., how often do users need to run such queries in the real world, etc.). A more interesting evaluation would be some user-based experiment to confirm whether the semantic pipeline indeed fulfils the expected requirements of experts.  The Bridge and WISSER ontologies are also not evaluated, they are missing proper documentation, purl IRIs are confusing and not working (based on the Github repo the bridge ontology seems to be using https://purl.org/wiser# and the WISSER https://purl.org/wiser/) General comments:  The title mentions \"reducing of emissions\" however it is not clear how the reduction is to be achieved with the technologies discussed in the paper. I think illustrative motivating example early in the paper would help.  line 38 -39 \"The XML schema  tags were defined as OWL classes, and in some cases it was preferred to define them as data properties to connect classes directly instead of using identifiers.\"  Could you please provide an example?  re: Algorithm  line 35 and 36 \"ILCD divides concepts at a lower granularity and distributes them among different XML files, creating dependencies among each other\"  how were the links and cardinality restrictions created? The algorithm does not seem to cover this as it currently shows only creation of RDF-literals \"Go to 2\" -> what does 2 refer to?  A simple example of side by side comparison of XML and resulting RDF would help How is the management of IRIS handled if same concepts are mentioned in multiple files?  re: data in GITHUB lines 35 - 44 together with Figure 5 - I found it difficult to understand how the assertions presentenced  in lines 35 - 44 are implemented using the WISSER ontology terms. Is the induvial in Fig5 of type WisserGeography (subclass of BGeography)? Can you please point me to the correct file in the Github where the logical constraints are modelled?  I have found  ###  https://purl.org/wiser#BRERwoCHDE  rdf:type owl:NamedIndividual ;                                      \"RER w/o CH+DE\" . in https://github.com/researchAndMore/swj/blob/main/Ontologies/WISEROntolog... And I have also found  ###  https://purl.org/wiser#BEuropeWithoutSwitzerland  rdf:type owl:NamedIndividual ;                                                    owl:sameAs  ;                                                     \"Europe without Switzerland\" . which is presumably incorrectly linked to the geonames instance representing only European Union?  Misc Footnotes 10 and 11 are missing form the PDF Perhaps https://tec-toolkit.github.io/ might be relevant to look at as well  References:  [1] Germano, S., Saunders, C., Horrocks, I. and Lupton, R., 2021, September. Use of semantic technologies to inform progress toward zero-carbon economy. In International Semantic Web Conference (pp. 665-681). Cham: Springer International Publishing",
         "0.7853",
         "3",
         "11",
         "0.0857462195923734",
         "0.5148",
         "0.9148530960083008",
         "35.47",
         "13.0",
         "12.98",
         "14.9",
         "14.8",
         "82",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "3.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "4.0",
         "80.0",
         "85"
        ],
        [
         "35",
         "3641-4855",
         "Anonymous",
         "27/Mar/2024",
         "Major Revision",
         "2294",
         "Repairing $\\mathcal{EL_\\perp}$ Ontologies Using Debugging, Weakening and Completing",
         "The quality of ontologies in terms of their correctness and completeness is crucial for developing high-quality ontology-based applications. \\nTraditional debugging techniques repair ontologies by removing unwanted axioms, but may thereby remove consequences that are correct in the domain of the ontology. In this paper we propose an interactive approach to mitigate this for  $\\mathcal{EL_\\perp}$ ontologies by axiom weakening and completing. We present the first approach for repairing that takes into account debugging, removing, weakening and completing. We show different combination strategies, discuss the influence on the final ontologies and show experimental results. We show that previous work has only considered special cases, and that there is a trade-off, and how to deal with it, involving the amount of validation work for a domain expert and the quality of the ontology in terms of correctness and completeness. We also present new algorithms for weakening and completing.",
         "35",
         "Review of: \"Repairing EL_$\\bot$ Ontologies Using Debugging, Weakening and Completing\" The paper deals with the subject of repairing ontologies. It addresses the combinations of different variants of fundamental operations that constitute a repairing process. The paper introduces an interactive approach for repairing ontologies, and discusses the quality of the obtained repairs in terms of their correctness and completeness with respect to their entailments. Additionally, this work includes both an implementation of the discussed approach and an experiment.   I find the topic of this paper to be of great relevance to the journal. The paper presents a framework for repairing ontologies that is general enough to characterize previous works on the subject. Given an EL bottom TBox and a set of wrong axioms, the framework allows the combination of debugging, removing, weakening and completing operations to obtain a repaired TBox that does not entail any of the wrong axioms. The framework also incorporates an oracle (user) in order to validate axioms during the entire process of repairing. The paper presents multiple variants of those operations, and discusses their trade-offs in terms of completeness and correctness of the repaired TBoxes, where completeness and correctness concern the entailments of the resulting TBoxes. The paper also introduces new algorithms for weakening and completing. Furthermore, it describes two systems: an implementation of the framework as an extension of the EL version of RepOSE, and a Protégé plugin for a specific instantiation of the framework. Additionally, an experiment evaluating the discussed approach is also included. The authors also provide access to implementations and resources used in this work. This paper extends the authors' previous work. Here, the considered Description Logic is EL bottom instead of EL. Wrong axioms can be any entailed axiom instead of only asserted axioms. Additionally, the debugging operation has been integrated into the framework.  Overall, the paper is well structured and interesting to read. However, I am not sure if the provided extensions are sufficient to merit a significant delta. Furthermore, there are some issues that require clarification. The authors assert that all proposed algorithms generate repairs as defined in Definition 1. However, I have concerns about this claim based on several observations. Notably, in the authors' previous work, debugging was not included in the repairing pipeline, and the set W of wrong axioms was assumed to be complete in a way that, once removed from a TBox T, T would not entail any axioms in W. The authors have this assumption in this paper as well. However, since debugging is now part of the framework, the set W of wrong axioms is not exactly the set D of axioms that need to be removed, which now have to be computed instead of being given as part of the input.  Furthermore, the paper mentions that the oracle used in the approach has no restrictions and may provide incorrect or inconsistent answers. This raises questions about the correctness of the set D, which is computed based on the oracle validations, as illustrated by Algorithm C14 for example. The possibility of oracle errors suggests that the set D might not be comprehensive, potentially affecting the reliability of the repair output. For example, if T = {A <= B, B <=C} and W = {A <= C}, an erroneous oracle could lead to a scenario where A = {A <= B, B <= C} and D = {}, resulting in an output T_r identical to the input T, which still entails the incorrect axiom. I understand the reason behind not requiring the oracle to always be correct, as this mirrors the reality where domain experts can make mistakes. However, it should be clearly stated in the text and the algorithms that generating a repair is not always guaranteed. I tested the previous example using the provided Protégé plugin. I noticed that, aside from the absence of warnings indicating the TBox has not been repaired, the plugin also requires the axiom A <= C to be asserted, which should no longer be a requirement. Additionally, here are the remaining points that require further explanation. - Preliminaries: \t- individual names are introduced but they are never used in the paper, as the footnote also suggests. So what is the reason behind introducing them? \t- P and Q are used here as arbitrary concepts, but later in the paper they are used as concept names. The authors make it clear that this is the case. For clarity, using different letters to differentiate between concept names and complex concepts might benefit the reader. - Problem Formulation \t- Definition 1: Let W be a finite set of TBox axioms in T ... -> The footnote on the first page indicates that, unlike in the authors' previous work, the wrong axioms in this paper do not need to be explicitly asserted. However, in this definition, \"a set of TBox axioms in T\" is understood as these axioms are indeed asserted. \t- line 6: ... a repair for Debug-Problem DP(T,Or,W) ... -> Symbols like \"Or\" and \"(A,D)\" have been introduced before the definition but \"DP(T,Or,W)\" was not. It may benefit the reader to be introduced to all components used in the definition beforehand. - Basic operations - debugging, removing, weakening and completing \t- line 46: N_C^T and N_R^T -> These symbols are used here but introduced later in Definition 4. It would be easier for the reader if the meaning of these symbol is clarified when they are first introduced. \t- line 24 - 26: ... where P, Q, R \\in N_C^T and r \\in N_R^T ... -> The authors note here that fresh concept names might be introduced. But with normalization, for example, added axioms might not adhere to having concept names only from N_C^T. Similarly with a weakening that can introduce new names. - Combination strategies \t- In Table 2, it is not clear to me what is the purpose of operations \"R-none\" and \"AB-none\". If no axioms should be removed (added), then why would one need a special process that removes (adds) nothing? \t- page 10 line 20: T_1 \\sqsubseteq T_2 -> Subsumption between TBoxes is not defined anywhere in the paper. I assume the authors imply T_2 \\models T_1 with this notation. But it is unclear to me why entailment is not simply used? \t- line 20: Der(T_1) \\sqsubseteq Der(T_2) -> Why not use \\subseteq instead of \\sqsubseteq? \t- line 24: ... sets of wrong asserted axioms D_1 and D_2 such that D_1 \\sqsubseteq T ... -> Again, why not use \\subseteq instead of \\sqsubseteq? \t- page 11 lines 10 - 14: I'm not clear on the argument presented here. Which computation is being referred to here? It would be helpful if this could be explained further. \t- line 17: ... updating after each wrong axiom is the same ...  -> Does this refer to the update after each axiom is weakened or removed, or something else. This requires more clarification. \t- I believe discussing the impact of various operation variants and their sequence on the input size for the next operation in the pipeline, as mentioned in this section, is crucial. However, have the authors also considered how the order in which axioms are weakened affects the quality of the repaired ontology (and similarly for completing), as well as the overall quality of the repairing process? - Appendix \t- In Algorithm 11, what is the difference between the if statements in lines 8 and 11? \t- Also in Algorithm 11, what happens when concepts Q, R or P are complex concepts? how are these concepts normalized? - Resources \t- Instructions on how to use the provided tools, as well as the data used in the experiment, are made available. However, I could not find any scripts or instructions for reproducing the results. Finally, I've noted some typos and minor wording issues that can be improved. - Introduction \t- page 1 line 40: ... and the repairing. -> ... and their repair. \t- page 2 line 2: In this paper we mitigate these effects of removing wrong axioms by, in addition to removing those axioms,... -> This might be a bit redundant, as it is already understood that certain axioms will be removed. - Preliminaries: \t- line 22: ... during the repairing and ... -> ... during repairing or during the repair process ... - Problem Formulation \t- line 6: ... a repair for Debug-Problem DP(T,Or,W) ... -> ... a repair for a Debug-Problem ... \t- line 15: ... that formalize these intuitions, respectively. -> ... that respectively formalize these intuitions. \t- reconsidering the line breaks in all definitions, particularly in Definitions 2 and 3, could yield a cleaner format. - Basic operations - debugging, removing, weakening and completing \t- The title of the previous section uses a title case style, whereas the rest of the titles use a sentence case style. Consistency across all section titles would enhance the document's appearance. \t- line 43: ... simple complex concept set for a TBox T, ... -> ... simple complex concept set for a TBox T, denoted by SCC(T), ... \t- line 14: It might look better if \"T\" were to fit in the previous line. \t- line 31: ... removed from the ontologies ... -> ... removed from the ontology ... \t- line 32: ... Figure 1 derived wrong axiom ... -> ... Figure 1, the derived wrong axiom ... \t- Hitting Set: sometimes \"Hitting set\" is used, and other times \"hitting set\". \t- line 38: ... for computing the justifications ... -> ... for computing all justifications ... \t- Figure 1: Completion: wanted axiom \\alpha2 \\sqsubseteq \\beta2 is replaced by correct axiom ... -> The term \"replace\" is somewhat misleading. It implies that an asserted axiom is swapped with another, whereas, in reality, the axiom is not and will instead be entailed as a result of completing. \t- page 7 line 16: a similar issue to the one previously mentioned. \t- Algorithm 1: Generate the justifications ... -> Generate all justifications ... \tLine 3 in the algorithm, the spacing in \"GenerateJustifications\" looks a bit off, maybe using something like $\\mathit{GenerateJustifications}$ could solve the problem. \t\"Or\" is italicized in line 6 but appears in a non-italicized format in the algorithm's input section (this issue appears in all algorithms). \tThe titles of most of the algorithms provided in this paper describe in length what the algorithms actually do, which results in some lengthy titles, for example Algorithm C15. - Combination strategies \t- line 5: In this section -> In this section, \t- line 6 and table 2: one at the time -> one at a time \t- line 8: ... the influence of using different choices ... ->  ... the influence of using different combinations ... \t- line 13: ... between the choices for different combination strategies ... -> ... between the choices of different combination strategies ... \t- Table 2: operations are not italicized, whereas in the main text, they are. \t- line 47: ... to generate asserted wrong axioms ... -> ... to extract asserted wrong axioms ... \t- line 19: ... as soon as one is computed ... -> ... as soon as it is computed ... \t- line 23: Similarly as for weakening, ... -> Similarly, as with weakening, ... \t- line 34: Figure 2b -> Figure 2c \t- line 36: Figure 2c -> Figure 2d \t- line 36: ... one at a time completing ... -> ... one at a time completing strategy ... \t- Figure 2: It seems that a different font is used for the node labels which makes the style of operation names inconsistent with the one in the text. \t- page 10 footnote: I think this should be moved to the main text. \t- page 11 line 8: If one wrong axiom at the time is removed ... -> If one wrong axiom is removed at a time ... \t- line 11: ... then they will be added back at the end or not. -> ... then they might be added back. \t- line 17: First, we note that updating immediately ... -> First, we note that updating the TBox immediately ... \t- line 26: When completing one axiom at a time ... -> When completing for one axiom at a time ... \t- line 42: ... transformed into the sequence of operators of a second algorithm, ... - >  ... transformed into a sequence of operators of another algorithm, ... \t- pages 12, 15, 19, etc.: The document contains a significant amount of white space. It may enhance readability if the space were managed more efficiently. - Implemented systems \t- line 4: ... for repairing based ... -> ... for repairing ontologies based ... \t- line 11 and 12: ... left/right hand concepts ... -> ... left/right hand side concepts ... \t- The paper contains many long sentences; for example, the sentence spanning lines 8 to 12, or the one from lines 46 to 49, just to point out a few. I believe breaking such sentences into shorter ones would enhance the paper's readability. \t- line 18: ... that focused on completing ... -> ... that focuses on completing ... \t- line 22: ... and save ... -> ... and saving ... \t- line 35: After loading the ontology, ... -> After loading an ontology, ... \t- All examples in this section are labeled \"Example.\" Numbering them, for instance, might improve their presentation. \t- page 22 line 29: For the completion step ... -> for the completing step ... \t- line 33: Figure2c -> Figure 2d \t- line 35: ... we also implemented the function that the user can remove the specified wrong asserted axioms ... -> ... we also implemented a function that allows users to remove specified wrong asserted axioms ...",
         "0.7151",
         "1",
         "0",
         "-0.0423110153152169",
         "0.0501",
         "0.9556509256362916",
         "49.72",
         "9.6",
         "8.38",
         "12.4",
         "10.0",
         "90",
         "0",
         "0",
         "0",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "36",
         "3641-4855",
         "Patrick Koopmann",
         "30/Apr/2024",
         "Reject",
         "2190",
         "Repairing $\\mathcal{EL_\\perp}$ Ontologies Using Debugging, Weakening and Completing",
         "The quality of ontologies in terms of their correctness and completeness is crucial for developing high-quality ontology-based applications. \\nTraditional debugging techniques repair ontologies by removing unwanted axioms, but may thereby remove consequences that are correct in the domain of the ontology. In this paper we propose an interactive approach to mitigate this for  $\\mathcal{EL_\\perp}$ ontologies by axiom weakening and completing. We present the first approach for repairing that takes into account debugging, removing, weakening and completing. We show different combination strategies, discuss the influence on the final ontologies and show experimental results. We show that previous work has only considered special cases, and that there is a trade-off, and how to deal with it, involving the amount of validation work for a domain expert and the quality of the ontology in terms of correctness and completeness. We also present new algorithms for weakening and completing.",
         "69",
         "The paper is concerned with repairing ontologies wrt. a set of unwanted consequences, where repairing may involve not only removing axioms, but also adding axioms, weakening existing axioms, and strengthening existing axioms. Furthermore, it is assumed that an oracle is available that can confirm or reject whether a given axiom is correct or not. In practical applications, this oracle could correspond to a domain expert that is asked questions during the computation of the repair. Rather than presenting one algorithm for computing repairs, the authors present a collection of operations that can be used to compute a repair, and then analyze how different combinations of these operations affect the repair result.  The different operations are: 1) removing unwanted axioms directly, 2) removing axioms that can be used to entail an unwanted axiom (as in classical repairs), 3) replacing an axiom by a set of logically weaker ones, and 4) replacing an axiom by a set of logically stronger ones. In each case, the oracle is used to determine whether only wrong axioms are removed and only correct axioms are added. To ensure that Operation 3 and 4 have only finitely many options, the authors put the restriction that only concepts are used that are concept names, conjunctions of two concept names, or a role restriction with a concept name. Further variations are introduced by distinguishing how operations are combined, e.g. whether always all instances of an operation are applied at once, or whether the instances are applied one after the other in parallel with another operation. This leads to a total of 20 repair algorithms that are all shown in algorithm environments in the paper (Table 8 on Page 30 gives an overview).  The different algorithms are compared wrt. to whether the resulting ontologies are \"more complete\" or \"less incorrect\", which the authors visualize using Hasse diagrams. In addition to arguing why these relations hold (which can be shown by analyzing subset relations between the generated ontologies). This leads to insightful observations such as: if my operations are \"remove wrong axioms\" and \"add wrong axioms back to the ontology\", How is the correctness of the ontology affected based on whether I compute a hitting set of just one wrong axiom at a time vs. computing a justification for all wrong axioms? The authors additionally confirm their theoretical observations using an experimental evaluation on a small set of small ontologies. Furthermore, the authors discuss a graphical user interface and a Protege plugin of the approach. The paper has a range of limitations and is in my opinion not good enough for a journal publication. There are some issues with the presentation that should be improved - I give a list further down to help the authors with future publications. The main issue however lies in the contribution: the observations made in the paper in great detail are often quite obvious and not so surprising, and it is not clear what one can gain from this detailed analysis. Furthermore, compared to other works on gentle repairs or abduction (which corresponds to the \"completion\" operation in the paper), the setting considered here is quite limited, since the authors put an explicit bound on the complexity of concepts introduced. Finally, the experimental evaluation can be improved both in presentation and setup. I think however that the Protege plugin could be useful in practice.  * Resources The resources are provided via FigShare, which should be fine. I downloaded it and could access the ontology files. There are also the protege plugin and the graphical tool discussed in the paper. However, it is not described how to reproduce the experiments, unless this is supposed to be done manually with the graphical frontends. * Comments to the authors: ** Style Listing 20 algorithms in algorithm environments, which just differ in the order in which operations are applied, and which anyway are discussed in the paper, does not make a lot of sense. A good paper should avoid redundancy, or only use it when it helps in understanding the content better, for instance through intuitive explanations. There are also other places where text is unecessarily extended: The best example is probably Section 4.3, which is dedicated to explaining the operation of removing axioms from the ontology, which really just consists of applying set difference, for which it manages to spent several lines and even a reference to a previous section. In total, 18 pages of the appendix are all dedicated to listing algorithms (12 pages), and tables with lists of axioms (6 pages). This is not a good use of space. Some general advice: - avoid pixelated, fuzzy images as in Page 10, Fig. 2. Such diagrams   should use vector graphics - lists of abbreviated axioms as in Figure 3 are not human readable   and do not add much to the text. Use a better formatting with align,   but generally avoid examples that involve so many axioms. The idea   of examples in the text is to illustrate ideas to the reader, not to   provide ontologies used in an experimental evaluation in full   detail. For this, you should use an online repository such as   zenodo. - don't overuse footnotes - if an explanation is central to the text,   it should be in the main text - never use past tense when describing your design decisions for your   framework. - make sure all used notations are defined, and are defined before   they are used ** Method Some aspects don't seem well thought-through: for instance, the concept refinement method may introduce fresh concept names due to a normalization step, as the authors also point out themselves. But since those fresh names will never be part of the \"correct\" ontology, the oracle would always filter them out.  Alg 1: in the text you describe the hitting set algorithm, but the algorithm here does something very different and not really friendly to the oracle: it goes over all axioms of all justifications (potentially visiting the same axiom more than once), and validates each of them with the oracle!  You exclude Top and Bottom from the set SCC(T) of concepts to be used by weakening and completing. You argue that this is done to avoid tautological axioms being generated when weakening---however this affects you in the completing step: what if the correct completion would have Top on the left-hand-side or Bottom on the right-hand side?  On the bottom of Page 7, you argue an optimization that avoid the introduction of axioms that make concepts equivalent - but again, what if the correct ontology contains such equivalences? ** Evaluation In general, when doing an experimental evaluation of some prototypical implementation, one would also be interested in the run time of the experiments, for which it would also be good to know about the hardware configuration of the computer used.  Apart from this, your description leaves some important questions open: - What are the versions of the ontologies used, and where did you take   them from? For instance, it feels strange that your version of NCI   only has 3304 concept names and one role name. So mentioning which   version you used and where you took it from would help. - You say that you remove parts of axioms that are not in EL---how   exactly was that done? Did you replace subconcepts by a fresh   concept name or by TOP or something like that? What one sees more   commonly is that entire axioms are removed if they are not   supported. I like the more fine grained approach you used, but you   should be more explicit in how you did it. - Tables 4-7 are not that informative: first, the reader cannot   understand what the algorithm numbers stand for, especially since   the list of algorithms is only shown in the appendix. Second,   listing the axioms explicitly leaves a lot of work for the   reader. More interesting would be metrics: how many axioms were   removed, added? What are the relationships between the different   outcomes in terms of additional/different axioms? Which proportion   of the wrong axioms was removed, and which proportion of missing   axioms added? In the appendix, more tables like that are shown with   all the different axioms that are involved by different algorithms   (6 pages in total). I don't think this is so useful and fruitful -   rather, I would supply a resource with the actual files that were   generated. - I understand that for each ontology, you manually changed some   axioms or marked them as wrong. This really calls for an automated,   more principled approach, rather than a manual selection. Since the   modificatiosn are so simple, it would both save you work with the   experiment, and give you more data to evaluate, which in turn would   add significance to your results. - Finally, I don't understand why you used HermiT as reasoner - all   your ontologies are restricted to EL+, so I would use the ELK   reasoner which is much faster on EL ontologies. ** Detailed comments Preliminaries - if all roles are atomic, there is no use in naming them explicitly   \"atomic roles\" - \"the interpretation function is straight-forwardly extended to   complex concepts\" -- how? (refer to table?) - \"Note that P and Q are arbitrary concepts. In the remainder we often   use P and Q for atomic concepts.\" -- this is unecessarily   confusing. Just stick with one form of notation How about A,B for   atomic concepts and C,D for complex concepts, as most papers do it - Footnote 3: if you do not use individuals, then don't introduce   them - Footnote 4: this should really be in the main text Section 3: - Page 3, Line 33 \"We have not required/We did not require\" --> \"We do   not require\" - Page 4, Line 6/18/23 the layout in your definitions is incosistent - Page 4, Line 9: what is an asserted axiom? (Do you just mean axioms in T?   But then this formulation is redundant) - Page 4, Line 16: What is the point in having a notion of ontologies   O1 and O2, which are represented as TBoxes T1 and T2? Is there   anything additional in O1 and O2? In the context of your paper, an   ontology is simply a TBox, and discussing O1 and O2 adds nothing to   the text but additional confusion - Page 4, Line 28 (and later): this hyphen should be an M-dash - Normalization of EL axioms is quite standard and I don't think there   is a need for providing an algorithm directly in the paper - SCC(T) is used before it is introduced. In general, the paragraph   before Definition 4 is not really easier to understand than the   definition itself - I would just leave it out. - I do not get how you get to that formula in Footnote 7: It is   clearly n^2+n+tn -- n^2 binary conjunctions, n concepts, tn role   restrictions. Why do you divide by 2? - Page 5: Definition 5 is not a definition. - Page 5, line 27: Something doesn't quite work here: N^T_C and N^T_R   are, according to Def 4, atomic concepts and roles that occur in the   TBox. How can you then introduce new atomic concepts? At the same   time, introducing atomic concepts when computing repairs is a bit   questionable, since the resulting axioms can never be correct (how   can the algorithm know the correct names?), and consequently would   be filtered out by the algorithm. In general, it   is interesting why this is even needed: the only interesting case   where you would introduce new atomic concept names is for an axiom   of the form \"exists r.P sqsubseteq exists s.Q\", but wouldn't it then   be easier to just allow these axioms to your normal form? - Section 4.3 really shouldn't be a section Page 6: - Fig 1 is not so clear - I think just showing the axioms would be   much more insightful Page 7: - sup(alpha) / sub(beta) is not defined (or is a T missing?) - Line 43: the point of the names \"source\" and \"target\" only becomes   clear in the evaluation - then introduce them there. At this point,   this notation is confusing, and in the evaluation section, readers   may have forgotten what they stand for. Page 8: - what is the point of the AB-operations? Why would one want to add   wrong axioms back into the ontology?? Page 10: - Fig 2: Resolution! Also: what is D^*? - the operation \"\\sqsubseteq\" (square subset) on TBoxes is never   defined, and I have also never seen it before. Do you mean   entailment between TBoxes? Then you should use \"\\models\", and also   define it in the preliminaries? Do you mean the subset relation?   Then use the subset symbol! Page 17: - Use a reference for the paper for a tool if you are using it Page 19: - why is there so much space? Page 24: - Line 45: \"these approaches\" comes again and again, but which   approaches has not been mentioned yet - \" In our approach we assume that when removing axioms from the   ontology, the wrong axioms cannot be derived anymore.\"   --> this is a very strong and in practice unrealistic assumption,   and has not been mentioned before!",
         "0.7648",
         "2",
         "0",
         "0.0783683420337831",
         "0.0865",
         "0.920523762702942",
         "50.06",
         "11.5",
         "12.1",
         "14.5",
         "12.4",
         "92",
         "1",
         "3",
         "1",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "37",
         "3641-4855",
         "Anonymous",
         "19/Oct/2024",
         "Major Revision",
         "903",
         "Repairing $\\mathcal{EL_\\perp}$ Ontologies Using Debugging, Weakening and Completing",
         "The quality of ontologies in terms of their correctness and completeness is crucial for developing high-quality ontology-based applications. \\nTraditional debugging techniques repair ontologies by removing unwanted axioms, but may thereby remove consequences that are correct in the domain of the ontology. In this paper we propose an interactive approach to mitigate this for  $\\mathcal{EL_\\perp}$ ontologies by axiom weakening and completing. We present the first approach for repairing that takes into account debugging, removing, weakening and completing. We show different combination strategies, discuss the influence on the final ontologies and show experimental results. We show that previous work has only considered special cases, and that there is a trade-off, and how to deal with it, involving the amount of validation work for a domain expert and the quality of the ontology in terms of correctness and completeness. We also present new algorithms for weakening and completing.",
         "241",
         "This submission studies combinations of methods for (i) finding wrong axioms, (ii) weakening them, and (iii) adding correct consequences, as a pipeline for debugging ontologies in the inexpressive description logic ELbottom (from now on called EL in this review). The overarching goal is to primarily remove from an ontology some consequences that have been labelled as erroneous, but the authors allow also to add new other (correct) consequences to avoid losing information previously implicitly included in the ontology. Following existing approaches from the area of axiom pinpointing, the authors explain how to detect the potentially wrong axioms; they also consider a simple (very limited) variant of axiom weakening which avoids the problems of other axiom weakening proposals by restricting the shape of the possible weakenings; and finally detect from the class of consequences those that should be restored in the repaired ontology. The main contribution is an analysis of strategies for obtaining the final ontology in terms of correctness, completeness, and human effort along with an empirical study associated to it. The general work is meaningful, although not extremely novel. It falls within the scope of the journal, and has potential, but there are issues of presentation and formalisation that should be fixed before it can be published. First of all, repairs are defined as pairs of sets of axioms (A,D) where A are the axioms to add, and D the axioms to delete from the ontology. But the rest of the paper ignores this definition. In particular, the algorithms and experiments do not compute repairs in this sense. The whole work is based on two properties that the authors call \"less incorrect\" and \"more complete\". These refer, in essence, to false positives and true positives from the ontology. Why is there no analogous notions for false negatives and true positives used? Definition 5 is quite strange. It defines the super- and sub-concepts of a concept name, which will be used during the weakening phase. Yet, these are defined w.r.t. the *original* TBox, which we know that contains errors. This yields lots of superfluous elements, which need to be verified later. After the definition (before Section 4.2), the authors contradict themselves in successive sentences. They say that axioms can only use concept names appearing in the TBox, before noting that atomic concepts not in the ontology can be used. It is either one or the other. In Section 4.3, the authors refer to \"Removing\" which is \"performed by applying Remove-axioms(T,D) as defined in Section 4.1\". Going back to Section 4.1, \"Remove-axioms\" is just a set difference T\\D. What is the scope of all this meandering? Things should be easy to understand. Algorithm 1 is extremely inefficient because it requires to compute all the (potentially exponentially many) justifications first and then validate each axiom in each justification. This means that (i) if an axiom appears in many justifications, it is validated several times and (ii) the structure of the justifications is actually irrelevant. Finding just the *union* of the justifications would be much more efficient. At the end of Section 5.1 the authors promise to prove some relationships in Section 5.2, but in reality they only give a high level argument that does not formally prove any of the claims.  The names of the algorithms (C14, C9, etc.) have no intuitive meaning. Where do these come from? Would it be possible to provide more meaningful names? Also, why are they presented out of order? The experiments are simply presented through tables without a real analysis of what they mean. The results just show what is the resulting ontology, but that information is not meaningful without knowing other parameters like the resources used to compute them, or the dependency on the order of the axioms chosen. Also tables 5-7 have a second row with sequences of numbers that are never explained. Minor comments: - Definition 2: in this setting ontologies are TBoxes (as ABoxes were said to be ignored for the work), so it does not make sense to speak about \"ontologies O represented by TBoxes T\". The definition can be greatly simplified. Same for Definition 3, of course. - Section 4: I was surprised not to see references to much work developed by Baader and his colleagues on debugging description logic ontologies and in particular on EL. Specifically: [1,2] explain how to find all justifications and use this to correct errors in EL; [3] presents an overview on the problem; [4] suggests a different (more efficient) strategy to reduce the search space; and [5] shows that it is not necessary to compute all justifications and then all the hitting sets, but the sets of diagnoses can be found directly - page 9 line 34: the text for figure 2b actually refers to 2c; similarly in line 35, the text refers to figure 2d. - in Section 5.2, all the \\sqsubseteq should be standard set inclusions = References: [1] Franz Baader, Rafael Peñaloza, Boontawee Suntisrivaraporn: Pinpointing in the Description Logic EL+. KI 2007: 52-67 [2] Franz Baader, Boontawee Suntisrivaraporn: Debugging SNOMED CT Using Axiom Pinpointing in the Description Logic EL+. KR-MED 2008 [3] Franz Baader, Rafael Peñaloza: Axiom Pinpointing in General Tableaux. J. Log. Comput. 20(1): 5-34 (2010) [4] Zhangquan Zhou, Guilin Qi, Boontawee Suntisrivaraporn: A New Method of Finding All Justifications in OWL 2 EL. Web Intelligence 2013: 213-220 [5] Michel Ludwig, Rafael Peñaloza: Error-Tolerant Reasoning in the Description Logic EL. JELIA 2014: 107-121",
         "0.7814",
         "3",
         "10",
         "0.0496519930286163",
         "0.0291",
         "0.9454354047775269",
         "45.86",
         "11.1",
         "11.48",
         "13.8",
         "11.6",
         "87",
         "0",
         "0",
         "0",
         "0",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "38",
         "3641-4855",
         "Anonymous",
         "27/Oct/2024",
         "Minor Revision",
         "659",
         "Repairing $\\mathcal{EL_\\perp}$ Ontologies Using Debugging, Weakening and Completing",
         "The quality of ontologies in terms of their correctness and completeness is crucial for developing high-quality ontology-based applications. \\nTraditional debugging techniques repair ontologies by removing unwanted axioms, but may thereby remove consequences that are correct in the domain of the ontology. In this paper we propose an interactive approach to mitigate this for  $\\mathcal{EL_\\perp}$ ontologies by axiom weakening and completing. We present the first approach for repairing that takes into account debugging, removing, weakening and completing. We show different combination strategies, discuss the influence on the final ontologies and show experimental results. We show that previous work has only considered special cases, and that there is a trade-off, and how to deal with it, involving the amount of validation work for a domain expert and the quality of the ontology in terms of correctness and completeness. We also present new algorithms for weakening and completing.",
         "249",
         "In)coherence: p.3, sect.2, l.-5 of: \"...a TBox is incoherent if it contains an unsatisfiable concept\": As per definition, a TBox contains concept inclusions, not concepts. The constant ⊥, present in the language, is always unsatisfiable. Is ⊥ not considered a concept? Clarify. Oracles & experts: p.3, sect.3, l.7 of: \"we did not require that an oracle always answers correctly...\": It seems that some assumption(s) on oracle behaviour are desirable, like perhaps an oracle gives a correct answer every once in a while, for otherwise it is not clear why an oracle is any better than a random bit generator. It is also not clear whether an oracle should always give the same answers for two identical queries. The difference, if there is any, between validating an axiom and an oracle query should be briefly explained, as well as any assumptions on validated axioms — are these supposed to always be correct? Axioms & concept inclusions: The authors use three terms — asserted axiom, axiom, and CGI — for what appears to be two concepts: an element of a given TBox, and a concept inclusion outside that TBox. There is a tendency to call an arbitrary concept inclusion an axiom. This is somewhat strange — unless this terminology follows an established tradition, in which case the authors should clarify their use of the terms, particularly that of \"axiom\". \"Derived axioms\" are typically called theorems. Normalization and ⊥ : From \" ⊤ and ⊥ are not in SCC(T)\" (p.4, l.-2) I conclude that ⊤ and ⊥ are not elements of N_C. With this understanding, the claim \"Every EL⊥ TBox can ... be transformed into a normalized TBox...\" is untrue: The inconsistent TBox { ⊤ ⊑ ⊥ } cannot be transformed into a normal TBox because any normal (as defined in 4.1) TBox is consistent — interpret all elements of N_C by Δ, and all elements of N_R by Δ×Δ. Algorithm A11 is apparently only supposed to handle EL rather than EL⊥ TBoxes. It is unclear what the normalization of, say, the consistent { P ⊓ Q ⊑ ⊥ } should look like. The authors should probably spell out (some) reasons for restricting to normal TBoxes. p.4, Defs.2&3: Would it not make sense to identify ontologies with TBoxes for the purposes of the paper in order not to duplicate the T/O notation? p.6, Algorithm 1: Is it OK that the algorithm may well ask to validate a given axiom more than once? Page 2 of 3 ReviewSWJ(1) 27/10/2024, 12:14 p.7, Algorithms 2 and 3: It is unclear whether α ⊑ β is supposed to be in or outside T. It is also unclear what ((sb ⊑ sb' ⋀ sp' ⊏ sp) ⋁ ...) means, as this is not a statement — did you forget to prefix this with \" T ⊨ \"? or perhaps with \" T ∖ { α ⊑ β } ⊨ \"? p.11, sect.5.2: \"the building blocks can be used to compare different combination algorithms...\": That's like saying \"flowers can be used to compare different bouquets\". p.25, sect.9: \"We also introduced a way to compare combination strategies...\": All conclusions have the form \"Combination A is more (or equally) complete and incorrect than Combination B\", and that more validation work benefits correctness. The authors do not state, let alone apply, any criteria for determining which completeness/correctness tradeoffs are sweeter than others. English usage, misprints etc.: p.3, sect.3, l.3 of: \"few ... information\" ↦ \"little ... information\" (twice) p.5, ll.8–9: \"more ... or equally complete (...), than the ontology...\": delete comma. p.5, l.-9: \"⋃_{S∈\\cal S} S\" ↦ \"\\bigcup \\cal S\" p.7, l.-7: \"the amounts of concepts\" ↦ \"the number of concepts\" p.8, sect.5; ff: \"at the time\" ↦ \"at a time\" (multiple occurrences): the expression \"at the time\" carries a different meaning, as in \"It seemed like a good idea at the time\". p.10, sect.5.2: \" ⊑ \" ↦ \" ⊆ \" (multiple occurrences): these are set inclusions, not concept inclusions.",
         "0.7555",
         "2",
         "0",
         "0.0949324324324324",
         "0.1853",
         "0.8260592222213745",
         "56.96",
         "8.9",
         "10.25",
         "12.3",
         "10.2",
         "60",
         "0",
         "1",
         "0",
         "1",
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null,
         null
        ],
        [
         "39",
         "3737-4951",
         "Anonymous",
         "29/Sep/2024",
         "Major Revision",
         "714",
         "NIS2Onto: an Ontological Representation of the NIS 2 Directive",
         "This paper presents NIS2Onto, an OWL ontology designed to model and manage the complexities of the NIS 2 Directive, aimed at bolstering cybersecurity across essential sectors in the European Union. \\nNIS2Onto offers the ontology that translates the Directive’s legal and technical requirements into an ontological format, facilitating improved compliance management and enhanced understanding among cybersecurity professionals, legal experts, and organisational stakeholders. \\nThrough the ontological representation of the NIS 2 entities, relationships, and obligations, NIS2Onto enables automated compliance verification, streamlined risk assessments, and effective policy implementation. Our evaluation employs both metrical and qualitative analysis through a real case study in order to witness the robustness and practical applicability of NIS2Onto. \\nThe ontology not only supports the accurate interpretation of complex legal texts but also aids in the systematic enforcement of cybersecurity measures. Furthermore, NIS2Onto’s extensibility allows for integration with other regulatory frameworks, fostering a comprehensive and unified approach to cybersecurity governance.",
         "47",
         "In this paper, the authors propose an ontology to model the NIS 2 Directive of the European Union. In times of increasing legal complexity support to cope with the legal requirements and ensure compliance with is highly welcomed. Additionally, the topic of the paper also fits into the scope of the journal. While the structure of the paper is suitable for the content, it would be highly beneficial for the reader to include more information. I understand that the paper is an extension of previous work, however, given the title of this paper users would expect to get all the information about the proposed ontology without having to read additional papers. Additionally, the previous paper contains more examples and figures from which this paper would also benefit. I would like to ask the authors to explicitly state what is new in this paper compared to the previous work(s).  In general, the paper is written in an understandable way and easy to follow, however, the writing style needs to be improved: There are many occurrences in the paper which are not precise enough and could be improved by adding information. For instance, missing references (e.g., line 38: AI Act) or use of abbreviations without prior spelling of the full name (NVD, GDPR, ISAP, PCI DSS,…). Furthermore, there are statements throughout the paper where adding the concrete information should be easy and would also help readers in understanding, some examples: •\t“issued less recently” -> add the date •\t“most important sectors” -> which sectors are important, who says that they are important? •\t“in some cases” -> which ones? •\t“a small part” -> of what? •\t“some security best practices” •\t“somewhat overlaps” Additionally, the proposed ontology is wrongly spelled multiple times throughout the paper. Since it is a directive, EU member states need to transpose it into national law. I’d like to ask the authors to elaborate on the impact of different national transpositions on the proposed ontology. The proposed ontology is provided via a Github repository. I didn’t find the link to the repository in the paper. There is no additional information available in the repository, there is also no readme available.  The authors follow the SecOnto methodology to create the ontology without providing details. While there approaches mentioned that did not seem to succeed, it is only stated that the ontology has been created “semi-manually”. The paper would therefore benefit from a detailed description of how the ontology has been created, including concrete examples of how the legal text is translated into classes and properties. Please also elaborate on the reuse of existing ontologies. Furthermore, nine different types of competency questions are defined in Section 3.4 but there are no actual competency questions. I’d like to ask the authors to add competency questions, which can also be used and answered in the ontology evaluation section.  The provided ontology itself (OWL file) does not contain meta information (e.g., authors, contributors, license, version,…) and also no labels or descriptions of the classes or properties. Also, there is not even a dedicated ontology IRI available, instead the standard IRI provided by Protégé is used. It would be very beneficial to register a namespace for the ontology (e.g., w3id.org). Where are the SWRL rules stated? Please also elaborate on the maintenance plan of the ontology. The evaluation of the ontology is done by providing metrics. I would expect an ontology evaluation to also contain the answered competency questions to show that the modelled ontology can answer the questions. Furthermore, I am missing an evaluation according to the FAIR principles (e.g., https://foops.linkeddata.es/FAIR_validator.html) which would also give a hint on the reusability of the ontology for interested parties. Could you please also elaborate on how you see the future application of the proposed ontology? For the case study, please add concrete examples to the paper as well as the SPARQL query. Overall, the paper addresses an interesting topic and the proposed ontology could be interesting for real-world applications. However, the paper does not provide the level of details expected of a journal, the writing style is not precise enough and the proposed ontology and its evaluation is missing parts. Therefore, this paper is not ready for publication in its current state and I suggest a major revision.",
         "0.7474",
         "0",
         "1",
         "0.1701406926406927",
         "0.7941",
         "0.9185303449630736",
         "37.1",
         "12.4",
         "10.74",
         "13.6",
         "12.2",
         "109",
         "1",
         "0",
         "0",
         "2",
         "3.0",
         "4.0",
         "9.0",
         "False",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "2.0",
         "3.0",
         "30.0",
         "60"
        ],
        [
         "40",
         "3737-4951",
         "Beatriz Esteves",
         "27/Nov/2024",
         "Major Revision",
         "1985",
         "NIS2Onto: an Ontological Representation of the NIS 2 Directive",
         "This paper presents NIS2Onto, an OWL ontology designed to model and manage the complexities of the NIS 2 Directive, aimed at bolstering cybersecurity across essential sectors in the European Union. \\nNIS2Onto offers the ontology that translates the Directive’s legal and technical requirements into an ontological format, facilitating improved compliance management and enhanced understanding among cybersecurity professionals, legal experts, and organisational stakeholders. \\nThrough the ontological representation of the NIS 2 entities, relationships, and obligations, NIS2Onto enables automated compliance verification, streamlined risk assessments, and effective policy implementation. Our evaluation employs both metrical and qualitative analysis through a real case study in order to witness the robustness and practical applicability of NIS2Onto. \\nThe ontology not only supports the accurate interpretation of complex legal texts but also aids in the systematic enforcement of cybersecurity measures. Furthermore, NIS2Onto’s extensibility allows for integration with other regulatory frameworks, fostering a comprehensive and unified approach to cybersecurity governance.",
         "106",
         "Paper Summary: In this paper, the authors describe the development of an ontology that conceptualizes the requirements of the NIS 2 directive, and provide concrete example on how a company can use it to track which requirements they are already in compliance with and which ones they are still non-compliant. Evaluation as an ‘Ontology description’ manuscript: (1) Quality and relevance of the described ontology: The work is appropriate for this journal, however, it is difficult to assess its quality due to a short evaluation (I give pointers on how to improve it further on) and due to a lack of human-readable documentation for the ontology itself (the provided repository only has a .owl file). A proper state of the art is also missing, in particular related to ontology-based regulatory compliance. (2) Illustration, clarity and readability of the paper: The paper could use a thorough review to have a more formal style of writing. Moreover, as I elaborate in the next sections of this review, it lacks figures and examples that assist with the overall readability of such a contribution. (3) Long-term stable URL for resources: The organisation of the repository should be improved as the provided URL does not contain a README file to guide readers through the contents of the repository. The provided OWL ontology appears to be complete for the replication of experiments and is stored on GitHub for long-term preservation and discoverability. There is no provenance information related to the contents of the repository. There is no human-readable documentation for the ontology. The versioning strategy to be used by the authors should also be mentioned. Detailed evaluation: Title & Abstract. The title is well-drafted and presents the main goal of the manuscript. The abstract describes well enough its purpose, findings and value, however the methodology used to create the ontology is not mentioned. The abstract should also provide an insight on how much coverage of the directive is provided in the ontology, as well as situate it in relation to the state of the art. The authors also mention that “NIS2Onto reduces time and effort required for the verification, both by enabling continuous monitoring of any modification that occurs during the lifespan of the company and by minimising the risk of error by human personnel”, but do not further elaborate on how they ensure this in any section of the paper, e.g., to establish that using their solution is more time-effiecient, I would expect a user-study to be performed and assessed. 1. Introduction. This section introduces the motivation of the paper. Although the ontological contribution of the work is well covered – the development of an ontology to describe the NIS2 directive –, it is not clear if/how the work was validated by legal experts or how the authors will support the claims of having an adaptable and enforceable compliance mechanism that is interoperable across implementers, which should also be a contribution of the manuscript if the ontology is to be used for automated compliance verification. The second paragraph should properly introduce the scope of NIS2 and to which entities it applies, and also compare the differences between NIS2 and its predecessor. Moreover, this section should also be supported by valid references, including citations for the laws and directives, and improved with definitions from the domain, to help readers that are not experts in cybersecurity and its regulatory aspects. Limitations, if any, are absent from the introduction or the overall paper.  2. Related work. DPV [1] is a state of the art resource to represent information related to usage and processing of personal data, which includes an extension to support the NIS2 Directive [2], which is currently missing from this Related Work section. For completeness, contributions related to cybersecurity ontologies [3-6] (non-exhaustive list) can also be considered for integration in this section, as well as to check whether they are good extension points for the developed ontology. There is also an extensive body of work related to ontology-based regulatory compliance, which is completely missing from this contribution, including using SWRL rules as proposed by the authors. This analysis will be helpful to understand why the authors chose SWRL for their work. 3.1 Overview of the NIS 2 Directive. The author’s decision to not consider Chapter I for the ontology is not comprehensible given that it includes information about the scope, involved entities and definitions that support the Directive’s legislative text. Moreover, a diagram would help readers to visualise the involved NIS2 entities and how they are expected to interact due to the obligations of the directive. A proper introduction to each studied Chapter and its requirements will also help the readers to understand the complexity of NIS2. 3.2 SecOnto Methodology. The contribution would benefit from a diagram/figure explaining the followed methodology, as it is an adapted version of Methontology for the security domain. Such a figure would also help connecting the dots between the proposed methodology and the following subsections related to the development of the ontology (subsections 3.3 to 3.10). The provided description is also not very clear regarding the outcomes of each step of the methodology, e.g., the Implementation step has the ontology, ‘associated paperwork’, and ‘conclusions drawn from the ontology’ as outcomes — what paperwork or conclusions are expected here? In what format? The followed methodology also does not mention any step of legal validation. Other ontology engineering methodologies, such as LOT [7], do this by integrating domain experts, e.g., in this case legal experts, in all phases of ontology development. A couple of sentences can also be added to address now NIS2Onto will adapt to the Member States national implementations of the directive. 3.3. Automating the Creation of the Ontology. The full NLP pipeline to automatically extract concepts from the directive should be better detaileed. In particular, the results of the extraction and its accuracy should be further elaborated by the authors, to provide an understanding of the efficiency, correctness and completeness of the chosen methodology. The protocol for manual evaluation of the created concepts is also missing from this section’s description. The authors also mention that “We deliberately avoided using certain tools, particularly in the context of ontological automated development, because they proved to be ineffective or incompatible with the context of security directives.”. Which tools are included here and why are they not eefective or compatible with security directives? 3.4. Competency Questions. The Compliance check CQ should be split in 2: one for checking whether an entity is compliant and a second one for checking if they are compliant with a certain article. The Integration I and Integration and Differential Analysis CQs introduce integration with other regulations, however this aspect has been left out of the manuscript so far. I would recommend to address this interplay of regulations in a previous section, perhaps in the section decribing the directive. Overall, the CQs would benefit from a more formal structuring. 3.5. NIS2Onto Overview. This section would benefit from a schematic diagram to showcase the main classes and properties of NIS2Onto. Moreover, the authors mention that NIS2Onto “associates specific agents with the security measures the agents must fulfil through the equivalence relationship, i.e., EquivalentTo” — I would expect that an equivalence relationship is used between related elements and not between distinct concepts such as entities, e.g., agents, and security measures. Furthermore, the usage of the term ‘agents’ is ambiguous and must be introduced, probably even in an earlier section. Are agents natural persons, legal entities, software agents, others? An example instantiation of a security measure and its associated actions and entities would also increase the understandability of this section. Concretely, the role of reasoning to evaluate generated inferences should be properly introduced and explained — what additional knowledge does it provide over the already extracted knowledge base? Providing an example of an instantiation of a measure into the concrete adoption of a specific standard would also give further readability to the text. 3.6. Classes and individuals. Examples of documents, agents and objects can be provided in this section. Furthermore, objects are very abstract classes that are seemingly trying to cover different concepts within the same class — if possible, dividing them and using separate classes for different concepts with be ideal. The modelling of compliance classes is not clear. Taking the used example, an instance of Article-10-MemberState-Compliant is supposed to be a subclass of all classes related to Article 10 that a Member State has to comply with or is it just a subclass of the ones which it is already compliant? The text seems to imply the former, while the term itself, i.e., Article-10-MemberState-Compliant, by using the word ‘Compliant’, seems to imply the latter. If what the authors which to express is the former, I would suggest changing the naming of the classes to use the word ‘Compliance’ instead and then use terms like ‘Compliant’ or ‘Non-Compliant’ to express the status of compliance of each class that needs to be complied with for a certain article/entity. 3.7. Object-properties (also applies to 3.8. Data-properties). Similar comment in the previous section, as the authors mention ‘The object property name is obtained by the verb, but it includes other additional elements.’. The result are complex terms that will hinder reusage, e.g., for other security-related ontologies. 3.9. SWRL rules. As mentioned in the comments related to Section 2, there is no justification on why the authors decided to use SWRL as their reasoning language, and as such, no state of the art on existing solutions for regulatory compliance, in particular for security, using SWRL or any other languages. Furthermore, considering that rules are used to verify compliance with the regulation, it would be good to understand their coverage of the regulation, e.g., if there is a rule for each measure in NIS 2, and the rules should be provided together with the ontological resource, e.g., in the linked code repository. 3.10. Evaluation. The provided evaluation can be further improved by the usage of tools such as OOPS! [8] and FOOPS! [9] to access if there are critical pitfalls in the ontology development and whether it follows the FAIR principles for ontology publication. It is also not clear how far the ontology goes in terms of answering the defined competency questions, e.g., SPARQL queries for all competency questions can be provided. 5. Conclusions. The authors mention that ‘NIS2Onto […] supports risk assessment,’ — this sentence should be supported in the previous sections. A concrete suggestion would be to improve the case study section with a risk assessment that is concretly supported by the use of NIS2Onto. As future work, I would also invite the authors to look into how to integrate their work with DPV, as it is a state of the art vocabulary for data protection-related requirements, which is also looking to have NIS 2 as one of its extensions. As such, I am at the disposal of the authors in case they want to work on such an integration, as I am an active member of the Community Group [10] that edits and maintains the DPV. Minor comments: Capitalise mentions of ‘Chapters’ and ‘Articles’ in the manuscript and use it consistently. 3.2 SecOnto Methodology Page 4 Line 7: ‘the ontology that describes the measurements’ -> measures ? Page 4 Line 15-16: ‘composed of the articles from 7 to 37’ -> composed by Articles 7 to 37 3.3. Automating the Creation of the Ontology Page 4 Line 35: ‘of SpaCy and ClausIE library’ -> of the SpaCy and ClausIE libraries 3.6. Classes and individuals NIS2Onto is mispelled in page 6, lines 13 an 14 Page 6 Line 28: ‘The class names adopted has been obtained’ -> have been 4. Case study Page 10 Line 21: ‘these are Article 12, paragraphs 1 and 2’ -> Figure 3 mentions Article 21, not 12 [1] https://arxiv.org/abs/2404.13426 [2] https://w3id.org/dpv/legal/eu/nis2 [3] https://link.springer.com/chapter/10.1007/978-3-030-63479-7_22 [4] https://ieeexplore.ieee.org/abstract/document/8205615 [5] https://www.mdpi.com/1424-8220/18/9/3053 [6] https://link.springer.com/chapter/10.1007/978-3-319-98842-9_1 [7] https://lot.linkeddata.es [8] https://oops.linkeddata.es [9] https://foops.linkeddata.es/FAIR_validator.html [10] https://www.w3.org/community/dpvcg/",
         "0.7644",
         "20",
         "26",
         "0.0513907501712379",
         "0.5445",
         "0.8974815011024475",
         "34.36",
         "13.4",
         "12.79",
         "15.3",
         "14.4",
         "100",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "8.0",
         "False",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "2.0",
         "63.0",
         "63"
        ],
        [
         "41",
         "3737-4951",
         "Harshvardhan J. Pandit",
         "02/Dec/2024",
         "Reject",
         "1720",
         "NIS2Onto: an Ontological Representation of the NIS 2 Directive",
         "This paper presents NIS2Onto, an OWL ontology designed to model and manage the complexities of the NIS 2 Directive, aimed at bolstering cybersecurity across essential sectors in the European Union. \\nNIS2Onto offers the ontology that translates the Directive’s legal and technical requirements into an ontological format, facilitating improved compliance management and enhanced understanding among cybersecurity professionals, legal experts, and organisational stakeholders. \\nThrough the ontological representation of the NIS 2 entities, relationships, and obligations, NIS2Onto enables automated compliance verification, streamlined risk assessments, and effective policy implementation. Our evaluation employs both metrical and qualitative analysis through a real case study in order to witness the robustness and practical applicability of NIS2Onto. \\nThe ontology not only supports the accurate interpretation of complex legal texts but also aids in the systematic enforcement of cybersecurity measures. Furthermore, NIS2Onto’s extensibility allows for integration with other regulatory frameworks, fostering a comprehensive and unified approach to cybersecurity governance.",
         "111",
         "The stated objectives of the work are to develop a NIS2 ontology that represents entities, relationships, and obligations, and using these for automated compliance verification and risk assessments. The artefact being presented is an OWL2 ontology, which is available at the given url. Overall, the work is extremely timely as the NIS2 implementation is kicking off at the moment, and there are specific policy and governance measures being adopted in response. However, the writing of the paper is severely lacking in describing the rationale and methodology for how the ontology was developed, assessment of the quality of the ontology, and how it is being applied to achieve the stated goals. At the same time, it is clear that the authors have performed a large amount of work as the artefact demonstrates a large number of concepts with terminology aligned to the NIS2 contents, though there also exists prior work by the same author which has significant overlaps in terms of methodologies and explanations of how to develop ontologies. It seems that the only contribution of this article is a quantification of that existing knowledge in the form of an ontology, and raises questions of novelty without sufficient evidence. Due to this, I think the article as well as the ontology/resource requires a large amount of work in terms of communicating the various aspects of its development and application, as well as regarding the application of best practices and evaluation. In its present state, I do not recommend publishing this article. ## Comparison with Prior Work by Authors - The reference [2] is mentioned as prior work on pg.2:16 as \"extends a previous contribution ... where the ontological approach ... is just sketched out\" - what is the different in the two works is not further clarified. The ontological approach mentioned in the previous paper seems more detailed than the rudimentary description of the work presented in this paper. - If the previous paper was used as the methodology to create the ontology, and it provides sufficient information - then this should be explicitly stated, and a summary should be included in this work - The SecOnto methodology in [5], also be the same author(s) is explained to have been used in Sec.3.2 - however it is not explained how that method was used to specifically construct the ontology. - In continuation of above, how does this methodology compare with other methodologies used in the legal domain? OR even general methods like Linked Open Terms and its predecessor NeOn? - The SecOnto paper [5], now published as https://doi.org/10.1016/j.cose.2024.104150 in Computer & Security journal, has a large overlap with this article in terms of describing in great detail how each article and clause was used to create a specific concept and how that is being used for developing the ontology - so the question arises as to what additional value does this paper provide in comparison to that (already complete and published) work? - In Sec 3.3, the authors mention semi-automatically generating the ontology - again how was this done is not explained in detail. What concepts were extracted through this process, how was it ensured that there were no errors in interpretation? For an ontology with a stated purpose of legal interpretation and compliance, any lapse or error can be of serious consequence. And at the same time, if this approach was based on the prior works as outlined in earlier comments - the paper should mention this clearly in terms of how it was applied and what is the distinction between this and the earlier works. ## State of the Art - in the introduction, it would be good to briefly explain why you have chosen semantic web to model this information, in particular what role do ontologies play in your specific motivation? - in the introduction as well as elsewhere, you have made a choice to only consider work explicitly modelling cybersecurity requirements, and in particular specific works related to modelling GDPR - these leave out a wide variety of other approaches that have modelled legislations (e.g. LegalRuleML, GDPRtEXT), or have developed ontologies specific to NIS2 (DPV 2.0 https://w3id.org/dpv/legal/eu/nis2), or developed approaches to evaluate compliance (e.g. Analysis of ontologies and policy languages to represent information flows in GDPR https://doi.org/10.3233/SW-223009). - Given that there is a significant amount of work existing regarding the implementation of GDPR, not comparing or considering how that work influences or compares with your approach is IMO a significant drawback - The references in Section 2 are mentioned without any context or relation back to the proposed work or its objectives e.g. PrOnto is mentioned as an ontology for GDPR - but that ontology is from 2018, is not available to be reused, and doesn't specifically model the security aspects required by GDPR. Similarly, other ontologies mentioned are also from 2018 - which is now 6 years in the past - and no statements are made as to whether these are reusable, available, or even if you looked at them and were influenced by their modelling and/or concepts. - There is a large amount of work being published by ENISA regarding the implementation of the NIS2 requirements - how does this work compare or integrate or plan to use that? ## Ontology Engineering - Sec 3.4 is titled competency questions, however the list provided is for functionalities and applications of the ontology rather than a list of questions that was used to determine the concepts and modelling within the ontology - It is never explained in the article what the concepts are supposed to represent specifically within NIS2 - there are clauses being represented, specific concepts for entities, actions, documents - but they are all bundled together - The assocaited artefact at https://github.com/gianpietroc/nis-ontology/blob/main/NIS2Onto.owl is accessible, and shows further issues in being unclear as to what is being modelled, there are far too many confusing modelling implications - For example, in the ontology, Incident is a class, IncidentImpact is a subclass of Incident - which is quite weird if we think that the impacts of incidents are also being considered impacts instead of being a separate concept on its own. As NIS2 as specific obligations regarding incidents, this leads to a recursive loop where resolution of an incident results in more incidents are impacts are identified or detected and are also treated as incidents. Regulations therefore always distinguish between incidents and impacts in their obligations, which the ontology doesn't seem to do. - Another example, there are a large number of cases where a class is defined as an instance of itself, such as IncidentImpact is declared as a type of owl:Class as well as an IncidentImpact (self). This results in recursive loops which will render any reasoning unfeasible and impossible. How this was not detected or what choice of modelling led to the creation of such a design pattern? Why is this not mentioned in the article? - The concepts in the ontology have no annotations to support human understanding and usability - there are no labels, no comments, no documentation whatsoever. The github repo also does not contain any documentation. ## Lack of Evidence of Utility - there are several statements made in the article regarding the utility of the produced ontology, such as pg.2:11 \"these requirements can change over time and such changes are handled automatically\" - which in the context of a regulation is a very influential statement to make as the regulations have implementing legislations, case law, and other implementation details, especially as this is a directive, and it is entirely unclear how the ontology plans to automatically keep itself updated for that. Similarly, the claim pg.2:9 \"fewer resources are required for compliance verification\" is not justified with evidence in the article. - pg.8 describes the application of ontology to a specific use-case, however the concepts are directly shown as being used in a rule without an explanation of how that rule was constructed and how dose the ontology help compliance processes - There is a risk here that the ontology is being too literal in representing the text of the regulation directly, and will require a large amount of effort as the interpretation of the law evolves and additional considerations are identified - which means the ontology will have to be updated with further concepts and properties to model these. How the existing rules can incorporate that practicality is not considered or even discussed. - Sec.3.10 is titled evaluation, but no actual evaluation is shown. There are some metrics, and three tasks listed without any information on how they were carried out or what was the outcome. - There is no reference to existing best practice e.g. OOPS! or FOOPS! for evaluation, WIDOCO best practices for documentation, or even the use of a semantic reasoning step for ensuring logical consistency - Sec.4 describes a case study which directly states the modelling of a specific rule without offering any insight into how someone who doesn't know the ontolgy will approach the task. Combined with a lack of information or documentation, it is difficult to see how such a case study will be implemented in practice. ## Style / Formatting - pg.1:48 it would be better to provide the url in the main text or as a footnote, rather than as a reference which is intended more to communicate resources external to the work being presented - pg.2:1-6 the phrasing here is confusing and it is not clear as to what is being stated - please clarify and write more directly for a reader not familiar with your style of modelling or your interpretations of the processes involved in use of the ontology ## Declarations - GDPRtEXT and DPV are works where I am an involved author, and they are referenced in context of their status as state of the art. - The DPVCG, which maintains the DPV, is working on the NIS2 extension for modelling concepts relevant to the implementation of the NIS2 regulation. DPV already models GDPR, AI Act, and other regulations, and provides a framework to create harmonised information systems for legal compliance related to data and AI laws. The authors are invited to consider analysing the DPV as part of the state of the art, and to participate and contribute their work on NIS2 for the DPV's next iteration.",
         "0.7705",
         "1",
         "7",
         "0.0867584745762711",
         "0.5489",
         "0.9280440807342528",
         "35.71",
         "15.0",
         "15.16",
         "16.9",
         "16.8",
         "99",
         "0",
         "0",
         "0",
         "0",
         "1.0",
         "3.0",
         "11.0",
         "0",
         "2",
         "4",
         "3",
         "1",
         "2.0",
         "3.0",
         "2.0",
         "29.0",
         "44"
        ],
        [
         "42",
         "3733-4947",
         "Anonymous",
         "28/Sep/2024",
         "Reject",
         "893",
         "Ontology Framework for Privacy Protection Pertaining to Learning, Education & Training (LET)",
         "In recent years, teaching-learning methods have emerged into a completely new dimension from what used to be a traditional approach. The in-person lectures have been converted into online virtual learning, the traditional record-keeping has been replaced by robust learning management systems which have made the teaching-learning process a lot more efficient and convenient. However, the increased use of digital storage and access to students' personal information raises concerns about data privacy and security for both LET (Learning, Education, and Training) users and providers. The lack of knowledge of the users about their rights and privacy leading to the lack of practice has resulted in illegal processing and piracy of personal information. Thus, this study focuses on modeling the ISO/IEC 29187-1:2013 standard which has been developed to support modeling generic international requirements for identifying and providing privacy protection of personal information throughout any kind of Information and Communication Technology(ICT)-based learning transaction where the individual has the role of an individual learner. This standard consists of the definition of key ISO concepts and rules that are used to govern the learning transaction involving LET users and providers. This article proposes an ontology framework as a knowledge framework for a compliance assessment service. Furthermore, the study elaborates on the initial implementation of the proposed ontology to establish APIs to create a compliance question-answering system related to LET using a faceted search for the stakeholders of LET. Through the ontology modeling of the ISO/IEC 29187-1 standard version 2, this study provides a clear path toward innovation, enabling the creation of complex validation systems with the introduction of several semantic web-based rules and axioms which not only enhance the standardization process but also serve as a platform for future developments and improvements.\\n\\n",
         "58",
         "This paper presents an ontology to implement an ISO standard related to privacy protection in ICT-based learning systems. The aim is to develop a validation system assessing the compliance of an ICT-based learning system to the ISO standard. In general, the quality of the writing does not meet the standard: the presentation of the ontology is awkward in many places. The paper lacks at least a clear presentation of the modeling choices and their justification. A validation of the ontology by experts and through competency questions is missing. As a result, at this stage of the project, the results are of little significance. The provided link for the Long-term Stable Link to Resources is the Github site of one of the author, and I could not find a path to the project resources (ontology and competency questions) associated to the paper.  Detailed comments: In section 1.4 what is the FSV view should be explained and the last sentence reformulated. Section 1.5 shows a certain confusion or lack of familiarity with the notion of ontology. An introduction to ontologies should not start with ontology learning from text which is here out of the scope. Then UML is not an approach but a language and the rest of the sentence is very weird with the use of the verb help twice and inadequately. Also the automatic ontology synthesis does not make sense. In section 1.6, again awkward introduction to the state of the art. The first sentence is out of the scope and the focus should be on ontologies. The paragraph on WordNet is also out of the scope. In section 2, SPARQL endpoint is not a step/action in a methodology, it is an artifact. In section 2.1 the competency question should be better presented. In particular the second one should be rephrased, in the 4th one Agent should be explained, in the last one Registration schemas and Authority should be explained. In section 2.2 there should not be any reference to an ontology as this step is prior to the construction of the ontology. Clause 3 is not understandable, as it is not introduced. In section 2.3 what are concepts, rules, guidelines, principles and field should be precisely described. The names of the classes should be singular (Guideline, Principle, etc.). The choice of an OWL ontology should be justified; it seems to me that the model should better be a SKOS thesaurus with hierarchies of SKOS concepts inside SKOS collections and or schemes. Also the SWRL rules, what they capture and how they are intended to be used should be discussed. The explanations in table 2 are very unclear. Finally the presentation of the relations is very awkward and mixes useless generalities very badly presented on the distinction between datatype properties, object properties and annotation properties. “the relationship of ISO concepts that belong to a subject field” does not make sense. The first sentence on ontology validation is also far too general and not correct, it should better be deleted. What are subject matter experts? The paragraph on the validation of the ontology is far insufficient. The validation of the ontology should be given a dedicated section reporting the work of the experts and the result and the implementation of the competency questions with SPARQL queries and the result. Section 2.4. As already mentioned, a SPARQL endpoint is not a task but an artifact. The installation of a SPARQL endpoint is not part of a methodology but a technical task that supports the knowledge engineering process. What is described in the section are useless generalities that should be deleted.  In section 3, Again the technical details on the API should be discarded. Also the screenshots do not bring anything. In Table 7, the difference between Axiom and Logical axiom should be explained. In Table 8, there is a confusion between keywords, terms and concepts that should be fixed. In section 3.3 there is also a confusion between keyword search and concept search In section 3.4, again there are awkward explanations. What are “relationships between multiple rules on the standard”? How SWRL rule are intended to be used for compliance checking should be precisely explained. The example with rules 72 and 71 lacks explanations. The description of the possible use of the ontology for Let providers is far too general and hardly understandable. Also, again inadequate vocabulary, e.g. “properties value for these rules”. Section 4 The conclusion is far too general and does not reflect the current state of the project, the current functionalities offered to end users using the developed ontology.  Other minor comments: P2 l43: rephrase usage of their personal information prior to its collection. P3 add space character before (UN) P4 l3 (a) P4 l8 delete quotes around ontology P4 l30 no need to go to the line P4 l43 delete Similarly P4 l48 delete I addition to this P4 l48 add space character before (ICA) P5 l6 delete or rephrase Utilizing ideas P5 l12 delete Similarly P5 l22 add an empty line before the last paragraph and correct the numbers of the sections P5 l22 presents P5 l32 IV →V P6 l22 add space before [15] P6 l23 delete quotes around modular P7 l32 delete on expanding the ontology a step further which does not make sense P10 delete with the help of an API connection P10 creating APIs that create",
         "0.703",
         "2",
         "1",
         "-0.014008556547619",
         "0.0468",
         "0.8713651299476624",
         "55.03",
         "9.6",
         "10.42",
         "12.5",
         "10.0",
         "104",
         "0",
         "0",
         "0",
         "0",
         "2.0",
         "3.0",
         "4.0",
         "False",
         "negative",
         "impolite",
         "Heavy",
         "neutral",
         "2.0",
         "3.0",
         "2.0",
         "30.0",
         "30"
        ],
        [
         "43",
         "3733-4947",
         "Simon Steyskal",
         "03/Nov/2024",
         "Major Revision",
         "1465",
         "Ontology Framework for Privacy Protection Pertaining to Learning, Education & Training (LET)",
         "In recent years, teaching-learning methods have emerged into a completely new dimension from what used to be a traditional approach. The in-person lectures have been converted into online virtual learning, the traditional record-keeping has been replaced by robust learning management systems which have made the teaching-learning process a lot more efficient and convenient. However, the increased use of digital storage and access to students' personal information raises concerns about data privacy and security for both LET (Learning, Education, and Training) users and providers. The lack of knowledge of the users about their rights and privacy leading to the lack of practice has resulted in illegal processing and piracy of personal information. Thus, this study focuses on modeling the ISO/IEC 29187-1:2013 standard which has been developed to support modeling generic international requirements for identifying and providing privacy protection of personal information throughout any kind of Information and Communication Technology(ICT)-based learning transaction where the individual has the role of an individual learner. This standard consists of the definition of key ISO concepts and rules that are used to govern the learning transaction involving LET users and providers. This article proposes an ontology framework as a knowledge framework for a compliance assessment service. Furthermore, the study elaborates on the initial implementation of the proposed ontology to establish APIs to create a compliance question-answering system related to LET using a faceted search for the stakeholders of LET. Through the ontology modeling of the ISO/IEC 29187-1 standard version 2, this study provides a clear path toward innovation, enabling the creation of complex validation systems with the introduction of several semantic web-based rules and axioms which not only enhance the standardization process but also serve as a platform for future developments and improvements.\\n\\n",
         "94",
         "# Review **Summary:** The present article presents an ontology framework for modeling the ISO/IEC 29187-1 standard to address privacy protection in Learning Ecosystems and Technologies (LET). The proposed framework is used to develop a compliance question-answering system that can assist stakeholders in understanding and adhering to privacy regulations.  **Overall Review:** The ontology framework and the compliance question-answering system have the potential to significantly enhance privacy protection in online learning environments. However, the article could benefit from a more detailed comparison with existing methods and frameworks to highlight its unique contributions and advantages. As of now, the actual framework the article is about, is only briefly discussed in section 3, while the rest is either mostly filler text or explaining the ontology concepts already published in [28]. Additionally, more empirical evidence or case studies would strengthen the article and demonstrate the effectiveness and impact of the proposed system in real-world scenarios. Currently, one has to take the author's word for it being an actual improvement/help. Improvements in grammar, clarity, and detail would enhance the readability and comprehensibility of the paper (see detailed comments below). understanding. Also, the provided link to resources is non-functional, as it only links to the github profile of one of the autors. ## Detailed Comments ###  1. Introduction  ---  - >`[p.2, 3-4]`: ... unheard-of *issues* related to safety, health, and education   - challenges - >`[p.2, 5-6]`: According to the statistics shared by UNESCO   - missing reference - >`[p.2, 7-8]`: Numerous students *are still required* to learn online in this unique circumstance   - still? what year is this? - >`[p.2, 9-10]`: The need for personal data and privacy protection has never been greater than it is *now*   - ... because? - >`[p.2, 9-10]`: which is why students, instructors, and parents *are growing more concerned* about safeguarding personal information and privacy in online learning   - are they though? are they actually aware of the risks? - >`[p.2, 12-13]`: Personal information and privacy *are the peace of a person’s natural private existence*,   - what? what does that mean? - >`[p.2, 14-15]`: *The development of technology* currently makes use of such granular data to optimize systems through prediction and analysis   - what technology? - >`[p.2, 16-17]`: However, *when employing this data for teaching/learning platforms*, the consequences and difficulties associated with storing vast quantities of sensitive data *are greater*   - are greater than?   - only when employing this data for teaching/learning platforms? - >`[p.2, 16-17]`: which is why data privacy and digital transformation have emerged as *two of the world’s most pressing issues* [8].   - because of the consequences and difficulties associated with storing vast quantities of sensitive data _when employing this data for teaching/learning platforms_?  ###  1.1. Policies around the World for LET  ---  - >`[p.2, 23-24]`: As an illustration, the *Family Educational Rights and Privacy Act (FERPA)*   - missing reference  ###  1.2. Importance of Privacy Protection  ---  - >`[p.2, 38-39]`: *websites will be required to use clear and plain language*   - for what? in general? or only for explaining if and how personal information will be used? - >`[p.2, 46-47]`: – Right to access: Learners should always have the right to access their data stored by the learning provider in digital format.   - what if the personal data was not collected in digital format in the first place?   - where are all those rights coming from? GDPR? add references to the respective articles - >`[p.2, 50-51]`: – Right to object: Learners have [...] the right to object to the use of their information *which is different from those consented to*.   - only to those uses that are different from those consented to? can't you object to also those uses that you consented to? - >`[p.3, 12-13]`: Such assistance is now scarce on the market   - according to whom? why? what market? - >`[p.3, 14-15]`: *Therefore*, an automated system built on top of an ontology framework can assist general users...   - therefore? why?  ###  1.3. ISO Standard & Compliance  ---  - >`[p.3, 16-34]`: What's the relevance of this entire subsection? Is it needed at all? ###  1.4. ISO/IEC LET Privacy Protection standard   ---  - >`[p.4, 8-9]`: Functional Support Services *(*(FSV) view   - extra parenthesis  ###  1.5. Ontology Overview   ---  - >`[p.4, 16-20]`: the entire paragraph is a bit wishy-washy and could be more concise - >`[p.4, 17-18]`: is ontology [17]   - are ontologies - >`[p.4, 26-27]`: a particularly *attractive* study subject [3]   - rephrase - >`[p.4, 27-28]`: According to W3C (World Wide Web Consortium), ontologies define the terms used to describe and represent an area of knowledge   - missing reference  - >`[p.4, 51]`: when legal facts were triggered. [29]   - move the reference to the end before the period ###  1.7. Existing Ontology Models   ---  - >`[p.5, 11-12]`: Additionally, it includes 26 sub-classes and *21 class attributes*   - what are class attributes? you mean (datatype/object) properties? - >`[p.5, 13-14]`: Similarly, the UT (Uniform Terminology for European Private Law) initiative   - missing reference - >`[p.5, 22-26]`: Section ??   - section references are broken ###  2. Research Methodology  ###  2.1. Domain & Scope Analysis  ---  - >`[p.6, 5-6]`: ontology creation based on ISO/IEC 29187-1 standard *V2*   - so standard version 2 but ontology version 1? - >`[p.6, 10]`: – Upon a learning transaction,   - the concept of a \"learning transaction\" wasn't introduced before - >`[p.6, 14]`: – Which rule *speaks for*   - what does that mean?  ###  2.2. Concept Ingestion   ---  - >`[p.6, general]`: clause 3.0 but also clause 3   - use consisting naming schemes - the entire section is very hard to read and follow, especially without any references to the respective tables and figures - >`[p.6, 32-33]`: the reference which is stored in the *Source* feature.   - ??  ###  2.3. Ontology Construction   ---  - >`[p.6, 47-48]`: As per the ISO/IEC 29187-1 standard version 2, the principles can be classified into a total of 7 main classes and 21 sub-classes under *the main 7 classes of principle* whereas among these 21 sub-classes, a   - what? what are classes of principle?  - >`[p.7, 38-39]`: SWRL Rules   - What about SHACL Rules? I reckon they could serve as a good alternative to SWRL rules   - replace all $->$ with $\\rightarrow$ - >`[p.7, 42-43]`: Guideline(?g) ∧ belongsToRule(?g, ?r)− >   - the dash from the arrow is actually modelled as superscript  - >`[p.8, 44-45]`: The domain and ranges of all the object properties are provided in Table 3   - the arrow direction of \"belongsToRule\" is wrong in the diagram and should point from Guideline to Rule   - a lot of the object properties in Table 3 aren't included in Fig 3 and vice versa (belongsToSubjectfield, ruleProperties,..)   - use rdfs:subClassOf arrows to indicate the subclass relationships in Fig 3 instead of the reverse bold arrows - >`[p.9, 30-31]`: Table 6Annotation Properties and descriptions.   - can be removed  - >`[p.9, 37-43]`: The proposed ontology was presented and acclaimed by the ISO/IEC JTC 1/SC 36 Working Group 3 committee ... The developed compliance system is able to accurately answer all defined competency questions.   - reference? we have to take your word for it?  ###  2.4. SPARQL Endpoint  ###  3. Results and Discussion  ###  3.1. Ontology Framework  - >`[p.10, 19-20]`: As shown in Table 7,   - according to table 7 there are 9 datatype properties, 5 annotation properties, and 15 object properties, but tables 4-6 only list 8 datatype properties, 3 annotation properties, and 10 object properties ###  3.2. API Connection  ---  - >`[p.11, 19-20]`: get_concept($term )Takes a term as a keyword and provides all the details on the concept.   - only snake case function, why not camel case?   - what term? how can one get the \"concept\" for a term? - >`[p.11, 23-24]`: those rule that involves individual learner.   - rules that involve - >`[p.11, 25-26]`: and returns only those rule that involves   - rules that involve - >`[p.11, 25-26]`: getAllRulesDetail()Returns all the rules and detailed information *about the rule*.   - about them - >`[p.11, 28-29]`: Although the API for this study is hosted on a local machine, this can be easily hosted on any server as required.   - link to repository?  ###  3.3. Compliance Q/A System   ---  - >`[p.11, 38-39]`:  by using any terms   - ? what terms?  ###  3.4. Discussion & Limitations   ---  - >`[p.12, 48-49]`: unlike other modeling approaches.   - such as? missing ref - >`[p.12, 50-51]`: as described in Clause 3.0   - missing ref  - >`[p.14, 5-6]`: must be aware of which is not easily understood using the standard document.   - standards document   - but it is easily understood using the ontology? - >`[p.14, 6-7]`: Rule 086, Rule 087, and Rule 089),   - inconsistent numbering, see page 13, line 45: rule 71 and rule 71 (no leading 0) - >`[p.14, 10-11]`: Therefore, *some of the properties value for these rules are not set *   - ?? what does that mean?",
         "0.7582",
         "13",
         "5",
         "0.0872830912025827",
         "0.0521",
         "0.9272972345352172",
         "50.53",
         "9.3",
         "9.43",
         "12.2",
         "12.2",
         "87",
         "0",
         "1",
         "0",
         "0",
         "3.0",
         "4.0",
         "5.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "80.0",
         "80"
        ],
        [
         "44",
         "3733-4947",
         "Anonymous",
         "15/Dec/2024",
         "Reject",
         "489",
         "Ontology Framework for Privacy Protection Pertaining to Learning, Education & Training (LET)",
         "In recent years, teaching-learning methods have emerged into a completely new dimension from what used to be a traditional approach. The in-person lectures have been converted into online virtual learning, the traditional record-keeping has been replaced by robust learning management systems which have made the teaching-learning process a lot more efficient and convenient. However, the increased use of digital storage and access to students' personal information raises concerns about data privacy and security for both LET (Learning, Education, and Training) users and providers. The lack of knowledge of the users about their rights and privacy leading to the lack of practice has resulted in illegal processing and piracy of personal information. Thus, this study focuses on modeling the ISO/IEC 29187-1:2013 standard which has been developed to support modeling generic international requirements for identifying and providing privacy protection of personal information throughout any kind of Information and Communication Technology(ICT)-based learning transaction where the individual has the role of an individual learner. This standard consists of the definition of key ISO concepts and rules that are used to govern the learning transaction involving LET users and providers. This article proposes an ontology framework as a knowledge framework for a compliance assessment service. Furthermore, the study elaborates on the initial implementation of the proposed ontology to establish APIs to create a compliance question-answering system related to LET using a faceted search for the stakeholders of LET. Through the ontology modeling of the ISO/IEC 29187-1 standard version 2, this study provides a clear path toward innovation, enabling the creation of complex validation systems with the introduction of several semantic web-based rules and axioms which not only enhance the standardization process but also serve as a platform for future developments and improvements.\\n\\n",
         "136",
         "This paper presents an ontology representing the ISO/IEC 29187 model and an application making use of it.  First of all, it is difficult to validate the work carried out building the ontologies without access to the full list of ontological requirements as well as the ontology code. Therefore, the first comment for authors is to make all resources related with the ontology available, if not openly, at least for reviewers. Regarding the ontology described, it is not clear whether it is a new ontology or what is the difference with reference 28 [the file is available only for registered users.]  The related work lacks some references such as ORDL vocabulary (https://www.w3.org/TR/odrl-model/) or DPV family (https://w3c.github.io/dpv/2.0/dpv/). A detailed comparison of existing ontologies and why they are not reused is not provided. Probably a consequence of using an ad-hoc methodology rather than existing ones based on reused as the Neon Methodology [1] or LOT [2]. Authors should follow best practices and reuse existing ontologies.  The ontology evaluation is based on Hemit reasoner, expert revies, and competency question evaluation. The reasoner-based evaluation gives positive results, however, it is not clear whether the evaluation was done only over the ontology or also instantiated data, as some logical consistency problems could be hidden if no data making them visible is added. For the other two evaluations, more details and data should be provided, who were the experts, knowledge about ontologies and the standard, grade of involvement with the ontology developers, overlap with authors' teams, etc. Is the SPARQL endpoint available somewhere? It is claimed that \"A SPARQL endpoint is a way to interact with linked data on the web and to obtain the results in a structured format,\" but no URL for the endpoint is provided. In the next section, it is mentioned that the fuseki server is hosted locally, shouldn’t it be avaiale online to be part of the web of data? In section 3.1 it is not clear if that refers to the ontology schema or the data. In addition, how is the data used for the system presented? How is that graph exploited by the application? It is not clear whether SWRL rules are created or could be created in the future. In section 3.4 the sentence \"For instance, any system built using the proposed ontology helps the LET Providers to interact and understand the concepts and the rules associated with any actions that they wish to pursue.\" should be proven and in conclusions section \"The use of ontology in compliance management not only helps SMEs understand their obligations but also enables them to take a proactive approach to compliance, reducing the risk of potential violations or penalties.\" [1] de Figueroa, MC Suárez, et al. NeOn methodology for building ontology networks: Specification, scheduling and reuse. Diss. Universidad Politécnica de Madrid, 2010. [2] Poveda-Villalón, María, et al. \"LOT: An industrial oriented ontology engineering framework.\" Engineering Applications of Artificial Intelligence 111 (2022): 104755.",
         "0.7487",
         "4",
         "7",
         "0.097561553030303",
         "0.072",
         "0.750064492225647",
         "37.4",
         "12.2",
         "12.32",
         "14.2",
         "12.0",
         "98",
         "0",
         "3",
         "1",
         "0",
         "2.0",
         "3.0",
         "6.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "2.0",
         "78.0",
         "78"
        ],
        [
         "45",
         "3732-4946",
         "Anonymous",
         "25/Sep/2024",
         "Minor Revision",
         "442",
         "Towards Explainable Automated Knolwedge Engineering with Human-in-the-loop",
         "Knowledge graphs are important in human-centered AI as they provide large labeled machine learning datasets, enhance retrieval-augmented generation, and generate explanations. However, knowledge graph construction has evolved into a complex, semi-automatic process that increasingly relies on black-box deep learning models and heterogeneous data sources to scale. The knowledge graph lifecycle is not transparent, accountability is limited, and there are no accounts of, or indeed methods to determine, how fair a knowledge graph is in downstream applications. Knowledge graphs are thus at odds with AI regulation, for instance, the EU's AI Act, and with ongoing efforts elsewhere in AI to audit and debias data and algorithms.\\n  This paper reports on work towards designing explainable (XAI) knowledge-graph construction pipelines with humans in-the-loop and discusses research topics in this area. Our work is based on a systematic literature review, in which we study tasks in knowledge graph construction that are often automated, as well as common methods to explain how they work and their outcomes, and an interview study with 13 people from the knowledge engineering community. To analyze the related literature, we introduce use cases, their related goals for XAI methods in knowledge graph construction, and the gaps in each use case. To gain an understanding of the role of explainable models in practical scenarios, and reveal the requirements for improving the current XAI methods, we designed interview questions covering broad transparency and explainability topics, along with example discussion sessions using examples from the literature review. From practical knowledge engineering experience, we collect requirements for designing XAI methods, propose design blueprints, and outline directions for future research: (i) tasks in knowledge graph construction where manual input remains essential and where AI assistance could be beneficial; (ii) integrating XAI methods into established knowledge engineering practices to improve stakeholder experience; (iii) the need to evaluate how effective explanations genuinely are making human-machine collaboration in knowledge graph construction more trustworthy; (iv) adapting explanations for multiple use cases; and (v) verifying and applying the XAI design blueprint in practical settings.",
         "56",
         "The paper addresses an interesting and timely topic, analyzing the role of XAI methods and techniques in KGC tasks with human intervention, while posing four RQs. The study is particularly relevant given the increasing automation and use of LLMs in the knowledge graph construction process, where common challenges must be addressed. To tackle this, the authors have designed a hybrid methodology that, mainly, combines a review of scientific literature and expert interviews. My comments are as follows: 1. Review concepts such as transparency and explainability. Post-hoc methods will not provide transparency to a machine learning model such as XGBoost or LLMs. 2. The use of terms is not sufficiently clear. I would suggest using \"models\" when referring to academic solutions that involve machine learning, even if they are not related to explainability solutions. When referring to techniques such as LIME, I would refer to them as XAI techniques. If the model inherently uses techniques to address explainability, I would also specify this. 3. When introducing an acronym, please explain it (KGC aka Knowledge Graph Construction). 4. Figure 1. Knowledge Graph Construction is not the same as Ontology Engineering, so this task must be separated in Fig.1 or omitted. 5. Regarding the organization of the paper:  5.1. In the introduction, I would not anticipate the conclusions of the work; instead, I would introduce the sections of the paper and their relationship to the RQs.  5.2. In this regard, the work done is very thorough. The methodology consists of two basic activities: the literature review and the interviews. Therefore, these activities are linked to addressing the different RQs. I felt a figure was missing that links these phases and activities to the corresponding RQ responses. In this sense, the context is lost during the presentation of the interview results regarding the objectives they aim to address.  Moreover, I suggest summarizing the conclusions obtained from the questionnaires. For example, a table with the main conclusions from the questionnaires, along with a brief explanation of how these responses impact the stated objectives. This way, the reading of the article could be easier.   5.3. I would consider moving some tables to appendices (for example, the interview design on page 11).  5.4. I would link the use cases to the specific task in the context of knowledge graph construction (table 6).  5.5 Section 4.1 should follow the structure of Figure 3, i.e., grouping XAI dimensions and tasks into sub-sections.  5.6. Section 4.4.2 is significant enough to be moved to a new Section 5. In this sense, your proposal can be viewed as a future guideline or methodology that leverages on many of the gaps found on the paper",
         "0.7628",
         "9",
         "0",
         "0.085195707070707",
         "0.4828",
         "0.9291675090789796",
         "48.09",
         "10.2",
         "10.86",
         "12.5",
         "10.6",
         "100",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "yes",
         "positive",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "4.0",
         "85.0",
         "85"
        ],
        [
         "46",
         "3732-4946",
         "Sitt Min Oo",
         "26/Sep/2024",
         "Major Revision",
         "1408",
         "Towards Explainable Automated Knolwedge Engineering with Human-in-the-loop",
         "Knowledge graphs are important in human-centered AI as they provide large labeled machine learning datasets, enhance retrieval-augmented generation, and generate explanations. However, knowledge graph construction has evolved into a complex, semi-automatic process that increasingly relies on black-box deep learning models and heterogeneous data sources to scale. The knowledge graph lifecycle is not transparent, accountability is limited, and there are no accounts of, or indeed methods to determine, how fair a knowledge graph is in downstream applications. Knowledge graphs are thus at odds with AI regulation, for instance, the EU's AI Act, and with ongoing efforts elsewhere in AI to audit and debias data and algorithms.\\n  This paper reports on work towards designing explainable (XAI) knowledge-graph construction pipelines with humans in-the-loop and discusses research topics in this area. Our work is based on a systematic literature review, in which we study tasks in knowledge graph construction that are often automated, as well as common methods to explain how they work and their outcomes, and an interview study with 13 people from the knowledge engineering community. To analyze the related literature, we introduce use cases, their related goals for XAI methods in knowledge graph construction, and the gaps in each use case. To gain an understanding of the role of explainable models in practical scenarios, and reveal the requirements for improving the current XAI methods, we designed interview questions covering broad transparency and explainability topics, along with example discussion sessions using examples from the literature review. From practical knowledge engineering experience, we collect requirements for designing XAI methods, propose design blueprints, and outline directions for future research: (i) tasks in knowledge graph construction where manual input remains essential and where AI assistance could be beneficial; (ii) integrating XAI methods into established knowledge engineering practices to improve stakeholder experience; (iii) the need to evaluate how effective explanations genuinely are making human-machine collaboration in knowledge graph construction more trustworthy; (iv) adapting explanations for multiple use cases; and (v) verifying and applying the XAI design blueprint in practical settings.",
         "57",
         "Decision: Major Revision ## High-level Review I would like to thank the authors for this submission. The paper summarizes existing XAI techniques and conducted a survey to find possible applications of XAI techniques in the domain of knowledge graph engineering. It is an easy to digest paper for introducing XAI to the knowledge engineering community. The following are the feedbacks that I have for this submission ## General feedback -   There is a previous work by the author which covers 1/3 of the content in     this paper     [https://doi.org/10.3233/FAIA230091](https://doi.org/10.3233/FAIA230091)     word for word. If this journal is an extension upon this previous paper,     there is a need for clear indication in the introduction section: i)     clarifying what this work contributes on top of the previous work (the     delta), ii) that this work is a clear extension of the previous work and not     a standalone work. -   In my opinion, this paper could be evaluated better as a **survey paper**     rather than a full research paper. A majority of this work focuses on     studying a significant amount of related literatures (specifically other     systematic review papers on XAI's) to analyze them, summarize/categorize     them, derive new findings from those existing works and conduct an interview     to verify the findings. Otherwise, if evaluated as a full research paper,     this paper, as is, lacks the originality of a full research paper since it     is not clearly stated and the results of the interview study are     insignificant to push new boundaries, it just made the requirements for XAI     methods in knowledge graph engineering clearer. Thus, I cannot recommend     accepting this paper in its current form as a full research paper. -   In the methodology section for literature review, the use cases are defined     without any motivation nor citations on why these particular sets of use     cases are used for analysis of the collected literatures. How are these use     case derived from the literature? Are there any literatures to support these     use cases in terms of AI usage in knowledge graph constructions?     There are also a few problems with the provided use cases. Although the     following two problems are handled in the interview study methodology, they     are not mentioned in the literature review methodology. Firstly, I do not     see any mentions of regulations compatibility as part of the use case     analysis even though it was a significant focus in the problem context     paragraph of the introduction section. Is it possible to also consider     regulations compatibility as part of the analysis of the literatures?     Secondly, there is no mention of data provenance considerations in the use     cases, which is a significant part of the problem context described in the     introduction section (this is also related to the previous point about     regulations compatibility). -   For the pool of interview participants, it would be interesting if there     were more participants from the industry (currently, there are only 3     industry participants) leading to the results of the interview study leaning     more to the academia. -   Explanation Design (Figure 6) and Section 4.4.2 only gave details on the     requirement analysis for **users**, **use cases**, and **representations of     explanations**. A major component on **regulations** was just briefly     mentioned in the paper and **not discussed in depth** leaving it as just a     background context for the introduction section of the paper. Similarly,     \"Evaluation\" step is also left out from the in-depth discussion in Section     4.4.2.     Regarding the XAI design blueprint step on \"Evaluation\", are there     recommendations for the selection process on the type of metrics/dimensions     when evaluating the XAI models? If this is mentioned somewhere in the     \"Findings\" sections, it would be nice to reiterate the recommendations when     describing the proposed XAI design blueprint. -   It would also be nice to indicate where/which part of the findings answers     the 4 research questions mentioned in the introduction section. -   A few citations lack either a DOI or a URL to the paper. It would be nice to     have URLs to follow the citations. ## Detailed Review ### Introduction **Page 2:** -   KG lifecycle --> what do you mean with KG lifecycle? The construction phase?     The usage of KG? The storage of KG? (Rereading it, it is fully introduced in     Background 2.4, but it would be nice to have a short sentence explaining     what it is in introduction) -   Most regulators take a risk-based approach to the use of AI ... are     compliant with the law (line 10-13) --> is there a citation to support these     two statements? -   Up-to-date comparative surveys... (line 20-21) --> this statement is very     disconnected from the rest of the paragraph on human-centric approach.     Remove it if it's not needed. -   ... we would like to advance the field of **explainable knowledge     engineering** (line 23-24) --> How? A sentence or two to show \"how\" would     strongly support this statement. If the \"how\" is development of     human-in-the-loop approaches for transparency and accountability, the     accompanying sentence needs to be rewritten/restructured for more clarity. ### Background Page 4: -   Reviews and surveys ... from **end-users** have also become increasingly     common (line 11-12) --> Looks very out of place since the paragraph is     mostly focused on XAI without involvement of end-users. Would also need     citations if you decide to keep this statement. Page 5: -   KGs are interacting with AI capabilities in complex ways (line 30) -->     How/What are the complex ways AI interacts with KG in the figure? From the     figure it looks pretty simple since the **input** for stage C, where I     assume most of the AI methods/models are, comes from stage D and as     **output**, it enriches the generated KG. Similarly, stage D also has a very     clear input/output direction. -   While KGs constructed using these approaches ... similar transparency     challenges as the algorithms it complements (line 45-47) --> Doesn't it mean     that crowdsourcing approach, in general, is a bad idea since it results in     biased, bad quality data while also suffering from transparency issues? This     sentence doesn't read well. ### Methodology Page 9: -   Table 3's tasks is not aligned with the tasks mentioned in Stage B of Figure     1). Is this intentional? If yes, it would be nice to also have another     column with relevant tasks that are aligned with the ones provided in the     figure for knowledge graph construction stage of the KG lifecycle. Page 9-10: -   3.2.1 Interview questions section (2 paragraphs)     The first paragraph leads the reader through the interview process     step-by-step until the end where risk concerns are addressed. It reads well     and has an _order_ to it. However, the second paragraphs came in totally     disconnected talking about the \"examples\" selection, which I believe is for     the topics **Use Cases**, **XAI Example Discussion**, and **Requirements**     of the interview.     I think it would read better to make the second paragraph a separate     subsection titled \"Examples and use cases selection from literature process\"     and link the sentences \"Inspired by \\[55\\], we designed ... concerns,     challenges, and requirements\" (Page 9 line 45-47) to that section. ### Findings #### SOTA study/review Page 12: -   a human-in-the-loop system that complies ... (line 41) --> compiles (do you     mean compile?) -   For instance, NERO uses... (line 51) --> ... NERO \\[++citation\\] (citation     missing) Page 13 -   SIRE employs... (line 20) --> SIRE \\[++citation\\] (citation) -   Beyond NERO, LogiRE ...(line 24) --> LogiRE \\[++citation\\] (citation) -   Diverging from text-based explanations, ProtoRE ...(line 24) --> ... ProtoRE     \\[++citation\\] (citation) -   RULESYNTH, proposed by Singh et al.... (line 35) --> citations reference     link? -   Last sentence on _Entity Resolution_: Additionally, ... attempt to add them     to make non-matching pairs more similar. It took me a while to read this     sentence and understand it. If it is about entity pairs which are     different/non-matching, but **contextually** similar due to the input     attributes, this sentence needs to be rewritten to provide the clarity. Page 14: -   which require feeding more data and extending training time. (line 31) -->     which require feeding more data **thus** extending training time (it reads     better this way?) *   The relationship between the complexity of functions and ... educate them     --> What kind of relationship? Complex functions + more freedom of     operations leads to lesser time required to educate the users? -   approxSemanticCrossE proposed explanation... target the link --> targetting? #### Use cases and capabilities Page 15: -   Among the use cases, three areas, ... (line 42-43) -> Which three areas? -   such as explainers designed for any knowledge... and some mode-specific     methods... -> such explainers designed for **both** any knowledge ... and ?",
         "0.7515",
         "0",
         "1",
         "0.1254279497098646",
         "0.8755",
         "0.8771349191665649",
         "46.67",
         "10.7",
         "10.59",
         "13.2",
         "12.7",
         "87",
         "0",
         "1",
         "0",
         "0",
         "3.0",
         "4.0",
         "2.0",
         "no",
         "neutral",
         "neutral",
         "minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "3.0",
         "60.0",
         "75"
        ],
        [
         "47",
         "3732-4946",
         "Irene Celino",
         "07/Nov/2024",
         "Minor Revision",
         "835",
         "Towards Explainable Automated Knolwedge Engineering with Human-in-the-loop",
         "Knowledge graphs are important in human-centered AI as they provide large labeled machine learning datasets, enhance retrieval-augmented generation, and generate explanations. However, knowledge graph construction has evolved into a complex, semi-automatic process that increasingly relies on black-box deep learning models and heterogeneous data sources to scale. The knowledge graph lifecycle is not transparent, accountability is limited, and there are no accounts of, or indeed methods to determine, how fair a knowledge graph is in downstream applications. Knowledge graphs are thus at odds with AI regulation, for instance, the EU's AI Act, and with ongoing efforts elsewhere in AI to audit and debias data and algorithms.\\n  This paper reports on work towards designing explainable (XAI) knowledge-graph construction pipelines with humans in-the-loop and discusses research topics in this area. Our work is based on a systematic literature review, in which we study tasks in knowledge graph construction that are often automated, as well as common methods to explain how they work and their outcomes, and an interview study with 13 people from the knowledge engineering community. To analyze the related literature, we introduce use cases, their related goals for XAI methods in knowledge graph construction, and the gaps in each use case. To gain an understanding of the role of explainable models in practical scenarios, and reveal the requirements for improving the current XAI methods, we designed interview questions covering broad transparency and explainability topics, along with example discussion sessions using examples from the literature review. From practical knowledge engineering experience, we collect requirements for designing XAI methods, propose design blueprints, and outline directions for future research: (i) tasks in knowledge graph construction where manual input remains essential and where AI assistance could be beneficial; (ii) integrating XAI methods into established knowledge engineering practices to improve stakeholder experience; (iii) the need to evaluate how effective explanations genuinely are making human-machine collaboration in knowledge graph construction more trustworthy; (iv) adapting explanations for multiple use cases; and (v) verifying and applying the XAI design blueprint in practical settings.",
         "99",
         "In general, the paper is a very good contribution and it is very welcome now, because the topic of explainability and human-in-the-loop AI are very timely in knowledge graph construction (KGC). With respect to the global evaluation criteria: - Originality is pretty high, as I'm not aware of any other work that specifically address this area at the intersection of explainability and KGC - Significance of results is also good: the analysis was carried out very professionally, both for the literature review and the interview study; the proposed \"blueprint\" is very interesting and valuable, even if it could be made stronger and more prominent in the paper, as detailed below - Quality of writing is quite high as well, as the paper is quite easy and pleasant to read; there are some possible improvements to the narrative and structure of the paper, as detailed below Some more detailed comments on different aspects of the paper are offered hereafter. Paper title: it seems to me that the paper mostly refer to KGC tasks, rather than knowledge engineering in general; I’d recommend to reflect this also in the title, putting “knowledge graph construction” instead of “knowledge engineering”. Concept of explanation: throughout the paper I felt the need to have a definition of what the authors mean by “explanation” and some more examples; while everybody has an intuitive understanding of what can constitute an explanation, I think that a definition and some more examples would highly improve the reader to correctly interpret the presented work. This definition can either be placed at the beginning to clarify the scope of the paper or be offered at the end as part of the blueprint to clarify how an explanation should look like. It would also be great to add an example of explanation for each of the KGC tasks, which are quite diverse and so may need different kinds of explanation. The authors correctly identify the paper by Miller (reference [50]) in their literature review, there are a couple of other papers that could be used to better scope the definition of explanation (especially in the dichotomy between something that explains what the machine does internally vs. something that is useful for the human user to understand if the machine result is relevant/correct): - Miller, Tim, Piers Howe, and Liz Sonenberg. \"Explainable AI: Beware of inmates running the asylum or: How I learnt to stop worrying and love the social and behavioural sciences.\" arXiv preprint arXiv:1712.00547 (2017). - Mittelstadt, Brent, Chris Russell, and Sandra Wachter. \"Explaining explanations in AI.\" Proceedings of the conference on fairness, accountability, and transparency. ACM, 2019. Literature review: the state-of-the-art analysis was performed very well in general, but Section 4.1 with the findings is a bit hard to read because, for sake of brevity, it is very condensed and refers to a lot of technical details that are (correctly) not fully explained. In order to improve this, the authors could either shorten the discussion even more or could add some examples here and there to clarify the different approaches. Use cases (e.g. in Table 2): I find the naming a bit odd, because usually a use case is an application scenario related to a specific domain/context, with the description of what are the needs/goals of a set of users/stakeholders. The “use cases” in this paper are more moments/steps of a ML lifecycle, so I’d suggest the authors to find a different naming. Also, the reader is left wondering whether those “use cases” are specific to KGC or generic; in the latter case, it would be very helpful to give some examples of explanations of those ML steps in the KGC context (for example, adding a column to Table 2). Blueprint: while it is a very relevant contribution of the paper and quite prominent in the abstract, it does not strongly emerge from the current narrative of the paper as a proposal but rather as a “surfacing” result of the analysis. I’d suggest the authors to devote a separate section to the blueprint (extracting and reshaping contents from Sections 4.3 and especially 4.4), by expanding and proposing more concretely how to apply/follow the blueprint: Figure 6 is not fully/precisely explained and a list of best practices (in the form of a checklist?) could represent a valuable additional contribution. Moreover, since human-in-the-loop is an important point of the paper motivation (and title!) that resulted to be only very limitedly covered in the specific KGC-related literature, I would welcome some further considerations/speculations about the applicability of human-in-the-loop best practices to KGC starting from the literature coming from different areas. Paper structure: while it follows the usual paper structure (methods first, findings after), I would recommend to have methods and findings on the literature review first (i.e. Sections 3.1 and 4.1) and then methods and finding on the interview study after (i.e. Sections 3.2 and 4.2). While the two analysis are clearly related, during my reading I found myself going back and forth in the paper to understand it better.",
         "0.7706",
         "4",
         "2",
         "0.2198080357142857",
         "0.2025",
         "0.9430014491081238",
         "36.73",
         "14.6",
         "14.46",
         "15.5",
         "16.0",
         "95",
         "0",
         "0",
         "0",
         "1",
         "4.0",
         "5.0",
         "3.0",
         "yes",
         "neutral",
         "polite",
         "Moderate",
         "somewhat specific",
         "4.0",
         "4.0",
         "3.0",
         "85.0",
         "85"
        ],
        [
         "48",
         "3732-4946",
         "Anonymous",
         "15/Dec/2024",
         "Accept",
         "298",
         "Towards Explainable Automated Knolwedge Engineering with Human-in-the-loop",
         "Knowledge graphs are important in human-centered AI as they provide large labeled machine learning datasets, enhance retrieval-augmented generation, and generate explanations. However, knowledge graph construction has evolved into a complex, semi-automatic process that increasingly relies on black-box deep learning models and heterogeneous data sources to scale. The knowledge graph lifecycle is not transparent, accountability is limited, and there are no accounts of, or indeed methods to determine, how fair a knowledge graph is in downstream applications. Knowledge graphs are thus at odds with AI regulation, for instance, the EU's AI Act, and with ongoing efforts elsewhere in AI to audit and debias data and algorithms.\\n  This paper reports on work towards designing explainable (XAI) knowledge-graph construction pipelines with humans in-the-loop and discusses research topics in this area. Our work is based on a systematic literature review, in which we study tasks in knowledge graph construction that are often automated, as well as common methods to explain how they work and their outcomes, and an interview study with 13 people from the knowledge engineering community. To analyze the related literature, we introduce use cases, their related goals for XAI methods in knowledge graph construction, and the gaps in each use case. To gain an understanding of the role of explainable models in practical scenarios, and reveal the requirements for improving the current XAI methods, we designed interview questions covering broad transparency and explainability topics, along with example discussion sessions using examples from the literature review. From practical knowledge engineering experience, we collect requirements for designing XAI methods, propose design blueprints, and outline directions for future research: (i) tasks in knowledge graph construction where manual input remains essential and where AI assistance could be beneficial; (ii) integrating XAI methods into established knowledge engineering practices to improve stakeholder experience; (iii) the need to evaluate how effective explanations genuinely are making human-machine collaboration in knowledge graph construction more trustworthy; (iv) adapting explanations for multiple use cases; and (v) verifying and applying the XAI design blueprint in practical settings.",
         "137",
         "The article provides an overview of methods and use cases for explainable automated knowledge engineering with human-in-the-loop. The authors performed a systematic literature review, analyzed use cases, designed and performed interviews and discuss directions for future research. The work is well motivated, the authors follow a sound methodology and clearly defined research questions. The presentation of the results is clearly structured and easy to follow. The findings are presented following a thorough overview of relevant background on expainable AI and the knowledge graph lifecycle. When it comes to the use cases covered, I in parts had the impresssion that the selection is skewed by what has been published/can be found in the literature rather than the use cases and methods that would really be relevant from the perspective of knowledge engineering/knowledge graph construction. For example, a significant part of the analyzed work is about link prediction – clearly a task that has recently received a lt of attention and is interesting from an automation and explainability perspective, but not really a core task in knowledge graph construction (not even according to the knowledge graph lifecycle shown in figure 1). In turn, interesting core knowledge engineering tasks are underrepresented. I acknowledge that redoing these central parts of the selection of covered work is not feasible; also the results are still meaningful, I am therefore not asking for a revision. What I believe could be revised is the taxonomy of expainable KGC in Figure 3: With the mutli-classification by KGC Tasks and XAI dimensions, every approach/reference is listed twice. I believe a presentation in a matrix (Tasks horizontally, XAI dimensions vertically, or the other way around) would be more digestable. Overall, the work is original, the findings interesting and relevant, the discussion of research directions meaningful.  I therefore recommend acceptance.",
         "0.7543",
         "0",
         "0",
         "0.2547101449275362",
         "0.0993",
         "0.9422681927680968",
         "31.41",
         "14.5",
         "15.05",
         "16.1",
         "16.5",
         "103",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "3.0",
         "4.0",
         "5.0",
         "92.0",
         "92"
        ],
        [
         "49",
         "3670-4884",
         "Anonymous",
         "21/Apr/2024",
         "Major Revision",
         "844",
         "Retrieval-Augmented Generation-based Relation Extraction",
         "Information Extraction (IE) is a transformative process that converts unstructured text data into a structured format by employing entity and relation extraction (RE) methodologies. The identification of the relation between a pair of entities plays a crucial role within this framework. Despite the existence of various techniques for relation extraction, their efficacy heavily relies on access to labeled data and substantial computational resources. In addressing these challenges, Large Language Models (LLMs) emerge as promising solutions; however, they might return hallucinating responses due to their own training data. To overcome these limitations, Retrieved-Augmented Generation-based Relation Extraction (RAG4RE) in this work is proposed, offering a pathway to enhance the performance of relation extraction tasks.\\n\\nThis work evaluated the effectiveness of our RAG4RE approach utilizing different LLMs. Through the utilization of established benchmarks, such as TACRED, TACREV,  Re-TACRED, and SemEval RE datasets, our aim is to comprehensively evaluate the efficacy of our RAG4RE approach. In particularly, we leverage prominent LLMs including Flan T5, Llama2, and Mistral in our investigation. The results of our study demonstrate that our RAG4RE approach surpasses performance of traditional RE approaches based solely on LLMs, particularly evident in the TACRED dataset and its variations. Furthermore, our approach exhibits remarkable performance compared to previous RE methodologies across both TACRED and TACREV datasets, underscoring its efficacy and potential for advancing RE tasks in natural language processing.",
         "38",
         "The paper describes a retrieval-augmented generation-based relation extraction approach. The core idea is to append a similar sentence from the same dataset (training subset) to the prompt of the LLM. It shows that this addition can improve the results in three out of four datasets with every LLM used in the study. The paper is well-written and easy to follow. Figures 5 and 6 are a bit redundant (tables with exact numbers exist), but they are still fine. The provided resources are a Github link, which is fine, and the repository is well structured. The description of the approach is lacking a few details: In Section 3, it would be better to describe directly that similar sentences are chosen from the corresponding dataset (more specifically, from the training set). In Section 3.1, it is unclear what result is returned if no specified relation is mentioned in the generated text. Maybe it is a good idea to introduce a new artificial relation (instead of using no_relation) to analyze later for how many examples the LLM is not able to produce a relation mentioned in the prompt. For the main approach, it is unclear whether any prompt engineering was executed or not. The output of a LLM can highly vary if the promt is changed. Thus if the authors already tried out different promts, it would be good to include them in the results. Because the reason why adding one similar sentence (without any ground truth) should improve the results by a large margin is not clear to me. Maybe adding any other text or changing the prompt would have similar or even better results. Thus, such an additional experiment would be useful and would make the results in the paper even stronger. Similarly, a comparison to a prompt with a few examples, including the result (and the format of the result), usually increases the chance of getting a defined relation as output. Min et al. [1] showed that even the correct label is not so important at all, but it also describes the way how the LLM should respond (which makes the result parsing step easier and more reliable). Even though the paper is about the RAG part, this is very similar and is worth a comparison. The LLM selection could also be improved by using larger LLMs, like Llama-13b or 70b, to see if larger models perform better (and what the influence of the choice of the model is). It is nice to see the authors present an error analysis, which already gives some insights, but a more in-depth analysis would be interesting. This could include e.g. an analysis on the level of relations (which relations are usually predicted correctly and which are usually wrong). When using an additional artificial relation type for the case when no relation could be extracted, then one can see if the result is just wrong or if the LLM is producing text (maybe describing the correct relation) that does not mention the relation itself. Thus, the micro average would not hide some of the crucial details. In Table 2, it would be nice to highlight the best values in each column (at least for F1 in SemEval). Table 4 and 5 could be also integrated in Table 2 to have a direct comparison between the related work and the proposed approach (without just selecting different proposed models combined in Table 4/5 e.g. best model for SemEval is not the best for TACRED). On page 8, line 17, the authors say that \"it is clear that our RAG4RE approach, consisting of the relevant example sentence about the query, has improved F1 scores\". This is not really clear to me. Why should the model predict better if a similar sentence is contained in the prompt? The selection of related work is good. A similar approach using T5 is presented by Han et al. [2] and could be included as well. Interestingly, the results for TACRED and TACREV are much better than all of the SOTA approaches (including [2] which achived 75.3 on TACRED and 84.0 on TACREV). Even tough other approaches e.g. [2] include more training data and finetune the models, the results are worse. If the author has any insights into why this is the case, it would be good to include them in the paper as well (is it just based on the larger model by using T5XL or based on the prompt or the selected sentence by the RAG approach?). Furthermore, a discussion of why the model is better by a large margin on TACRED and TACREV but worse on Re-TACRED (in comparison to related work) is necessary and would give more insights into the dataset and the proposed RAG model (similarly with SemEval). Thus, I'm looking forward to the next revision of the paper to see some more analysis and good justifications for why adding a similar sentence is getting better results than the SOTA approaches. [1] Rethinking the Role of Demonstrations: What Makes In-Context Learning Work? https://arxiv.org/pdf/2202.12837.pdf [2] Generative Prompt Tuning for Relation Classification https://arxiv.org/pdf/2210.12435v1.pdf",
         "0.7586",
         "2",
         "8",
         "0.1659230175509244",
         "0.0556",
         "0.8716182708740234",
         "52.39",
         "10.6",
         "10.7",
         "12.3",
         "10.6",
         "95",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "4.0",
         "2.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "3",
         "4.0",
         "4.0",
         "4.0",
         "82.0",
         "82"
        ]
       ],
       "shape": {
        "columns": 38,
        "rows": 1805
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_suggestion</th>\n",
       "      <th>length_words</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>days_to_submit</th>\n",
       "      <th>review_text</th>\n",
       "      <th>mattr</th>\n",
       "      <th>...</th>\n",
       "      <th>llm_citation_usage</th>\n",
       "      <th>llm_sentiment_polarity</th>\n",
       "      <th>llm_politeness</th>\n",
       "      <th>llm_hedging</th>\n",
       "      <th>llm_specificity</th>\n",
       "      <th>llm_domain_terms</th>\n",
       "      <th>llm_relevance_alignment</th>\n",
       "      <th>llm_readability</th>\n",
       "      <th>llm_overall_quality</th>\n",
       "      <th>llm_overall_score_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3771-4985</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>02/Dec/2024</td>\n",
       "      <td>Accept</td>\n",
       "      <td>19</td>\n",
       "      <td>The ANthropological Notation Ontology (ANNO): ...</td>\n",
       "      <td>The Anthropological Notation Ontology (ANNO) a...</td>\n",
       "      <td>56</td>\n",
       "      <td>After the revision, this paper looks better. I...</td>\n",
       "      <td>0.8947</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3771-4985</td>\n",
       "      <td>Yuming Shen</td>\n",
       "      <td>16/Dec/2024</td>\n",
       "      <td>Accept</td>\n",
       "      <td>24</td>\n",
       "      <td>The ANthropological Notation Ontology (ANNO): ...</td>\n",
       "      <td>The Anthropological Notation Ontology (ANNO) a...</td>\n",
       "      <td>70</td>\n",
       "      <td>The revised manuscript has been reviewed thoro...</td>\n",
       "      <td>0.9167</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3763-4977</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>08/Oct/2024</td>\n",
       "      <td>Accept</td>\n",
       "      <td>18</td>\n",
       "      <td>Enhancing Ontology Matching: Lexically and Syn...</td>\n",
       "      <td>Ontology matching systems commonly leverage si...</td>\n",
       "      <td>9</td>\n",
       "      <td>After reviewing the updated manuscript, I find...</td>\n",
       "      <td>0.8333</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3763-4977</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>09/Jan/2025</td>\n",
       "      <td>Accept</td>\n",
       "      <td>107</td>\n",
       "      <td>Enhancing Ontology Matching: Lexically and Syn...</td>\n",
       "      <td>Ontology matching systems commonly leverage si...</td>\n",
       "      <td>102</td>\n",
       "      <td>In my initial review, I had concerns around \"(...</td>\n",
       "      <td>0.7149</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>very specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3754-4968</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>14/Dec/2024</td>\n",
       "      <td>Reject</td>\n",
       "      <td>493</td>\n",
       "      <td>Nordic Spatial Humanities: Ups and Downs in LO...</td>\n",
       "      <td>The article constitutes a report of a LOD appl...</td>\n",
       "      <td>103</td>\n",
       "      <td>The paper discusses the results of two worksho...</td>\n",
       "      <td>0.7886</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1800</th>\n",
       "      <td>431-1572</td>\n",
       "      <td>Aidan Hogan</td>\n",
       "      <td>17/Jan/2013</td>\n",
       "      <td>Accept</td>\n",
       "      <td>69</td>\n",
       "      <td>Linked European Television Heritage</td>\n",
       "      <td>The EUscreen project represents the European t...</td>\n",
       "      <td>2</td>\n",
       "      <td>Thanks to the authors for all of their careful...</td>\n",
       "      <td>0.8029</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>No Hedging</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801</th>\n",
       "      <td>431-1572</td>\n",
       "      <td>Emanuele Della Valle</td>\n",
       "      <td>30/Jan/2013</td>\n",
       "      <td>Accept</td>\n",
       "      <td>10</td>\n",
       "      <td>Linked European Television Heritage</td>\n",
       "      <td>The EUscreen project represents the European t...</td>\n",
       "      <td>15</td>\n",
       "      <td>I checked the comments. The paper is ready for...</td>\n",
       "      <td>0.9000</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1802</th>\n",
       "      <td>392-1487</td>\n",
       "      <td>Jiewen Huang</td>\n",
       "      <td>25/Dec/2012</td>\n",
       "      <td>Major Revision</td>\n",
       "      <td>473</td>\n",
       "      <td>A Scalable RDF Data Processing Framework based...</td>\n",
       "      <td>In order to effectively handle the growing amo...</td>\n",
       "      <td>36</td>\n",
       "      <td>This paper proposes a salable RDF data managem...</td>\n",
       "      <td>0.7967</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>392-1487</td>\n",
       "      <td>Marcin Wylot</td>\n",
       "      <td>05/Jan/2013</td>\n",
       "      <td>Reject</td>\n",
       "      <td>643</td>\n",
       "      <td>A Scalable RDF Data Processing Framework based...</td>\n",
       "      <td>In order to effectively handle the growing amo...</td>\n",
       "      <td>47</td>\n",
       "      <td>In the paper the authors want to tackle with R...</td>\n",
       "      <td>0.7704</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1804</th>\n",
       "      <td>392-1487</td>\n",
       "      <td>Haofen Wang</td>\n",
       "      <td>31/Jan/2013</td>\n",
       "      <td>Reject</td>\n",
       "      <td>594</td>\n",
       "      <td>A Scalable RDF Data Processing Framework based...</td>\n",
       "      <td>In order to effectively handle the growing amo...</td>\n",
       "      <td>73</td>\n",
       "      <td>In this paper, authors address an interesting ...</td>\n",
       "      <td>0.8007</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>No Hedging</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1805 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       paper_id              reviewer  review_date review_suggestion  \\\n",
       "0     3771-4985             Anonymous  02/Dec/2024            Accept   \n",
       "1     3771-4985           Yuming Shen  16/Dec/2024            Accept   \n",
       "2     3763-4977             Anonymous  08/Oct/2024            Accept   \n",
       "3     3763-4977             Anonymous  09/Jan/2025            Accept   \n",
       "4     3754-4968             Anonymous  14/Dec/2024            Reject   \n",
       "...         ...                   ...          ...               ...   \n",
       "1800   431-1572           Aidan Hogan  17/Jan/2013            Accept   \n",
       "1801   431-1572  Emanuele Della Valle  30/Jan/2013            Accept   \n",
       "1802   392-1487          Jiewen Huang  25/Dec/2012    Major Revision   \n",
       "1803   392-1487          Marcin Wylot  05/Jan/2013            Reject   \n",
       "1804   392-1487           Haofen Wang  31/Jan/2013            Reject   \n",
       "\n",
       "      length_words                                              title  \\\n",
       "0               19  The ANthropological Notation Ontology (ANNO): ...   \n",
       "1               24  The ANthropological Notation Ontology (ANNO): ...   \n",
       "2               18  Enhancing Ontology Matching: Lexically and Syn...   \n",
       "3              107  Enhancing Ontology Matching: Lexically and Syn...   \n",
       "4              493  Nordic Spatial Humanities: Ups and Downs in LO...   \n",
       "...            ...                                                ...   \n",
       "1800            69                Linked European Television Heritage   \n",
       "1801            10                Linked European Television Heritage   \n",
       "1802           473  A Scalable RDF Data Processing Framework based...   \n",
       "1803           643  A Scalable RDF Data Processing Framework based...   \n",
       "1804           594  A Scalable RDF Data Processing Framework based...   \n",
       "\n",
       "                                               abstract  days_to_submit  \\\n",
       "0     The Anthropological Notation Ontology (ANNO) a...              56   \n",
       "1     The Anthropological Notation Ontology (ANNO) a...              70   \n",
       "2     Ontology matching systems commonly leverage si...               9   \n",
       "3     Ontology matching systems commonly leverage si...             102   \n",
       "4     The article constitutes a report of a LOD appl...             103   \n",
       "...                                                 ...             ...   \n",
       "1800  The EUscreen project represents the European t...               2   \n",
       "1801  The EUscreen project represents the European t...              15   \n",
       "1802  In order to effectively handle the growing amo...              36   \n",
       "1803  In order to effectively handle the growing amo...              47   \n",
       "1804  In order to effectively handle the growing amo...              73   \n",
       "\n",
       "                                            review_text   mattr  ...  \\\n",
       "0     After the revision, this paper looks better. I...  0.8947  ...   \n",
       "1     The revised manuscript has been reviewed thoro...  0.9167  ...   \n",
       "2     After reviewing the updated manuscript, I find...  0.8333  ...   \n",
       "3     In my initial review, I had concerns around \"(...  0.7149  ...   \n",
       "4     The paper discusses the results of two worksho...  0.7886  ...   \n",
       "...                                                 ...     ...  ...   \n",
       "1800  Thanks to the authors for all of their careful...  0.8029  ...   \n",
       "1801  I checked the comments. The paper is ready for...  0.9000  ...   \n",
       "1802  This paper proposes a salable RDF data managem...  0.7967  ...   \n",
       "1803  In the paper the authors want to tackle with R...  0.7704  ...   \n",
       "1804  In this paper, authors address an interesting ...  0.8007  ...   \n",
       "\n",
       "      llm_citation_usage  llm_sentiment_polarity  llm_politeness  llm_hedging  \\\n",
       "0                    yes                 neutral         neutral      Minimal   \n",
       "1                    yes                 neutral         neutral      Minimal   \n",
       "2                    yes                positive         neutral      Minimal   \n",
       "3                    yes                positive          polite      Minimal   \n",
       "4                     no                 neutral         neutral     Moderate   \n",
       "...                  ...                     ...             ...          ...   \n",
       "1800                True                 neutral          polite   No Hedging   \n",
       "1801                 yes                 neutral         neutral      Minimal   \n",
       "1802                  no                 neutral         neutral     Moderate   \n",
       "1803               False                 neutral         neutral     Moderate   \n",
       "1804               False                 neutral         neutral   No Hedging   \n",
       "\n",
       "        llm_specificity  llm_domain_terms  llm_relevance_alignment  \\\n",
       "0     somewhat specific               3.0                      4.0   \n",
       "1     somewhat specific               3.0                      4.0   \n",
       "2     somewhat specific               4.0                      5.0   \n",
       "3         very specific               4.0                      5.0   \n",
       "4     somewhat specific               3.0                      4.0   \n",
       "...                 ...               ...                      ...   \n",
       "1800  somewhat specific               4.0                      5.0   \n",
       "1801  somewhat specific               5.0                      4.0   \n",
       "1802  somewhat specific               4.0                      3.0   \n",
       "1803  somewhat specific               4.0                      3.0   \n",
       "1804  somewhat specific               2.0                      3.0   \n",
       "\n",
       "      llm_readability  llm_overall_quality  llm_overall_score_100  \n",
       "0                 3.0                 70.0                     75  \n",
       "1                 5.0                 95.0                     95  \n",
       "2                 3.0                 90.0                     92  \n",
       "3                 5.0                 95.0                     96  \n",
       "4                 2.0                 42.0                     58  \n",
       "...               ...                  ...                    ...  \n",
       "1800              3.0                 90.0                     90  \n",
       "1801              3.0                 80.0                     85  \n",
       "1802              4.0                 80.0                     82  \n",
       "1803              4.0                 60.0                     70  \n",
       "1804              4.0                 40.0                     40  \n",
       "\n",
       "[1805 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Read the two CSV files\n",
    "file1 = pd.read_csv('Soroush/processed/f1000.csv')\n",
    "file2 = pd.read_csv('Soroush/processed/semanticweb.csv')\n",
    "\n",
    "# Display the dataframes\n",
    "display(file1)\n",
    "display(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_suggestion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "days_to_submit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "llm_llamaV3-2_length_effort",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_lexical_diversity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_questions_raised",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_citation_usage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_llamaV3-2_sentiment_polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_llamaV3-2_politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_llamaV3-2_hedging",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_llamaV3-2_specificity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_llamaV3-2_domain_terms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_relevance_alignment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_readability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_overall_quality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_llamaV3-2_overall_score_100",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "5e1a9591-02db-4ee7-9737-97a83082fecb",
       "rows": [
        [
         "16",
         "shaimaa Mohamed Amin",
         "29 Jul 2024",
         "Approved With Reservations",
         "1557",
         "Estimating the efficacy of Newborn-Communication, Health, Feeding and Swallowing Education Program (N-CHFSEP) for primiparous mothers",
         "Background Primiparous mothers face diverse challenges during pregnancy and post-childbirth. There is a lack of comprehensive educational programs for primiparous mothers on maternal functioning and newborn care. This study aimed to explore the efficacy of a developed educational program on the attitude of primiparous mothers towards newborn communication, general health, feeding and swallowing. The objectives were (1) to develop an attitude questionnaire (AQ), a parent education program, and a feedback questionnaire (FQ); and (2) to estimate the efficacy of the education program pre- and post-delivery.  Methods Ninety-eight primiparous mothers without any obstetric history, proficient in English or Kannada, and delivering healthy newborns were recruited for the study. Phase 1 involved the development and validation of AQ, the parent education program [Newborn Communication, Health, Feeding and Swallowing Education Program (N-CHFSEP)], and FQ; while Phase 2 comprised of administering them on the mothers. Both quantitative (descriptive statistics, paired t-test, and chi-square test) and qualitative analysis were done on the parameters of interest.  Results The results of the study demonstrated a notable increase in the number of mothers (not all) reporting heightened confidence levels following receiving the N-CHFSEP (which was observed in all the domains). This observed change (pre and post) was statistically significant as per paired t-test analysis (p <0.05) indicating a significant increase in confidence levels post-N-CHFSEP intervention, as well as recognizing warning signs related to the same. Sociodemographic factors such as age, education, occupation, and family type were reported to have a significant effect (p <0.05) on maternal confidence levels before and after N-CHFSEP administration. Feedback from participants highlighted the effectiveness of the program in enhancing knowledge and awareness, while also suggesting areas for improvement.  Conclusions This study demonstrates the effectiveness of N-CHFSEP in enhancing primiparous mothers' confidence in newborn care, thereby improving maternal and infant health.",
         "20",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Dear [editor ], I hope this message finds you well. I wanted to extend my sincere gratitude to you for sending me the article for review. I truly appreciate the opportunity to contribute to the process and offer my insights. I've gone through the article and I have some constructive feedback that I believe could enhance the overall quality and impact of the piece. Title: Your research title is clear and informative, but it can be made more concise and engaging. Here are a few suggestions to refine and enhance the title: Evaluating the Efficacy of the Newborn Communication, Health, Feeding, and Swallowing Education Program (N-CHFSEP) for First-Time Mothers  Assessing the Impact of the N-CHFSEP on Newborn Care Among Primiparous Mothers Effectiveness of the N-CHFSEP in Enhancing Newborn Care Skills for Primiparous Mothers  Abstract  Background: The background section effectively outlines the problem that primiparous mothers face challenges during pregnancy and post-childbirth. However, the statement \"There is a lack of comprehensive educational programs for primiparous mothers on maternal functioning and newborn care\" could benefit from citation of existing literature to support this claim. Additionally, specifying what aspects of \"maternal functioning\" are included could provide clarity. Objectives: The objectives are clearly stated and logically divided into two main goals: development of tools (attitude questionnaire, education program, feedback questionnaire) and evaluation of the program's efficacy. This separation is clear and helpful for readers to understand the study’s aims. Methods: The methods section is concise but detailed enough to understand the study design. However, it could be improved by specifying the inclusion criteria more precisely (e.g., \"primiparous mothers without any obstetric history\" could specify what kind of history excludes participants). Additionally, mentioning the duration of the study and the specific content covered in the N-CHFSEP could provide more context. Results: The results section effectively communicates the main findings, highlighting the statistically significant increase in maternal confidence levels post-intervention. The use of both quantitative and qualitative analysis is a strength. However, the phrase \"a notable increase in the number of mothers (not all)\" is vague and could be more precise. For example, specifying the percentage of mothers who reported increased confidence would provide more concrete data. Additionally, discussing the specific sociodemographic factors in more detail would enhance understanding of their impact. Conclusions: The conclusions succinctly summarize the study's implications, emphasizing the program's effectiveness in enhancing maternal confidence. However, it would be beneficial to briefly mention any limitations of the study or suggest directions for future research to provide a more balanced view. Keywords: The keywords are relevant and cover the main topics of the study. However, adding keywords like \"confidence,\" \"maternal education,\" and \"program evaluation\" might improve the searchability of the study.  Introduction: The introduction provides a comprehensive overview of the challenges faced by primiparous mothers and underscores the importance of educational programs to support them. Here are some suggestions to refine and strengthen the introduction:  Clarity and Focus: The introduction covers a broad range of issues and studies, which can make it somewhat dense. Consider focusing more sharply on the main problem and the gap your study aims to fill. For example: Highlight the specific challenges primiparous mothers face and how these impact newborn care. Clearly state the need for a comprehensive educational program that addresses these challenges.  Structure: First Paragraph: Introduce the general context of pregnancy and childbirth, emphasizing the unique challenges for primiparous mothers. Second Paragraph: Discuss the importance of maternal confidence, knowledge, and attitudes, and their impact on newborn care. Third Paragraph: Present the specific gaps in current educational programs, citing key studies that demonstrate the need for comprehensive support. Fourth Paragraph: Highlight existing educational programs and their limitations, particularly focusing on the need for a holistic approach. Fifth Paragraph: Conclude by summarizing the need for your study and its objectives.  Citations and Evidence: Ensure all claims are supported by citations. For example, when discussing the impact of maternal confidence or the effectiveness of various programs, provide specific references. Use consistent and current references to strengthen the credibility of your argument.  Flow and Readability: Improve readability by breaking long sentences into shorter, more concise ones. Use transition phrases to connect ideas and ensure a smooth flow from one paragraph to the next.  Specific Suggestions: Opening Sentence: \"Pregnancy and childbirth represent significant milestones in a woman's life, permanently altering her identity and way of living in a continuous and dynamic manner.\" Second Sentence: \"Primiparous mothers (first-time mothers) face a wide range of emotions including joy, excitement, and anxiety, alongside overwhelming and stressful experiences such as routine newborn care, breastfeeding difficulties, lack of sleep, and physically taxing household duties.\" Importance of Maternal Confidence: \"Reduced levels of confidence in primiparous mothers compared to multiparous mothers negatively impact their ability to provide infant care.\" Developmental Milestones: \"Effective identification of developmental milestones by caregivers facilitates early interventions, improving overall health outcomes.\" Educational Programs: \"Although numerous educational programs exist, there is a lack of a holistic approach that comprehensively addresses newborn communication, feeding, swallowing, and general health.\"  Conclusion of Introduction: Summarize Gaps and Objectives: \"Despite the availability of various educational initiatives, there is a noticeable gap in comprehensive programs that address all critical areas of newborn development. This study aims to develop and validate a comprehensive educational program and assess its efficacy in enhancing maternal confidence and knowledge among primiparous mothers.\"  Methods  Study Design and Ethics: Clarity: This section is clear and provides essential information about the study design and ethical approvals. Detail: Including the registration number and ethical approval details adds credibility. Mentioning the adherence to the CONSORT checklist and Declaration of Helsinki is crucial. Participants: Clarity: The paragraph provides detailed demographic data which is good for understanding the sample population. Structure: Breaking this into two paragraphs might enhance readability - one for sample size calculation and the other for demographic details. Detail: Including the sample size formula and demographic breakdown is thorough and helpful. Inclusion and Exclusion Criteria: Clarity: The criteria are clearly listed, which helps in understanding the participant selection process. Structure: The criteria are clearly separated into inclusion and exclusion, making it easy to follow. Detail: Including the proficiency in English or Kannada is important for understanding participant communication abilities. Procedure: The present study was conducted in 2 phases. Phase 1 included the development of an (a) attitude questionnaire, (b) parent education program, and (3) feedback questionnaire; while Phase 2 included the administration of the questionnaires and the education program on the participants, followed by data analysis of the retrieved data. Clarity: The procedure is outlined, indicating a clear structure to the study. Detail: Describing the phases helps in understanding the study's flow. Development of Tools: a) Attitude questionnaire (AQ): Clarity: The development process of the AQ is well-explained, detailing the domains and types of questions. Detail: Including specific item numbers and their domains adds precision. b) Parent Education Program : Clarity: The development process of the N-CHFSEP is described in detail. Detail: Mentioning the consultation with experts adds credibility. c) Feedback Questionnaire (FQ): Clarity: The development process of the FQ is clear and detailed. Detail: Including the types of questions adds precision. Discussion  The discussion section of this study provides a comprehensive analysis of the impact of the Newborn Communication, Hearing, Feeding, and Swallowing Education Program (N-CHFSEP) on the confidence levels of primiparous mothers, emphasizing key areas such as communication, feeding-swallowing skills, and newborn health. While the study effectively highlights the statistical significance of increased confidence post-intervention and relates these findings to previous research, it could benefit from a more concise presentation. The detailed breakdown of influencing variables (age, education, family type, and occupation) is insightful, yet the narrative occasionally becomes repetitive, potentially diluting the focus. Additionally, the discussion extensively references existing literature to contextualize findings, which is commendable, but a more balanced approach with critical reflections on the study's limitations, such as the lack of a control group and the short-term assessment of the intervention's impact, would enhance the overall analysis. The feedback from mothers and the suggestion for practical demonstrations underscore the need for a hands-on approach in educational programs, a point that could be more prominently integrated into the discussion. Overall, while the discussion is thorough and well-supported by data, a more streamlined and critically reflective narrative would strengthen its impact Please address conclusion,  limitations & implications  of the study  Once again, thank you for entrusting me with this task. I look forward to our continued collaboration and to seeing the final version of the article. Warm regards, Shaimaa Mohamed Amin  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? No",
         "0.7872",
         "1",
         "0",
         "0.1835304054054053",
         "0.9542",
         "0.9364086389541626",
         "17.44",
         "15.8",
         "13.86",
         "16.9",
         "17.6",
         "102",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "4.0",
         "3.0",
         "True",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "4.0",
         "3.0",
         "83.0",
         "83"
        ],
        [
         "17",
         "Amogh Verma",
         "03 Sep 2024",
         "Approved With Reservations",
         "653",
         "Estimating the efficacy of Newborn-Communication, Health, Feeding and Swallowing Education Program (N-CHFSEP) for primiparous mothers",
         "Background Primiparous mothers face diverse challenges during pregnancy and post-childbirth. There is a lack of comprehensive educational programs for primiparous mothers on maternal functioning and newborn care. This study aimed to explore the efficacy of a developed educational program on the attitude of primiparous mothers towards newborn communication, general health, feeding and swallowing. The objectives were (1) to develop an attitude questionnaire (AQ), a parent education program, and a feedback questionnaire (FQ); and (2) to estimate the efficacy of the education program pre- and post-delivery.  Methods Ninety-eight primiparous mothers without any obstetric history, proficient in English or Kannada, and delivering healthy newborns were recruited for the study. Phase 1 involved the development and validation of AQ, the parent education program [Newborn Communication, Health, Feeding and Swallowing Education Program (N-CHFSEP)], and FQ; while Phase 2 comprised of administering them on the mothers. Both quantitative (descriptive statistics, paired t-test, and chi-square test) and qualitative analysis were done on the parameters of interest.  Results The results of the study demonstrated a notable increase in the number of mothers (not all) reporting heightened confidence levels following receiving the N-CHFSEP (which was observed in all the domains). This observed change (pre and post) was statistically significant as per paired t-test analysis (p <0.05) indicating a significant increase in confidence levels post-N-CHFSEP intervention, as well as recognizing warning signs related to the same. Sociodemographic factors such as age, education, occupation, and family type were reported to have a significant effect (p <0.05) on maternal confidence levels before and after N-CHFSEP administration. Feedback from participants highlighted the effectiveness of the program in enhancing knowledge and awareness, while also suggesting areas for improvement.  Conclusions This study demonstrates the effectiveness of N-CHFSEP in enhancing primiparous mothers' confidence in newborn care, thereby improving maternal and infant health.",
         "56",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study evaluates the effectiveness of a tailored educational program, the Newborn-Communication, Health, Feeding, and Swallowing Education Program (N-CHFSEP), in enhancing the confidence of primiparous mothers in newborn care. The research addresses a significant gap in maternal education, particularly in the context of first-time mothers who face unique challenges in caring for their newborns. Strengths: Relevance and Impact: The study addresses a highly relevant topic in maternal and child health. The focus on primiparous mothers and the development of a comprehensive educational program is commendable, particularly in regions where such resources may be limited. Methodological Rigor: The development and validation of the study tools (Attitude Questionnaire, Feedback Questionnaire, and N-CHFSEP) are well-detailed and supported by content validation from experts in pediatrics and speech-language pathology. Statistically Significant Findings: The study presents statistically significant improvements in maternal confidence levels across communication, feeding-swallowing, and general health domains, which suggests that the N-CHFSEP is an effective intervention. Practical Implications: The study provides valuable insights for healthcare providers and policymakers, highlighting the importance of structured educational programs for new mothers. Weaknesses: Study Design: The absence of a control group limits the ability to attribute the observed improvements in confidence levels solely to the N-CHFSEP intervention. This is a significant limitation that should be addressed in future studies. The single-arm pre-post study design, while valid for exploratory research, does not provide the level of rigor necessary to establish causality. Generalizability: The sample is limited to primiparous mothers in a specific region, and the exclusion of multiparous mothers may limit the generalizability of the findings to the broader population. Expanding the sample to include a more diverse demographic would strengthen the study. Short-term Assessment: The study measures outcomes immediately post-intervention, leaving questions about the long-term retention of knowledge and skills. A follow-up assessment at 6 months or beyond would provide a more comprehensive understanding of the program's sustained impact. Limited Qualitative Data: While quantitative data is well-represented, the qualitative feedback from participants is not fully explored. Incorporating more qualitative insights could provide a richer context to the statistical findings and highlight areas for improvement in the program. Recommendations for Publication: Revisions: I recommend that the authors address the limitations in their discussion section by clearly acknowledging the absence of a control group and the implications for the study's findings. Additionally, suggestions for future research should be included, particularly regarding long-term follow-up and expanding the sample population. Potential for Improvement: The study would benefit from a more in-depth analysis of the qualitative data collected, as this could provide valuable insights into the participants' experiences and the practical application of the program. Additionally, including recommendations for enhancing the program, such as integrating practical demonstrations, would be beneficial. Suitability for Indexing: Despite its limitations, the study contributes valuable insights into maternal education and has practical implications for improving maternal and infant health. I believe the manuscript is suitable for indexing with revisions. However, the authors should emphasize that this is a preliminary study, laying the groundwork for more rigorous future research.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7955",
         "1",
         "0",
         "0.2008718133718133",
         "0.2025",
         "0.920393705368042",
         "8.47",
         "17.1",
         "15.88",
         "17.2",
         "18.5",
         "88",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "4.0",
         "2.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "84.0",
         "84.0"
        ],
        [
         "60",
         "Selmy Awad",
         "28 Dec 2024",
         "Approved With Reservations",
         "174",
         "Case Report: A giant ruptured splenic hydatic cyst in a patient with a complete situs inversus: Diagnostic challenge and intra-operative difficulties",
         "The splenic localization of hydatid cysts is extremely rare. A 50-year-old obese female who consults with a painful and febrile syndrome of the right hypochondrium. Abdominal ultrasound and a CT scan computed tomography revealed a complete situs inversus, a mass of the right hypochondrium measuring 152 mm with membrane detachment, and infiltration of the surrounding fat, evoking a type II complicated splenic hydatic cyst. The patient was operated on in an emergency via midline laparotomy. Exploration revealed situs inversus, an angiant cyst of the spleen. Exposition of the splenic pedicle is difficult. The samples were then infected. Total splenectomy was performed. The postoperative period was unproblematic, and the patient was discharged with antibiotic and antiparasitic treatment and habitual vaccination.",
         "24",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Thanks for the novel case as an incidence and location. many typos and grammar mistakes are abundant. What is the role of medical treatment in preoperative preparation and post-operative regimens? please follow the standards for writing case reports  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Yes  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? No  Is the case presented with sufficient detail to be useful for other practitioners? Partly",
         "0.7693",
         "1",
         "0",
         "0.1114035087719298",
         "0.6587",
         "0.589046061038971",
         "23.97",
         "15.3",
         "17.92",
         "16.5",
         "16.9",
         "97",
         "0",
         "1",
         "0",
         "0",
         "3.0",
         "4.0",
         "2.0",
         "False",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "3.0",
         "60.0",
         "60"
        ],
        [
         "61",
         "Silvio Buscemi",
         "07 Jan 2025",
         "Approved",
         "280",
         "Case Report: A giant ruptured splenic hydatic cyst in a patient with a complete situs inversus: Diagnostic challenge and intra-operative difficulties",
         "The splenic localization of hydatid cysts is extremely rare. A 50-year-old obese female who consults with a painful and febrile syndrome of the right hypochondrium. Abdominal ultrasound and a CT scan computed tomography revealed a complete situs inversus, a mass of the right hypochondrium measuring 152 mm with membrane detachment, and infiltration of the surrounding fat, evoking a type II complicated splenic hydatic cyst. The patient was operated on in an emergency via midline laparotomy. Exploration revealed situs inversus, an angiant cyst of the spleen. Exposition of the splenic pedicle is difficult. The samples were then infected. Total splenectomy was performed. The postoperative period was unproblematic, and the patient was discharged with antibiotic and antiparasitic treatment and habitual vaccination.",
         "34",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The case described is very interesting and well-written. I have some general considerations for you below. It is appropriate to discuss cystic echinococcosis in female with obesity. Given the unique nature of this case with situs inversus, including descriptive arrows in the CT images is essential and reassuring. This will provide clear visual guidance for the reader, enhancing their confidence in the case report. Please elaborate on the antiparasitic treatment used, including the specific regimen followed (it is important to continue the treatment after the cyst spontaneously ruptures to avoid possible dissemination). It is essential to document the changes in antibody titers and blood chemistry tests following surgical treatment and therapy (it would be appropriate to document how in the article, that could also be mentioned: Ref 1). This will not only inform the reader but also enhance their knowledge about the progression of the disease.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Partly  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Partly  Is the case presented with sufficient detail to be useful for other practitioners? Partly",
         "0.7857",
         "1",
         "0",
         "0.1403645833333333",
         "0.3225",
         "0.7798862457275391",
         "24.27",
         "15.2",
         "16.6",
         "16.6",
         "16.3",
         "94",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "92.0",
         "92"
        ],
        [
         "420",
         "Nitin Liladhar Rane",
         "17 Oct 2024",
         "Approved",
         "239",
         "What we know and what should we know about the future of blockchain in finance",
         "Background In response to the transformative impact of blockchain technology on economic and financial landscapes, there is a critical need for a review study that analyses the knowledge landscape from diverse perspectives.  Methods This research VOSviewer, and Bibliometrix to undertake a bibliometric analysis of the expanding literature related to blockchain technology within the financial sector. Through a examination of 500 published articles, the study identifies insightful trends, patterns, and emerging domains on a global scale.  Results The findings highlight the advancing trajectory of blockchain research in finance, with a notable concentration of studies originating from the United States and China, both in terms of total publications and citations. Key thematic clusters identified include “smart contracts,” “financial institutions,” “initial coin offerings,” and “big data analytics.” Intersections with financial risk management, digital transformation, and the integration of big data analytics with artificial intelligence and machine learning are particularly noteworthy, marking focal points of exploration.  Conclusions While affirming the potential of blockchain, the analysis also sheds light on persistent impediments hindering its widespread adoption and utilization. This study not only contributes to the current understanding of blockchain in finance but also serves as a valuable resource for future researchers. It guides systematic reviews by pinpointing prominent journals and influential authors within the dynamic field of blockchain finance, thereby fostering a deeper understanding and facilitating further exploration in this evolving field.",
         "35",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  \"What we know and what should we know about the future of blockchain in finance\" Authors' have made a good attempt by highlighting the advancing trajectory of blockchain research in finance, with a notable concentration of studies originating from the United States and China, both in terms of total publications and citations. Key thematic clusters identified include “smart contracts,” “financial institutions,” “initial coin offerings,” and “big data analytics.” Intersections with financial risk management, digital transformation, and the integration of big data analytics with artificial intelligence and machine learning are particularly noteworthy, marking focal points of exploration.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.763",
         "1",
         "0",
         "0.13546918767507",
         "0.1303",
         "0.9726446270942688",
         "21.84",
         "16.2",
         "19.43",
         "17.7",
         "18.5",
         "97",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "5.0",
         "4.0",
         "3.0",
         "92.0",
         "92"
        ],
        [
         "538",
         "Rajinder K. Sharma",
         "17 Jan 2025",
         "Approved With Reservations",
         "268",
         "Case Report: The Sausage Technique using Anorganic Bovine Bone Mineral for Horizontal Bone Augmentation at the Crestal Part of a Posterior Mandibular Ridge: A Case Report.",
         "Following tooth extraction, the alveolar bone goes through a natural remodeling process resulting in a significant bone resorption which may complicate dental implant placement without prior bone augmentation treatment. The sausage technique is a modified guided bone regeneration (GBR) method that has been successfully used for horizontal bone augmentation. This technique was developed to increase the bone growth at the alveolar crest. Although the sausage technique uses a combination of autograft chips and xenograft particles with a native collagen membrane, several studies have questioned whether adding autograft chips is essential for bone formation with guided bone regeneration. Moreover, harvesting the bone graft may increase the donor site morbidity and patient discomfort. This case report aimed to investigate the bone gain radiologically when the sausage technique was applied to treat a healthy, thirty-year-old patient with a horizontal defect in the posterior mandibular region using anorganic bovine bone mineral (ABBM) particles with Jason membrane, assess the implant primary stability in the augmented ridge, and present the surgical procedure steps in details. After nine months of healing, the cone-beam computed tomography (CBCT) revealed approximately 4.32 mm of bone gain at the alveolar crest in the buccal-lingual direction. The graft particles were well integrated into the newly formed bone. Two implants were inserted with an insertion torque of 35 N/cm. The ISQ values were 76 for the most anterior implant and 78 for the posterior implant. Within the limitations of this case report, the sausage technique using ABBM particles without autograft chips was an effective approach in achieving the prerequisite bone width at the crest in cases with horizontal bone defects.",
         "164",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The case report is about horizontal bone augmentation through staged GBR using the sausage technique to facilitate implant placement. Please consider the following points to improve the quality of discussion section. 1. How the surgical procedure is different from the procedure proposed by Istvan Urban and colleagues, except the exclusion of autogenous graft. 2. What are the alternatives to bone augmentation to facilitate implant placement in this case. Please describe briefly the merits and limitations. 3. What are the probable outcomes of attempted bone augmentation in this case? And how the bone augmentation was ascertained? 4. What are the  long-term complications associated with fragmented bone graft materials?  5. Is the procedure described in this case relevant for improving the success of implant placement?  6.Ethical considerations for use of materials with animal origin.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Yes  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? No  Is the case presented with sufficient detail to be useful for other practitioners? Yes",
         "0.7475",
         "6",
         "0",
         "0.0722222222222222",
         "0.0515",
         "0.8633317947387695",
         "27.93",
         "13.8",
         "15.37",
         "15.5",
         "14.9",
         "100",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "3.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "5.0",
         "75.0",
         "83"
        ],
        [
         "613",
         "Yankai Xia",
         "30 Aug 2024",
         "Approved With Reservations",
         "605",
         "Neurotoxicity of nanoplastics: A review",
         "With the increase in plastic waste in the environment, it is undeniable that humans and most organisms are exposed to plastic particles of various sizes, including nanoplastics (NPs). Humans are at risk owing to various routes of entry, including ingestion, inhalation, and dermal contact. While the toxicity of NPs is still debatable due to the scarcity of resources and research, most studies have concluded that NPs may exert toxicity, which exacerbates their neurotoxicity potential. Earlier studies concluded that NPs can cause oxidative stress, which results in apoptosis of neuronal cells. Some studies have shown that NPs can affect fundamental cell functions by inducing physical stress through deposition. Furthermore, studies on in vivo models exposed to NPs have demonstrated behavioral changes that are presumably due to alterations in acetylcholinesterase activity and neurotransmitter levels. This review discusses studies conducted on the neurotoxic potential of NPs and their effects, which are dependent on several parameters, including size and type of NPs, exposure concentration, duration, and various models at risk of NP exposure. Furthermore, speculations on how NPs are related to neurotoxicity are also discussed.",
         "49",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The review addresses the increasingly relevant topic of the neurotoxic potential of nanoplastics (NPs) in the context of escalating plastic pollution, effectively summarizing key findings from the literature with an emphasis on the various exposure routes and associated risks. However, the manuscript would benefit from a more comprehensive synthesis of the existing literature, particularly in addressing the inconsistencies and gaps in current research, while also providing a clearer articulation of the limitations of current research methodologies and offering suggestions for future studies. Additionally, a discussion of the broader implications for public health and potential regulatory frameworks would strengthen the manuscript's contribution to the field. Overall, the review could be further improved by deepening the analysis of existing studies and providing a more critical perspective on the current state of knowledge. I recommend that the authors consider resubmitting after making significant improvements. Major comments While the review discusses various detection and quantification methods for NPs, a more detailed critique of the limitations of these methodologies is needed. This should include an examination of the challenges related to detecting NPs in environmental samples versus laboratory conditions, as well as the implications these limitations have for interpreting research findings. The manuscript needs a more critical analysis of key research gaps, especially concerning the inconsistencies in findings related to the mechanisms of NP-induced neurotoxicity. Strengthening this section with a more detailed comparison of the outcomes across different experimental models and conditions would greatly enhance the review's contribution. The discussion on the mechanisms of NP-induced neurotoxicity is crucial. For instance, exploring the specific biochemical pathways through which NPs interact with cellular components at a molecular level would provide a more comprehensive understanding.  The role of protein corona formation in neurotoxicity, mentioned towards the end, should be integrated earlier in the manuscript to establish a clear connection between NP exposure and neurodegenerative diseases. While the manuscript covers many trending topics, it often treats them in isolation, which leads to a lack of coherence. An integrated approach that links these topics and demonstrates their interconnections would greatly improve the flow and continuity of the review. Minor comments The manuscript relies heavily on older studies, with relatively few references from the past three years. Incorporating more recent studies will ensure that the review reflects the current state of research and provides a comprehensive overview of the field. In some sections, particularly those discussing in vivo studies, the outcomes are not always clearly connected to the broader implications for neurotoxicity. It would be helpful to more explicitly link the results of these studies to the potential mechanisms of NP-induced neurotoxicity and their relevance to human health. The conclusion primarily restates the findings discussed throughout the review but does not provide a comprehensive synthesis of the key takeaways. The summary of neurotoxicity of NPs in different models presented in Table 1 is not comprehensive and should be thoroughly enumerated. The language of the manuscript should be polished.  Is the topic of the review discussed comprehensively in the context of the current literature? Partly  Are all factual statements correct and adequately supported by citations? Yes  Is the review written in accessible language? Partly  Are the conclusions drawn appropriate in the context of the current research literature? Partly",
         "0.8004",
         "1",
         "0",
         "0.1484375",
         "0.1633",
         "0.8763298392295837",
         "13.99",
         "17.1",
         "17.25",
         "17.7",
         "18.6",
         "92",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "6.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "2",
         "4.0",
         "3.0",
         "4.0",
         "62.0",
         "62"
        ],
        [
         "614",
         "Amitava Mukherjee",
         "25 Nov 2024",
         "Approved With Reservations",
         "538",
         "Neurotoxicity of nanoplastics: A review",
         "With the increase in plastic waste in the environment, it is undeniable that humans and most organisms are exposed to plastic particles of various sizes, including nanoplastics (NPs). Humans are at risk owing to various routes of entry, including ingestion, inhalation, and dermal contact. While the toxicity of NPs is still debatable due to the scarcity of resources and research, most studies have concluded that NPs may exert toxicity, which exacerbates their neurotoxicity potential. Earlier studies concluded that NPs can cause oxidative stress, which results in apoptosis of neuronal cells. Some studies have shown that NPs can affect fundamental cell functions by inducing physical stress through deposition. Furthermore, studies on in vivo models exposed to NPs have demonstrated behavioral changes that are presumably due to alterations in acetylcholinesterase activity and neurotransmitter levels. This review discusses studies conducted on the neurotoxic potential of NPs and their effects, which are dependent on several parameters, including size and type of NPs, exposure concentration, duration, and various models at risk of NP exposure. Furthermore, speculations on how NPs are related to neurotoxicity are also discussed.",
         "136",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The review presents an exhaustive coverage of the neurotoxic effects of nanoplastics. The authors have done a commendable job of collecting literature and making a balanced presentation. However, I suggest the following points. 1. Introduction: The introduction is rather about the issues with plastic pollution, kindly introduce the importance and relevance of the neurotoxicity of the plastics here and also add a brief outline of the topics covered in the Review. Given that already a sizeable number of reviews are available on the topic of plastic pollution, please make this part brief and bring out the title of the work, \"neurotoxicity\" here. 2. Under Nanopalstics please revise the discussion on sources of the NPs relevant to human uptake and toxicity. Please connect this part with the main thread of the review. This is also much discussed in the literature already, and so with appropriate citations, the authors can shorten the description here. In the detection and quantification clearly distinguish and discuss the in vitro and in vivo detection and challenges associated briefly. The differences between MPs and Nps is a misfit in the review and out of context, in the introduction section itself one or two lines can be added with specific references for interested readers. 3. In the \"potential routes of NP exposure to Humans\" please avoid adding mechanisms of interaction/effects in this section, stick to the sources. Intracellular fate and bio-corona again may not fit well as a separate section, please integrate them briefly into the section on \"uptake\" and make their relevance clear for neurotoxicity effects. 4. Instead of sensitivity of the brain to oxidative stress discuss the various modes of action of the plastic particles mentioning why ROS is considered predominant one.. add relevance to plastic particles here briefly explain the effects of multiple chemical types, and possibly leaching of additives briefly. 5. Looking at the length of the review roughly 30% is covered on neurotoxicity, please elaborate on mechanisms of action, effects of plastic types, and size-based effects of nano plastics with specifics on neurotoxicity. I assume the literature is replete with studies with polystyrene NPs but please see whether the effects of other plastic types can be added and the effects of weathered or environment-derived ones. 6. Add a section on current gaps and challenges in these studies. 7. Please add a section on methods of review, year range selected, inclusion/exclusion criteria adopted search engines used, and so on. Please add this after the introduction section. This is an important miss in the article.  Is the topic of the review discussed comprehensively in the context of the current literature? Partly  Are all factual statements correct and adequately supported by citations? Partly  Is the review written in accessible language? Yes  Are the conclusions drawn appropriate in the context of the current research literature? Partly",
         "0.7593",
         "8",
         "0",
         "0.1164814814814814",
         "0.4415",
         "0.915136992931366",
         "32.73",
         "14.0",
         "14.32",
         "14.9",
         "15.0",
         "92",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "4.0",
         "3.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "5.0",
         "4.0",
         "3.0",
         "86.0",
         "86.0"
        ],
        [
         "645",
         "Bhamini Krishna Rao",
         "12 Jul 2024",
         "Approved",
         "763",
         "Parents’ satisfaction with physiotherapy services for neuropediatric outpatients in government and private hospitals in the United Arab Emirates: a cross-sectional study",
         "Background Healthcare, like other industries, emphasizes performance, quality, and consumer experience while also attempting to reduce costs. However, high-quality healthcare remains paramount for vulnerable and ill patients. This study aimed to investigate parents' and caregivers' level of satisfaction with physiotherapy services provided to neuropediatric outpatients on the United Arab Emirates (UAE).  Methods This descriptive cross-sectional study included 103 parents/caregivers of children with neurological disabilities that were randomly selected from different Emirates Health Services Hospitals in the UAE. Data was collected using the long-form Patient Satisfaction Questionnaire (PSQ-III).  Results The overall mean satisfaction was 159±7.73 (out of 250 points). Communication (20.36/25), interpersonal factors (20.17/35), and doctor-patient time (20.17/35) had the highest mean satisfaction scores (8.06/10). The lowest mean satisfaction scores were for access/availability/convenience (34.60/60), technical quality (33.17/50), and economic elements (23.83/40).  Conclusion Despite participants’ overall satisfaction scores being positive, some service domains require improvement to improve satisfaction, specifically the access/availability/convenience, technical quality, and economic elements. These areas should be prioritized by service providers and managers to improve patients’ experiences and clinical outcomes.",
         "8",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The manuscript titled \"Parents’ satisfaction with physiotherapy services for neuropediatric outpatients in government and private hospitals in the United Arab Emirates: a cross-sectional study\" presents a valuable exploration of parental satisfaction with physiotherapy services for children with neurological disabilities in the UAE. The study design, which utilizes a cross-sectional correlational approach, is appropriate for the research objectives and provides a comprehensive overview of the satisfaction levels among parents and caregivers.  The methods section is detailed and well-structured, clearly outlining the study design, participant recruitment, data collection, and analysis procedures. The choice of the Patient Satisfaction Questionnaire (PSQ-III) is justified and its reliability is well-documented, making it a suitable tool for this study. The ethical considerations are thoroughly addressed, ensuring the integrity and ethical soundness of the study. However, providing more details on the sampling process, including the selection criteria and any potential biases, would enhance the transparency and replicability of the methodology. The results are presented clearly and concisely, with comprehensive tables that effectively illustrate the key findings. The analysis is robust, and the interpretation of the data is logical and consistent with the study's objectives. The sociodemographic characteristics of the participants are well-documented, providing important context for understanding the results. The correlation analysis between demographic variables and satisfaction scores is particularly useful, highlighting the factors that influence parental satisfaction. Including more detailed subgroup analyses could provide additional insights into these factors. The discussion effectively interprets the results in the context of existing literature, highlighting both the strengths and areas needing improvement in the physiotherapy services. The identification of areas requiring improvement, such as access, technical quality, and economic elements, is particularly valuable for informing future service enhancements. The discussion could be further enriched by exploring potential strategies for addressing these areas and by discussing the implications of the findings for policy and practice in more detail. Additionally, a comparison with similar studies in other regions could provide a broader perspective on the findings and underscore the study's relevance in a global context. In conclusion, this study sheds light on the crucial aspect of parents' satisfaction with physiotherapy treatment for neuropediatric outpatients in the UAE. The findings underscore the overall positive satisfaction reported by parents and caregivers regarding various aspects of physiotherapy services, particularly in communication, interpersonal factors, and doctor-patient time. However, it is evident that there are areas in need of improvement, notably access, technical quality, and economic elements. These findings emphasize the importance of continuous assessment and enhancement of healthcare services to meet the evolving needs of patients and their families. Addressing the identified areas of concern is paramount to enhancing patient experiences and ultimately improving clinical outcomes. Therefore, it is imperative for service providers and managers to prioritize these domains in their efforts to optimize the quality of care provided to neuropediatric outpatients and ensure the delivery of patient-centered healthcare in the UAE. Suggestions for Improvement: The abstract can be reorganized to suit the title of the study by giving importance to parents whose children receive long term rehabilitation services. The introduction can emphasize more on how caregiving is difficult in neuropediatric population rather than giving too much importance to general aspects of patient satisfaction Provide more details on the sampling process and potential biases in the methods section. Include more detailed subgroup analyses in the results section to provide additional insights into factors influencing satisfaction. The results section can highlight parents' or caregivers' characteristics and then compare it with the patient satisfaction scores. Explore potential strategies for improving areas of low satisfaction in the discussion. Compare findings with similar studies in other regions to provide a broader context. Include specific recommendations for future research and practice in the conclusion. Recommendation: Approve for indexing with minor revisions.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7771",
         "1",
         "0",
         "0.1780205905205905",
         "0.0999",
         "0.9188451766967772",
         "7.66",
         "17.5",
         "16.92",
         "18.3",
         "18.8",
         "89",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "5.0",
         "1.0",
         "yes",
         "positive",
         "polite",
         "Moderate",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "80.0",
         "82"
        ],
        [
         "646",
         "Ehab Mohamed Abd El-Kaf",
         "30 Jul 2024",
         "Approved",
         "532",
         "Parents’ satisfaction with physiotherapy services for neuropediatric outpatients in government and private hospitals in the United Arab Emirates: a cross-sectional study",
         "Background Healthcare, like other industries, emphasizes performance, quality, and consumer experience while also attempting to reduce costs. However, high-quality healthcare remains paramount for vulnerable and ill patients. This study aimed to investigate parents' and caregivers' level of satisfaction with physiotherapy services provided to neuropediatric outpatients on the United Arab Emirates (UAE).  Methods This descriptive cross-sectional study included 103 parents/caregivers of children with neurological disabilities that were randomly selected from different Emirates Health Services Hospitals in the UAE. Data was collected using the long-form Patient Satisfaction Questionnaire (PSQ-III).  Results The overall mean satisfaction was 159±7.73 (out of 250 points). Communication (20.36/25), interpersonal factors (20.17/35), and doctor-patient time (20.17/35) had the highest mean satisfaction scores (8.06/10). The lowest mean satisfaction scores were for access/availability/convenience (34.60/60), technical quality (33.17/50), and economic elements (23.83/40).  Conclusion Despite participants’ overall satisfaction scores being positive, some service domains require improvement to improve satisfaction, specifically the access/availability/convenience, technical quality, and economic elements. These areas should be prioritized by service providers and managers to improve patients’ experiences and clinical outcomes.",
         "26",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This manuscript makes a valuable contribution to understanding parental satisfaction with physiotherapy services for children with neurological disabilities in the UAE. The study highlights the local importance and relevance of this issue and provides useful insights for healthcare providers seeking to improve service quality. Overall, this manuscript provides a comprehensive overview of parental satisfaction with physiotherapy services for children with neurological disabilities in the UAE. Enhancing the introduction with additional references, clarifying secondary objectives, and providing more details on the sampling process and subgroup analyses would further improve the manuscript. Here are a detailed review of the sections. 1. The introduction is clear and effectively sets the stage for the study, emphasizing the importance of patient satisfaction in healthcare within the UAE's evolving landscape. While the background information on patient satisfaction is comprehensive, adding recent studies on similar settings would enhance this section. 2. The goals and objectives of the study are well-stated and align with the introduction. The aim to investigate parents' satisfaction with physiotherapy services for neuropediatric patients is clear. However, clarifying any secondary objectives would provide a more complete picture of the study's scope. 3. The methods section is detailed and well-organized, outlining the study design, participant recruitment, data collection, and analysis procedures. The use of the Patient Satisfaction Questionnaire (PSQ-III) is well-justified, and ethical considerations are thoroughly addressed. More details on the sampling process, including selection criteria and potential biases, would improve transparency and replicability. 4. Results are presented clearly with tables that effectively illustrate key findings. The mean satisfaction scores for different service domains are well-documented, and the statistical analysis is sound. Including more detailed demographic data and subgroup analyses would provide additional context and highlight factors influencing parental satisfaction. 5. The discussion interprets the results well, relating them to existing literature and emphasizing the study's local significance. Identifying areas for improvement, such as access, technical quality, and economic elements, is valuable. The discussion could be enriched by exploring strategies for addressing these areas and discussing the implications for policy and practice in more detail. 6. Comparing the findings with similar studies in other regions would offer a broader perspective. 7. The conclusion succinctly summarizes the main findings and their implications, emphasizing the need for ongoing assessment and improvement of physiotherapy services. Including specific recommendations for future research and practice would strengthen the conclusion.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.792",
         "8",
         "0",
         "0.1634672619047619",
         "0.0999",
         "0.9228382706642152",
         "19.06",
         "15.1",
         "15.82",
         "16.9",
         "17.3",
         "98",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "somewhat specific",
         "4.0",
         "5.0",
         "5.0",
         "85.0",
         "85"
        ],
        [
         "820",
         "Jennifer Gaddy",
         "07 Aug 2024",
         "Approved",
         "464",
         "GBS vaccines in the UK: a round table discussion",
         "Background Group B streptococcus (GBS) remains a leading cause of infant sepsis, meningitis and death despite intrapartum antibiotic prophylaxis. A vaccine is urgently required, and two candidates are in advanced clinical trials. For successful GBS vaccine implementation, especially if a vaccine is licensed based on an immunological threshold, there must be cross-sector engagement, effective advocacy, robust plans for phase IV studies and equitable access.  Meeting A round-table discussion, held at St George’s University of London, reviewed the current position of GBS vaccines in the UK context, focusing on phase IV plans, convening a diverse group of stakeholders from across the UK, with a role in GBS vaccine licensure, advocacy, implementation or effectiveness evaluation. Presentations outlined the latest UK epidemiology, noting the rising infant invasive GBS (iGBS) infection rates from 1996 to 2021 for both early and late onset disease, with the highest disease rates in Black infants (1.1/1000 livebirths vs white infants (0.81/1000 livebirths). Potential coverage of the candidate vaccines was high (>95%). Regulatory input suggested that EU regulators would consider waiving the need for a pre-licensure efficacy study if a putative correlate of protection could be adequately justified. Phase IV study methodologies for a GBS vaccine were considered, largely based on previous UK maternal vaccine assessments, such as a nationwide cohort study design using a vaccine register and a maternal services dataset. Other strategies were also discussed such as a cluster or stepped-wedge randomised trial to evaluate implementation outcomes. Opportunities for advocacy, education and engagement with additional key partners were discussed and identified.  Conclusions With an approved GBS vaccine a near possibility, planning of phase IV studies and identification of critical barriers to implementation are urgently needed. Cross-sector engagement is essential and will facilitate a successful pathway.",
         "78",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The manuscript by Natasha Thorn and colleagues entitled, “GBS vaccines in the UK: a round table discussion” presents a compelling discussion of the status of a protective vaccine against Group B Streptococcus, an important perinatal pathogen.  This manuscript is full of important information about disease risk from GBS infection and gaps in current treatment and prevention strategies.  There are many positive aspects about this manuscript that I would like to highlight.  First, the authors are extremely deliberate in their use of language, specifically referring to “pregnant patients” and “pregnant people”.  This is a subtle but important aspect of discussing these populations without introducing highly gendered language. Excellent work. The inclusion of stakeholders in the community such as Midwives was also a strength as these providers have the capacity to meet individuals who may be unaware of GBS risk and/or vaccine hesitant.  Buy-in from these groups will help with deployment in the future. Comparing/contrasting efficacy of other vaccination programmes deployed in pregnant patients was also a strength of this manuscript. I have a few comments to improve the quality of the manuscript. 1.  The authors mention AMR very briefly in the second paragraph of the Introduction.  It would be helpful to expand this section to acknowledge that the standard first line therapeutic choice for GBS is penicillin, but up to 10% of populations report penicillin hypersensitivity. Second line choice is often erythromycin or clindamycin and emerging clinical strains are exhibiting high resistance to these drugs (about 40% of strains are resistant).  2.  First line of the Introduction.  The authors refer to Group B streptococcus and italicize the word “streptococcus” but leave it lowercase.  If the authors are referring to the genus, this word should be capitalized and italicized. If they are referring to general morphology and arrangement of bacteria it can be lowercase but should not be italicized.  Most common references to GBS use the former (genus nomenclature).  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? No source data required  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7773",
         "4",
         "0",
         "0.1642103729603729",
         "0.6746",
         "0.9360240697860718",
         "34.97",
         "13.2",
         "15.48",
         "15.5",
         "14.7",
         "98",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "3.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "5.0",
         "4.0",
         "3.0",
         "93.0",
         "93"
        ],
        [
         "821",
         "Lisa Hanson",
         "27 Aug 2024",
         "Approved",
         "270",
         "GBS vaccines in the UK: a round table discussion",
         "Background Group B streptococcus (GBS) remains a leading cause of infant sepsis, meningitis and death despite intrapartum antibiotic prophylaxis. A vaccine is urgently required, and two candidates are in advanced clinical trials. For successful GBS vaccine implementation, especially if a vaccine is licensed based on an immunological threshold, there must be cross-sector engagement, effective advocacy, robust plans for phase IV studies and equitable access.  Meeting A round-table discussion, held at St George’s University of London, reviewed the current position of GBS vaccines in the UK context, focusing on phase IV plans, convening a diverse group of stakeholders from across the UK, with a role in GBS vaccine licensure, advocacy, implementation or effectiveness evaluation. Presentations outlined the latest UK epidemiology, noting the rising infant invasive GBS (iGBS) infection rates from 1996 to 2021 for both early and late onset disease, with the highest disease rates in Black infants (1.1/1000 livebirths vs white infants (0.81/1000 livebirths). Potential coverage of the candidate vaccines was high (>95%). Regulatory input suggested that EU regulators would consider waiving the need for a pre-licensure efficacy study if a putative correlate of protection could be adequately justified. Phase IV study methodologies for a GBS vaccine were considered, largely based on previous UK maternal vaccine assessments, such as a nationwide cohort study design using a vaccine register and a maternal services dataset. Other strategies were also discussed such as a cluster or stepped-wedge randomised trial to evaluate implementation outcomes. Opportunities for advocacy, education and engagement with additional key partners were discussed and identified.  Conclusions With an approved GBS vaccine a near possibility, planning of phase IV studies and identification of critical barriers to implementation are urgently needed. Cross-sector engagement is essential and will facilitate a successful pathway.",
         "98",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  *Very well written article. Statistics and references are up to date and appropriate. Tables are very effective. A few suggestions for clarity. *\"more crowded pregnancy vaccine space\" is unclear. *In the GBS3 trial description, more clarity is needed as to why participants in the routine testing arms receive either rapid PCR IP (versus 35-37 weeks). A reference here about the sensitivity and utiliy of rapid IP testing is needed-as this is not a usual strategy in culture-based EOGBS prevention approach recommended by the CDC and now ACOG (2019). *Table 3. The points about midwives having hesitancy to offer vaccines was interesting, as this is not the case in the USA. *Table 4 is redundant of the text on Potential Phase IV study designs.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? No source data required  Are the conclusions drawn adequately supported by the results? Yes",
         "0.774",
         "2",
         "1",
         "0.2182758620689655",
         "0.0999",
         "0.8594522476196289",
         "37.4",
         "12.2",
         "14.61",
         "14.5",
         "12.6",
         "95",
         "0",
         "2",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "3",
         "4.0",
         "5.0",
         "3.0",
         "86.0",
         "86"
        ],
        [
         "822",
         "Hannah R Frost",
         "10 Sep 2024",
         "Approved",
         "385",
         "GBS vaccines in the UK: a round table discussion",
         "Background Group B streptococcus (GBS) remains a leading cause of infant sepsis, meningitis and death despite intrapartum antibiotic prophylaxis. A vaccine is urgently required, and two candidates are in advanced clinical trials. For successful GBS vaccine implementation, especially if a vaccine is licensed based on an immunological threshold, there must be cross-sector engagement, effective advocacy, robust plans for phase IV studies and equitable access.  Meeting A round-table discussion, held at St George’s University of London, reviewed the current position of GBS vaccines in the UK context, focusing on phase IV plans, convening a diverse group of stakeholders from across the UK, with a role in GBS vaccine licensure, advocacy, implementation or effectiveness evaluation. Presentations outlined the latest UK epidemiology, noting the rising infant invasive GBS (iGBS) infection rates from 1996 to 2021 for both early and late onset disease, with the highest disease rates in Black infants (1.1/1000 livebirths vs white infants (0.81/1000 livebirths). Potential coverage of the candidate vaccines was high (>95%). Regulatory input suggested that EU regulators would consider waiving the need for a pre-licensure efficacy study if a putative correlate of protection could be adequately justified. Phase IV study methodologies for a GBS vaccine were considered, largely based on previous UK maternal vaccine assessments, such as a nationwide cohort study design using a vaccine register and a maternal services dataset. Other strategies were also discussed such as a cluster or stepped-wedge randomised trial to evaluate implementation outcomes. Opportunities for advocacy, education and engagement with additional key partners were discussed and identified.  Conclusions With an approved GBS vaccine a near possibility, planning of phase IV studies and identification of critical barriers to implementation are urgently needed. Cross-sector engagement is essential and will facilitate a successful pathway.",
         "112",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Thank you for the invitation to review the manuscript \"GBS vaccines in the UK: a round table discussion\" by Thorn et al., it was an interesting and informative read. The article provides a concise and well-rounded update to the current status of GBS Vaccines, including an appropriate focus on knowledge gaps and barriers to success with useful recommendations for how to address them. It is particularly interesting to have an update on important ongoing or planned trials, which is not normally available in the literature until >1 year after the completion of the trial. I appreciate the focus on forward planning around vaccine uptake and phase IV trials, and keeping in mind lessons from COVID-19 and other vaccines given in pregnancy.  I have a few minor comments which may improve readability of the manuscript. 1) There is some repetition of points throughout, likely due to the nature of the manuscript as proceedings of a meeting. The authors could clean up the narrative, for example on page four, two subsequent paragraphs have the same conclusion regarding the need for improved surveillance.  2) Different acronyms are used to refer to the same thing (e.g. EOGBS, EOD and EO disease are all used in the first page) and some acronyms are never expanded (e.g. UR when discussing case estimates).  3) It would be good to have references and links provided for the burden of disease data used, acknowledging that some data is as yet unpublished.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7937",
         "2",
         "0",
         "0.1619918699186991",
         "0.8514",
         "0.8808193206787109",
         "42.41",
         "12.4",
         "14.77",
         "14.9",
         "13.6",
         "98",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "92.0",
         "92"
        ],
        [
         "823",
         "Rosana Rocha Barros",
         "26 Sep 2024",
         "Approved",
         "258",
         "GBS vaccines in the UK: a round table discussion",
         "Background Group B streptococcus (GBS) remains a leading cause of infant sepsis, meningitis and death despite intrapartum antibiotic prophylaxis. A vaccine is urgently required, and two candidates are in advanced clinical trials. For successful GBS vaccine implementation, especially if a vaccine is licensed based on an immunological threshold, there must be cross-sector engagement, effective advocacy, robust plans for phase IV studies and equitable access.  Meeting A round-table discussion, held at St George’s University of London, reviewed the current position of GBS vaccines in the UK context, focusing on phase IV plans, convening a diverse group of stakeholders from across the UK, with a role in GBS vaccine licensure, advocacy, implementation or effectiveness evaluation. Presentations outlined the latest UK epidemiology, noting the rising infant invasive GBS (iGBS) infection rates from 1996 to 2021 for both early and late onset disease, with the highest disease rates in Black infants (1.1/1000 livebirths vs white infants (0.81/1000 livebirths). Potential coverage of the candidate vaccines was high (>95%). Regulatory input suggested that EU regulators would consider waiving the need for a pre-licensure efficacy study if a putative correlate of protection could be adequately justified. Phase IV study methodologies for a GBS vaccine were considered, largely based on previous UK maternal vaccine assessments, such as a nationwide cohort study design using a vaccine register and a maternal services dataset. Other strategies were also discussed such as a cluster or stepped-wedge randomised trial to evaluate implementation outcomes. Opportunities for advocacy, education and engagement with additional key partners were discussed and identified.  Conclusions With an approved GBS vaccine a near possibility, planning of phase IV studies and identification of critical barriers to implementation are urgently needed. Cross-sector engagement is essential and will facilitate a successful pathway.",
         "128",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Revision of the manuscript GBS vaccines in the UK: a round table discussion The manuscript is a comprehensive report of the round table held at St George University of London, that discussed the state of the art of GBS vaccines and planned phase IV trials. The manuscript brings the talks of different specialists, covering various issues regarding GBS vaccine background, vaccine implementation, and the follow-up after the beginning of vaccination. Overall, the text is very well-written and I have only an observation, as follows. Page 3 2nd paragraph. “IAP is not always deliverable, results in high antibiotic exposure...” This sentence seems a bit unclear. I suggest that the authors improve it.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? No source data required  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7639",
         "2",
         "0",
         "0.1280357142857143",
         "0.2025",
         "0.8627001643180847",
         "27.42",
         "14.0",
         "15.27",
         "15.2",
         "14.0",
         "102",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "3",
         "4.0",
         "3.0",
         "5.0",
         "90.0",
         "90"
        ],
        [
         "834",
         "Dharma Varapula",
         "21 Aug 2024",
         "Approved With Reservations",
         "606",
         "Negligible effects of read trimming on the accuracy of germline short variant calling in the human genome",
         "Background Next generation sequencing (NGS) has become a standard tool in the molecular diagnostics of Mendelian disease, and the precision of such diagnostics is greatly affected by the accuracy of variant calling from sequencing data. Recently, we have comprehensively evaluated the performance of multiple variant calling pipelines. However, no systematic analysis of the effects of read trimming on variant discovery with modern variant calling software has yet been performed.  Methods In this work, we systematically evaluated the effects of adapters on the performance of 8 variant calling and filtering methods using 14 standard reference Genome-in-a-Bottle (GIAB) samples. Variant calls were compared to the ground truth variant sets, and the effect of adapter trimming with different tools was assessed using major performance metrics (precision, recall, and F1 score).  Results We show that adapter trimming has no effect on the accuracy of the best-performing variant callers (e.g., DeepVariant) on whole-genome sequencing (WGS) data. For whole-exome sequencing (WES) datasets subtle improvement of accuracy was observed in some of the samples. In high-coverage WES data (~200x mean coverage), adapter removal allowed for discovery of 2-4 additional true positive variants in only two out of seven datasets tested. Moreover, this effect was not dependent on the median insert size and proportion of adapter sequences in reads. Surprisingly, the effect of trimming on variant calling was reversed when moderate coverage (~80-100x) WES data was used. Finally, we show that some of the recently developed machine learning-based variant callers demonstrate greater dependence on the presence of adapters in reads.  Conclusions Taken together, our results indicate that adapter removal is unnecessary when calling germline variants, but suggest that preprocessing methods should be carefully chosen when developing and using machine learning-based variant analysis methods.",
         "96",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  In this report, Barbitoff, Y. and Predeus, A. have described a study investigating if read trimming, specifically adapter trimming, affects variant calling accuracy using commonly employed variant callers. The authors find this investigation to be of significant value citing there is no prior systematic study exploring the impact of read trimming on variant calling accuracy. In the study, WES and WGS datasets from seven GIAB samples were processed using six different variant callers (DeepVariant, GATK HaplotypeCaller, Freebayes, Strelka2, Octopus, and Clair3) to measure the effect of read trimming performed prior to the variant calling. The authors show comparative metrics (differences between trimmed and untrimmed variant caller performance metrics – recall, precision and F1 scores) and find no substantial differences in variant calling performance, except in the case of 200x coverage WES. Subsequently, the authors downsampled the data to produce a simulated 80x WES dataset expecting a greater likelihood for an  increased impact of read trimming on variant calling accuracy. This simulated dataset too did not show significant impact due to read trimming. Further, the authors found no correlation between extent of adapter base contamination and impact of read trimming on variant caller performance metrics. Additionally, the authors ran the pipelines with different variant callers and found minimal impacts due to read trimming upstream. My comments below: The adapter base percentage variation ranged from 8.1% to 35.2%. Please comment if this is an expected range for WES datasets. Also, please mention the coverage of the WES dataset in the caption for Fig 1. How does one assess the changes in performance metrics to be significant or not (Fig 1b and 1c)? Recall and precision score metrics in Figure 1b for Indels in WES datasets show deviations from the mean and these are not explained thoroughly. If this variance is to be expected, is it likely that the sample set n of 7 is too low? Or is the data heteroscedastic? In my view, the observations made on data presented in Figure 1e are not sufficiently explained. Discussion section on this aspect is a rehash of the content in the Results section. Read trimming is often a lower time-cost step compared to the variant calling step. It would benefit the reader (and the authors) greatly if there was a more detailed explanation why this is an important decision to make, which this study is aimed to inform us better for. Data redundancy and potential loss of raw data (if only single copy retained) appear to be valid reasons on the surface, a more complete justification is need in my view. Review of prior literature work can be more exhaustive.  I was unable to access or review the Supplementary information, so it has not been included in my review. Please update in revised version  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7883",
         "1",
         "0",
         "0.0970054945054944",
         "0.2663",
         "0.9262039661407472",
         "35.37",
         "13.0",
         "13.18",
         "14.3",
         "13.4",
         "91",
         "0",
         "0",
         "1",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "3.0",
         "80.0",
         "83"
        ],
        [
         "835",
         "Xihao Li",
         "14 Oct 2024",
         "Approved With Reservations",
         "383",
         "Negligible effects of read trimming on the accuracy of germline short variant calling in the human genome",
         "Background Next generation sequencing (NGS) has become a standard tool in the molecular diagnostics of Mendelian disease, and the precision of such diagnostics is greatly affected by the accuracy of variant calling from sequencing data. Recently, we have comprehensively evaluated the performance of multiple variant calling pipelines. However, no systematic analysis of the effects of read trimming on variant discovery with modern variant calling software has yet been performed.  Methods In this work, we systematically evaluated the effects of adapters on the performance of 8 variant calling and filtering methods using 14 standard reference Genome-in-a-Bottle (GIAB) samples. Variant calls were compared to the ground truth variant sets, and the effect of adapter trimming with different tools was assessed using major performance metrics (precision, recall, and F1 score).  Results We show that adapter trimming has no effect on the accuracy of the best-performing variant callers (e.g., DeepVariant) on whole-genome sequencing (WGS) data. For whole-exome sequencing (WES) datasets subtle improvement of accuracy was observed in some of the samples. In high-coverage WES data (~200x mean coverage), adapter removal allowed for discovery of 2-4 additional true positive variants in only two out of seven datasets tested. Moreover, this effect was not dependent on the median insert size and proportion of adapter sequences in reads. Surprisingly, the effect of trimming on variant calling was reversed when moderate coverage (~80-100x) WES data was used. Finally, we show that some of the recently developed machine learning-based variant callers demonstrate greater dependence on the presence of adapters in reads.  Conclusions Taken together, our results indicate that adapter removal is unnecessary when calling germline variants, but suggest that preprocessing methods should be carefully chosen when developing and using machine learning-based variant analysis methods.",
         "150",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study provides a systematic evaluation of the effect of adapter trimming on the accuracy of germline short variant calling in the human genome, utilizing both whole-genome sequencing (WGS) and whole-exome sequencing (WES) datasets. The comparison of multiple variant calling tools, with and without adapter trimming, reveals minimal impact on WGS data but suggests modest improvements in certain WES samples, particularly in indel detection. The study concludes that while adapter trimming may not be essential for WGS, it shows some benefits for specific WES cases. The manuscript is well-written and clear, making it accessible for readers. Below are a few comments for the authors to consider: The authors mention that “adapter trimming had very limited effects on both precision and recall.” It would be helpful to clarify and quantify the threshold for \"limited.\" Providing a statistical measure, such as a p-value or confidence interval, would strengthen the interpretation of the findings. Additional explanation is needed for the samples that showed positive effects in Figure 1. Clarifying why these samples differ from the others would help contextualize the observed improvements. The authors are encouraged to elaborate on the reasons why results differ between SNP and indel calling. Further discussion on potential underlying mechanisms would enhance understanding. The statement that “trimming may even decrease the accuracy of analysis” warrants further discussion. Exploring potential reasons behind this observation could provide valuable insights into the circumstances in which trimming could be detrimental.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.8028",
         "1",
         "0",
         "0.1083887657058388",
         "0.072",
         "0.9649744629859924",
         "26.61",
         "14.3",
         "15.41",
         "15.7",
         "15.6",
         "96",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "3",
         "4.0",
         "5.0",
         "4.0",
         "92.0",
         "92"
        ],
        [
         "951",
         "Epari Venkatarao",
         "07 Jun 2024",
         "Not Approved",
         "398",
         "A cross-sectional study of neutrophil to lymphocyte ratio as a prognostic marker in acute organophosphorus poisoning in a tertiary care hospital in Central India",
         "Background Acute organophosphorus poisoning remains a significant public health concern, with variable clinical outcomes. Prognostic markers are crucial for patient management and risk stratification. This study aims to investigate the Neutrophil Lymphocyte Ratio (NLR) as a potential prognostic marker and its associations with severity and clinical outcomes in acute organophosphorus poisoning.  Methods This cross-sectional observational study will be conducted over two years, involving patients presenting with acute organophosphorus poisoning in the Medicine Ward and Intensive Care Unit of DMIHER Wardha. Informed consent will be obtained, and detailed clinical assessments, laboratory investigations, and NLR calculations will be performed. The Nambaet, Peradeniya, and Bardin classification scales will be used to measure severity. Statistical methods will be applied to explore the relationships between NLR, clinical parameters, and clinical outcomes, including descriptive statistics, bivariate analysis, correlation analysis, multivariate regression, and ROC analysis.  Expected Results The study is anticipated to elucidate the role of NLR as a prognostic marker in acute organophosphorus poisoning. Initial assessments and correlations between NLR and clinical parameters will be presented. The predictive capability of NLR for clinical outcomes, including the need for ventilatory support and length of hospital stay, will be explored. Agreement and discrepancies between the classification scales will be evaluated.",
         "43",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This is a protocol for publication before the research is being conducted. It talks about finding the ability of NLR as a prognostic indicator in organophosphorus poisoning. NLR as a prognostic indicator has been studied extensively in recent times in various other clinical conditions including cancer. Hence, the ROL should look into this including the methodology followed to find its prostic value, which will add further knowledge to the existing body of knowledge. The outcome variables of the study should be well defined before conducting the research. This will help in the designing the study and calculation of an appropriate sample size. The sample size should be calculated using AUC in ROC analysis from published literature. The outcome measures defined by the study's objectives will determine the role of appropriate statistical methods. The authors have not been able to spell out the outcome measures properly. Hence, the specificity of the use of statistical methods seems vague. This can lead to confusion at a later stage after data collection. Dummy tables and dummy analysis before the execution of the study will be useful. The Review of Literature (ROL) lacks a finding of NLR as an inflammatory marker. There is literature available on NLR as a prognostic marker in cancer. The authors have proposed data collection at a single time point, which will have a bias in the analysis as factors like time-to-intervention, dose-response, quality of care, etc., can not be accounted for in the analysis.  Finally, the sample size calculation is inappropriate as the study is NOT trying to find the prevalence of death among organophosphorus poisoning cases with NLR >12, rather with appropriate ROL, sample size calculation method has to be revisited.  Is the rationale for, and objectives of, the study clearly described? Yes  Is the study design appropriate for the research question? No  Are sufficient details of the methods provided to allow replication by others? Partly  Are the datasets clearly presented in a useable and accessible format? Not applicable",
         "0.7682",
         "1",
         "0",
         "0.1282840722495895",
         "0.1041",
         "0.8034374713897705",
         "36.18",
         "12.7",
         "13.77",
         "14.4",
         "13.0",
         "98",
         "0",
         "0",
         "0",
         "0",
         "2.0",
         "4.0",
         "3.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "2.0",
         "3.0",
         "40.0",
         "42"
        ],
        [
         "952",
         "Deepak Kumar",
         "22 Aug 2024",
         "Not Approved",
         "479",
         "A cross-sectional study of neutrophil to lymphocyte ratio as a prognostic marker in acute organophosphorus poisoning in a tertiary care hospital in Central India",
         "Background Acute organophosphorus poisoning remains a significant public health concern, with variable clinical outcomes. Prognostic markers are crucial for patient management and risk stratification. This study aims to investigate the Neutrophil Lymphocyte Ratio (NLR) as a potential prognostic marker and its associations with severity and clinical outcomes in acute organophosphorus poisoning.  Methods This cross-sectional observational study will be conducted over two years, involving patients presenting with acute organophosphorus poisoning in the Medicine Ward and Intensive Care Unit of DMIHER Wardha. Informed consent will be obtained, and detailed clinical assessments, laboratory investigations, and NLR calculations will be performed. The Nambaet, Peradeniya, and Bardin classification scales will be used to measure severity. Statistical methods will be applied to explore the relationships between NLR, clinical parameters, and clinical outcomes, including descriptive statistics, bivariate analysis, correlation analysis, multivariate regression, and ROC analysis.  Expected Results The study is anticipated to elucidate the role of NLR as a prognostic marker in acute organophosphorus poisoning. Initial assessments and correlations between NLR and clinical parameters will be presented. The predictive capability of NLR for clinical outcomes, including the need for ventilatory support and length of hospital stay, will be explored. Agreement and discrepancies between the classification scales will be evaluated.",
         "119",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Dear Editor I have gone through the manuscript (study protocol) titled “A cross-sectional study of neutrophil to lymphocyte ratio as a prognostic marker in acute organophosphorus poisoning in a tertiary care hospital in Central India”. Following are my comments for consideration (Major Revision) Several studies are already available which showed the role of neutrophil-to-lymphocyte ratio (NLR) as a prognostic marker in acute organophosphorus poisoning with detailed method/protocol (https://www.sciencedirect.com/science/article/abs/pii/S0736467914005034 file:///C:/Users/Dr%20Deepak%20Kumar/Downloads/5-OA-Basanta+Gauli.pdf, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8284330/ ). Please elaborate.  Under study status it is mentioned as “The study has yet to start after the publication of the protocol; we will start recruitment in the study.”  However, under study design it is mentioned as  “Data will be collected at a single time point setup for the 2023-2024 period.” Considering the fact that it is mid-August 2024, when will the authors start the work and complete it within 2023-2024 period. So kindly revise the relevant content in the manuscript and its ethical approval accordingly.  Include the statement that the work will be carried out following the tenets of the Helsinki Declaration.  How the diagnosis of organophosphorus pesticide exposure will be carried out? Or in other words which method was used to find out the confirmed cases of  OP poisoning? How the authors confirm the inclusion and exclusion criteria. Which parameter will be considered for this?  Estimation of AChE activity is of the method for understanding OP poisoning. However, both organophosphorus (OP) and organocarbamates (OC) inhibit AChE activity (https://pubmed.ncbi.nlm.nih.gov/37805177/ ). Then how do the authors distinguish OP cases from OC. Please address this issue. This should be properly mentioned in the protocol. Under objectives, it is mentioned as under “To investigate whether the Neutrophil to Lymphocyte Ratio is correlated with the dose of atropine administered to patients with acute organophosphorus poisoning.” In cases where organophosphate poisoning is on the differential but not confirmed, a trial of atropine is generally administered (https://www.ncbi.nlm.nih.gov/books/NBK470430/#:~:text=If%20organophosphate%20poisoning%20is%20on,suspicion%20of%20AChE%20inhibitor%20poisoning. ). Then how do the investigators access the control NLR value (i.e., value before administration of atropine). Please discuss.  Mention which clinical/biochemical parameters will be considered for assessment.  Kindly include the following in the exclusion criteria: The patients who are on steroids, pregnant patients, and patients with blood disorders (https://www.jcmc.com.np/jcmc/index.php/jcmc/article/download/1311/836 ).  Thanks  Is the rationale for, and objectives of, the study clearly described? Yes  Is the study design appropriate for the research question? Partly  Are sufficient details of the methods provided to allow replication by others? Yes  Are the datasets clearly presented in a useable and accessible format? Partly",
         "0.7713",
         "4",
         "5",
         "0.1888736263736263",
         "0.6118",
         "0.9150463342666626",
         "28.23",
         "13.7",
         "14.37",
         "15.0",
         "18.3",
         "92",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "3.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "no hedging (minimal)",
         "3",
         "4.0",
         "3.0",
         "4.0",
         "82.0",
         "82"
        ],
        [
         "1272",
         "Vivek Gupta",
         "07 Feb 2024",
         "Approved",
         "273",
         "To study the utility of tumor budding as a histopathological marker in comparison to various histopathological parameters and TNM staging in breast carcinoma",
         "Background Breast cancer is the leading cause of death in Indian females. Detection of breast cancer in later stages leads to poorer prognosis and therefore decreases patient survival. Various new modalities such as mammography and USG guided FNACs are developed and many new markers are available to diagnose breast cancer; however, tumour budding is a cost-effective method which can be helpful in early diagnosis. Tumour buds are found to have a positive correlation with various histopathological prognostic markers in breast cancer. The present study will be conducted to evaluate tumour buds as a prognostic marker in breast cancer. This study aims to compare tumour budding with histopathological prognostic markers, TNM staging and IHC phenotypes.  Methods The study will be observational, cross- sectional, and prospective, will include 60 cases and will be conducted at Jawaharlal Nehru Medical College (JNMC) Wardha in the Pathology Department.  Results Data will be collected and combined together over a period of two years and will be analysed statistically for tumour budding as a marker and its correlation with breast prognosis.",
         "23",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The rationale for the study is well-defined and has clarity. It highlights the gap in the literature and the research question. The objectives are in sequence and lead to clarity in assessing the tumor bud in breast carcinoma. Objective 4 needs to be reframed to “Assessing the tumor bud status in carcinoma breast.” The histopathological examination may be removed as the same has already been mentioned in earlier objectives. The study design is apt for study. It mentions inclusion and exclusion. They have graded tumor budding as ≤ 4/10 HPF – low tumor budding and > 4/10 HPF – high tumor budding. However, it can be graded as ≤ 4/10 HPF, 4 – 9/10 HPF, and >10/10 HPF. An optimal cut-off for the number of tumor budding and lymph node metastasis can also be correlated. The protocol provides sufficient details for the evaluation of tumor budding. Microscopic pictures of high and low tumor buds can be more effective.  Is the rationale for, and objectives of, the study clearly described? Yes  Is the study design appropriate for the research question? Yes  Are sufficient details of the methods provided to allow replication by others? Yes  Are the datasets clearly presented in a useable and accessible format? Not applicable",
         "0.6864",
         "1",
         "0",
         "0.1460919540229885",
         "0.0999",
         "0.847241997718811",
         "47.08",
         "10.6",
         "12.87",
         "13.2",
         "11.5",
         "101",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "4.0",
         "4.0",
         "3.0",
         "80.0",
         "85"
        ],
        [
         "2653",
         "Yan Naung Soe",
         "15 May 2023",
         "Not Approved",
         "656",
         "Towards achieving lightweight intrusion detection systems in Internet of Things, the role of incremental machine learning: A systematic literature review",
         "While the benefits of IoT cannot be overstated, its computational constraints make it challenging to deploy security methodologies that have been deployed in traditional computing systems. The benefits and computational constraints have made IoT systems attractive to cyber-attacks. One way to mitigate these attacks is to detect them. In this study, a Systematic Literature Review (SLR) has been conducted to analyze the role of incremental machine learning in achieving lightweight intrusion detection for IoT systems. The study analyzed existing incremental machine learning approaches used in designing intrusion detection systems for IoT ecosystems, emphasizing the incremental methods used in detecting intrusions, the datasets used to evaluate these methods, and how the method achieves lightweight status. The SLR outlined the contributions of each study, focusing on their strengths and gaps, the datasets used, and the incremental machine learning model used. This study revealed that incremental learning approaches in detecting intrusion in IoT systems are in their infant stage. Over 12 years, from 2010 to 2022, a total of twenty-one (21) studies were carried out in IDSs using incremental machine learning, with eight (8) studies carried out in IoT systems. In addition to reviewing the literature, we offer suggestions for improving existing solutions and achieving lightweight IDS for IoT systems. We also discussed some problems with making lightweight IDS for IoT systems and areas where more research could be done in the future.",
         "172",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors conducted a review for the lightweight purpose of IoT-based introduction detection systems. It is interesting, but the following concerns have to be addressed. Many typos are found.  In the abstract, you mentioned that your review is based on the 21 IDS research works. It is not enough to review a specific work. There are many related works in recent years. More references are necessary.  In Table-5, the authors listed the sources/publishers of their references. Many lightweight IoT-IDS could be easily found by exploring these publishers' web sources. E.g., the authors can explore many articles in their sources, like MDPI, ACM Digital Library, and so on. In Table-6, why can “only zero article in ACM” be considered as your quality assessment criteria?  According to the title and abstract, you focus on the lightweight purpose in the detection systems, but you mentioned only 7 lightweight models. Also, you have to check them again, are these really lightweight systems? The authors organized some lightweight models in Table 8, even if the referenced works are not deeply checked, the question arises, how could some of them be lightweight? E.g., in Table 8, in the reference [30], how it would be lightweight with computational complexity? And also, the reference [28], is it lightweight with memory consumption?  According to your abstract, you mentioned that you analyzed the systems regarding 4 kinds of criteria. But your research questions almost did not reflect them. In addition, these are not also correct. In the abstract, the authors described \"The study analyzed 1) existing incremental machine learning approaches used in designing intrusion detection systems for IoT ecosystems, 2) emphasizing the incremental methods used in detecting intrusions, 3) the datasets used to evaluate these methods, and 4) how the method achieves lightweight status. In the \"Research questions\" section, the authors generated 4-questions, such as RQ1: What is the primary contribution of the paper? RQ2: What incremental or online machine learning algorithm was used in this study? RQ3: How does the proposed method handle data, feature, or concept drift? RQ4: How does the proposed IDS handle the computational constraints of IoT systems? Is there any relation between these two parts? More importantly, even showing these facts in these parts, there is no significant explanation in this review, especially on the lightweight purpose. If so, why did the authors put the important concern in IoT-IDS, \"lightweight/handling the computational constraints\" in these parts, such as the title, abstract, and research questions?  According to your references list, you put many published reviews and survey works. It would be better if you study them again how to arrange the contents in the review works.  The citation styles are also different. E.g., the reference numbers 7 and 8. Other references are also facing the same issue. In addition, the reference indexing style in tables is confusing.  In the conclusion, you describe that you analyzed comprehensively ML-based intrusion detection systems. However, in the current version, the manuscript seems just a report that you have studied. The overall comment is that you have to improve your manuscript significantly, to be following the style of review works, to be focusing on the facts in the title and abstract, and be arranged as a well-structured manuscript.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Partly  Are sufficient details of the methods and analysis provided to allow replication by others? No  Is the statistical analysis and its interpretation appropriate? Partly  Are the conclusions drawn adequately supported by the results presented in the review? Partly",
         "0.7573",
         "1",
         "2",
         "0.1519965277777778",
         "0.0294",
         "0.9109573364257812",
         "46.78",
         "10.7",
         "11.7",
         "13.0",
         "12.3",
         "97",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "5.0",
         "False",
         "negative",
         "neutral",
         "Moderate",
         "2",
         "4.0",
         "3.0",
         "3.0",
         "24.0",
         "36"
        ],
        [
         "2661",
         "Gatot Soepriyanto",
         "30 Jun 2023",
         "Approved With Reservations",
         "400",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "220",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The study investigate whether financial distress, earnings management and audit quality as determinants/moderating variable for financial statements fraud in Indonesian listed firms during 2015 to 2019 period. The authors focused on infrastructure, utility and transportation sectors. In general, the study has been designed adequately to tackle the research questions and issues posed by the authors. However, there are some elements need to be addressed to improve the paper: Whilst the study provide adequate research background and institutional setting, it did not mention on why the study focuses on infrastructure, utility and transportation sectors? Is there any specific issues on that sector that related to financial statements fraud? In addition to that, why the study chooses 2015-2019 period?  The study should also discuss the reason choosing F-Score as its main measure for financial statement fraud. Why, for example, the study did not use, Beneish M-Score? Or other accounting irregularities measures in the literature?  The study needs to provide descriptive statistics table, so the reader can gauge and understand the dataset better. This should be provided before the authors arrive with the hypothesis discussion;  Given the study uses panel data (multi years, across different firms), is there any attempt to mitigate the issues of panel data regression? For example, using year-fixed effects or even using panel data regression analysis?  The manuscript need to be checked in terms of the quality of English write up. The title for example, is a little bit confusing, as it did not really represent what the study want to achieve in general.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7771",
         "1",
         "0",
         "0.1174549549549549",
         "0.0168",
         "0.9143848419189452",
         "26.81",
         "14.2",
         "14.1",
         "14.9",
         "14.6",
         "96",
         "0",
         "0",
         "2",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "no",
         "negative",
         "neutral",
         "Minimal",
         "3",
         "4.0",
         "3.0",
         "4.0",
         "60.0",
         "66"
        ],
        [
         "2662",
         "Toni Šušak",
         "25 Mar 2024",
         "Approved With Reservations",
         "909",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "489",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Despite the interesting idea for research, the paper has its shortcomings: ** The title of the paper is too long, it should be shortened. ** Throughout entire paper (including the title) the term “earning management” is used instead of “earnings management”. ** [Page 1] “Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases”. – Earnings management is not necessarily fraudulent behavior. Why are accounting practices and profit bubbles listed as fraudulent? ** [Page 1] The website www.idx.go.id cannot be reached. The better option was to write the name of the source instead of a website. ** [Page 3] The name of the company is not Xeroc, it is Xerox. ** [Page 3] “Fraud is practice that involves the use of deception to acquire unfair or unlawful advantages by one or more individuals. This means that fraud is an act committed by specific people, whether intentionally or unintentionally, to benefit themselves and others.” – How can a fraud be unintentional? ** [Page 3] “Earnings management (EM) is profit engineering carried out by managing revenues (cash inflows) and expenses (cash outflows) to ensure that the company's operations generate net operating profit.” – Revenues are not synonym of cash inflows, nor are expenses synonym of cash outflows. ** [Page 3] F-score should be written with capital F. ** [Page 3] “Principal” should be written instead of “principle”. ** [Page 4] “Asymmetric information” or “Information asymmetry” should be written instead of “Asymmetry information”. ** [Page 4] “Donald Cressey” should be written instead of “Donald Cressy”. ** [Page 6] “Financial statements” should be written instead of “financial statistics”. ** [Page 6] “The study's subjects are companies in the infrastructure, utilities, and transportation sectors that have been listed on the Indonesia Stock Exchange during five years observation.” – What is the reason for choosing these sectors? ** [Page 6] If panel regression model is used, methodology and applied tests should be elaborated. ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 6] “If a corporation has more than one fraud score model, it is assumed that it will commit fraud.” – Should it be written “If a corporation has F-score value more than one…”? ** [Page 7] “EM is classified as a form of fraud.” – Earnings management is not necessarily fraudulent behavior. ** [Page 7] DACC formula has duplicated content.Instead of DACCit = TAit/Ait-1*TAit/Ait-1 - NDACCit it should be written DACCit = TAit/Ait-1 - NDACCit. TAit/Ait-1 is duplicated in the formula. The same remark is applicable to: ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 7] Jones model formula should be included in the paper and elaborated. ** [Page 7] “Big Four” should be written with both capital letters (not “big four”). ** [Page 7] α, β, and ε is doubled in the explanations of formulas. ** [Page 8] Besides test variables, it is advisable to include additional control variables in the multiple regression model. ** [Page 8] “1. The constant is 0.258, indicating that the FSF is 0.193 if FD and EM are both zero. FSF does not occur in the research sample since the F-score is less than 1.” – Instead of “if FD and EM are both zero” it should be written “if all other variables are zero” given that AQ is also part of the model. ** [Page 8] “2. The FD coefficient is 0.791, which means that if the level of FD rises by one, the level of FSF rises by one as well.” – Instead of “the level of FSF rises by one as well” it should be written “the value of FSF rises by 0.791”. Ceteris paribus assumption should be stated. ** [Page 8] “3. EM's coefficient is 0.830. This means that if the management uses EM, the possibility of FSF will increase by 0.830.” – Instead of “if the management uses EM, the possibility of FSF will increase by 0.830.” it should be written “if the value of EM increases by 0.1, the value of FSF will increase by 0.083”. Ceteris paribus assumption should be stated. ** [Page 8] Variable explanations for moderating regression should be revised according to the previous three comments. ** [Page 10] “Industrial industry” should be corrected. ** Paper lacks descriptive statistics of the research sample. ** Robustness analysis could be conducted using alternative fraud measures. ** This paper would benefit from some closer proofreading. It may be useful to engage a professional English language editor. There is abundance of grammatical and typo errors (e.g. “diffucties”, “condisions”, “modeartes”, “criteras”, “coefiesient”, “shareloder” etc.).  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.6798",
         "5",
         "0",
         "0.1225925925925925",
         "0.072",
         "0.8569852709770203",
         "50.12",
         "9.4",
         "10.63",
         "12.4",
         "10.8",
         "98",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "6.0",
         "no",
         "neutral",
         "neutral",
         "minimal",
         "4",
         "3.0",
         "3.0",
         "3.0",
         "60.0",
         "60"
        ],
        [
         "2774",
         "Sergio Luis Náñez Alonso",
         "05 Dec 2022",
         "Approved",
         "490",
         "Cross-sectional data on stablecoin characteristics",
         "The article presents a dataset on the characteristics of stablecoins. Stablecoins represent a relatively young but increasingly important branch of the cryptocurrency market. Although they all share the same goal of maintaining a stable value in the digital market, they form a highly heterogeneous group. They differ in terms of collateral and stabilization mechanism, peg, availability of the technical documentation, presence on crypto exchanges or age. The dataset is cross-sectional and was created based on internet research. Individual information was collected from websites of the stablecoin projects and a crypto-data aggregator, and to a lesser extent from other auxiliary sources (websites related to finance and cryptocurrencies). The dataset is unique as there are no publicly available databases encompassing the features of stablecoins. It can be used in all stablecoin-related analyses to characterise the examined coins and to investigate the relationship between cryptocurrency market developments and stablecoin features.",
         "49",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The data note under review presents a brief introduction to the characterization of digital currencies called Stablecoins. This has allowed the authors to build up a novel database on stablecoins, mainly by searching the Internet. It is therefore a brief scientific review of the current state of the art on stablecoins, proposing a database that can be used by other researchers in their studies. It is in this last point that the value of the study lies. After reviewing the data note, it can be qualified as highly original, given that there are no other cross-sectional databases available for consultation by potential cryptocurrency researchers. This means that the contribution to scholarship is also high.  Regarding the structure, the data note under evaluation is of the short-paper type, so the introduction is sufficient.  There are a few issues that should be improved by the authors: In the methodology section, the authors should refer to previous database generation studies with their limitations. In the data description section, the authors should indicate a valid reason why only 30 Stablecoins were selected. In other words, originality in the attempt to construct this database is appreciated. The methodology details the criteria for selecting the sample of 30 stablecoins based on the information that appears in CoinMarketCap, the websites of the stablecoins themselves and other websites (at this point, they could mention some, perhaps including references). I understand that of the 98 listed on CoinMarketCap as of May 2022, many were excluded (down to 30) for the reasons stated. I don't know if Terra USD is no longer classified as a stablecoin after the crash that month (it dropped 40% in value). Do you guys consider keeping it in the sample? If so, I would like you to explain. I find table 1 very interesting as it raises 14 characteristics (a sufficient number) and a description of these. It is a research note that adds value to academic research on this topic. I recommend, however, to expand the references, either in the text or in Table 1, as there are many publications on stablecoins, in order to characterize stablecoins with previous studies and authors. Finally, I thank you for inviting me to review this data note. I found it relevant and interesting.  Is the rationale for creating the dataset(s) clearly described? Yes  Are the protocols appropriate and is the work technically sound? Yes  Are sufficient details of methods and materials provided to allow replication by others? Yes  Are the datasets clearly presented in a useable and accessible format? Yes",
         "0.7868",
         "1",
         "0",
         "0.118260582010582",
         "0.8817",
         "0.9205379486083984",
         "43.12",
         "12.1",
         "14.21",
         "14.8",
         "13.2",
         "97",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "5.0",
         "1.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "5.0",
         "4.0",
         "80.0",
         "86"
        ],
        [
         "2775",
         "Rekha Pillai",
         "03 Feb 2023",
         "Approved",
         "370",
         "Cross-sectional data on stablecoin characteristics",
         "The article presents a dataset on the characteristics of stablecoins. Stablecoins represent a relatively young but increasingly important branch of the cryptocurrency market. Although they all share the same goal of maintaining a stable value in the digital market, they form a highly heterogeneous group. They differ in terms of collateral and stabilization mechanism, peg, availability of the technical documentation, presence on crypto exchanges or age. The dataset is cross-sectional and was created based on internet research. Individual information was collected from websites of the stablecoin projects and a crypto-data aggregator, and to a lesser extent from other auxiliary sources (websites related to finance and cryptocurrencies). The dataset is unique as there are no publicly available databases encompassing the features of stablecoins. It can be used in all stablecoin-related analyses to characterise the examined coins and to investigate the relationship between cryptocurrency market developments and stablecoin features.",
         "109",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The article is novel. The rationale for creating the aforesaid data set is clearly outlined. The authors have collected Individual information from websites of the stablecoin projects and a crypto-data aggregator and they have clearly mentioned about the limited availability of stablecoin related information available on the public domain. It can be considered as an exploratory study as it unearths the stable coin dimensions, a less researched topic but one of high significance.  Future studies can build on the same and this is the main contribution of the paper. The data set is clearly presented in a useable and accessible format. It is clearly evident that no other cross- sectional studies of a similar nature has been conducted till date. However, as a suggestion, you may also justify the rationale behind why only 30 stable coins were selected, although the attempt is highly appreciated. You have clearly highlighted the rationale in excluding certain stable coins but you may elaborate on the total available, ones included and those excluded for providing a comprehensive picture.  As a recommendation to improve the paper, a brief literature review in a tabular form which only contains author names, year and key findings can add value. The paper may include a concluding paragraph, wrapping up the study with some future research/practical implications. Limitations of the study can be highlighted and suggest potential use of aforesaid data collected as recommendations for future research.  Finally thank you for giving this opportunity to review the paper and I hope the comments will be taken positively.  Is the rationale for creating the dataset(s) clearly described? Yes  Are the protocols appropriate and is the work technically sound? Yes  Are sufficient details of methods and materials provided to allow replication by others? Yes  Are the datasets clearly presented in a useable and accessible format? Yes",
         "0.7936",
         "1",
         "0",
         "0.0986591129958477",
         "0.6119",
         "0.8915177583694458",
         "33.65",
         "13.7",
         "16.02",
         "15.8",
         "14.7",
         "97",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "3",
         "4.0",
         "5.0",
         "4.0",
         "92.0",
         "92"
        ],
        [
         "2852",
         "Brian M Gurbaxani",
         "23 Aug 2023",
         "Approved With Reservations",
         "376",
         "Challenges in specifying parameter values for COVID-19 simulation models",
         "A recent modelling paper on the coronavirus disease 2019 (COVID-19) epidemic in the US (Bartsch et al.) suggested that maintaining face mask use until a high vaccine coverage (70–90%) is achieved is generally cost-effective or even cost-saving in many of the scenarios considered. Their conclusion was based on the assumed effectiveness of continued face mask use, cited from a study that reported an 18% reduction in the effective reproduction number associated with the introduction of state-level mask mandate policies in the US in the summer of 2020. However, using this value implicitly assumes that the effect of face mask use in 2021 through 2022 is the same as that of summer 2020, when stringent nonpharmaceutical interventions were in place. The effectiveness of universal mask wearing in 2021–2022 is probably more uncertain than considered in Bartsch et al. and rigorous sensitivity analysis on this parameter is warranted.",
         "336",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors take issue with the fixed, 18% efficacy figure for face masks in the economic evaluation of masks usage post-vaccination paper by Bartsch et al., and of course they are correct: the efficacy isn’t fixed, and it depends on a lot of factors. So the question is: if face mask impact on Rt is a function of 1) social behaviour (e.g. contact rates), 2) quality and quantity of face mask usage, and 3) intrinsic properties of the viral variant circulating (R0)1, and you’re trying to quantify the economic impact of maintaining facemask use during and after a vaccine campaign using a calibration of facemask impact on Rt from an earlier time when all 3 of those factors might be different, then couldn’t your economic impact assessment be off? Yes, it could. I’m not sure that the author’s suggestion of simply widening the uncertainty in the parameter value from 5 to 50% and doing a sensitivity analysis is going to do much good, however, because it won’t answer the policy questions people have, and will leave everyone more uncertain. I think it is possible, through modeling, to recalibrate the impact of facemasks on Rt for more recent times, when better quality masks are more widely available, but the variants are more easily transmissible as well, and society has less of a pandemic, lockdown mentality1,2. One could then present the results of different time periods corresponding to the spread of different variants, but with more certainty, and let the reader decide which scenario is more likely.  Is the rationale for commenting on the previous publication clearly described? Yes  Are any opinions stated well-argued, clear and cogent? Yes  Are arguments sufficiently supported by evidence from the published literature or by new data and results? Partly  Is the conclusion balanced and justified on the basis of the presented arguments? Yes",
         "0.7963",
         "1",
         "0",
         "0.1586038961038961",
         "0.1443",
         "0.902733564376831",
         "33.68",
         "15.7",
         "18.69",
         "17.3",
         "17.7",
         "96",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "2.0",
         "True",
         "neutral",
         "polite",
         "Moderate",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "72.0",
         "72"
        ],
        [
         "2853",
         "José L Herrera-Diestra",
         "07 Sep 2023",
         "Approved",
         "220",
         "Challenges in specifying parameter values for COVID-19 simulation models",
         "A recent modelling paper on the coronavirus disease 2019 (COVID-19) epidemic in the US (Bartsch et al.) suggested that maintaining face mask use until a high vaccine coverage (70–90%) is achieved is generally cost-effective or even cost-saving in many of the scenarios considered. Their conclusion was based on the assumed effectiveness of continued face mask use, cited from a study that reported an 18% reduction in the effective reproduction number associated with the introduction of state-level mask mandate policies in the US in the summer of 2020. However, using this value implicitly assumes that the effect of face mask use in 2021 through 2022 is the same as that of summer 2020, when stringent nonpharmaceutical interventions were in place. The effectiveness of universal mask wearing in 2021–2022 is probably more uncertain than considered in Bartsch et al. and rigorous sensitivity analysis on this parameter is warranted.",
         "351",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  I consider that the case made by the authors in this correspondence are valid and important. Changes in the conditions that lead to the 18% reduction of Rt are certainly a combination of all measures implemented in 2020, and may not be directly applicable in 2021-2022. I agree that a \"rigorous sensitivity analysis\" might be a good starting point. However, besides this sensitivity analysis, more elaborated methods need to be developed to assess more accurately the influence of the different interventions that were in play in the summer of 2020, and which of these interventions could be reasonably extrapolated to 2021-2022.  Is the rationale for commenting on the previous publication clearly described? Yes  Are any opinions stated well-argued, clear and cogent? Yes  Are arguments sufficiently supported by evidence from the published literature or by new data and results? Partly  Is the conclusion balanced and justified on the basis of the presented arguments? Yes",
         "0.7723",
         "1",
         "0",
         "0.1663711288711289",
         "0.1953",
         "0.7168864607810974",
         "29.79",
         "15.2",
         "18.49",
         "17.4",
         "16.9",
         "103",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "3.0",
         "yes",
         "neutral",
         "polite",
         "Moderate",
         "somewhat specific",
         "4.0",
         "5.0",
         "4.0",
         "92.0",
         "92"
        ],
        [
         "2856",
         "Palwinder Singh",
         "14 Jun 2022",
         "Not Approved",
         "333",
         "Anti-inflammatory activity and toxicity evaluation of 1,3-bis(p-hydroxyphenyl)urea",
         "Background: Inflammation is a normal protective response caused by an injury or tissue damage, through physical trauma, damaging chemicals, or invasion of pathogenic microorganisms. One of the modified p-aminophenol compounds is 1,3-bis(p-hydroxyphenyl)urea, which was estimated to have more potent analgesic activity and fewer hepatotoxic side effects than paracetamol. When the lipophilicity of this compound increases between 1.8 to 4.4, it is observed to serve as an anti-inflammatory agent. Therefore, the determination of safety precaution is very necessary while testing for the toxicity effect of 1,3-bis(p-hydroxyphenyl)urea. This is due to the effectiveness and safety of suitable drugs. Methods: An anti-inflammatory test was carried out by measuring the percentage of inflammation in rats, after the administration of 1,3-bis(p-hydroxyphenyl)urea was previously induced by the carrageenan solution intraplantar and the analysis of neutrophil values through a plethysmometer and Hematoxylin-Eosin method. Also, an acute toxicity test was performed by administering this p-aminophenol compound to female rats for 24 h and observed for 14 days. In addition, a subchronic toxicity test was conducted on male and female rats for 28 days, with continuous observations carried out for 42 days. Results: The doses of 1,3-bis(p-hydroxyphenyl)urea at 50, 100, and 200 mg/Kg BW, had anti-inflammatory activity compared to diclofenac sodium at 2.25 mg/Kg BW. Also, there is no toxicity and animal death symptoms were observed in the acute and subchronic tests. Conclusion: This 1,3-bis(p-hydroxyphenyl)urea compound had an anti-inflammatory activity and relatively low toxicity.",
         "62",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This reviewer read the manuscript with interest and rather several times to see what new science has been explored. To my surprise the subject is the compound 1,3-bis(p-hydroxyphenyl)urea. Some of the questions that arise are: Why did the authors choose this compound for the study?  What is the rationale for the selection of 1,3-bis(p-hydroxyphenyl)urea?  Endless data has been recorded by the authors. What reference drug/compound was used? Diclofenac is a COX-1/2 non-selective NSAID. In the first paragraph of ‘Results’ section, it is not clear whether the urea derivative is more potent than diclofenac or not.  Is it not possible to calculate IC50 for this urea derivative against COX-1 and COX-2?  Since this compound has already been studied for its analgesic effect, are  the results of the present study comparable to those already reported?  What exactly is the mode of action of this urea derivative? Does it act through COX-2 inhibition or some other pathway?  What about the COX-1, COX-2 selectivity?  In the light of above mentioned issues, this reviewer is not in favour of indexing this manuscript until the objectives are clear.  Is the work clearly and accurately presented and does it cite the current literature? No  Is the study design appropriate and is the work technically sound? No  Are sufficient details of methods and analysis provided to allow replication by others? No  If applicable, is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are all the source data underlying the results available to ensure full reproducibility? No  Are the conclusions drawn adequately supported by the results? No",
         "0.7545",
         "1",
         "0",
         "0.1541341991341991",
         "0.145",
         "0.7552205324172974",
         "39.84",
         "11.3",
         "12.53",
         "13.2",
         "11.6",
         "96",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "2.0",
         "11.0",
         "no",
         "neutral",
         "neutral",
         "Moderate",
         "3",
         "4.0",
         "2.0",
         "3.0",
         "25.0",
         "27"
        ],
        [
         "2857",
         "Neng Fisheri Kurniati",
         "07 Jul 2022",
         "Approved With Reservations",
         "317",
         "Anti-inflammatory activity and toxicity evaluation of 1,3-bis(p-hydroxyphenyl)urea",
         "Background: Inflammation is a normal protective response caused by an injury or tissue damage, through physical trauma, damaging chemicals, or invasion of pathogenic microorganisms. One of the modified p-aminophenol compounds is 1,3-bis(p-hydroxyphenyl)urea, which was estimated to have more potent analgesic activity and fewer hepatotoxic side effects than paracetamol. When the lipophilicity of this compound increases between 1.8 to 4.4, it is observed to serve as an anti-inflammatory agent. Therefore, the determination of safety precaution is very necessary while testing for the toxicity effect of 1,3-bis(p-hydroxyphenyl)urea. This is due to the effectiveness and safety of suitable drugs. Methods: An anti-inflammatory test was carried out by measuring the percentage of inflammation in rats, after the administration of 1,3-bis(p-hydroxyphenyl)urea was previously induced by the carrageenan solution intraplantar and the analysis of neutrophil values through a plethysmometer and Hematoxylin-Eosin method. Also, an acute toxicity test was performed by administering this p-aminophenol compound to female rats for 24 h and observed for 14 days. In addition, a subchronic toxicity test was conducted on male and female rats for 28 days, with continuous observations carried out for 42 days. Results: The doses of 1,3-bis(p-hydroxyphenyl)urea at 50, 100, and 200 mg/Kg BW, had anti-inflammatory activity compared to diclofenac sodium at 2.25 mg/Kg BW. Also, there is no toxicity and animal death symptoms were observed in the acute and subchronic tests. Conclusion: This 1,3-bis(p-hydroxyphenyl)urea compound had an anti-inflammatory activity and relatively low toxicity.",
         "85",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This article showed that 1,3-bis(p-hydroxyphenyl)urea had anti-inflammatory activity and safe to be used. However the results section in the abstract did not clearly show the efficacy and safety of the compound. Please provide the efficacy with number, percentage or else. Significance calculation should be shown in Figure 1 and 3 to make it easier for the reader to read the results. Legend of the figure and table should give more information, for example, the number of animals, magnification, etc. In Materials and Methods, many information have not been provided, such as the number of animal use for toxicity study, histology procedure, etc.  Please write a good introduction to the study. The first sentence of the paragraph should inform the primary information. Two or three next sentences should provide details information. Avoid repeated information. Furthermore, for the discussion section, please provide a more comprehensive discussion, such as comparing the data with the working hypotheses. Limitation of the study and future study should be mentioned as well.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? No",
         "0.7553",
         "2",
         "0",
         "0.2233870967741935",
         "0.378",
         "0.8138936161994934",
         "30.77",
         "12.7",
         "14.24",
         "14.3",
         "12.9",
         "85",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "3",
         "4.0",
         "3.0",
         "3.0",
         "60.0",
         "66"
        ],
        [
         "3260",
         "Sangeeta Saha",
         "16 Nov 2023",
         "Not Approved",
         "373",
         "Simulation model for the dynamics of dengue with asymptomatic transmission and the effect of temperature",
         "Background: One of the fastest spreading vector-borne diseases in tropical and subtropical regions is dengue, which generates cost overruns for public health entities. Several factors can influence the dynamics of dengue virus transmission: environmental and climatic (abundance of vectors), interactions between hosts (infections by asymptomatic individuals), and population immunological factors. Given these conditions, it is necessary to carry out theoretical studies based on meteorological factors and asymptomatic transmission that are associated with both the existence of the vector and its incidence, in order to provide a scientific basis for health entities in decision-making. Methods: A mathematical model based on nonlinear ordinary differential equations is proposed to interpret the dynamics of dengue transmission in humans coupled to the dynamics of the Aedes aegypti species, considering the population of symptomatic and asymptomatic infected humans and the effect of temperature variability. The basic reproduction number was found and some simulation results based on the Runge-Kutta numerical method were obtained. Results: The simulations showed that the temperature had a directly proportional relationship with the basic reproduction number. The cases of infected people and carrier mosquitoes increased when the temperature peaks increased drastically; in low temperatures the infection persisted with low morbidity due to the survival of asymptomatic people. Conclusions: High temperatures tolerable by mosquitoes increase their life expectancy and their numbers in the environment which, together with a reservoir of asymptomatic infected people, leads to a higher incidence of the dengue virus in certain seasons or maintains its circulation in seasons of low temperatures, despite lower vector survival rates.",
         "546",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors, in the manuscript, have proposed a compartmental epidemic model of dengue transmission where the mosquito biting rate and the transmission rates from host to vector as well as vector to host are assumed to be temperature dependent. The calculations are basic ones and seem to be ok, but there are few points which I need to mention. Firstly, whenever a model is proposed, it is very important to show the biological well-posedness of the system. So, proving the non-negativity and boundedness of the system variables make the base on which the rest of the analysis is performed. Secondly, I am unable to understand how the transmission from mosquito to human depends on the temperature with two types of conditions (noted in equations 15 and 16). It could have been analysed appropriately. Moreover, it is not demonstrated properly how the time variable is connected with the temperature. So, a proper analysis of the second subfigures of each of Figure 2- Figure 4 could improve the work. Also, as per the model assumption, the parameter denoting 'the increase in female mosquito population' should also depend on temperature, but it is chosen as a constant value only. The reason supporting it needs to be mentioned. Altogether I have found the concept interesting, but the mentioned points, if taken care of, will make the work more strong and presentable only.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7553",
         "1",
         "0",
         "0.143034188034188",
         "0.063",
         "0.8884497880935669",
         "33.54",
         "13.7",
         "15.25",
         "15.4",
         "14.1",
         "101",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "3.0",
         "80.0",
         "80"
        ],
        [
         "3261",
         "J H Arias-Castro",
         "16 Nov 2023",
         "Not Approved",
         "255",
         "Simulation model for the dynamics of dengue with asymptomatic transmission and the effect of temperature",
         "Background: One of the fastest spreading vector-borne diseases in tropical and subtropical regions is dengue, which generates cost overruns for public health entities. Several factors can influence the dynamics of dengue virus transmission: environmental and climatic (abundance of vectors), interactions between hosts (infections by asymptomatic individuals), and population immunological factors. Given these conditions, it is necessary to carry out theoretical studies based on meteorological factors and asymptomatic transmission that are associated with both the existence of the vector and its incidence, in order to provide a scientific basis for health entities in decision-making. Methods: A mathematical model based on nonlinear ordinary differential equations is proposed to interpret the dynamics of dengue transmission in humans coupled to the dynamics of the Aedes aegypti species, considering the population of symptomatic and asymptomatic infected humans and the effect of temperature variability. The basic reproduction number was found and some simulation results based on the Runge-Kutta numerical method were obtained. Results: The simulations showed that the temperature had a directly proportional relationship with the basic reproduction number. The cases of infected people and carrier mosquitoes increased when the temperature peaks increased drastically; in low temperatures the infection persisted with low morbidity due to the survival of asymptomatic people. Conclusions: High temperatures tolerable by mosquitoes increase their life expectancy and their numbers in the environment which, together with a reservoir of asymptomatic infected people, leads to a higher incidence of the dengue virus in certain seasons or maintains its circulation in seasons of low temperatures, despite lower vector survival rates.",
         "546",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The article aims to analyze the effects of temperature on dengue transmission considering the asymptomatic population. Initially, a model in which some temperature-dependent parameters are considered is presented. But then, the classical analysis of the model is performed without considering the dependence of the parameters on temperature, which simplifies the analysis of the model and puts it in the classical scheme, which practically makes the subject to be treated lose novelty. Additionally, some scenarios are presented in Figures 3 and 4, which turn out to be analogous because they model situations that have no differences, since the equations turn out to be equivalent, in the case of asymptomatic and infected humans.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7286",
         "1",
         "0",
         "0.1503623188405797",
         "0.0513",
         "0.8830835223197937",
         "22.55",
         "15.9",
         "18.22",
         "17.5",
         "17.0",
         "96",
         "0",
         "0",
         "1",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "no",
         "neutral",
         "neutral",
         "Moderate",
         "2",
         "4.0",
         "3.0",
         "5.0",
         "64.0",
         "66"
        ],
        [
         "3376",
         "Alison Kutywayo",
         "30 Nov 2023",
         "Approved With Reservations",
         "255",
         "A systematic review: Male engagement in adolescent and young adults’ sexual and reproductive health in the Americas",
         "Progress towards sexual and reproductive health (SRH) goals for adolescents across the Americas has stagnated. Of all the regions worldwide, Latin America has experienced the slowest decline in adolescent fertility rates. Reports published by the United Nations and multiple nongovernmental organizations demonstrate a growing consensus for a masculinities framework that engages men and boys in public health and social change. Male engagement acts as a complement - and not a replacement - of current SRH. Emerging evidence indicates that Coronavirus disease in 2019  has worsened SRH outcomes, especially related to gender-based violence; new evidence-based interventions are ever more urgent.  This systematic review includes a focus on education-based male engagement, a special consideration of gender equity, and systematic searches by fluent speakers in three most populous languages in the Americas (English, Spanish, and Portuguese). PubMed, EBSCO, SCOPUS, and Google Scholar databases were digitally searched. Publications were excluded if their focus did not align directly with sexual reproductive health, their location was outside the scope of study, its content derived from information collected before 2010, or its study’s population’s age of focus was not between 15-24 years of age. After abstract screening and full-text review, the original 10,721 articles identified were narrowed down to 13 articles whose references were further examined through hand searching, leading us to a total of 32 final articles chosen for analysis. The results were classified by geographic regions of the American continent. The literature emphasized that society often defines masculinity as a hegemonic role grounded in aggressive high-risk sexual behavior. Adolescent males internalize this and hold their peers to these expectations. These beliefs have detrimental SRH consequences that have yet to be fully understood among adolescent boys and males. The efficacy of future interventions will depend on further exploration of these topics, especially among minority populations.",
         "604",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Thank you for the opportunity to review this systematic review of male engagement in SRH in the Americas. It is an interesting piece of work.  Having reviewed this manuscript, my main comments are related to the structure of the Methods, Results and Discussion. The Results need to be thematically analyzed by theme, rather than by geographical area and there are many things in the Methods that need to be in the Results.  I suggest that the authors please carefully review the following manuscript  ( https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8005924/ ) for guidance on what to include in the respective sections. Table 1 in this PRISMA manuscript provides a clear guide that will help you strengthen your manuscript. In addition to these main comments, I have a 61 editorial comments throughout the manuscript for your consideration. (See attached PDF)  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Not applicable  Are the conclusions drawn adequately supported by the results presented in the review? Partly",
         "0.7795",
         "1",
         "1",
         "0.1264492753623188",
         "0.9417",
         "0.8444064855575562",
         "34.76",
         "13.3",
         "15.39",
         "15.2",
         "15.1",
         "102",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "3.0",
         "True",
         "neutral",
         "polite",
         "Moderate",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "82.0",
         "82"
        ],
        [
         "3490",
         "Hadina Habil",
         "21 Apr 2022",
         "Approved With Reservations",
         "317",
         "Role of English language in agricultural organisations",
         "Background – The importance placed on having good English language proficiency and skills to secure employment in Malaysia is a well-known fact. However, very little is known about the role of the English language in multilingual organisations within the agricultural industry in Malaysia. As such, this study aimed to examine the employees’ perception of the use of the English language in a professional context particularly in the Malaysian agricultural and agricultural related sectors.  Methods – A concurrent triangulation design was used to quantitatively evaluate the data. A total of 320 questionnaires from employees of 10 agriculture and agriculture related companies were analysed.  Additionally, interviews were also conducted with 10 employers from the human resources department as they provided deep insights into the language matters of the organisations.  Results – The employers and employees agree that English language proficiency has economic value and can play an important role at the workplace, as this skill can influence one’s career path in terms of employability and career progression.  Conclusions - From the standpoint of employees, a more insightful idea on the influence of English on career development in the agricultural industry has been obtained. These findings have implications for learning outcomes of students, education system, and policymakers aspiring for the human capital which is needed for Malaysia to become a high income and developed nation.",
         "50",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The findings from the survey questionnaire were not discussed in detail. Therefore, suggestions on how to improve the present situation were not mentioned, although it was stated in the conclusion section that the universities must ensure that the students develop English proficiency and good communication skills. For example, under Results: English language proficiency skills, information can be added to show what the skills are that the respondents can or cannot do with their English language proficiency. The same goes with the second result: Language use in the workplace: the role of English language. More details could be presented as to the role of English in the organisation. This is the same with the third finding: Employees' perception on importance of English. The present information does not provide much information for a detailed discussion of the findings.  The article will be more impactful if more details are provided about the data, the analysis, and the findings so that the discussion would be more precise and suggestions could be given to improve the situation.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? No",
         "0.7112",
         "1",
         "0",
         "0.1878205128205128",
         "0.0999",
         "0.8121065497398376",
         "33.14",
         "13.9",
         "14.88",
         "15.1",
         "15.3",
         "102",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "2.0",
         "80.0",
         "80"
        ],
        [
         "3491",
         "Mekala Sethuraman",
         "31 Mar 2023",
         "Approved With Reservations",
         "826",
         "Role of English language in agricultural organisations",
         "Background – The importance placed on having good English language proficiency and skills to secure employment in Malaysia is a well-known fact. However, very little is known about the role of the English language in multilingual organisations within the agricultural industry in Malaysia. As such, this study aimed to examine the employees’ perception of the use of the English language in a professional context particularly in the Malaysian agricultural and agricultural related sectors.  Methods – A concurrent triangulation design was used to quantitatively evaluate the data. A total of 320 questionnaires from employees of 10 agriculture and agriculture related companies were analysed.  Additionally, interviews were also conducted with 10 employers from the human resources department as they provided deep insights into the language matters of the organisations.  Results – The employers and employees agree that English language proficiency has economic value and can play an important role at the workplace, as this skill can influence one’s career path in terms of employability and career progression.  Conclusions - From the standpoint of employees, a more insightful idea on the influence of English on career development in the agricultural industry has been obtained. These findings have implications for learning outcomes of students, education system, and policymakers aspiring for the human capital which is needed for Malaysia to become a high income and developed nation.",
         "394",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Review of the Research Article: “Role of English Language in Agricultural Organisations” The article deals with the importance of English Language for the employees working in agricultural and agriculture-related organisations. It has employed concurrent triangulation design to analyse the data by quantitatively as well as qualitatively using questionnaires and interviews. The findings of the study reinstates the assumption of the authors on the pivotal role of English language for the employees to survive as well as to secure higher positions in the organisations. The authors suggest that the policymakers in Malaysia have to look into this need and modify the educational policy for enhancing the economic situation of Malaysia besides transforming it into a developed nation in the long run. Overall the article discusses the aim with clarity and suggests solution for the problem addressed. Abstract: Abstract is concise and clear. However, the authors have missed to mention the year of the study being conducted. It would give clear idea to the readers to relate with the educational policy of Malaysia at the time of the study as it plays a huge role in addressing the problem suggested in the article. Introduction: Introduction deals with the explanation on the Language proficiency level of employees in the agricultural and its related sectors. In addition, it discusses the role of agriculture in Malaysian economic growth. The authors should use the recent quote of Ministry of Education as this quote addresses the Proficiency level of graduates and employees. Recent report of graduates’ English language proficiency should be mentioned to explain the current situation in Malaysia. Marschan et al. (1977) quote should be rephrased for clarity. The authors have mentioned ‘previous studies’. However, they have not included the studies published in the year 2021. Methods: As mentioned in the earlier comment, the authors should include the period of the study. Profile of the respondent has not been given in detail but only mentioned that respondents vary at different background knowledge. At the end of the Methods section, the authors have mentioned that the data were categorized into themes. They have not elaborated on the themes they have mentioned. Results: Language Use in the Workplace: Sentence construction on the interpretation of the results should be modified for clarity of expression. Besides, the interpretation should be rechecked by the authors in line with the data presented in Figure 2. Further, in Figure 2, there is repetition of the variables, “Listening/Speaking (Malay)”, which should be revised. Employees’ perception on importance of English: The authors have mentioned that the employees are aware of the ‘importance of the role that language has in the workplace’. Do they have to stress the role of language in general or English language in particular? In the following paragraph, they have said, “it is imperative that they have the language competence”. This implies that the employees have the language competence. But the authors want to explain that the employees understand that they need to have the language competence. So, the authors have to rephrase the statement for clarity. At the end of the paragraph, they have used ‘As an employer explains’. The use of ‘As’ is inappropriate at the place used, as the authors neither have used a statement after the quote nor have merged with previous sentence. So, it is better to remove it. Discussion: The authors have discussed the significance of English language for employees in organisations in general and have not discussed in specific to the role of English language for the employees working in agricultural and its related sectors. How do the findings explain the influence of English language for the employees?. This question has been neglected to be discussed. It is good that the authors have used Piekkari et al.’s (2015) model of Language Barrier to support their theory, but they have not elaborated on its role in specific to the agriculture and its related sectors. Conclusion: The authors have stated conclusion very precisely with clarity. However, it would be good to add two or three sentences on the summary of what the article has dealt with so far.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7113",
         "2",
         "2",
         "0.1383080808080808",
         "0.038",
         "0.9129533767700196",
         "44.75",
         "11.5",
         "12.53",
         "14.2",
         "12.9",
         "99",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "1.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "3",
         "4.0",
         "4.0",
         "4.0",
         "85.0",
         "85"
        ],
        [
         "3554",
         "Slobodan M Janković",
         "21 Feb 2022",
         "Approved",
         "324",
         "Correlation between serum methotrexate-polyglutamate 3 (MTX-PG3) level and disease activity in rheumatoid arthritis patients: A prospective cohort study",
         "Background: Rheumatoid arthritis (RA) is one of the most common autoimmune diseases, characterized by systemic inflammation, joint destruction and disability. Methotrexate (MTX) is used as the primary treatment for RA patients. However, the response to MTX therapy is highly varied and difficult to predict. This study sought to determine the role of MTX by measuring the MTX polyglutamate 3 (MTX-PG3) levels and the disease activity score 28 based on C-reactive protein (DAS28-CRP) of RA patients. Method: A prospective cohort study was conducted at the Rheumatology Polyclinic of Dr. Cipto Mangunkusumo General Hospital. Thirty-four patients with RA were included and followed up to 12 weeks. The RA patients were treated with MTX 10 mg per week and an increased dose of 5 mg per week every month. DAS28-CRP and MTX-PG3 level were assessed at week 8 and 12. Multivariate logistic regression analysis was used to determine the correlation between MTX-PG3 and DAS28-CRP. Result: A total of 34 RA patients were followed and the MTX was well tolerated in which no increase of serum glutamic oxaloacetic transaminase (SGOT), serum glutamic pyruvic transaminase (SGPT) and glomerular filtration rate (GFR) were observed. The mean scores of DAS28-CRP decreased following the MTX-treatment: 3.93, 3.22 and 2.82 at week 0, 8 and 12, respectively. In contrast, the median concentration of MTX-PG3 increased from week 8 to week 12 followed by increasing the dose of MTX. Our analysis suggested there was a moderate positive correlation between MTX-PG3 levels and DAS28-CRP score at week 8 and week 12 post-MTX treatment. Conclusion: The level of MTX-PG3 is correlated with DAS28-CRP score suggesting that MTX-PG3 could be used as an indicator to assess the disease activity in RA patients. Nevertheless, a prospective study with a higher number of patients is needed to confirm this finding.",
         "6",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors made an observational study trying to correlate MTX PG levels with disease activity of RA (as measured by a clinical score). The topic is of general interest, and the study brings results with practical significance. The manuscript is well written, and merits acceptance for publication. However, there are a few issues that should be corrected: In the Methods section the authors should state precisely how they measures the MTX PG levels in erythrocytes. As it is written now, it is not clear whether the MTX PG levels were measured in erythrocytes or in full blood.  Number of patients is small, so it is critical that statistical methods were used properly. The authors should state whether assumptions of multivariate logistic regression were met. Also, what was the categorical outcome used as dependent variable of the regression? Finally, quality of the regression model should be stated (Hosmer Lemeshow test, Cox and Snellen...).  Something should be said about adherence of the patients to the therapy. Was there any method used to check for adherence? If not, mention this in the Limitation paragraph.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7684",
         "1",
         "0",
         "0.1401785714285714",
         "0.0999",
         "0.801764965057373",
         "37.2",
         "12.3",
         "14.25",
         "14.2",
         "12.8",
         "96",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "85.0",
         "80"
        ],
        [
         "3555",
         "Andri Frediansyah",
         "23 Feb 2022",
         "Approved With Reservations",
         "388",
         "Correlation between serum methotrexate-polyglutamate 3 (MTX-PG3) level and disease activity in rheumatoid arthritis patients: A prospective cohort study",
         "Background: Rheumatoid arthritis (RA) is one of the most common autoimmune diseases, characterized by systemic inflammation, joint destruction and disability. Methotrexate (MTX) is used as the primary treatment for RA patients. However, the response to MTX therapy is highly varied and difficult to predict. This study sought to determine the role of MTX by measuring the MTX polyglutamate 3 (MTX-PG3) levels and the disease activity score 28 based on C-reactive protein (DAS28-CRP) of RA patients. Method: A prospective cohort study was conducted at the Rheumatology Polyclinic of Dr. Cipto Mangunkusumo General Hospital. Thirty-four patients with RA were included and followed up to 12 weeks. The RA patients were treated with MTX 10 mg per week and an increased dose of 5 mg per week every month. DAS28-CRP and MTX-PG3 level were assessed at week 8 and 12. Multivariate logistic regression analysis was used to determine the correlation between MTX-PG3 and DAS28-CRP. Result: A total of 34 RA patients were followed and the MTX was well tolerated in which no increase of serum glutamic oxaloacetic transaminase (SGOT), serum glutamic pyruvic transaminase (SGPT) and glomerular filtration rate (GFR) were observed. The mean scores of DAS28-CRP decreased following the MTX-treatment: 3.93, 3.22 and 2.82 at week 0, 8 and 12, respectively. In contrast, the median concentration of MTX-PG3 increased from week 8 to week 12 followed by increasing the dose of MTX. Our analysis suggested there was a moderate positive correlation between MTX-PG3 levels and DAS28-CRP score at week 8 and week 12 post-MTX treatment. Conclusion: The level of MTX-PG3 is correlated with DAS28-CRP score suggesting that MTX-PG3 could be used as an indicator to assess the disease activity in RA patients. Nevertheless, a prospective study with a higher number of patients is needed to confirm this finding.",
         "8",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The researchers looked at 34 people with rheumatoid arthritis (RA) to see if there was a link between MTX-PG levels and how active their RA was. There were two women and 32 men in the study. The subject matter is of general interest, and the study yields useful information. There are, however, a few issues that should be addressed: 1) Please specify the date, duration, and months of the experiment. 2) Please verify the following statement: \"low disease activity, <3.2–5.1\". Is this correct? 3)The methods section is unclear. Please describe it in detail. Is there a particular type of blood (whole blood, red, or white blood cells) that you used in the study? Additionally, please provide detailed information about the centrifugation parameters, such as time, temperature, and g-force/RCF (g). Prior to analysis, is the blood subjected to any special treatment? 4) Please rewrite the section on chromatography measurement and analysis in detail. Include the HPLC specification and brand; column details (including particle size, pore size, inner diameter, and length); ammonium hydrochloride concentration and pH; solvent B composition (or A, if any); and the reference you cited. 5) Did you combine ammonium bicarbonate and ammonium chloride, and if so, in what proportion? Which detector (UV/CAD/MS) did you use? If UV/DAD, at what wavelength did you adjust the detector? 6) Please specify the brand of the MTX-PG3 standard and the R2 (nmol) value of the standard you used.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7661",
         "1",
         "0",
         "0.1242921492921493",
         "0.5077",
         "0.7883067727088928",
         "39.43",
         "11.5",
         "12.66",
         "13.1",
         "11.8",
         "91",
         "0",
         "1",
         "1",
         "0",
         "4.0",
         "5.0",
         "6.0",
         "True",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "84.0",
         "84"
        ],
        [
         "3556",
         "Talha Bin Emran",
         "02 Mar 2022",
         "Approved With Reservations",
         "317",
         "Correlation between serum methotrexate-polyglutamate 3 (MTX-PG3) level and disease activity in rheumatoid arthritis patients: A prospective cohort study",
         "Background: Rheumatoid arthritis (RA) is one of the most common autoimmune diseases, characterized by systemic inflammation, joint destruction and disability. Methotrexate (MTX) is used as the primary treatment for RA patients. However, the response to MTX therapy is highly varied and difficult to predict. This study sought to determine the role of MTX by measuring the MTX polyglutamate 3 (MTX-PG3) levels and the disease activity score 28 based on C-reactive protein (DAS28-CRP) of RA patients. Method: A prospective cohort study was conducted at the Rheumatology Polyclinic of Dr. Cipto Mangunkusumo General Hospital. Thirty-four patients with RA were included and followed up to 12 weeks. The RA patients were treated with MTX 10 mg per week and an increased dose of 5 mg per week every month. DAS28-CRP and MTX-PG3 level were assessed at week 8 and 12. Multivariate logistic regression analysis was used to determine the correlation between MTX-PG3 and DAS28-CRP. Result: A total of 34 RA patients were followed and the MTX was well tolerated in which no increase of serum glutamic oxaloacetic transaminase (SGOT), serum glutamic pyruvic transaminase (SGPT) and glomerular filtration rate (GFR) were observed. The mean scores of DAS28-CRP decreased following the MTX-treatment: 3.93, 3.22 and 2.82 at week 0, 8 and 12, respectively. In contrast, the median concentration of MTX-PG3 increased from week 8 to week 12 followed by increasing the dose of MTX. Our analysis suggested there was a moderate positive correlation between MTX-PG3 levels and DAS28-CRP score at week 8 and week 12 post-MTX treatment. Conclusion: The level of MTX-PG3 is correlated with DAS28-CRP score suggesting that MTX-PG3 could be used as an indicator to assess the disease activity in RA patients. Nevertheless, a prospective study with a higher number of patients is needed to confirm this finding.",
         "15",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Title: Correlation between serum methotrexate-polyglutamate 3 (MTX-PG3) level and disease activity in rheumatoid arthritis patients: A prospective cohort study Minor comments: Although the article has scientific rigor, several minor flows need to be improved before publication: 1. The abstract section is unsuitable—no focus point in the abstract section. 2. \"Nevertheless, a prospective study with a higher number of patients is needed to confirm this finding.\" Is this necessary? 3. Authors are suggested to use the full form when used for the first time throughout the manuscript. 4. The aim of the study should be written as the last paragraph of the introduction. 7. MTX treatment and follow-up: How was this selected? 8. Receiver Operating Characteristics (ROC) analysis: Please describe in further detail. 9. \"Further analysis using the ROC curve showed that MTX-PG3 level…\" needs more insights with relevant references. 10. Presentation of figures is good. 11. Figure legends are appropriate and self-explanatory. 12. The conclusion needs to address future perspectives. 13. Spacing, punctuation marks, grammar, and spelling errors should be reviewed thoroughly.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7843",
         "11",
         "0",
         "0.1904411764705882",
         "0.1939",
         "0.8207837343215942",
         "29.96",
         "13.0",
         "14.06",
         "13.9",
         "13.8",
         "81",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "5.0",
         "7.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "4.0",
         "92.0",
         "92"
        ],
        [
         "3768",
         "Setya Haksama",
         "14 Jan 2022",
         "Approved With Reservations",
         "214",
         "Globalization and life lost due to tuberculosis: evidence from a multi-country study",
         "Background: Tuberculosis affects around 30% of the population of the world. Tuberculosis causes an increase in early mortality and thus has the potential to increase the number of years of life lost. Globalization directly or indirectly by affecting the factors that increase the susceptibility for tuberculosis infection has the potential to increase the spread and mortality due to tuberculosis. This study assessed the causal link between globalization and the years of life lost due to tuberculosis. Methods: Data from the Demographic and Health Survey (DHS) and World Bank for 2004 and 2005 were used for a number of covariates and possible mediators. Data from the Institute of Health Metrics and Evaluation (IHME) were used for the outcome variable and important globalization indicators. The primary health outcome that was studied is tuberculosis and the measure that was used to quantify tuberculosis mortality is the years of life lost (YLL). Path analysis was used. Results: The main independent variables of economic and social integration were not statistically significant. For every unit increase in the proportion of people that were using treated drinking water, there was a -0.0002 decrease in the YLL due to tuberculosis. For every unit increase in the proportion of people with earth floor, there was a 0.0002 units increase in YLL due to tuberculosis. For every unit increase in the proportion of people living using clean fuel, there was a 0.0004 decrease in the YLL due to tuberculosis. Conclusions: Social and economic globalization have no effect on the years of life lost due to tuberculosis, highlighting that globalization actually does not contribute to tuberculosis mortality. However, improving other important determinants such as sanitation, providing safe drinking water and clean households will reduce the mortality due to tuberculosis, highlighting the need to invest in them.",
         "38",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  1. All variables should be written clearly and systematically, first the independent variables should be described, then the dependent variables should be described. 2. Resources of data from World Bank was too old. 3. No data was obtained from 40 countries measured in relation to this research, there should be a ranking for each country that can indicate which countries have good scores and which countries have low scores.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7434",
         "3",
         "0",
         "0.1909999999999999",
         "0.1041",
         "0.7335164546966553",
         "34.76",
         "13.3",
         "15.46",
         "14.9",
         "14.8",
         "101",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "4.0",
         "3.0",
         "4.0",
         "82.0",
         "82"
        ],
        [
         "3769",
         "Mohamed Adil AA",
         "17 Jan 2022",
         "Approved",
         "251",
         "Globalization and life lost due to tuberculosis: evidence from a multi-country study",
         "Background: Tuberculosis affects around 30% of the population of the world. Tuberculosis causes an increase in early mortality and thus has the potential to increase the number of years of life lost. Globalization directly or indirectly by affecting the factors that increase the susceptibility for tuberculosis infection has the potential to increase the spread and mortality due to tuberculosis. This study assessed the causal link between globalization and the years of life lost due to tuberculosis. Methods: Data from the Demographic and Health Survey (DHS) and World Bank for 2004 and 2005 were used for a number of covariates and possible mediators. Data from the Institute of Health Metrics and Evaluation (IHME) were used for the outcome variable and important globalization indicators. The primary health outcome that was studied is tuberculosis and the measure that was used to quantify tuberculosis mortality is the years of life lost (YLL). Path analysis was used. Results: The main independent variables of economic and social integration were not statistically significant. For every unit increase in the proportion of people that were using treated drinking water, there was a -0.0002 decrease in the YLL due to tuberculosis. For every unit increase in the proportion of people with earth floor, there was a 0.0002 units increase in YLL due to tuberculosis. For every unit increase in the proportion of people living using clean fuel, there was a 0.0004 decrease in the YLL due to tuberculosis. Conclusions: Social and economic globalization have no effect on the years of life lost due to tuberculosis, highlighting that globalization actually does not contribute to tuberculosis mortality. However, improving other important determinants such as sanitation, providing safe drinking water and clean households will reduce the mortality due to tuberculosis, highlighting the need to invest in them.",
         "41",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The article highlights important areas in the arena of globalization and the spread of infectious diseases. The article particularly looks into data from a number of countries globally, thus increasing the validity and reliability of the study across continents and also globally.  Could this study be replicated by using longitudinal data to establish causality and stronger inferences? Do the path regression results provide more robust results than OLS analysis? What was the main logic in choosing only a specific set of covariates and not all the possible covariates for tuberculosis?  This a good study and will help in addressing many lacunae in the area of global health research.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7655",
         "1",
         "0",
         "0.1954301075268817",
         "0.072",
         "0.8643754720687866",
         "26.51",
         "14.4",
         "16.64",
         "16.1",
         "14.5",
         "103",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "95.0",
         "True"
        ],
        [
         "3770",
         "Arutselvi Devarajan",
         "18 Jan 2022",
         "Approved",
         "297",
         "Globalization and life lost due to tuberculosis: evidence from a multi-country study",
         "Background: Tuberculosis affects around 30% of the population of the world. Tuberculosis causes an increase in early mortality and thus has the potential to increase the number of years of life lost. Globalization directly or indirectly by affecting the factors that increase the susceptibility for tuberculosis infection has the potential to increase the spread and mortality due to tuberculosis. This study assessed the causal link between globalization and the years of life lost due to tuberculosis. Methods: Data from the Demographic and Health Survey (DHS) and World Bank for 2004 and 2005 were used for a number of covariates and possible mediators. Data from the Institute of Health Metrics and Evaluation (IHME) were used for the outcome variable and important globalization indicators. The primary health outcome that was studied is tuberculosis and the measure that was used to quantify tuberculosis mortality is the years of life lost (YLL). Path analysis was used. Results: The main independent variables of economic and social integration were not statistically significant. For every unit increase in the proportion of people that were using treated drinking water, there was a -0.0002 decrease in the YLL due to tuberculosis. For every unit increase in the proportion of people with earth floor, there was a 0.0002 units increase in YLL due to tuberculosis. For every unit increase in the proportion of people living using clean fuel, there was a 0.0004 decrease in the YLL due to tuberculosis. Conclusions: Social and economic globalization have no effect on the years of life lost due to tuberculosis, highlighting that globalization actually does not contribute to tuberculosis mortality. However, improving other important determinants such as sanitation, providing safe drinking water and clean households will reduce the mortality due to tuberculosis, highlighting the need to invest in them.",
         "42",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This paper explored an important aspect of the public health issue of TB and its association with globalization. I have some suggestions for the authors: The nature of data was cited as the reason for not being able to completely explain the causal link, I suggest the authors mention only association (as the data may exhibit some correlation but not causation) instead of the \"causal link\" in the objective.  Although the current introduction is good, it would be better if there are more indirect indicators or covariates that affect tuberculosis incidence.  The methods section is good and elaborate. The aspects of globalization - economic and social, and other aspects of globalization could also be considered in this research or for future research.  The main outcome variable is Years of Life Lost due to tuberculosis. It would be much better if disability-adjusted life years could have been used in future papers to expand this research.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.765",
         "1",
         "0",
         "0.2096153846153846",
         "0.2025",
         "0.8910351991653442",
         "33.14",
         "13.9",
         "15.74",
         "15.1",
         "14.8",
         "102",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "90.0",
         "90"
        ],
        [
         "4072",
         "Elizabeth A. Stokes",
         "21 Sep 2021",
         "Approved",
         "457",
         "Cost-effectiveness of hydroxychloroquine versus placebo for hand osteoarthritis: economic evaluation of the HERO trial",
         "Background: An economic evaluation alongside the Hydroxychloroquine Effectiveness in Reducing symptoms of hand Osteoarthritis (HERO) trial was undertaken to assess the cost-effectiveness of hydroxychloroquine compared with placebo for symptomatic treatment of hand osteoarthritis for patients with at least moderate hand pain and inadequate response to current therapies. Methods: A trial-based cost–utility analysis was undertaken from the perspective of the UK National Health Service and Personal Social Services over a 12-month time horizon, using evidence from 248 participants included in the HERO trial, conducted in England. Patient-level data were collected prospectively over a 12-month period, using participant-completed questionnaires and investigator forms, to collect healthcare utilisation, costs and quality-adjusted life years (QALYs) using the EQ-5D-5L. The base-case analysis was conducted on an intention-to-treat basis and used multiple imputation methods to deal with missing data. Results were presented in terms of incremental cost-effectiveness ratios (incremental cost per QALY) and net health benefit, with uncertainty surrounding the findings explored using cost-effectiveness acceptability curves. Results: The base-case analysis estimated slightly lower costs on average (−£11.80; 95% confidence interval (CI) −£15.60 to −£8.00) and marginally fewer QALYs (−0.0052; 95% CI −0.0057 to −0.0047) for participants in the hydroxychloroquine group versus placebo group at 12 months. The resulting incremental cost-effectiveness ratio of £2,267 per QALY lost indicated that although costs were saved, health-related quality of life was lost. Even assuming symmetrical preferences regarding losses and gains for health benefits, the findings do not fall within the cost-effective region. Similar findings arose for analyses conducted from the societal perspective and using complete cases only. Conclusions: This economic evaluation indicates that hydroxychloroquine is unlikely to provide a cost-effective pain relief option for improving health-related quality of life in adult patients with moderate-to-severe hand osteoarthritis.",
         "35",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This paper reports a within-trial cost-utility analysis (CUA) and cost-effectiveness analysis (CEA). The paper is clearly written, and appropriate methods have been used to conduct analyses. The text around interventions being cost-effective where findings are reported in terms of cost per QALY lost is very well explained. I have the following comments: A CUA and a CEA were planned, did you pre-specify which was the primary analysis?  Introduction – first sentence – who is at-risk?  Resource use was captured at baseline, 6 and 12 months. Did the questionnaires at each of these time points ask participants to recall their resource use over the previous 6 months? Was resource use captured at baseline solely for the purpose of including baseline costs in the multiple imputation models?  Did you explore the missing at random assumption?  Costs – resource use was captured on day cases, but no unit cost for this is reported in Table 1. Were there no participants who reported a day case admission? Were hospital admissions not captured as there is no chance that this patient group would be admitted for hand OA? In the introduction, surgery is cited as one of the high costs in this patient group.  The mean difference between groups and 95% CI is presented in Table 3 for costs and Table 5 for EQ-5D utilities, but not in Table 2 for resource use? It would help the reader to include this.  Table 3 – did you consider separating medication costs into HCQ and other medications?  The time horizon for the CUA was 12 months but for the CEA was 6 months? While the primary clinical outcome of hand pain severity was measured at 6 months, this was also captured at 12 months. Why was your analysis for this outcome based on a shorter time horizon than the CUA analysis? Was a CEA over 12 months a pre-planned sensitivity analysis?  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7362",
         "1",
         "0",
         "0.1312373737373737",
         "0.1879",
         "0.8965256214141846",
         "45.96",
         "11.0",
         "12.46",
         "13.5",
         "11.2",
         "92",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "9.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "4.0",
         "84.0",
         "84"
        ],
        [
         "4073",
         "David Mark Epstein",
         "10 Dec 2021",
         "Approved",
         "274",
         "Cost-effectiveness of hydroxychloroquine versus placebo for hand osteoarthritis: economic evaluation of the HERO trial",
         "Background: An economic evaluation alongside the Hydroxychloroquine Effectiveness in Reducing symptoms of hand Osteoarthritis (HERO) trial was undertaken to assess the cost-effectiveness of hydroxychloroquine compared with placebo for symptomatic treatment of hand osteoarthritis for patients with at least moderate hand pain and inadequate response to current therapies. Methods: A trial-based cost–utility analysis was undertaken from the perspective of the UK National Health Service and Personal Social Services over a 12-month time horizon, using evidence from 248 participants included in the HERO trial, conducted in England. Patient-level data were collected prospectively over a 12-month period, using participant-completed questionnaires and investigator forms, to collect healthcare utilisation, costs and quality-adjusted life years (QALYs) using the EQ-5D-5L. The base-case analysis was conducted on an intention-to-treat basis and used multiple imputation methods to deal with missing data. Results were presented in terms of incremental cost-effectiveness ratios (incremental cost per QALY) and net health benefit, with uncertainty surrounding the findings explored using cost-effectiveness acceptability curves. Results: The base-case analysis estimated slightly lower costs on average (−£11.80; 95% confidence interval (CI) −£15.60 to −£8.00) and marginally fewer QALYs (−0.0052; 95% CI −0.0057 to −0.0047) for participants in the hydroxychloroquine group versus placebo group at 12 months. The resulting incremental cost-effectiveness ratio of £2,267 per QALY lost indicated that although costs were saved, health-related quality of life was lost. Even assuming symmetrical preferences regarding losses and gains for health benefits, the findings do not fall within the cost-effective region. Similar findings arose for analyses conducted from the societal perspective and using complete cases only. Conclusions: This economic evaluation indicates that hydroxychloroquine is unlikely to provide a cost-effective pain relief option for improving health-related quality of life in adult patients with moderate-to-severe hand osteoarthritis.",
         "115",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors conduct an economic evaluation alongside the RCT. There were no differences found between the groups in terms of hand pain or quality-of-life and no significant differences in costs.  Although there were no differences, it is nevertheless worthwhile publishing these results, in order to avoid \"publication bias\" and guide future research in this area. The study, in general, is well conducted and I have no comments on technical matters.  Rather than calculate an ICER, which implies some measurable difference in outcomes and costs, personally, I would interpret the results in the abstract and conclusions that there were no meaningful or statistically significant differences in any outcomes or costs at 1 year.  The authors do not discuss other therapies or research in this area and this contextual comparison would be useful.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7818",
         "1",
         "0",
         "0.1495833333333333",
         "0.1213",
         "0.8935310244560242",
         "24.68",
         "15.1",
         "16.18",
         "16.0",
         "15.5",
         "99",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "80.0",
         "80"
        ],
        [
         "4195",
         "Rita Margaretha Setianingsih",
         "02 Aug 2021",
         "Approved With Reservations",
         "536",
         "Cultural heritage buildings for urban tourism destinations: portraits of Siantar, Indonesia, in the past",
         "Background: This study was motivated by the failure to use historic buildings, plantations heritage, and modernization of Siantar. The problem is focused on the optimization of historic buildings, icons for urban tourism destinations. The study contribution is useful for the protection, utilization, and development of cultural heritage buildings into a tourist destination in urban areas. More specifically, the study aims to explore and discuss the optimization of urban tourism to support economic and territorial growth. Methods: The study was carried out qualitatively with a pragmatic methodological approach according to the tourism paradigm. The study departs from the colonial archives: photographs, maps, notes, and field research focused on the identification, significance, and contribution to urban history. The data were transcribed verbatim and analyzed thematically. Raw information was reduced and coded according to the relevance of the study. Data are combined into categories and themes reflecting descriptive analysis, classification, and interpretation. Data validation was done through triangulation strategies, member checking, rich descriptions, and saturation.  Results:The Historic Tours of Siantar and Its Surroundings, the findings of this study were carried out in three stages; development based on national consensus in law, utilization into public space, appreciation for managers, and management incentives, and determining urban tourism designs. Conclusions: Utilization of cultural heritage buildings for urban tourism destinations reflects the urban with plantation characteristics, portraits of cities in the past, packed into urban tourism experiences.",
         "24",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  There are no other resources or activities located in urban areas and providing entertainment. For example, what is in the Simbolon area or in the China area around Jalan Dr. Cipto, or in the Simalungun area? More discussion on matters related to The Historic Tours of Siantar and its Surroundings. So the discussion talks about Geopark and others - we recommend discussing the potential that exists in Pematang Siantar urban area.  Cultural heritage is indeed a primary element in urban tourism in Siantar City, but it must also be supported by secondary elements related to the combination of attractiveness that is felt to be unique and becomes a motivation for tourists. Secondary elements describe urban facilities that support and complement the tourist experience. For example, Pematang Siantar has old transportation facilities (such as: BSA = Birmingham Small Arms Company, Java, and others) which may be accessible by tourists for short distances.  There is less description of what tourists should do in Siantar City – something to see, something to do, and something to buy. Something to see – cultural heritage. Something to buy – culinary at Cipto Street, Ganda Bakery, Horas Market. Something to do – walk in the garden, city park walks, Goddess Kwam Im Statue (Vihara Avalokitesvara), Maha Vihara Vidya Maitreya.  In the abstract section, it is mentioned about the research results, one of which is the determination of urban tourism design. But there is nothing in the conclusion and discussion section. It is better to discuss this, especially based on locality and it is better to focus on Siantar City (limited research).  For urban tourism, an itinerary should be made, so that tourists know the list of activities and budget estimates (this is for management incentives). It has been listed, but it extends outside the city of Siantar, for example to the areas of Sarbelawan and Tanohdjawa. This is not in accordance with the title of urban tourism. Maybe the title should be The Historic Tours of Siantar and its Surroundings.  As stated in the abstract on the results of research on the use of public space, the appreciation of managers and incentives for managers has not been discussed and is not included in the conclusions.  It is better to use a library about the city of Siantar, not a library about the Simalungun area or plantations. .  Is the work clearly and accurately presented and does it cite the current literature? No  Is the study design appropriate and is the work technically sound? No  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? No  Are the conclusions drawn adequately supported by the results? No",
         "0.744",
         "2",
         "0",
         "0.114139712488769",
         "0.1136",
         "0.8740142583847046",
         "35.37",
         "13.0",
         "13.84",
         "14.8",
         "13.0",
         "100",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "8.0",
         "no",
         "neutral",
         "neutral",
         "Moderate",
         "2",
         "3.0",
         "4.0",
         "3.0",
         "42.0",
         "42"
        ],
        [
         "4196",
         "Michael Hitchcock",
         "18 Aug 2021",
         "Not Approved",
         "364",
         "Cultural heritage buildings for urban tourism destinations: portraits of Siantar, Indonesia, in the past",
         "Background: This study was motivated by the failure to use historic buildings, plantations heritage, and modernization of Siantar. The problem is focused on the optimization of historic buildings, icons for urban tourism destinations. The study contribution is useful for the protection, utilization, and development of cultural heritage buildings into a tourist destination in urban areas. More specifically, the study aims to explore and discuss the optimization of urban tourism to support economic and territorial growth. Methods: The study was carried out qualitatively with a pragmatic methodological approach according to the tourism paradigm. The study departs from the colonial archives: photographs, maps, notes, and field research focused on the identification, significance, and contribution to urban history. The data were transcribed verbatim and analyzed thematically. Raw information was reduced and coded according to the relevance of the study. Data are combined into categories and themes reflecting descriptive analysis, classification, and interpretation. Data validation was done through triangulation strategies, member checking, rich descriptions, and saturation.  Results:The Historic Tours of Siantar and Its Surroundings, the findings of this study were carried out in three stages; development based on national consensus in law, utilization into public space, appreciation for managers, and management incentives, and determining urban tourism designs. Conclusions: Utilization of cultural heritage buildings for urban tourism destinations reflects the urban with plantation characteristics, portraits of cities in the past, packed into urban tourism experiences.",
         "40",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Generally, the paper is descriptive, and it is not clear what the contribution is to debates about urban heritage and tourism. This is partly a consequence of a lack of an adequate literature review. For example, the paper mentions the World Heritage Site issue, but overlooks some critical texts such as (some I have been involved in): Harrison and Hitchcock (2005)1; Hitchcock, King and Parnwell (2010)2, and King (2016)3. The methodology is a bit disorganised and there is no explanation as to why this one and not another one was selected. It also does not engage sufficiently with other papers on research methods. The name of the approach needs to be stated clearly and close to the beginning of the section. It takes a while to work out what is being done. The results are written in a largely descriptive manner and there is a curious lack of critical engagement. It was not quite clear what the aim of the paper is. It is also inconclusive even though there is an attempt at a Conclusion. In its current form the paper is not indexable, and the authors would need to thoroughly re-write it for it to be accepted. It needs to be thoroughly rewritten with much more development of its analytical purpose and more critical engagement with the existing literature.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? No  Are sufficient details of methods and analysis provided to allow replication by others? No  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7495",
         "1",
         "3",
         "0.1470748299319728",
         "0.1213",
         "0.861151933670044",
         "43.53",
         "12.0",
         "14.38",
         "14.4",
         "12.5",
         "101",
         "0",
         "2",
         "0",
         "0",
         "2.0",
         "4.0",
         "5.0",
         "no",
         "negative",
         "neutral",
         "3",
         "2",
         "3.0",
         "4.0",
         "4.0",
         "44.0",
         "50"
        ],
        [
         "4197",
         "Milena Ivanovic",
         "31 Aug 2021",
         "Not Approved",
         "708",
         "Cultural heritage buildings for urban tourism destinations: portraits of Siantar, Indonesia, in the past",
         "Background: This study was motivated by the failure to use historic buildings, plantations heritage, and modernization of Siantar. The problem is focused on the optimization of historic buildings, icons for urban tourism destinations. The study contribution is useful for the protection, utilization, and development of cultural heritage buildings into a tourist destination in urban areas. More specifically, the study aims to explore and discuss the optimization of urban tourism to support economic and territorial growth. Methods: The study was carried out qualitatively with a pragmatic methodological approach according to the tourism paradigm. The study departs from the colonial archives: photographs, maps, notes, and field research focused on the identification, significance, and contribution to urban history. The data were transcribed verbatim and analyzed thematically. Raw information was reduced and coded according to the relevance of the study. Data are combined into categories and themes reflecting descriptive analysis, classification, and interpretation. Data validation was done through triangulation strategies, member checking, rich descriptions, and saturation.  Results:The Historic Tours of Siantar and Its Surroundings, the findings of this study were carried out in three stages; development based on national consensus in law, utilization into public space, appreciation for managers, and management incentives, and determining urban tourism designs. Conclusions: Utilization of cultural heritage buildings for urban tourism destinations reflects the urban with plantation characteristics, portraits of cities in the past, packed into urban tourism experiences.",
         "53",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The article presents an overview of the heritage buildings in Siantar from the plantation period, the need for their conservation and possible utilisation as attractions in urban tourism, and the development of the heritage tours through the Historic Tours of Siantar and its Surroundings. It could have been an interesting article, but the argument put forward by the researcher falls short of expectations. The article lacks focus, organisation, and constructive argument. Sections presenting the study results and discussion of the findings are intertwined with the literature. Since the aim of the article is not clearly stated, the literature review is misguided and too generalised. In addition, the site description should not be discussed in the literature. Statistical data meant to highlight the growth of urban tourism is confusing, and none is referring to Sumatra and Siantar. The authors cannot use a percentage of urban tourism growth in Europe to argue the potential growth of urban tourism in Sumatra. Europe is the most visited continent globally, the continuous cultural heritage destination with the most famous cities in the world. What exactly are the points for comparison with Sumatra or Siantar? The study is well designed, especially because historical records of historical buildings were checked, compared, and verified on the ground. This approach gives credibility to a study. In addition, the study design follows a strict procedure of the inventory phase of the cultural attractions selection process. The clustering of attractions into four districts is the result of this process. Still, the primary historical significance of each cluster, the linkage corridors and the relationship between the clusters are not explained. The geographical map should be presented showing each cluster and how they are linked. The unique selling point is an offering of European, Chinese, and local heritage clusters surviving in a medium-sized city. The study is not designed to be replicated because it implements the well-known selection process of determining cultural attractions. The sources of data are submitted. General comments: The aim of the article is not clear. Also, the reason for the conservation of cultural heritage is misinterpreted and cannot be for tourism. The main reason should be for education and in building national identity and pride. Tourism is just one of the uses of cultural heritage, but when heritage is negatively impacted by tourism numbers, it should be conserved and protected. Another way of conserving cultural heritage through tourism use is by creating clusters and possibly by theming the areas and, in turn, creating functional tourism precincts. This should be better explained, given the richness of the data obtained on the ground. The inventory is just a starting point -  the first phase of the selection process in turning historic buildings into a tourist attractions. See chapter 7 of [ref 1]. The conceptual framework is too broad. Urban tourism destination is not synonymous with historical heritage destination. It is unclear how nostalgia fits in; it was not well integrated. It is not clear the link between Siantar as a student-friendly city and the further development and inclusion of tourism clusters into urban tours. The size and population of the city and its main urban functions are not explained. If the article is completely rewritten and restructured, it can present a valuable contribution to applying the selection process in creating viable tourism attractions. In its current form, the article is not suitable for indexing.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? No  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7227",
         "2",
         "0",
         "0.1059272300469483",
         "0.072",
         "0.918596625328064",
         "37.1",
         "12.4",
         "13.5",
         "15.3",
         "13.1",
         "100",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "3.0",
         "6.0",
         "no",
         "neutral",
         "neutral",
         "Moderate",
         "2",
         "4.0",
         "3.0",
         "4.0",
         "52.0",
         "80"
        ],
        [
         "4401",
         "Akira Endo",
         "04 May 2021",
         "Approved With Reservations",
         "1775",
         "The feasibility of targeted test-trace-isolate for the control of SARS-CoV-2 variants",
         "The SARS-CoV-2 variant B.1.1.7 reportedly exhibits substantially higher transmission than the ancestral strain and may generate a major surge of cases before vaccines become widely available, while the P.1 and B.1.351 variants may be equally transmissible and also resist vaccines. All three variants can be sensitively detected by RT-PCR due to an otherwise rare del11288-11296 mutation in orf1ab; B.1.1.7 can also be detected using the common TaqPath kit. Testing, contact tracing, and isolation programs overwhelmed by SARS-CoV-2 could slow the spread of the new variants, which are still outnumbered by tracers in most countries. However, past failures and high rates of mistrust may lead health agencies to conclude that tracing is futile, dissuading them from redirecting existing tracers to focus on the new variants. Here we apply a branching-process model to estimate the effectiveness of implementing a variant-focused testing, contact tracing, and isolation strategy with realistic levels of performance. Our model indicates that bidirectional contact tracing can substantially slow the spread of SARS-CoV-2 variants even in regions where a large fraction of the population refuses to cooperate with contact tracers or to abide by quarantine and isolation requests.",
         "18",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study considers the effectiveness of contact tracing focused on variants in reducing the reproduction number. Focusing contact tracing efforts on variants is an interesting approach and may be relevant to the current situation of variant circulations worldwide. The model and the analysis themselves seem well constructed and implemented. However, the authors’ analysis only focuses on a single variant essentially, and does not account for some important aspects that need to be considered to estimate the effect of real-world contact tracing in the presence of multiple variants. As a result, I am not sure if this study provides new insights that are distinct from existing studies on contact tracing for a single-pathogen outbreak. In addition, it should be noted that given a fixed capacity for contact tracing, the reduction in the reproduction number would not be permanent if the outbreak continues to grow. I believe these issues, along with other comments detailed below, need to be addressed for this study to be truly of epidemiological and public health interest. Major comments: Please clarify how this study is distinct from existing studies on contact tracing considering a single-pathogen outbreak (including the authors’ own study cited here).  There seems to be a mismatch between the study motivation/context and the modelling approach. One of the points the authors are trying to make is that the contact tracing efforts should be focused on variants because they are of more epidemiological importance (due to potentially higher transmission or immunoescape). I do not disagree with this point, but there are several major issues regarding how it was handled in the manuscript.  The reproduction number R is used as an objective variable to measure the effect of contact tracing. This is useful to connect interventions and the dynamic evolution of the epidemic, but essentially assumes that the same level of tracing can continue everywhere long-term, regardless of the epidemic size. This is obviously not true as the authors also state in the manuscript. In conditions where R is above 1, transmission of variants would continue and overwhelms the tracing capacity at some point, pushing R back to the original value eventually. Focusing on R may be useful in identifying conditions required to control the outbreak (i.e. R<1), but it is unrealistic to consider that the tracing can keep R lower than the original value in a long term if the resulting value exceeds 1.  Variants are no longer minor in many places now (see for example: https://covid.cdc.gov/covid-data-tracker/#variant-proportions), and I am not sure how much this assumption of ‘minor variants’ is relevant to the actual situation. Moreover, even in places where the variants are still minor, if the (effective) transmissibility of the variants is higher than the existing virus, they would rapidly replace the existing viruses, potentially in a few weeks/months. Exclusion of existing strains. The main argument regarding the tracing capacity is that the variants account for a small proportion of cases and thus can be handled if tracing focuses on these variants. However, even if such focused intervention is possible by tests that can distinguish variants, existing non-variant viruses may continue spreading if their R is above 1. Although such a situation may still have some benefit, e.g. if preventing the spread of immunoescaping variants would ensure the success of the vaccination program, such contexts should be clarified and discussed.  Cost and capacity. As discussed above, contact tracing would work as estimated here only until the capacity is reached. However, I feel efforts associated with tracing is not seriously considered in the analysis. For example, if all contacts of cases within the tracing period are traced, extending the tracing period from 2 days to 6 days would incur substantial additional effort for tracing. I believe it is important to discuss to what extent contact tracing might be sustainable for each setting because the presented results become invalid once the capacity is reached.  Given the points above, I would recommend the authors reconsider what outcome measure to use and how to present them; e.g. consideration of the growth of \"non-targeted\" viruses, conditions required to keep R below 1, whether tracing can “buy time” until achieving a sufficient level of vaccination before reaching the capacity, optimising the intensity of other NPIs (e.g. lockdowns) in the presence of contact tracing, etc., such that the results are relevant to what may actually happen. The Introduction looks lightweight and lacking necessary details or contexts. There are a lot of concepts that may not be familiar enough to every reader but are not sufficiently explained (e.g. TTI, backward contact tracing, bidirectional tracing, why TaqPath test can distinguish B.1.1.7… etc.) and thus may require a succinct clarification. Please also note that this paper may be read in 20 years from now, when the reader may not have the same level of recognition of the current situation. In this light, for example, I feel the first paragraph of Introduction may sound a bit abrupt to the reader who is less aware of the overall timeline of the pandemic. Also see some of the specific comments in the Minor comments section.  The Methods section is too simple and does not contain sufficient information for the reader to comprehend the overall structure of the analysis. Although it does not need to contain every technical detail of the model and analysis as the supplementary methods can be found in the repository (but please include a link and description in the paper so that the reader can easily find it), I feel more information from the supplementary methods should be extracted and summarised in the main text. For example, from the current Methods section I cannot interpret how the course of transmission was characterised, what is the assumed procedure of tracing (Is it always bidirectional tracing? I feel 2-day window is too short for backward tracing), how environmental transmission was assumed to work, how R was calculated, etc.  I believe additional sensitivity analysis would be necessary. For example, the overdispersion parameter (0.11 used in the current analysis) is estimated to be slightly higher (0.3-0.5) in some studies where interventions were in place (Adam et al., 20201). As the authors assume that interventions may be affecting R during contact tracing, possible changes in overdispersion should also be considered. Delay from secondary transmission to quarantine of contacts (defined as a sum of various delay distribution) would also affect the effectiveness of contact tracing in a nontrivial manner.  Is the effect of vaccines not considered, although as in Introduction it was one of the major motivation for considering controlling variants? Vaccines may affect different viruses similarly or differently, depending on the type of variants.  Supplementary Methods, “Identified contacts are quarantined, …isolated, tested, and traced as described above”: what is the difference between quarantining and isolation of traced contacts? Does this mean all traced contacts of a case are put under quarantine regardless of their true infection status, but only tested if they are symptomatic (which changes the label from quarantine to isolation)? If so, it is expected that as the epidemic grows there would be a substantial number of quarantined individuals, and at some point this might be impossible (e.g. due to depletion of essential workers) and the Reff control could collapse.  Minor comments: Throughout: please spell out acronyms at their first appearance, including SARS-CoV-2 and COVID-19.  Introduction, protection against B.1.351 and P.1: now the evidence is not limited to in-vitro studies (e.g. Madhi et al., 20212 and Kustin et al., 20213). Please update and include clinical findings. Also summarise what we know about protection against B.1.1.7.  “All three variants share…; B.1.1.7 can also be…”: I would suggest that the authors first describe B.1.1.7 that can be detected by TaqPath tests (with some more background context, as this is primarily happening in UK and not necessarily recognized by the wider audience) and then go on to a discussion of potential detectability of other variants (because this is only a hypothetical scenario so far in my understanding, as opposed to detection of B.1.1.7). Also, would there be any data on the rollout of these variant-distinguishable tests worldwide?  “Samples testing positive…”: This needs more context. Why is authorisation going to be an issue and why can re-screening bypass it?  “as is true for SARS-CoV-2 – but not yet the variants – in many regions”: I feel this is unclear. TTI capacity would be overwhelmed when the overall caseloads are high, even if the variants account for a very small fraction of them. It should be made clear if this indicates contact tracing would only target variants distinguished by the (variant-specific) tests.  Method, “child cases” may be interpreted as cases that are children. Secondary transmissions?  Results, “In the absence of contact tracing, identification and isolation of symptomatic cases alone reduced Reff by 0.2 to 0.3…”: I couldn’t read this from the top rows of Figure 1. This may correspond to 0% of cases sharing data or 0% trace success probability, but Reff for such a scenario cannot be read from the figure because there is no colour scales or numbers.  “When identification and isolation…substantial effects.”: I am not sure how “moderate levels” and “substantial effects” are defined.  “Due to the exponential growth of uncontrolled epidemics…over a given timespan”: As stated above, this is only the case if contact tracing can continue without hitting the capacity. If R goes back to the original level after tracing is overwhelmed, there may be only a marginal difference in the final epidemic size.  Discussion, “Higher rates of cooperation…quarantine and isolation”: related to the first major comment, these efforts would make tracing more effective but require a substantial amount of effort and cost, and warrant discussion.  Please update references. Many of the preprints cited here have now been published in peer-reviewed journals, which might include more up-to-date information.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? No",
         "0.8027",
         "3",
         "1",
         "0.1066198131137155",
         "0.2522",
         "0.8703778982162476",
         "35.17",
         "13.1",
         "12.42",
         "14.5",
         "13.6",
         "103",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "3.0",
         "11.0",
         "True",
         "negative",
         "neutral",
         "Moderate",
         "somewhat specific",
         "2.0",
         "3.0",
         "2.0",
         "22.0",
         "78"
        ],
        [
         "4402",
         "Tim C. D. Lucas",
         "14 May 2021",
         "Approved With Reservations",
         "828",
         "The feasibility of targeted test-trace-isolate for the control of SARS-CoV-2 variants",
         "The SARS-CoV-2 variant B.1.1.7 reportedly exhibits substantially higher transmission than the ancestral strain and may generate a major surge of cases before vaccines become widely available, while the P.1 and B.1.351 variants may be equally transmissible and also resist vaccines. All three variants can be sensitively detected by RT-PCR due to an otherwise rare del11288-11296 mutation in orf1ab; B.1.1.7 can also be detected using the common TaqPath kit. Testing, contact tracing, and isolation programs overwhelmed by SARS-CoV-2 could slow the spread of the new variants, which are still outnumbered by tracers in most countries. However, past failures and high rates of mistrust may lead health agencies to conclude that tracing is futile, dissuading them from redirecting existing tracers to focus on the new variants. Here we apply a branching-process model to estimate the effectiveness of implementing a variant-focused testing, contact tracing, and isolation strategy with realistic levels of performance. Our model indicates that bidirectional contact tracing can substantially slow the spread of SARS-CoV-2 variants even in regions where a large fraction of the population refuses to cooperate with contact tracers or to abide by quarantine and isolation requests.",
         "28",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  In this study the authors use established and previously published models of contact tracing to examine whether targeted test and trace systems could suppress novel variants. The premise is sound; contact tracing scales poorly, so while it is not necessarily effective at control SARS-CoV-2 at large once national prevalence is high, the numbers of certain variants are still low in a number of countries and therefore contact tracing might be able to control those new variants as they are seeded into a country. Whether this approach would work or not is not trivially obvious and so this study is asking an important question with policy implications globally. The analytical approach taken is quite simple in that the authors assume (and back up with some literature) that the variants can be identified easily and that therefore contact tracing of a new variant can continue without any reference to the dominant variant.  Comments: Most of my comments relate to this assumption that contact tracing of new variants can be modelled by simply ignoring the dominant variant.  First, I would like to see this assumption explicitly stated in the methods just to make it completely clear to the reader.  There are a number of further considerations with this assumption that I think should be discussed.  Given the high rate of vaccination and previous infection with the original SARS-CoV-2 strain, many countries are now in a state where immunity cannot be ignored. This is all handled by Reff, but I think it needs to be mentioned that Reff is combining NPIs, immunity or partial immunity from vaccination (depending on whether there's vaccine escape in the variant)  and partial immunity from previous infection with other strains.  The authors state that new variants can be detected with RT-PCR and TaqPath. However, does this extra step create no extra delay in the process? I imagine this would depend on the specific organisation but might be worth considering and mentioning.  Furthermore, is this identification of variants 100% accurate? The false negative rate (someone is infected with a new variant but the test says they are infected with the original variant) can be just included as part of the test sensitivity and I wouldn't be surprised if the difference is fairly small. More worrying for me is the false positive rate (someone is infected with the original variant but the tests says they are infected with a new variant). This is important because the rationale for the study relies entirely on the fact that there are not many cases with the new variant in a country but if, say, the false positive rate (as defined above) is even 1% then the large number of original variant cases in a country will quickly lead to the targeted test-trace-isolate system being swamped. This effect will obviously vary with the prevalence of original variant SARS-CoV-2.  I only know the literature for the UK, but even the lowest compliance rates used here are much higher than those measured (I wouldn't be surprised if some countries have much high compliance rates though). I am taking my values from the reference below (Smith et al., 20201),  but there might be more up-to-date surveys in the UK and I don't know at all about other countries.  From self-reported behaviour (past behaviour, not intentions) in the UK, about 12% of people with symptoms requested a test. This relates to the 50% of symptomatic cases identified without tracing parameter. Some details of how you selected 50% from ref 32 would be useful, as the values in that paper range from 5% to 100% depending on the country and time. In the UK, of those contacted by track and trace, 11% of people fully complied with 2 weeks self isolation (this relates to the 50%-90% comply with isolation parameter). So at the very least I think it might be useful to state that these values might be quite optimistic in some settings.  Finally, a minor and subjective point, but it might be useful to present Figure 1 with a diverging colour palette that clearly distinguishes Reff < 1 and Reff > 1.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7912",
         "1",
         "0",
         "0.114608760415212",
         "0.1733",
         "0.926215410232544",
         "37.64",
         "14.2",
         "14.79",
         "15.5",
         "15.2",
         "101",
         "0",
         "0",
         "2",
         "0",
         "4.0",
         "5.0",
         "8.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "4.0",
         "5.0",
         "5.0",
         "82.0",
         "82"
        ],
        [
         "4504",
         "Prajwal Ghimire",
         "05 Mar 2021",
         "Approved",
         "249",
         "Case Report: Ziprasidone induced neuroleptic malignant syndrome",
         "Neuroleptic malignant syndrome (NMS) is a well-recognized neurologic emergency. It presents with classic features including hyperthermia, autonomic instability, muscle hypertonia, and mental status changes. The syndrome is potentially fatal and is associated with significant morbidity due to complications such as rhabdomyolysis, acute kidney injury, and ventricular arrhythmias due to the trans-cellular electrolyte shift. NMS is conventionally associated with the first-generation antipsychotic agents, however, has been described with the use of atypical and novel antipsychotics including Ziprasidone. A case of NMS with Ziprasidone use at the therapeutic dose is reported here.",
         "16",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors have presented a rare case report of a well recognised drug induced neurologic emergency of Neuroleptic malignant syndrome due to Ziprasidone. Sedhai et al. have highlighted major challenges and salient points during management of these conditions including the current knowledge regarding its pathophysiology. The case report raises the awareness regarding this potentially life-threatening condition during use of an emerging drug which is now more commonly used for neuro-psychiatric conditions of schizophrenia and bipolar disorders. The case report is well written and highlights the current knowledge and brief literature review in the discussion section with relevant references. It certainly adds a vital information regarding the drug to the current available knowledge in the literature.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Yes  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Yes  Is the case presented with sufficient detail to be useful for other practitioners? Yes",
         "0.7907",
         "2",
         "0",
         "0.0816707717569786",
         "0.0999",
         "0.8509092926979065",
         "23.16",
         "15.6",
         "18.68",
         "17.5",
         "17.9",
         "91",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "5.0",
         "90.0",
         "95"
        ],
        [
         "4505",
         "Ashish Saraf",
         "09 Mar 2021",
         "Approved",
         "209",
         "Case Report: Ziprasidone induced neuroleptic malignant syndrome",
         "Neuroleptic malignant syndrome (NMS) is a well-recognized neurologic emergency. It presents with classic features including hyperthermia, autonomic instability, muscle hypertonia, and mental status changes. The syndrome is potentially fatal and is associated with significant morbidity due to complications such as rhabdomyolysis, acute kidney injury, and ventricular arrhythmias due to the trans-cellular electrolyte shift. NMS is conventionally associated with the first-generation antipsychotic agents, however, has been described with the use of atypical and novel antipsychotics including Ziprasidone. A case of NMS with Ziprasidone use at the therapeutic dose is reported here.",
         "20",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The case report is well written. The authors have given detailed description of the case mentioning the clinical features, the diagnostic workup and treatment given. The other causes of the rigidity have been ruled out during the diagnostic workup. The discussion is also well written and highlighted the importance of this case report.  This case report will definitely make the clinicians aware of the fact of NMS in newer drugs and hence making them vigilant.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Yes  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Yes  Is the case presented with sufficient detail to be useful for other practitioners? Yes",
         "0.7103",
         "1",
         "0",
         "0.0706140350877193",
         "0.0999",
         "0.6933223009109497",
         "33.34",
         "13.8",
         "16.02",
         "15.5",
         "15.4",
         "101",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "yes",
         "neutral",
         "polite",
         "No Hedging",
         "very specific",
         "5.0",
         "4.0",
         "3.0",
         "80.0",
         "83"
        ],
        [
         "4518",
         "Joseph philipraj",
         "22 Mar 2021",
         "Approved",
         "292",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "39",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This systematic review is appropriate for the journal with a global problem of Mets and Urolithiasis. The introduction part clearly explains the motivation. The manuscript is clear and balanced. The manuscript stays focused on the subject. Authors have gone through the process of searching relevant articles from all websites and of sufficient duration. The inclusion and exclusion criteria in the analysis have been clearly stated. The impact of the analysis is clearly stated. The statistical analysis supports the paper well. The interpretation of the results, visualisation are well presented. The tables and figures are clear, relevant and correct. The authors demonstrate the knowledge of basic composition skills, including word choice, sentence structure, paragraph development and grammar. Limitations:  The studies included in the meta-analysis have cross-sectional nature and hence ascertainment of temporal association is not possible which also dictates need for further prospective studies. The specific type of stone formation is not correlated with studies. Despite these limitations all studies included in the meta-analysis showed the same directionality in the association between urolithiasis and Mets.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         "0.7415",
         "1",
         "0",
         "0.1145833333333333",
         "0.0999",
         "0.8487246632575989",
         "30.46",
         "12.8",
         "13.83",
         "14.6",
         "14.3",
         "99",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "4.0",
         "4.0",
         "92.0",
         "92"
        ],
        [
         "4519",
         "Muhammad Faruk",
         "08 Nov 2021",
         "Approved",
         "422",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "270",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study assessed the association between metabolic syndrome and its components with the risk of developing nephrolithiasis by conducting systematic review, Bayesian random-effects meta-analysis, meta-regression and dose-response analysis. This study was done appropriately based on PRISMA flowchart. Risk of bias was also conducted of the included studies. This study has successfully presented the proper meta-analysis for this design. However, to complete this study for indexing, I personally recommended several revisions: 1. Abstract: Introduction section: It is better to address meta-regression as the analysis to assess the correlation of association along with dose-response analysis  Conclusion section: In reporting the association between predictors and nephrolithiasis, state only the predictors in which its coefficient was statistically significant 2. R language was not considered as a statistical software for data analysis. The software for data analysis should be written as \"R\" (Please refer to methods section in statistical analysis subsection). 3. Please update the PRISMA flowchart (refer to PRISMA guideline 2009). 4. Give the numbering of each Forrest plot in Figure 3 and numbering of each meta-regression plot in Figure 4. Design these figures so that it could be well presented. 5. Uniformly decide the word choice of \"traits\" or \"components\", choose whether to use traits or components in the whole text, use one of these words consistently to avoid any misunderstanding. 6. It is better to provide the meta-regression of hypertension in systolic blood pressure and diastolic blood pressure as it is important to explain the relationship to nephrolithiasis in differentiation for these two types of blood pressure. 7. Meta-regression of body mass index  was sufficient in this study thus waist circumference meta-regression was not necessary to be included. 8. Provide the value of coefficient and confidence interval of each meta-regression analysis in the result section so that better understanding of predictors-outcome relationship could be reached clearly.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         "0.7554",
         "7",
         "0",
         "0.1982758620689655",
         "0.2302",
         "0.9299524426460266",
         "24.68",
         "15.1",
         "14.79",
         "16.3",
         "16.8",
         "91",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "4.0",
         "3.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "5.0",
         "4.0",
         "3.0",
         "90.0",
         "90"
        ]
       ],
       "shape": {
        "columns": 37,
        "rows": 110
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_suggestion</th>\n",
       "      <th>length_words</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>days_to_submit</th>\n",
       "      <th>review_text</th>\n",
       "      <th>mattr</th>\n",
       "      <th>question_count</th>\n",
       "      <th>...</th>\n",
       "      <th>llm_llamaV3-2_citation_usage</th>\n",
       "      <th>llm_llamaV3-2_sentiment_polarity</th>\n",
       "      <th>llm_llamaV3-2_politeness</th>\n",
       "      <th>llm_llamaV3-2_hedging</th>\n",
       "      <th>llm_llamaV3-2_specificity</th>\n",
       "      <th>llm_llamaV3-2_domain_terms</th>\n",
       "      <th>llm_llamaV3-2_relevance_alignment</th>\n",
       "      <th>llm_llamaV3-2_readability</th>\n",
       "      <th>llm_llamaV3-2_overall_quality</th>\n",
       "      <th>llm_llamaV3-2_overall_score_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>shaimaa Mohamed Amin</td>\n",
       "      <td>29 Jul 2024</td>\n",
       "      <td>Approved With Reservations</td>\n",
       "      <td>1557</td>\n",
       "      <td>Estimating the efficacy of Newborn-Communicati...</td>\n",
       "      <td>Background Primiparous mothers face diverse ch...</td>\n",
       "      <td>20</td>\n",
       "      <td>Approved With Reservations  info_outline Along...</td>\n",
       "      <td>0.7872</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>Amogh Verma</td>\n",
       "      <td>03 Sep 2024</td>\n",
       "      <td>Approved With Reservations</td>\n",
       "      <td>653</td>\n",
       "      <td>Estimating the efficacy of Newborn-Communicati...</td>\n",
       "      <td>Background Primiparous mothers face diverse ch...</td>\n",
       "      <td>56</td>\n",
       "      <td>Approved With Reservations  info_outline Along...</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Selmy Awad</td>\n",
       "      <td>28 Dec 2024</td>\n",
       "      <td>Approved With Reservations</td>\n",
       "      <td>174</td>\n",
       "      <td>Case Report: A giant ruptured splenic hydatic ...</td>\n",
       "      <td>The splenic localization of hydatid cysts is e...</td>\n",
       "      <td>24</td>\n",
       "      <td>Approved With Reservations  info_outline Along...</td>\n",
       "      <td>0.7693</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>Silvio Buscemi</td>\n",
       "      <td>07 Jan 2025</td>\n",
       "      <td>Approved</td>\n",
       "      <td>280</td>\n",
       "      <td>Case Report: A giant ruptured splenic hydatic ...</td>\n",
       "      <td>The splenic localization of hydatid cysts is e...</td>\n",
       "      <td>34</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>Nitin Liladhar Rane</td>\n",
       "      <td>17 Oct 2024</td>\n",
       "      <td>Approved</td>\n",
       "      <td>239</td>\n",
       "      <td>What we know and what should we know about the...</td>\n",
       "      <td>Background In response to the transformative i...</td>\n",
       "      <td>35</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.7630</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>No Hedging</td>\n",
       "      <td>very specific</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9967</th>\n",
       "      <td>Cliff Ragsdale</td>\n",
       "      <td>12 Mar 2013</td>\n",
       "      <td>Approved</td>\n",
       "      <td>174</td>\n",
       "      <td>Longitudinal RNA sequencing of the deep transc...</td>\n",
       "      <td>Using paired-end RNA sequencing, we have quant...</td>\n",
       "      <td>33</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.8164</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9968</th>\n",
       "      <td>Joyce van de Leemput</td>\n",
       "      <td>14 May 2013</td>\n",
       "      <td>Approved</td>\n",
       "      <td>244</td>\n",
       "      <td>Longitudinal RNA sequencing of the deep transc...</td>\n",
       "      <td>Using paired-end RNA sequencing, we have quant...</td>\n",
       "      <td>96</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.8079</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9978</th>\n",
       "      <td>Elizaveta Kon</td>\n",
       "      <td>06 Feb 2013</td>\n",
       "      <td>Approved</td>\n",
       "      <td>315</td>\n",
       "      <td>Neotendon infilling of a full thickness rotato...</td>\n",
       "      <td>This is a case report on excellent clinical ou...</td>\n",
       "      <td>13</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.8383</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9979</th>\n",
       "      <td>Nicola Maffulli</td>\n",
       "      <td>27 Jan 2014</td>\n",
       "      <td>Approved With Reservations</td>\n",
       "      <td>153</td>\n",
       "      <td>Neotendon infilling of a full thickness rotato...</td>\n",
       "      <td>This is a case report on excellent clinical ou...</td>\n",
       "      <td>368</td>\n",
       "      <td>Approved With Reservations  info_outline Along...</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>positive</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9980</th>\n",
       "      <td>Marco Patruno</td>\n",
       "      <td>21 Mar 2014</td>\n",
       "      <td>Approved</td>\n",
       "      <td>146</td>\n",
       "      <td>Neotendon infilling of a full thickness rotato...</td>\n",
       "      <td>This is a case report on excellent clinical ou...</td>\n",
       "      <td>421</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.8156</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>110 rows × 37 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  reviewer  review_date           review_suggestion  \\\n",
       "16    shaimaa Mohamed Amin  29 Jul 2024  Approved With Reservations   \n",
       "17             Amogh Verma  03 Sep 2024  Approved With Reservations   \n",
       "60              Selmy Awad  28 Dec 2024  Approved With Reservations   \n",
       "61          Silvio Buscemi  07 Jan 2025                    Approved   \n",
       "420    Nitin Liladhar Rane  17 Oct 2024                    Approved   \n",
       "...                    ...          ...                         ...   \n",
       "9967        Cliff Ragsdale  12 Mar 2013                    Approved   \n",
       "9968  Joyce van de Leemput  14 May 2013                    Approved   \n",
       "9978         Elizaveta Kon  06 Feb 2013                    Approved   \n",
       "9979       Nicola Maffulli  27 Jan 2014  Approved With Reservations   \n",
       "9980         Marco Patruno  21 Mar 2014                    Approved   \n",
       "\n",
       "      length_words                                              title  \\\n",
       "16            1557  Estimating the efficacy of Newborn-Communicati...   \n",
       "17             653  Estimating the efficacy of Newborn-Communicati...   \n",
       "60             174  Case Report: A giant ruptured splenic hydatic ...   \n",
       "61             280  Case Report: A giant ruptured splenic hydatic ...   \n",
       "420            239  What we know and what should we know about the...   \n",
       "...            ...                                                ...   \n",
       "9967           174  Longitudinal RNA sequencing of the deep transc...   \n",
       "9968           244  Longitudinal RNA sequencing of the deep transc...   \n",
       "9978           315  Neotendon infilling of a full thickness rotato...   \n",
       "9979           153  Neotendon infilling of a full thickness rotato...   \n",
       "9980           146  Neotendon infilling of a full thickness rotato...   \n",
       "\n",
       "                                               abstract  days_to_submit  \\\n",
       "16    Background Primiparous mothers face diverse ch...              20   \n",
       "17    Background Primiparous mothers face diverse ch...              56   \n",
       "60    The splenic localization of hydatid cysts is e...              24   \n",
       "61    The splenic localization of hydatid cysts is e...              34   \n",
       "420   Background In response to the transformative i...              35   \n",
       "...                                                 ...             ...   \n",
       "9967  Using paired-end RNA sequencing, we have quant...              33   \n",
       "9968  Using paired-end RNA sequencing, we have quant...              96   \n",
       "9978  This is a case report on excellent clinical ou...              13   \n",
       "9979  This is a case report on excellent clinical ou...             368   \n",
       "9980  This is a case report on excellent clinical ou...             421   \n",
       "\n",
       "                                            review_text   mattr  \\\n",
       "16    Approved With Reservations  info_outline Along...  0.7872   \n",
       "17    Approved With Reservations  info_outline Along...  0.7955   \n",
       "60    Approved With Reservations  info_outline Along...  0.7693   \n",
       "61    Approved  info_outline Alongside their report,...  0.7857   \n",
       "420   Approved  info_outline Alongside their report,...  0.7630   \n",
       "...                                                 ...     ...   \n",
       "9967  Approved  info_outline Alongside their report,...  0.8164   \n",
       "9968  Approved  info_outline Alongside their report,...  0.8079   \n",
       "9978  Approved  info_outline Alongside their report,...  0.8383   \n",
       "9979  Approved With Reservations  info_outline Along...  0.8462   \n",
       "9980  Approved  info_outline Alongside their report,...  0.8156   \n",
       "\n",
       "      question_count  ...  llm_llamaV3-2_citation_usage  \\\n",
       "16                 1  ...                          True   \n",
       "17                 1  ...                           yes   \n",
       "60                 1  ...                         False   \n",
       "61                 1  ...                           yes   \n",
       "420                1  ...                           yes   \n",
       "...              ...  ...                           ...   \n",
       "9967               0  ...                           yes   \n",
       "9968               0  ...                          True   \n",
       "9978               0  ...                           yes   \n",
       "9979               0  ...                           yes   \n",
       "9980               0  ...                         False   \n",
       "\n",
       "      llm_llamaV3-2_sentiment_polarity  llm_llamaV3-2_politeness  \\\n",
       "16                             neutral                    polite   \n",
       "17                            positive                    polite   \n",
       "60                             neutral                   neutral   \n",
       "61                             neutral                    polite   \n",
       "420                           positive                    polite   \n",
       "...                                ...                       ...   \n",
       "9967                          positive                    polite   \n",
       "9968                           neutral                   neutral   \n",
       "9978                           neutral                    polite   \n",
       "9979                          positive                   neutral   \n",
       "9980                           neutral                    polite   \n",
       "\n",
       "      llm_llamaV3-2_hedging  llm_llamaV3-2_specificity  \\\n",
       "16                  Minimal          somewhat specific   \n",
       "17                  Minimal          somewhat specific   \n",
       "60                  Minimal          somewhat specific   \n",
       "61                  Minimal          somewhat specific   \n",
       "420              No Hedging              very specific   \n",
       "...                     ...                        ...   \n",
       "9967                Minimal          somewhat specific   \n",
       "9968                Minimal          somewhat specific   \n",
       "9978                Minimal                          2   \n",
       "9979               Moderate          somewhat specific   \n",
       "9980                Minimal          somewhat specific   \n",
       "\n",
       "      llm_llamaV3-2_domain_terms  llm_llamaV3-2_relevance_alignment  \\\n",
       "16                           4.0                                4.0   \n",
       "17                           3.0                                4.0   \n",
       "60                           3.0                                4.0   \n",
       "61                           3.0                                4.0   \n",
       "420                          5.0                                4.0   \n",
       "...                          ...                                ...   \n",
       "9967                         3.0                                4.0   \n",
       "9968                         4.0                                5.0   \n",
       "9978                         4.0                                3.0   \n",
       "9979                         4.0                                4.0   \n",
       "9980                         3.0                                4.0   \n",
       "\n",
       "      llm_llamaV3-2_readability  llm_llamaV3-2_overall_quality  \\\n",
       "16                          3.0                           83.0   \n",
       "17                          4.0                           84.0   \n",
       "60                          3.0                           60.0   \n",
       "61                          5.0                           92.0   \n",
       "420                         3.0                           92.0   \n",
       "...                         ...                            ...   \n",
       "9967                        5.0                           85.0   \n",
       "9968                        3.0                           92.0   \n",
       "9978                        4.0                           76.0   \n",
       "9979                        3.0                           85.0   \n",
       "9980                        5.0                           78.0   \n",
       "\n",
       "      llm_llamaV3-2_overall_score_100  \n",
       "16                                 83  \n",
       "17                               84.0  \n",
       "60                                 60  \n",
       "61                                 92  \n",
       "420                                92  \n",
       "...                               ...  \n",
       "9967                               85  \n",
       "9968                               92  \n",
       "9978                               76  \n",
       "9979                               85  \n",
       "9980                               78  \n",
       "\n",
       "[110 rows x 37 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "paper_id",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_suggestion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "days_to_submit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "llm_length_effort",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_lexical_diversity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_questions_raised",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_citation_usage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_sentiment_polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_hedging",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_specificity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_domain_terms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_relevance_alignment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_readability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_overall_quality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_overall_score_100",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "0b048ed4-65dc-471a-97ae-6f4e822d1d60",
       "rows": [
        [
         "152",
         "3582-4796",
         "Maria-Esther Vidal",
         "25/Nov/2023",
         "Accept",
         "26",
         "PAPyA: a Library for Performance Analysis of SQL-based RDF Processing Systems",
         "Prescriptive Performance Analysis (PPA) has shown to be more useful than traditional descriptive and diagnostic\\nanalyses for making sense of Big Data (BD) frameworks’ performance. In practice, when processing large (RDF) graphs on top of relational BD systems, several design decisions emerge and cannot be decided automatically, e.g., the choice of the schema, the partitioning technique, and the storage formats. PPA, and in particular ranking functions, helps enable actionable insights on performance data, leading practitioners to an easier choice of the best way to deploy BD frameworks, especially for graph processing. However, the amount of experimental work required to implement PPA is still huge. In this paper, we present PAPyA 1, a library for implementing PPA that allows (1) preparing RDF graphs data for a processing pipeline over relational BD systems, (2) enables automatic ranking of the performance in a user-defined solution space of experimental dimensions; (3) allows user-defined flexible extensions in terms of systems to test and ranking methods. We showcase PAPyA on a set of\\nexperiments based on the SparkSQL framework. PAPyA simplifies the performance analytics of BD systems for processing large (RDF) graphs. We provide PAPyA as a public open-source library under an MIT license that will be a catalyst for designing new research prescriptive analytical techniques for BD applications.",
         "8",
         "The authors have addressed my comments and recommend the acceptance of this work. As stated in my previous assessment, the community can positively receive this library.",
         "0.8462",
         "0",
         "0",
         "0.0303030303030303",
         "0.1571",
         "0.6541498899459839",
         "41.36",
         "10.7",
         "14.43",
         "0.0",
         "11.2",
         "26",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "3.0",
         "5.0",
         "4.0",
         "90.0",
         "90"
        ],
        [
         "153",
         "3582-4796",
         "Anonymous",
         "24/Dec/2023",
         "Accept",
         "8",
         "PAPyA: a Library for Performance Analysis of SQL-based RDF Processing Systems",
         "Prescriptive Performance Analysis (PPA) has shown to be more useful than traditional descriptive and diagnostic\\nanalyses for making sense of Big Data (BD) frameworks’ performance. In practice, when processing large (RDF) graphs on top of relational BD systems, several design decisions emerge and cannot be decided automatically, e.g., the choice of the schema, the partitioning technique, and the storage formats. PPA, and in particular ranking functions, helps enable actionable insights on performance data, leading practitioners to an easier choice of the best way to deploy BD frameworks, especially for graph processing. However, the amount of experimental work required to implement PPA is still huge. In this paper, we present PAPyA 1, a library for implementing PPA that allows (1) preparing RDF graphs data for a processing pipeline over relational BD systems, (2) enables automatic ranking of the performance in a user-defined solution space of experimental dimensions; (3) allows user-defined flexible extensions in terms of systems to test and ranking methods. We showcase PAPyA on a set of\\nexperiments based on the SparkSQL framework. PAPyA simplifies the performance analytics of BD systems for processing large (RDF) graphs. We provide PAPyA as a public open-source library under an MIT license that will be a catalyst for designing new research prescriptive analytical techniques for BD applications.",
         "37",
         "The authors have taken care of my comments.",
         "1.0",
         "0",
         "0",
         "0.0",
         "0.1028",
         "0.6380839347839355",
         "80.28",
         "4.1",
         "3.2",
         "0.0",
         "3.8",
         "8",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "True",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "5.0",
         "90.0",
         "95"
        ],
        [
         "196",
         "3552-4766",
         "Alexandry Augustin",
         "02/Oct/2023",
         "Accept",
         "10",
         "Dura-Europos Stories: Developing Interactive Storytelling Applications Using Knowledge Graphs for Cultural Heritage Exploration",
         "We introduce Dura-Europos Stories, a multimedia application for viewing artifacts and places related to the Dura-Europos archaeological excavation. We describe the process of mapping data to the Wikidata data model as well as the process of contributing data to Wikidata. We provide an overview of the functionality of an interactive application for viewing images of the artifacts in the context of their metadata. We contextualize this project as an example of using knowledge graphs in research projects in order to leverage technologies of the Semantic Web in such a way that data related to the project can be easily combined with other data on the web. Presenting artifacts in this story-based application allows users to explore these objects visually, and provides pathways for further exploration of related information.",
         "7",
         "Thank you for amending the manuscript with my prior suggestions.",
         "1.0",
         "0",
         "0",
         "0.0",
         "0.8456",
         "0.6447120308876038",
         "52.87",
         "8.4",
         "16.0",
         "0.0",
         "9.5",
         "10",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "0.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "80.0",
         "82"
        ],
        [
         "197",
         "3552-4766",
         "Anonymous",
         "19/Oct/2023",
         "Accept",
         "102",
         "Dura-Europos Stories: Developing Interactive Storytelling Applications Using Knowledge Graphs for Cultural Heritage Exploration",
         "We introduce Dura-Europos Stories, a multimedia application for viewing artifacts and places related to the Dura-Europos archaeological excavation. We describe the process of mapping data to the Wikidata data model as well as the process of contributing data to Wikidata. We provide an overview of the functionality of an interactive application for viewing images of the artifacts in the context of their metadata. We contextualize this project as an example of using knowledge graphs in research projects in order to leverage technologies of the Semantic Web in such a way that data related to the project can be easily combined with other data on the web. Presenting artifacts in this story-based application allows users to explore these objects visually, and provides pathways for further exploration of related information.",
         "24",
         "Upon reviewing the current version of the manuscript, I am pleased with the improvements and the quality of the content presented. The authors have effectively addressed the previously highlighted concerns. The methodology is well-explained, the results are clearly presented, and the conclusion effectively summarizes the findings. I'd like to remind the authors that using LLM to generate descriptions would not be time-consuming. Simply feeding all the elements into LLM and prompting it to generate a description could serve as a good baseline. Overall, I believe this paper will make a valuable contribution to the existing body of literature. I recommend accepting it.",
         "0.7371",
         "0",
         "0",
         "0.2592592592592592",
         "0.1858",
         "0.7079907655715942",
         "39.74",
         "11.3",
         "14.47",
         "14.3",
         "12.3",
         "99",
         "1",
         "1",
         "0",
         "1",
         "5.0",
         "5.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "5.0",
         "5.0",
         "5.0",
         "95.0",
         "95"
        ],
        [
         "204",
         "3512-4726",
         "Anonymous",
         "04/Oct/2023",
         "Reject",
         "457",
         "Knowledge Level Tags: Applied to Collaborative Recommender Systems on the Web",
         "This article aims to present a tag recommendation model at the knowledge level in a collaborative system on the Web. One of the main reasons for this proposal is due to limitations in the tagging process, causing loss in the quality of the terms used in the metadata that are indexed in posts on social networks in the form of tags, losing the meaning of the relationship between the tags and the object, resulting in a lack of engagement in the collaborative system by not exploring the potential of collective intelligence in a more practical and visual way to be identified by the user when choosing tags in the process of indexing the object. In this study, an algorithm for classifying metadata at the knowledge level is proposed, which uses metrics capable of measuring the collective intelligence aggregated to the metadata generated in the system, with two main steps being assigned, which are the classification and recommendation of a set of tags at the knowledge level.",
         "68",
         "The paper addresses a problem that Twitter researchers face of filtering and identifying relevant tweets by proposing a method to recommend 'better' hashtags to users composing tweet-like content. In doing so, they also propose a number of metrics to determine the quality of a hashtag. They demonstrate their method by means of an implemented system, Cognomy, which is also used to conduct a user experiment to validate their method.  There are multiple problems with the problem statement and the paper. 1. It is not clear how and to what extent better hashtag usage by users will improve the ability of a generic unspecified researcher to identify relevant tweets for their purpose. 2. It is not clear what the characteristics of a 'high-quality' hashtag are and whether users can recognise and use these appropriately when shown a number of examples. 3. There exist multiple hashtag recommendation algorithms in the recommendation systems literature. There is no reference to these algorithms, only to collaborative filtering, so it is not clear how this work relates to existing literature in the relevant field. 4. While there is lengthy discussion of the metrics, there is minimal discussion of how the proposed metrics capture desirable features of high-quality hashtags.  In summary, the paper does not demonstrate or contribute knowledge or experience that is clearly additive to the state of the art. Furthermore, there is no evidence that the proposed recommendation method and metrics address the original problem posed by the paper.  The quality of the writing is strikingly poor with missing words and convoluted language that is hard to comprehend and sometimes sound nonsensical, e.g. 'The proposed metrics aim to improve the quality of metadata used in posts on social networks, offering the user a set of qualified metadata at the level of knowledge where the term used in the metadata has a better understanding of the collective understanding, helping in the content rating process'. Novel ideas such as 'content rating process' above are mentioned without any link to which content is being rated and how. The words metadata, tags, hashtags, terms, knowledge, collective intelligence are used without precise definitions and with low consistency, making it hard to parse text such as 'the metadata term ... has a low level of knowledge compared to the collective intelligence.'  I therefore recommend this paper be rejected in its current state.  The authors have provided resources and data on easily accessible pages. However, I suspect it will be hard to replicate their experiments as I do not see the tweet data and only hashtag data for a sample. Furthermore, the code comments and variable names are in Portuguese (presumably), making it hard to understand the code. There are also similar significant language issues as with the paper.",
         "0.784",
         "4",
         "0",
         "0.0900462962962963",
         "0.2025",
         "0.7808064222335815",
         "40.99",
         "12.9",
         "14.56",
         "15.1",
         "14.2",
         "99",
         "0",
         "2",
         "0",
         "0",
         "2.0",
         "1.0",
         "5.0",
         "no",
         "negative",
         "impolite",
         "Heavy",
         "3",
         "2.0",
         "1.0",
         "2.0",
         "15.0",
         "20"
        ],
        [
         "205",
         "3512-4726",
         "Anonymous",
         "26/Nov/2023",
         "Reject",
         "543",
         "Knowledge Level Tags: Applied to Collaborative Recommender Systems on the Web",
         "This article aims to present a tag recommendation model at the knowledge level in a collaborative system on the Web. One of the main reasons for this proposal is due to limitations in the tagging process, causing loss in the quality of the terms used in the metadata that are indexed in posts on social networks in the form of tags, losing the meaning of the relationship between the tags and the object, resulting in a lack of engagement in the collaborative system by not exploring the potential of collective intelligence in a more practical and visual way to be identified by the user when choosing tags in the process of indexing the object. In this study, an algorithm for classifying metadata at the knowledge level is proposed, which uses metrics capable of measuring the collective intelligence aggregated to the metadata generated in the system, with two main steps being assigned, which are the classification and recommendation of a set of tags at the knowledge level.",
         "121",
         "The paper aims to propose a tag recommendation model for collaborative systems on the web, focusing mainly on the social media platform \"X\" (formerly known as Twitter). In the paper, the authors stated the following main contributions of the paper: (i) a method of classifying and recommending metadata; (ii) a set of metrics to measure the knowledge level of tags/metadata; (iii) applying visual resources to improve interpretation in the tagging process; and (iv) prototype tool development for evaluation.  The paper proposes three type of metrics: (i) KLE - Knowledge Level Estimate, measuring the level of agreement between user-chosen tags and system-generated tags (based on tags produced by other users in the systems); (ii) KLA - Knowledge Level Adaptation, measuring the level and identify possible deviation of user knowledge about the domain; and (iii) MLK - Metadata Knowledge Level, measuring the added knowledge to the tag/metadata in the search process; sum of KLA + KLE. It is hard to accept the paper in its current state, mainly due to no apparent contribution to or application of semantic web technologies as part of the proposed approach. The SWJ webpage for authors [1] clearly states, \"The journal invites high-quality submissions on all topics related to the Semantic Web, including the use of semantic technologies in other contexts than the World Wide Web\", which is not the case with this article.  A GitHub URL for article resources is available, and it contains (i) source code, (ii) example data, and (iii) a README file containing information to replicate the experiment. The resource further clarifies that no semantic web artefacts are involved.  In addition, there are several issues with the paper: (1) Unclear research gaps and research questions The topic of tag recommendation (especially on \"X\"/Twitter) has been investigated for many years. While several approaches to the topic are mentioned and explained in the related work section, there are no apparent research gaps that the authors wanted to address regarding the limitations of the existing approaches.  (2) Limited evaluation and generalization of the approach The evaluation of the approach is conducted within a specific chosen topic. One may question whether the result will differ if a different topic is selected. For user evaluation (Section 8.2.4; Experiment II), how the evaluation is being conducted needs to be clarified, e.g., Are users tasked to propose their hashtags given a tweet? Are they only use the cognomy tool? Are there any control group that conducted the tasks without using the tool? Further, since the paper's main topic is tag recommendation, it is expected that the paper reports a comparison of their approach and state of the art regarding the performance and/or user acceptance of tag recommendation as part of their evaluation. While the result of the Cognomy tool (from the paper) is available, there is no indication of how they fare against state-of-the-art approaches. (3) Quality of writing The paper contains excessive use of lengthy compound sentences, which makes it difficult to read and understand (e.g., the second sentence of the abstract consists of five lines of text). Furthermore, the article did not define key terms, such as \"Knowledge Level Tag\" or \"Collective Intelligence\". Lastly, there are no clear definitions of the terms \"hashtag\", \"tag\", and \"metadata\", which are sometimes used interchangeably.",
         "0.7686",
         "0",
         "1",
         "-0.0501133786848072",
         "0.1213",
         "0.9209131598472596",
         "38.15",
         "14.0",
         "14.92",
         "15.7",
         "16.3",
         "91",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "1.0",
         "4.0",
         "0",
         "2",
         "3",
         "4",
         "2",
         "2.0",
         "2.0",
         "3.0",
         "33.0",
         "36"
        ],
        [
         "206",
         "3512-4726",
         "Anonymous",
         "30/Nov/2023",
         "Major Revision",
         "177",
         "Knowledge Level Tags: Applied to Collaborative Recommender Systems on the Web",
         "This article aims to present a tag recommendation model at the knowledge level in a collaborative system on the Web. One of the main reasons for this proposal is due to limitations in the tagging process, causing loss in the quality of the terms used in the metadata that are indexed in posts on social networks in the form of tags, losing the meaning of the relationship between the tags and the object, resulting in a lack of engagement in the collaborative system by not exploring the potential of collective intelligence in a more practical and visual way to be identified by the user when choosing tags in the process of indexing the object. In this study, an algorithm for classifying metadata at the knowledge level is proposed, which uses metrics capable of measuring the collective intelligence aggregated to the metadata generated in the system, with two main steps being assigned, which are the classification and recommendation of a set of tags at the knowledge level.",
         "125",
         "The article titled “Knowledge Level Tags: Applied to Collaborative Recommender Systems on the Web”. The main contribution of this article lies in the introduction of an algorithm for classifying metadata at the knowledge level, addressing limitations in the tagging process within collaborative systems on the web. By utilizing metrics that measure collective intelligence, the proposed model aims to enhance the quality and meaningful relationships of tags with objects, ultimately improving user engagement in the collaborative system. Introduction section need to rewrite with more valuable points about the proposed work. Some sentences are not clear to understand the motivation of the article. The related work is better to be presented in a table and compare the presented work with the previous work. A comparative table can help to find the gaps of existing work that can be fulfilled by proposed work. Authors are suggested to highlight the limitations of existing approaches. Section 3 and 6 are very short, it doesn’t make sense to have an individual section for a few lines. Please merge these lines in previous sections.",
         "0.7476",
         "0",
         "0",
         "0.0902777777777777",
         "0.1376",
         "0.9656246900558472",
         "36.59",
         "12.6",
         "13.63",
         "14.6",
         "12.9",
         "100",
         "0",
         "2",
         "0",
         "0",
         "4.0",
         "3.0",
         "1.0",
         "yes",
         "neutral",
         "neutral",
         "No Hedging",
         "somewhat specific",
         "2.0",
         "3.0",
         "4.0",
         "80.0",
         "83"
        ],
        [
         "210",
         "3153-4367",
         "Sabbir Rashid",
         "16/Jan/2023",
         "Major Revision",
         "1975",
         "The Numerate Web: Mathematical Formulas and Computations on the Web of Data",
         "Ontologies and related Semantic Web technologies are applied in many areas where\\nmathematical relationships are essential to the domain knowledge.\\nHowever, unlike ontologies and logical rule languages, mathematical expressions\\nand calculation rules are not an intrinsic part of the linked data\\nrepresentation. Therefore, additional mapping processes between semantic domain\\nmodels and the programs executing the mathematical computations are usually\\nrequired.\\nThe Numerate Web is an approach to representing mathematical models with RDF,\\nlinking them to RDF resources and properties, running computations, and finally\\nalso making the results available as part of the RDF representation.",
         "223",
         "SWJ Review In this article, the author presents the Numerate Web, an approach that leverages and extends earlier work to advance the support for the representation of mathematical models in RDF. This work has a significant potential impact, is well-motivated, and is supported through the demonstration of examples. The syntax and incorporated shorthand notations for incorporating mathematical equations are well explained and several algorithms for calculation execution are provided. Nevertheless, despite the numerous strengths of this article, the major shortcoming is the lack of a rigorous quantitative evaluation of the approach. Instead, how this work can be leveraged in the context of two case studies is provided. Additionally, the mathematics in the examples included were relatively straightforward. Could this approach be used for calculus or solving differential equations? There is a mention regarding the incorporation of time-varying behavior as future work, but the discussion on the limitation of this approach should be extended. In terms of mathematics, it should be made very clear what this approach can and cannot do. Listed below are many of the grammatical issues found within the article. Several issues were likely missed, so it is highly recommended that the author addresses the following and also carefully proofreads the article afterward. For example, I didn't comment on the use of Oxford commas, but you mostly use them but in some places do not. Whether or not to use Oxford commas is debatable, but whatever you decide, it should be consistent throughout the paper. Section 1 Page 1 Line 42-43 - Single sentence paragraph, should be combined with the following paragraph. Line 48-49 - Single sentence paragraph, should be combined with the previous paragraph. Line 49 - footnote should go after the punctuation: \"...that both have RDF serializations^1.\" -> \"...that both have RDF serializations.^1\" Page 2 Line 12-14 - Single sentence paragraph, should be combined with the following paragraph or the thought should be expanded upon. Line 37-38 - Single sentence paragraph, should be combined with the previous paragraph. Line 39-40 - Single sentence paragraph, should be combined with the following paragraph, which is also a single sentence paragraph. Section 2 Line 50 - Missing comma: \"In 2003 Marchiori...\" -> \"In 2003, Marchiori...\" Page 3 Line 22 - Missing comma: \"In 2011 Lange...\" -> \"In 2011, Lange...\" Line 25-26 - phrasing and missing comma: \"Additional to OMDoc the work introduces...\" -> \"In addition to OMDoc, the work introduces...\" Line 29 - Missing comma: \"In 2012 Ferre...\" -> \"In 2012, Ferre...\" Line 45-46 - Unnecessary comma: \"For example, constants, and variables are only...\" -> \"For example, constants and variables are only...\" Line 49 - Missing comma: \"In 2014 Munoz...\" -> \"In 2014, Munoz...\" Section 3 Page 4 Line 15-16 - Single sentence paragraph, should be combined with the following paragraph. Line 45-46 - Single sentence paragraph, should be combined with the previous paragraph. As noted for these first 4 pages, many single-sentence paragraphs are included and continue to be included in the remainder of the paper. The use of single-sentence paragraphs is not technically grammatically incorrect. It can serve a stylistic purpose typically for emphasis in story-telling, but that is not the case here so we recommend that such occurrences should be corrected. The remainder of this review will not continue to include comments for single-sentence paragraphs, but that is not because they went unnoticed. We leave it to the authors to remedy this issue. Section 4 Page 6 Line 25 - Figure 5 caption, typo and missing article: \"Example for representig a gear motor as RDF model\" -> \"Example for representing a gear motor as an RDF model\" Section 5 Line 45 - missing comma and article: \"As mentioned in Section 1 these objects may be represented using Content MathML as markup language.\" -> \"As mentioned in Section 1, these objects may be represented using Content MathML as a markup language.\" Page 7 Line 16 - missing comma: \"Therefore an OWL ontology for OpenMath...\" -> \"Therefore, an OWL ontology for OpenMath...\" Page 8 Line 46 - footnote should go after the punctuation: \"...within the POPCORN definition^2.\" -> \"...within the POPCORN definition.^2\" Section 6 Page 9 Line 40 - missing comma: \"Analogous to connecting programming languages to SPARQL endpoints via APIs a hypothetical Content\" -> \"Analogous to connecting programming languages to SPARQL endpoints via APIs, a hypothetical Content\" Page 10 Line 14 - missing comma: \"In [30] we already proposed...\" -> \"In [30], we already proposed...\" Line 16 - footnote should go after the punctuation: \"...is reviewed and available on the OpenMath website^3.\" -> \"...is reviewed and available on the OpenMath website.^3\" Line 42 - missing comma: \"With rdf:resource and rdf:resourceset it is possible to select...\" -> \"With rdf:resource and rdf:resourceset, it is possible to select...\" Line 43 - missing comma: \"However, for traversing the edges further operators are necessary.\" -> \"However, for traversing the edges further, operators are necessary.\" Line 43-44 - phrasing can be improved and it is not clear what is meant here. Why does it say \"with one\" when it seems from the examples that both operators expect multiple values? It should be clarified that \"one and multiple\" is referring to the output of the functions rather than the input: \"For this purpose, two additional operators for RDF properties with one and multiple values are defined: rdf:value and rdf:valueset.\" -> For this purpose, two additional operators for RDF properties with the ability to return a single value or multiple values, respectively, are defined: rdf:value and rdf:valueset.\" Page 11 Line 7 - missing comma: \"Complementary to the operator rdf:value the operator rdf:valueset is able...\" -> \"Complementary to the operator rdf:value, the operator rdf:valueset is able...\" Line 41 - the quotes don't match up: 'A literal with the content \"‘This is an English text.\"’ and the language label \"‘en\"’ is representable...' -> 'A literal with the content \"‘This is an English text.’\" and the language label \"‘en’\" is representable...' Line 48 - footnote should go after the punctuation: \"...and reduce the amount of data required for encoding^4.\" -> \"...and reduce the amount of data required for encoding.^4\" Page 12 Line 1 - missing comma: \"For the RDF operators defined in the previous sections short forms for URIs are not necessary for the functionality.\" -> \"For the RDF operators defined in the previous sections, short forms for URIs are not necessary for the functionality.\" Line 3 - typo: \"...to assign parts of of URIs to...\" -> \"...to assign parts of URIs to...\" Line 4-5 - incompletes sentence: \"In this case, the prefixes...ontology about persons.\" -> \"In this case, the prefixes...ontology about persons are used.\" Line 5 - typo and phrasing: \"As can be can be seen,...\" -> \"As shown,...\" Line 17 - missing comma: \"In order to support prefix declarations in OpenMath semantic attributions could be used, comparable to...\" -> \"In order to support prefix declarations in OpenMath, semantic attributions could be used, comparable to...\" Line 25-26 - redundancy: \"It is possible to overwrite a prefix within a child object is possible.\" -> \"It is possible to overwrite a prefix within a child object.\" Line 35 - tense agreement: \"...the inheritance of the prefixes to child objects itself.\" -> \"...the inheritance of the prefixes to child objects themselves.\" Line 45 - spelling: \"...elements fulfil a certain...\" -> \"...elements fulfill a certain...\" Page 13 Line 1 - missing word: \"...the example shown the efficiency...\" -> \"...the example shown of the efficiency...\" Line 2 - typo: \"...has to be loaded from the from the RDF database.\" -> \"...has to be loaded from the RDF database.\" Line 3 - missing comma: \"If the filter condition could be pushed down to the database then this would allow...\" -> \"If the filter condition could be pushed down to the database, then this would allow...\" Line 35-36 - missing comma and unnecessary comma: \"Therefore it can be checked for consistency by OWL reasoners, and it can be...\" -> \"Therefore, it can be checked for consistency by OWL reasoners and it can be...\" Line 41 - incorrect pluralization: \"In order to improve the usability of mathematical expressions input and output when...\" -> \"In order to improve the usability of mathematical expression inputs and outputs when...\" Section 7 Page 14 Line 33 - typo: \"...their linkage with with RDF resources...\" -> \"...their linkage with RDF resources...\" Line 33 - missing comma: \"On this basis the creation...\" -> \"On this basis, the creation...\" Page 17 Line 26 - unnecessary article: \"The Algorithm 1...\" -> \"Algorithm 1...\" Page 18 Line 44 - unnecessary article: \"The algorithm 2...\" -> \"Algorithm 2...\" Page 19 Line 20-21 - unnecessary article: \"...(line 12 of the Algorithm 2).\" -> \"...(line 12 of Algorithm 2).\" Page 20 Line 1-2 - unnecessary article: \"To support this, the algorithms 1 and 3 must be adapted...\" -> \"To support this, Algorithms 1 and 3 must be adapted...\" Line 4 - phrasing: \"An example depicts Figure 7, which shows...\" -> \"An example is depicted in Figure 7, which shows...\" Line 25 - footnote goes after the punctuation: \"...Ontology^9 (MUO).\" -> \"...Ontology (MUO).^9\" Line 29-30 - phrasing: \"...with QUDT contains [56, pp. 294].\" -> \"...with QUDT is contained in [56, pp. 294].\" Line 42 - unnecessary article: \"...into the algorithm 3...\" -> \"...into Algorithm 3...\" Line 46 - footnote goes after the punctuation: \"An example is shown in Listing 13^11, where...\" -> \"An example is shown in Listing 13,^11 where...\" Page 21 Line 40 - missing comma: \"For this purpose the conversion...\" -> \"For this purpose, the conversion...\" Line 42 - missing commas: \"For the given example therefore the conversion...\" -> \"For the given example, therefore, the conversion...\" Page 22 Line 8 - missing comma: \"...via OWL restrictions as shown in Listing 14.\" -> \"...via OWL restrictions, as shown in Listing 14.\" Section 8 Line 29 - missing commas: \"The first case study OpenMath Content Dictionaries (Section 8.2) investigates...\" -> \"The first case study, OpenMath Content Dictionaries (Section 8.2), investigates...\" Line 33 - missing commas: \"The second case study process chain planning and evaluation (Section 8.3) investigates...\" -> \"The second case study, process chain planning and evaluation (Section 8.3), investigates...\" Line 39 - typo: \"...described insection 8.1 was...\" -> \"...described in Section 8.1 was...\" Line 49 - footnote goes after the punctuation: \"...representation of mathematical objects and the execution of calculations^12.\" -> \"...representation of mathematical objects and the execution of calculations.^12\" Page 23 Line 37 - redundancy: \"For example, the KOMMA ontology editor, for example, supports textual...\" -> \"For example, the KOMMA ontology editor supports textual...\" Line 42 - capitalization of proper noun: \"As already described in section 5, OpenMath...\" -> \"As already described in Section 5, OpenMath...\" Page 24 Line 4 - footnote goes after the punctuation: \"...platform eniLINK^14, an extension...\" -> \"...platform eniLINK,^14 an extension...\" Page 26 Line 2 - typo: \"...sums or products in in any...\" -> \"...sums or products in any...\" Line 5 - footnote goes after the punctuation: \"...SPARQL query^19.\" -> \"...SPARQL query.^19\" Line 44 - typo: \"...calculations wer developed with...\" -> \"...calculations were developed with...\" Page 31 Line 46 - footnote goes after the punctuation: \"...into the Schema.org vocabulary^21.\" -> \"...into the Schema.org vocabulary.^21\" Line 46-47 - phrasing: \"An example of the use of the GoodRelations ontology for the domain mountain sports equipment gives [67].\" -> \"An example of the use of the GoodRelations ontology for the domain mountain sports equipment is given in [67].\" Page 32 Line 36 - unnecessary comma: \"...the integration of external data in mathematical models is possible, if it is available in an RDF...\" -> \"...the integration of external data in mathematical models is possible if it is available in an RDF...\" Line 41 - capitalization: \"...in section 8.1 extended...\" -> \"...in Section 8.1 extended...\" Line 47 - unnecessary article: \"The figure 18...\" -> \"Figure 18...\" Page 34 Line 18 - phrasing: \"Questions are here the embedding...\" -> \"Questions include the embedding...\"",
         "0.5918",
         "2",
         "4",
         "-0.0331199225096863",
         "0.1878",
         "0.8533676862716675",
         "51.95",
         "8.7",
         "7.44",
         "11.5",
         "11.0",
         "103",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "8.0",
         "yes",
         "neutral",
         "neutral",
         "No Hedging",
         "somewhat specific",
         "3.0",
         "4.0",
         "3.0",
         "75.0",
         "82"
        ],
        [
         "211",
         "3153-4367",
         "Anonymous",
         "29/Jan/2023",
         "Major Revision",
         "239",
         "The Numerate Web: Mathematical Formulas and Computations on the Web of Data",
         "Ontologies and related Semantic Web technologies are applied in many areas where\\nmathematical relationships are essential to the domain knowledge.\\nHowever, unlike ontologies and logical rule languages, mathematical expressions\\nand calculation rules are not an intrinsic part of the linked data\\nrepresentation. Therefore, additional mapping processes between semantic domain\\nmodels and the programs executing the mathematical computations are usually\\nrequired.\\nThe Numerate Web is an approach to representing mathematical models with RDF,\\nlinking them to RDF resources and properties, running computations, and finally\\nalso making the results available as part of the RDF representation.",
         "236",
         "Abstract section need to discuss more about the proposed work. The major findings should be discussed with the significance of Numerate Web. The major contribution of this paper: proposed an approach for structured semantic models of systems as an ontology for mathematical expressions and design of a textual syntax and methods for accessing RDF data within mathematical formulas. Finally, the proposed work has been evaluated. Introduction section should be more descriptive with the proposed work and its findings. Authors have discussed the limitations in the related work section but it should be concisely discussed the need to propose a new web as Numerate Web. Community and readers should be satisfied with the proposal. It is also noticed that related work section only discussed till 2014 papers so is there no any research has been done after 2014 in this area or authors missing to include please check it carefully. Numerate Web Applications has included as a new layer of Semantic Web Layer Cake, it is challenging as there are already several mathematical ontologies and vocabularies are available so is it really needed to include a new layer. Authors should justify this. Algorithms are organized well and the proposed approach can provide an essential basis for future applications in digital system models and mathematical knowledge management. There are some typo mistakes that need to handle carefully such as, “Fig. 5. Example for representig representing a gear motor as RDF model”",
         "0.8063",
         "1",
         "0",
         "0.1086700336700336",
         "0.0981",
         "0.8590922355651855",
         "35.88",
         "12.8",
         "13.39",
         "14.0",
         "12.8",
         "104",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "4.0",
         "3.0",
         "80.0",
         "86"
        ],
        [
         "212",
         "3153-4367",
         "Anonymous",
         "06/Feb/2023",
         "Minor Revision",
         "437",
         "The Numerate Web: Mathematical Formulas and Computations on the Web of Data",
         "Ontologies and related Semantic Web technologies are applied in many areas where\\nmathematical relationships are essential to the domain knowledge.\\nHowever, unlike ontologies and logical rule languages, mathematical expressions\\nand calculation rules are not an intrinsic part of the linked data\\nrepresentation. Therefore, additional mapping processes between semantic domain\\nmodels and the programs executing the mathematical computations are usually\\nrequired.\\nThe Numerate Web is an approach to representing mathematical models with RDF,\\nlinking them to RDF resources and properties, running computations, and finally\\nalso making the results available as part of the RDF representation.",
         "244",
         "The author presented a formal approach aiming to define mathematical models using RDF-based techniques and overcome limitations of current semantic-based languages (e.g., SWRL and SPARQL). The proposal also includes a specific rule language and a textual syntax (named POPCORN-LD) for modeling mathematical objects and properties following the linked data guidelines. Two simple case studies are evaluated using a KOMMA-based application framework extending the basic software with additional functionalities. The proposed approach is interesting and coherent with Semantic Web journal aims. The idea is quite original but it is difficult to understand the real benefits of the work with respect to state of the art frameworks in real-world scenarios. This aspect should be emphasized in the case study section. The manuscript is well written and easy to follow. The background section provides a brief but satisfactory overview of the domain and related work. The software is publicly available on GitHub and the user interface is minimalist and simple to use. Source code is well organized and the README file details all steps required to run the software. General remarks: - Section 2, include a comparison table to summarize and highlight the main features of all cited works. I also suggest to identify, if existing, further recent approaches proposed in the last 2 years; - Section 7.6 is very interesting and should be extended with more details and examples about inheritance and overwriting of mathematical rules; - Section 8.1, KOMMA is a very useful framework for this work but a possible integration in Protégé should be taken into consideration to facilitate the usage of the system in the Semantic Web community; - is it possible to use the proposed system without KOMMA? Are there any specific APIs? The case study described is Section 8.3 can be easily extended to Industry 4.0 scenarios for data management/processing. An implementation running on embedded platforms could be very useful; - a performance evaluation section is suggested to compare the proposed approach with existing works also in terms of processing time. Minor remarks and suggestions: - Section 1, introduction should end with some details about all sections of the paper. Move here the paragraph reported in Section 3, p.5, lines 18-29; - Sections 4-5-6-7 can be organized as subsections of Section 3, representing the fundamental elements of the whole Numerate Web vision; - Section 8.4 is very concise. Aggregate with Section 9; - p.12, line 3, \"of of\" --> \"of\"; - p.25, figure 10 is not cited in the text; - rename the Github repository, \"numerateweb-swj-2022\" --> \"numerateweb\"; - include a docker (or vagrant) configuration file to simplify building and running the web application.",
         "0.7918",
         "0",
         "0",
         "0.1402450980392157",
         "0.1695",
         "0.8603233695030212",
         "38.62",
         "11.8",
         "12.62",
         "13.4",
         "12.5",
         "90",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "1.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "4.0",
         "5.0",
         "85.0",
         "85"
        ],
        [
         "280",
         "3116-4330",
         "Anonymous",
         "01/Jun/2022",
         "Accept",
         "25",
         "Publishing planned, live and historical public transport data on the Web with the Linked Connections framework",
         "Publishing transport data on the Web for consumption by others poses several challenges for data publishers. In\\naddition to planned schedules, access to live schedule updates (e.g. delays or cancellations) and historical data is fundamental to enable reliable applications and to support machine learning use cases. However publishing such dynamic data further increases the computational burden for data publishers, resulting in often unavailable historical data and live schedule updates for most public transport networks. In this paper we apply and extend the current Linked Connections approach for static data to also support cost-efficient live and historical public transport data publishing on the Web. Our contributions include (i) a reference specification and system architecture to support cost-efficient publishing of dynamic public transport schedules and historical data; (ii) empirical evaluations on route planning query performance based on data fragmentation size, publishing costs and a comparison with a traditional route planning engine such as OpenTripPlanner; (iii) an analysis of potential correlations of query performance with particular public transport network characteristics such as size, average degree, density, clustering coefficient and average connection duration. Results confirm that fragmentation size influences route planning query performance and\\nconverges on an optimal fragment size per network. Size (stops), density and connection duration also show correlation with route planning query performance. Our approach proves to be more cost-efficient and in some cases outperforms OpenTripPlanner when supporting the earliest arrival time route planning use case. Moreover, the cost of publishing live and historical schedules remains in the same order of magnitude for server-side resources compared to publishing planned schedules only. Yet, further optimizations are needed for larger networks (> 1000 stops) to be useful in practice. Additional dataset fragmentation strategies (e.g. geospatial) may be studied for designing more scalable and performant Web API s that adapt to particular use cases, not only limited to the public transport domain.",
         "40",
         "I recognize that the authors have revised parts of the text and added some detailed explanations. I stand by my recommendation to accept the paper.",
         "0.88",
         "0",
         "0",
         "0.4",
         "0.2468",
         "0.6021196246147156",
         "58.79",
         "8.2",
         "9.8",
         "0.0",
         "8.0",
         "25",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "4.0",
         "5.0",
         "80.0",
         "84"
        ],
        [
         "281",
         "3116-4330",
         "Anonymous",
         "13/Jun/2022",
         "Accept",
         "20",
         "Publishing planned, live and historical public transport data on the Web with the Linked Connections framework",
         "Publishing transport data on the Web for consumption by others poses several challenges for data publishers. In\\naddition to planned schedules, access to live schedule updates (e.g. delays or cancellations) and historical data is fundamental to enable reliable applications and to support machine learning use cases. However publishing such dynamic data further increases the computational burden for data publishers, resulting in often unavailable historical data and live schedule updates for most public transport networks. In this paper we apply and extend the current Linked Connections approach for static data to also support cost-efficient live and historical public transport data publishing on the Web. Our contributions include (i) a reference specification and system architecture to support cost-efficient publishing of dynamic public transport schedules and historical data; (ii) empirical evaluations on route planning query performance based on data fragmentation size, publishing costs and a comparison with a traditional route planning engine such as OpenTripPlanner; (iii) an analysis of potential correlations of query performance with particular public transport network characteristics such as size, average degree, density, clustering coefficient and average connection duration. Results confirm that fragmentation size influences route planning query performance and\\nconverges on an optimal fragment size per network. Size (stops), density and connection duration also show correlation with route planning query performance. Our approach proves to be more cost-efficient and in some cases outperforms OpenTripPlanner when supporting the earliest arrival time route planning use case. Moreover, the cost of publishing live and historical schedules remains in the same order of magnitude for server-side resources compared to publishing planned schedules only. Yet, further optimizations are needed for larger networks (> 1000 stops) to be useful in practice. Additional dataset fragmentation strategies (e.g. geospatial) may be studied for designing more scalable and performant Web API s that adapt to particular use cases, not only limited to the public transport domain.",
         "52",
         "All my previous comments were addressed by the authors in the current version of the paper or the revision letter.",
         "0.85",
         "0",
         "0",
         "-0.0833333333333333",
         "0.1028",
         "0.568379282951355",
         "51.18",
         "11.1",
         "12.0",
         "0.0",
         "10.9",
         "20",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "True",
         "neutral",
         "neutral",
         "No Hedging",
         "somewhat specific",
         "3.0",
         "5.0",
         "4.0",
         "92.0",
         "92"
        ],
        [
         "330",
         "3207-4421",
         "Anne Thessen",
         "01/Sep/2022",
         "Minor Revision",
         "122",
         "Reuse of the FoodOn Ontology in a Knowledge Base of Food Composition Data",
         "We describe our work to integrate the FoodOn ontology with our knowledge base of food composition data, WikiFCD. WikiFCD is knowledge base of structured data related to food composition and food items. With a goal to reuse FoodOn identifiers for food items, we imported a subset of the FoodOn ontology into the WikiFCD knowledge base. We aligned the import via a shared use of NCBI taxon identifiers for the taxon names of the plants from which the food items are derived. Reusing FoodOn benefits WikiFCD by allowing us to leverage the food item groupings that FoodOn contains. This integration also has potential future benefits for the FoodOn community due to the fact that WikiFCD provides food composition data at the food item level, and that WikiFCD is mapped to Wikidata and contains a SPARQL endpoint that supports federated queries. Federated queries across WikiFCD and Wikidata allow us to ask questions about food items that benefit from the cross-domain information of Wikidata, greatly increasing the breadth of possible data combinations. ",
         "28",
         "Overall, this is an interesting paper. I think making the types of connections that are described in this paper will be helpful for my work. I have a few minor suggestions. 1. I find that referring to properties by number can be confusing. This could just be me and is not an important change. 2. When I visited tinyurl.com/28uu3sm5 I got a \"query malformed\" error. 3. page 7 line 51 \"that has\" should be \"that have\" 4. page 8 line 12 \"diaries and\" should be \"diaries are\" 5. If you need an identifier for a taxon that is not in NCBI you would probably have more luck looking in Catalog of Life or Encyclopedia of Life. This is not an important change.",
         "0.7362",
         "2",
         "0",
         "0.15625",
         "0.3011",
         "0.7357035875320435",
         "77.13",
         "5.3",
         "8.7",
         "10.2",
         "4.6",
         "85",
         "1",
         "2",
         "0",
         "0",
         "5.0",
         "4.0",
         "3.0",
         "True",
         "neutral",
         "neutral",
         "No Hedging",
         "neutral",
         "2.0",
         "4.0",
         "3.0",
         "80.0",
         "82"
        ],
        [
         "331",
         "3207-4421",
         "Anonymous",
         "05/Oct/2022",
         "Accept",
         "133",
         "Reuse of the FoodOn Ontology in a Knowledge Base of Food Composition Data",
         "We describe our work to integrate the FoodOn ontology with our knowledge base of food composition data, WikiFCD. WikiFCD is knowledge base of structured data related to food composition and food items. With a goal to reuse FoodOn identifiers for food items, we imported a subset of the FoodOn ontology into the WikiFCD knowledge base. We aligned the import via a shared use of NCBI taxon identifiers for the taxon names of the plants from which the food items are derived. Reusing FoodOn benefits WikiFCD by allowing us to leverage the food item groupings that FoodOn contains. This integration also has potential future benefits for the FoodOn community due to the fact that WikiFCD provides food composition data at the food item level, and that WikiFCD is mapped to Wikidata and contains a SPARQL endpoint that supports federated queries. Federated queries across WikiFCD and Wikidata allow us to ask questions about food items that benefit from the cross-domain information of Wikidata, greatly increasing the breadth of possible data combinations. ",
         "62",
         "This manuscript was submitted as 'full paper' and should be reviewed along the usual dimensions for research contributions which include (1) originality, (2) significance of the results, and (3) quality of writing. Please also assess the data file provided by the authors under “Long-term stable URL for resources”. In particular, assess (A) whether the data file is well organized and in particular contains a README file which makes it easy for you to assess the data, (B) whether the provided resources appear to be complete for replication of experiments, and if not, why, (C) whether the chosen repository, if it is not GitHub, Figshare or Zenodo, is appropriate for long-term repository discoverability, and (4) whether the provided data artifacts are complete. Please refer to the reviewer instructions and the FAQ for further information.",
         "0.7382",
         "0",
         "0",
         "0.174074074074074",
         "0.2893",
         "0.7036123275756836",
         "20.76",
         "18.6",
         "20.24",
         "18.2",
         "20.5",
         "91",
         "0",
         "1",
         "2",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "4.0",
         "85.0",
         "85"
        ],
        [
         "332",
         "3207-4421",
         "Anonymous",
         "13/Oct/2022",
         "Accept",
         "133",
         "Reuse of the FoodOn Ontology in a Knowledge Base of Food Composition Data",
         "We describe our work to integrate the FoodOn ontology with our knowledge base of food composition data, WikiFCD. WikiFCD is knowledge base of structured data related to food composition and food items. With a goal to reuse FoodOn identifiers for food items, we imported a subset of the FoodOn ontology into the WikiFCD knowledge base. We aligned the import via a shared use of NCBI taxon identifiers for the taxon names of the plants from which the food items are derived. Reusing FoodOn benefits WikiFCD by allowing us to leverage the food item groupings that FoodOn contains. This integration also has potential future benefits for the FoodOn community due to the fact that WikiFCD provides food composition data at the food item level, and that WikiFCD is mapped to Wikidata and contains a SPARQL endpoint that supports federated queries. Federated queries across WikiFCD and Wikidata allow us to ask questions about food items that benefit from the cross-domain information of Wikidata, greatly increasing the breadth of possible data combinations. ",
         "70",
         "This manuscript was submitted as 'full paper' and should be reviewed along the usual dimensions for research contributions which include (1) originality, (2) significance of the results, and (3) quality of writing. Please also assess the data file provided by the authors under “Long-term stable URL for resources”. In particular, assess (A) whether the data file is well organized and in particular contains a README file which makes it easy for you to assess the data, (B) whether the provided resources appear to be complete for replication of experiments, and if not, why, (C) whether the chosen repository, if it is not GitHub, Figshare or Zenodo, is appropriate for long-term repository discoverability, and (4) whether the provided data artifacts are complete. Please refer to the reviewer instructions and the FAQ for further information.",
         "0.7382",
         "0",
         "0",
         "0.174074074074074",
         "0.2893",
         "0.7036123275756836",
         "20.76",
         "18.6",
         "20.24",
         "18.2",
         "20.5",
         "91",
         "0",
         "1",
         "2",
         "0",
         "4.0",
         "5.0",
         "1.0",
         "True",
         "neutral",
         "neutral",
         "No Hedging",
         "somewhat specific",
         "4.0",
         "5.0",
         "4.0",
         "80.0",
         "80"
        ],
        [
         "333",
         "3183-4397",
         "Uli Sattler",
         "02/Aug/2022",
         "Accept",
         "475",
         "Interpretable Ontology Extension in Chemistry",
         "Reference ontologies provide a shared vocabulary and knowledge resource for their domain. Manual construction and annotation enables them to maintain high quality, allowing them to be widely accepted across their community. However, the manual ontology development process does not scale for large domains. \\nWe present a new methodology for automatic ontology extension for domains in which the ontology classes have associated graph-structured annotations, and apply it to the ChEBI ontology, a prominent reference ontology for life sciences chemistry. We train Transformer-based deep learning models on the leaf node structures from the ChEBI ontology and the classes to which they belong. The models are then able to automatically classify previously unseen chemical structures, resulting in automated ontology extension. The proposed models achieved an overall F1 scores of 0.80 and above, improvements of at least 6 percentage points over our previous results on the same dataset. In addition, the models are interpretable: we illustrate that visualizing the model's attention weights can help to explain the results by providing insight into how the model made its decisions. We also analyse the performance for molecules that have not been part of the ontology and evaluate the logical correctness of the resulting extension.",
         "21",
         "This is a revised version, and so I will focus on relevant comments. In general it's improved and clearer, and I recommend acceptance. I have basically two remaining points for the authors to consider:     In reaction to the following comment in the first round, the authors added an explanatory paragraph to Section 4, changed its header to ‘Interpretability’, and mentioned the limitation to atomic subclass relationships (in Section 6).  While this clarifies matters, I still think that the title, in particular, promises more than the paper provides: \"Some of the claims made are not strongly supported by the evidence provided in the paper: the interpretability/explainability is discussed by an interesting example, but a suitable evaluation is left for future work. Furthermore, it seems that explanations will only be available for positive classification: what would one do for false negatives? Similarly, the current approach addresses ontology learning in a very weak form as it is restricted to learning of atomic subclass-relationships. While the results are interesting, one could also call this ‘class localisation’ or ‘class insertion’.” Related to this, a sentence such as \"Visualisations such as those in Figure 11 provide a representation of the attention structure that is more intuitive for chemists, and provide a sort of visual explanation for the classification.” …do still read a little strong as we’re missing any evidence that a chemist would find these helpful (or perhaps the authors have such evidence?)?  Regarding the following comment: \"Would the following be clearer? ”Given the *documented, structured* design decisions by the ontology developers, how would they extend their ontology to cover a novel entity? “, the authors responded that their \"approach has been developed under the assumption that there are certain reoccurring design decisions that are *implicitly* reflected in the structure of the ontology. The goal of the system is to understand these design decisions and reflect them in its classification. We rephrased the submission to put a higher emphasis on the exact kind of input data that is used.” …and I am still confused: the current approach *does* consider the structured annotations of classes in the ontology, and so one could argue that the design decisions are partly implicit in the structure of the ontology and partly explicitly documented in the structured annotations? I.e., the approach uses *both* the structure/logical axioms of the ontology as well as the (structured) annotations?!   Related to this, page 5 still says \"Our goal is to train a system that automatically extends the ChEBI ontology with new classes of chemical entities (such as molecules) based on the design decisions that are implicitly reflected in the structure of ChEBI. “. I maintain that this (’the structure’ of Chebi) is still confusing as I read it as, eg, the class hierarchy/graph of ChEBI and definitely not as including its annotations!   Details:  Page 5: \"The preformance” -> \"The performance”?",
         "0.7814",
         "1",
         "0",
         "0.0845640793315212",
         "0.2552",
         "0.8827577233314514",
         "29.38",
         "15.3",
         "15.85",
         "16.4",
         "16.6",
         "95",
         "1",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "True",
         "neutral",
         "polite",
         "No Hedging",
         "3",
         "4.0",
         "5.0",
         "4.0",
         "92.0",
         "92"
        ],
        [
         "334",
         "3183-4397",
         "Anonymous",
         "15/Aug/2022",
         "Minor Revision",
         "34",
         "Interpretable Ontology Extension in Chemistry",
         "Reference ontologies provide a shared vocabulary and knowledge resource for their domain. Manual construction and annotation enables them to maintain high quality, allowing them to be widely accepted across their community. However, the manual ontology development process does not scale for large domains. \\nWe present a new methodology for automatic ontology extension for domains in which the ontology classes have associated graph-structured annotations, and apply it to the ChEBI ontology, a prominent reference ontology for life sciences chemistry. We train Transformer-based deep learning models on the leaf node structures from the ChEBI ontology and the classes to which they belong. The models are then able to automatically classify previously unseen chemical structures, resulting in automated ontology extension. The proposed models achieved an overall F1 scores of 0.80 and above, improvements of at least 6 percentage points over our previous results on the same dataset. In addition, the models are interpretable: we illustrate that visualizing the model's attention weights can help to explain the results by providing insight into how the model made its decisions. We also analyse the performance for molecules that have not been part of the ontology and evaluate the logical correctness of the resulting extension.",
         "34",
         "Comments were largely addressed Figure text on x and y axes are still small in some cases Why does the introduction still have a sentence about explainability? I think that can be cut completely",
         "0.9091",
         "0",
         "0",
         "0.0214285714285714",
         "0.1527",
         "0.6980777978897095",
         "62.68",
         "8.7",
         "10.33",
         "0.0",
         "9.4",
         "33",
         "1",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "neutral",
         "4.0",
         "5.0",
         "3.0",
         "92.0",
         "92"
        ],
        [
         "335",
         "3183-4397",
         "Anonymous",
         "11/Sep/2022",
         "Accept",
         "23",
         "Interpretable Ontology Extension in Chemistry",
         "Reference ontologies provide a shared vocabulary and knowledge resource for their domain. Manual construction and annotation enables them to maintain high quality, allowing them to be widely accepted across their community. However, the manual ontology development process does not scale for large domains. \\nWe present a new methodology for automatic ontology extension for domains in which the ontology classes have associated graph-structured annotations, and apply it to the ChEBI ontology, a prominent reference ontology for life sciences chemistry. We train Transformer-based deep learning models on the leaf node structures from the ChEBI ontology and the classes to which they belong. The models are then able to automatically classify previously unseen chemical structures, resulting in automated ontology extension. The proposed models achieved an overall F1 scores of 0.80 and above, improvements of at least 6 percentage points over our previous results on the same dataset. In addition, the models are interpretable: we illustrate that visualizing the model's attention weights can help to explain the results by providing insight into how the model made its decisions. We also analyse the performance for molecules that have not been part of the ontology and evaluate the logical correctness of the resulting extension.",
         "61",
         "I am satisfied with the author's responses and with the current state of the paper, and I believe that it can be accepted.",
         "0.75",
         "0",
         "0",
         "0.25",
         "0.2468",
         "0.6265180110931396",
         "65.05",
         "9.9",
         "14.42",
         "0.0",
         "10.6",
         "22",
         "1",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "True",
         "positive",
         "polite",
         "No Hedging",
         "3",
         "4.0",
         "5.0",
         "4.0",
         "92.0",
         "92"
        ],
        [
         "342",
         "3294-4508",
         "Sara Colantonio",
         "01/Dec/2022",
         "Accept",
         "141",
         "Knowledge Graphs for Enhancing Transparency in Health Data Ecosystems ",
         "Tailoring personalized treatments demands the analysis of a patient's characteristics, which may be scattered over a wide variety of sources. These features include family history, life habits, comorbidities, and potential treatment side effects. Moreover, the analysis of the services visited the most by a patient before a new diagnosis and the type of requested tests, may uncover patterns that contribute to earlier disease detection and treatment effectiveness.\\nBuilt on the concept of knowledge-driven ecosystems, we devise DE4LungCancer, a data ecosystem of health data sources for lung cancer. \\nKnowledge extracted from heterogeneous sources, e.g., clinical records, scientific publications, and pharmacologic data, is integrated into knowledge graphs. Ontologies describe the meaning of the combined data, and mapping rules enable the declarative definition of the transformation and integration processes. Moreover, DE4LungCancer is assessed in terms of the methods followed for data quality assessment and curation. Lastly, the role of controlled vocabularies and ontologies in health data management is discussed and their impact on transparent knowledge extraction and analytics. \\nThis paper presents the lesson learned in the DE4LungCancer development and demonstrates the transparency level supported by the proposed knowledge-driven ecosystem \\nin the context of the lung cancer pilots in the EU H2020 funded project BigMedilytic, the ERA PerMed funded project P4-LUCAT, and the EU H2020 projects CLARIFY and iASiS. ",
         "38",
         "The authors have suitably addressed the reviewers' comments This manuscript was submitted as 'full paper' and should be reviewed along the usual dimensions for research contributions which include (1) originality, (2) significance of the results, and (3) quality of writing. Please also assess the data file provided by the authors under “Long-term stable URL for resources”. In particular, assess (A) whether the data file is well organized and in particular contains a README file which makes it easy for you to assess the data, (B) whether the provided resources appear to be complete for replication of experiments, and if not, why, (C) whether the chosen repository, if it is not GitHub, Figshare or Zenodo, is appropriate for long-term repository discoverability, and (4) whether the provided data artifacts are complete. Please refer to the reviewer instructions and the FAQ for further information.",
         "0.748",
         "0",
         "0",
         "0.2116666666666666",
         "0.2893",
         "0.7250347137451172",
         "18.73",
         "19.4",
         "21.21",
         "18.8",
         "21.8",
         "94",
         "0",
         "1",
         "2",
         "0",
         "4.0",
         "5.0",
         "0.0",
         "True",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "85.0",
         "80"
        ],
        [
         "343",
         "3294-4508",
         "Stelios Sfakiannakis",
         "02/Dec/2022",
         "Accept",
         "133",
         "Knowledge Graphs for Enhancing Transparency in Health Data Ecosystems ",
         "Tailoring personalized treatments demands the analysis of a patient's characteristics, which may be scattered over a wide variety of sources. These features include family history, life habits, comorbidities, and potential treatment side effects. Moreover, the analysis of the services visited the most by a patient before a new diagnosis and the type of requested tests, may uncover patterns that contribute to earlier disease detection and treatment effectiveness.\\nBuilt on the concept of knowledge-driven ecosystems, we devise DE4LungCancer, a data ecosystem of health data sources for lung cancer. \\nKnowledge extracted from heterogeneous sources, e.g., clinical records, scientific publications, and pharmacologic data, is integrated into knowledge graphs. Ontologies describe the meaning of the combined data, and mapping rules enable the declarative definition of the transformation and integration processes. Moreover, DE4LungCancer is assessed in terms of the methods followed for data quality assessment and curation. Lastly, the role of controlled vocabularies and ontologies in health data management is discussed and their impact on transparent knowledge extraction and analytics. \\nThis paper presents the lesson learned in the DE4LungCancer development and demonstrates the transparency level supported by the proposed knowledge-driven ecosystem \\nin the context of the lung cancer pilots in the EU H2020 funded project BigMedilytic, the ERA PerMed funded project P4-LUCAT, and the EU H2020 projects CLARIFY and iASiS. ",
         "39",
         "This manuscript was submitted as 'full paper' and should be reviewed along the usual dimensions for research contributions which include (1) originality, (2) significance of the results, and (3) quality of writing. Please also assess the data file provided by the authors under “Long-term stable URL for resources”. In particular, assess (A) whether the data file is well organized and in particular contains a README file which makes it easy for you to assess the data, (B) whether the provided resources appear to be complete for replication of experiments, and if not, why, (C) whether the chosen repository, if it is not GitHub, Figshare or Zenodo, is appropriate for long-term repository discoverability, and (4) whether the provided data artifacts are complete. Please refer to the reviewer instructions and the FAQ for further information.",
         "0.7382",
         "0",
         "0",
         "0.174074074074074",
         "0.2893",
         "0.714293897151947",
         "20.76",
         "18.6",
         "20.24",
         "18.2",
         "20.5",
         "91",
         "0",
         "1",
         "2",
         "0",
         "4.0",
         "5.0",
         "3.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "5.0",
         "90.0",
         "92"
        ],
        [
         "415",
         "3215-4429",
         "Umutcan Serles",
         "23/Sep/2022",
         "Accept",
         "42",
         "LinkedDataOps:Quality Oriented End-to-end Geospatial Linked Data Production Governance",
         "This work describes the application of semantic web standards to data quality governance of data production pipelines in the architectural, engineering, and construction (AEC) domain for Ordnance Survey Ireland (OSi). It illustrates a new approach to data quality governance based on establishing a unified knowledge graph for data quality measurements across a complex, heterogeneous,  quality-centric data production pipeline. It provides the first comprehensive formal mappings between semantic models of data quality dimensions defined by the four International Organization for Standardization (ISO) and World Wide Web Consortium (W3C) data quality standards applied by different tools and stakeholders. It provides an approach to uplift rule-based data quality reports into quality metrics suitable for aggregation and end-to-end analysis. Current industrial practice tends towards stove-piped, vendor-specific and domain-dependent tools to process data quality observations however there is a lack of open techniques and methodologies for combining quality measurements derived from different data quality standards to provide end-to-end data quality reporting, root cause analysis or visualization. This work demonstrated that it is effective to use a knowledge graph and semantic web standards to unify distributed data quality monitoring in an organization and present the results in an end-to-end data dashboard in a data quality standards-agnostic fashion for the Ordnance Survey Ireland data publishing pipeline. ",
         "42",
         "the paper addresses my main concerns about the previous version sufficiently. It would be still beneficial to do a final proofread as I have seen some \"et al.\" written as \"etal\" and the first paragraph of the evaluation has section 3 twice.",
         "0.9268",
         "0",
         "0",
         "0.0625",
         "0.1149",
         "0.6524085998535156",
         "57.27",
         "8.8",
         "11.31",
         "11.2",
         "7.9",
         "41",
         "0",
         "0",
         "0",
         "1",
         "4.0",
         "5.0",
         "3.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "86.0",
         "84"
        ],
        [
         "416",
         "3215-4429",
         "Julian Rojas",
         "28/Sep/2022",
         "Accept",
         "49",
         "LinkedDataOps:Quality Oriented End-to-end Geospatial Linked Data Production Governance",
         "This work describes the application of semantic web standards to data quality governance of data production pipelines in the architectural, engineering, and construction (AEC) domain for Ordnance Survey Ireland (OSi). It illustrates a new approach to data quality governance based on establishing a unified knowledge graph for data quality measurements across a complex, heterogeneous,  quality-centric data production pipeline. It provides the first comprehensive formal mappings between semantic models of data quality dimensions defined by the four International Organization for Standardization (ISO) and World Wide Web Consortium (W3C) data quality standards applied by different tools and stakeholders. It provides an approach to uplift rule-based data quality reports into quality metrics suitable for aggregation and end-to-end analysis. Current industrial practice tends towards stove-piped, vendor-specific and domain-dependent tools to process data quality observations however there is a lack of open techniques and methodologies for combining quality measurements derived from different data quality standards to provide end-to-end data quality reporting, root cause analysis or visualization. This work demonstrated that it is effective to use a knowledge graph and semantic web standards to unify distributed data quality monitoring in an organization and present the results in an end-to-end data dashboard in a data quality standards-agnostic fashion for the Ordnance Survey Ireland data publishing pipeline. ",
         "47",
         "All my previous comments were addressed and I think the rewriting applied to the paper have increased its quality and clarity. I recommend to accept the paper. P.S.: A couple of typos found: - Page 22, Line 46: \"...naively...\" → \"...natively...\". - Page 23, Line 1: Missing closing parenthesis.",
         "0.8043",
         "2",
         "0",
         "-0.1833333333333333",
         "0.2025",
         "0.5791976451873779",
         "59.8",
         "7.8",
         "11.56",
         "11.2",
         "9.5",
         "48",
         "1",
         "0",
         "0",
         "0",
         "5.0",
         "5.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "very specific",
         "5.0",
         "4.0",
         "5.0",
         "90.0",
         "93.0"
        ],
        [
         "417",
         "3215-4429",
         "David Chaves-Fraga",
         "04/Oct/2022",
         "Minor Revision",
         "389",
         "LinkedDataOps:Quality Oriented End-to-end Geospatial Linked Data Production Governance",
         "This work describes the application of semantic web standards to data quality governance of data production pipelines in the architectural, engineering, and construction (AEC) domain for Ordnance Survey Ireland (OSi). It illustrates a new approach to data quality governance based on establishing a unified knowledge graph for data quality measurements across a complex, heterogeneous,  quality-centric data production pipeline. It provides the first comprehensive formal mappings between semantic models of data quality dimensions defined by the four International Organization for Standardization (ISO) and World Wide Web Consortium (W3C) data quality standards applied by different tools and stakeholders. It provides an approach to uplift rule-based data quality reports into quality metrics suitable for aggregation and end-to-end analysis. Current industrial practice tends towards stove-piped, vendor-specific and domain-dependent tools to process data quality observations however there is a lack of open techniques and methodologies for combining quality measurements derived from different data quality standards to provide end-to-end data quality reporting, root cause analysis or visualization. This work demonstrated that it is effective to use a knowledge graph and semantic web standards to unify distributed data quality monitoring in an organization and present the results in an end-to-end data dashboard in a data quality standards-agnostic fashion for the Ordnance Survey Ireland data publishing pipeline. ",
         "53",
         "First of all, I would like to thank the authors for their effort in accommodating my previous comments and improving the quality of the paper. However, IMO the paper requires another round of review as I still have the following concerns: 1) There are still many sentences that are really long and very complex to understand and are key for the comprehension of the paper. For example, the 9th paragraph of the introduction (contribution description) is a long sentence with many technical words difficult to follow. I would encourage the authors to re-review the text and simplify sentences (better to be clear and concise) to enhance the readability and also to not increase the complexity with concepts or ideas that are not well introduced or explained in the text, it should be self-contained.  2) Missing a motivating example or a set of examples to clarify and enhance the understandability of some explanations. I would suggest adding it together with the description of the use-case in Section 2 as a specific real example, and it could be reused to support other ideas and explanations along the rest of the paper. 3) Review all repositories (neither DOI nor License is provided) because we do not know if they can be reused and how at this moment. 4) Review R2RML to be consistent. There are some cases where rr:class in the SubjecMap is used and others where is declared using rdf:type in the POM. There are ObjectMaps with templates, aiming to generate an IRI but without rr:IRI (so the engine would generate a literal). Listing 4 still contains RDF errors (e.g., daq#value object), datatype for isEstimate (which is defined in the mapping rules). 5) Fine-grained contributions: in my previous review I was concerned about the number of contributions in the paper but I was surprised that in the new version they have been removed. I would like to see the contributions of the work in detail but in a more concise and clear way. 6) Missing a Figure with the general procedure (maybe improving Fig4 with more details), that gives an overview of all the steps and processes involved. In addition, there are other figures (e.g., fig 5) that can be improved with more details and better organization (is difficult to see that there are arrows from data access to data principles).",
         "0.7618",
         "0",
         "0",
         "0.0670615243342516",
         "0.5662",
         "0.7571347951889038",
         "48.23",
         "12.2",
         "13.17",
         "13.8",
         "13.0",
         "104",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "4.0",
         "5.0",
         "yes",
         "neutral",
         "neutral",
         "No Hedging",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "85.0",
         "85"
        ],
        [
         "444",
         "3159-4373",
         "Enrico Daga",
         "29/Jun/2022",
         "Accept",
         "17",
         "Typed properties and negative typed properties: dealing with type observations and negative statements in the CIDOC CRM",
         "A typical case of producing records within the domain of conservation of cultural heritage is considered. During condition and collection surveys in memory organisations, surveyors observe types of multiple components of an object but without creating a record for each one. They also observe the absence of components. Such observations are significant to researchers and are documented in registration forms but they are not easy to implement using popular ontologies, such as the CIDOC CRM which primarily consider individuals. In this paper techniques for expressing such observations within the context of the CIDOC CRM in both OWL and RDFS are explored. OWL cardinality restrictions are considered and new special properties deriving from the CIDOC CRM are proposed, namely ‘typed properties’ and ‘negative typed properties’ which allow stating the types of multiple individuals and the absence of individuals. The nature of these properties is then explored in relation to their correspondence to longer property paths, their hierarchical arrangement and relevance to thesauri. An example from bookbinding history is used alongside a demonstration of the proposed solution with a dataset from the library collection of the Saint Catherine Monastery in Sinai, Egypt.",
         "19",
         "This new revision answers my remarks and I believe the article is now in a publishable status.",
         "1.0",
         "0",
         "0",
         "0.1363636363636363",
         "0.1028",
         "0.6865378618240356",
         "54.22",
         "9.9",
         "13.86",
         "0.0",
         "8.7",
         "16",
         "1",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "True",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "5.0",
         "4.0",
         "4.0",
         "80.0",
         "84"
        ],
        [
         "445",
         "3159-4373",
         "Luigi Asprino",
         "11/Jul/2022",
         "Accept",
         "23",
         "Typed properties and negative typed properties: dealing with type observations and negative statements in the CIDOC CRM",
         "A typical case of producing records within the domain of conservation of cultural heritage is considered. During condition and collection surveys in memory organisations, surveyors observe types of multiple components of an object but without creating a record for each one. They also observe the absence of components. Such observations are significant to researchers and are documented in registration forms but they are not easy to implement using popular ontologies, such as the CIDOC CRM which primarily consider individuals. In this paper techniques for expressing such observations within the context of the CIDOC CRM in both OWL and RDFS are explored. OWL cardinality restrictions are considered and new special properties deriving from the CIDOC CRM are proposed, namely ‘typed properties’ and ‘negative typed properties’ which allow stating the types of multiple individuals and the absence of individuals. The nature of these properties is then explored in relation to their correspondence to longer property paths, their hierarchical arrangement and relevance to thesauri. An example from bookbinding history is used alongside a demonstration of the proposed solution with a dataset from the library collection of the Saint Catherine Monastery in Sinai, Egypt.",
         "31",
         "The rationale for the evaluation is much clearer now. That was my only doubt about the submission, then, I can suggest the acceptance.",
         "0.8261",
         "0",
         "0",
         "0.1",
         "0.1262",
         "0.6237373352050781",
         "59.8",
         "7.8",
         "11.56",
         "0.0",
         "7.3",
         "23",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "85.0",
         "85"
        ],
        [
         "526",
         "2827-4041",
         "Anonymous",
         "11/Aug/2021",
         "Major Revision",
         "179",
         "Multi-Task Learning Framework for Stance Detection and Veracity Prediction",
         "As more people rely on online media, it becomes more challenging to identify trustworthy information. As a result of this increased complexity, stance detection and rumour detection have gained prominence. Although both tasks are highly correlated and should be performed concurrently, most existing models train them independently. Additionally, while each target topic may contain numerous conflicting claims, previous work treated each claim independently, resulting in conflict claims wrongly assigned with the same truth label. Because some lengthy rumour posts cover a wide range of topics, determining the positions of the posts can be done with a variety of target topics. Existing models may take a biased position toward the correct target topic or the incorrect target topic, resulting in an incorrect determination of veracity. The purpose of this article is to address these problems by proposing a framework for stance detection and veracity prediction that takes into account source credibility and compares the strength of arguments in order to forecast the truth. Experiments are conducted using two well-known datasets: Emergent and RumourEval-2019. On the gold-standard datasets, the results demonstrate that the proposed framework outperforms other methods",
         "48",
         "(1) originality The paper proposes a novel multi-task learning mechanism to jointly predict rumour stance and veracity to improve stance detection, considering the fact that both tasks are highly correlated. While the tasks may be of interest to the semantic web community, the methods used in this paper were rather solely based on NLP. I am not sure if this paper is a good match for the Semantic Web journal, I do not see much relevance to the journal's scope. The authors should clearly describe the novelty of their work in terms of the Semantic Web methods. I also recommend that they look at the literature (e.g., DOI: 10.3233/SW-2012-0073) on how argumentation can be represented and how it can affect rumour stance and veracity prediction.  (2) significance of the results The results look significant, but it is difficult to assess the reproducibility of the results as no code has been shared. (3) quality of writing. Overall, the writing quality is acceptable, but adding a background section on stance and veracity detection, and argumentation-based truth discovery will improve writing quality.",
         "0.7643",
         "0",
         "0",
         "0.098125",
         "0.1953",
         "0.9300763607025146",
         "42.82",
         "12.2",
         "13.55",
         "14.2",
         "13.0",
         "100",
         "0",
         "3",
         "1",
         "0",
         "3.0",
         "4.0",
         "1.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "73.0",
         "73"
        ],
        [
         "527",
         "2827-4041",
         "Anonymous",
         "12/Nov/2021",
         "Reject",
         "715",
         "Multi-Task Learning Framework for Stance Detection and Veracity Prediction",
         "As more people rely on online media, it becomes more challenging to identify trustworthy information. As a result of this increased complexity, stance detection and rumour detection have gained prominence. Although both tasks are highly correlated and should be performed concurrently, most existing models train them independently. Additionally, while each target topic may contain numerous conflicting claims, previous work treated each claim independently, resulting in conflict claims wrongly assigned with the same truth label. Because some lengthy rumour posts cover a wide range of topics, determining the positions of the posts can be done with a variety of target topics. Existing models may take a biased position toward the correct target topic or the incorrect target topic, resulting in an incorrect determination of veracity. The purpose of this article is to address these problems by proposing a framework for stance detection and veracity prediction that takes into account source credibility and compares the strength of arguments in order to forecast the truth. Experiments are conducted using two well-known datasets: Emergent and RumourEval-2019. On the gold-standard datasets, the results demonstrate that the proposed framework outperforms other methods",
         "141",
         "Summary: The core work of this article is on identifying trustworthy information on social media, which is challenged by several different problems, such as target topics containing numerous conflicting claims. The authors presented a multi-task learning framework for stance detection and veracity prediction, namely Argumentation-based Truth Discovery Model, to discover multiple truths from conflicting sources. Experimental results on Emergent and Rumour Eval-2019 Task A+B showed the performance of the proposed model.  (1) Originality: To the best of my knowledge, it is a novel idea to apply multi-tasking to stance detection and veracity prediction. Many similar works exist, such as https://aclanthology.org/D19-6603.pdf https://arxiv.org/pdf/2007.07803v2.pdf https://aclanthology.org/D19-1485/ https://aclanthology.org/C18-1288/ Also, its main contributions to the knowledge of the SWJ community are not apparently significant. (2) Significance of the results: The results on two public datasets (Emergent, Rumour Eval-2019 Task A + B) demonstrated the effectiveness of the proposed methods. Plus, the authors had 9 observations from the results. I think it is hard to show the significant contributions to the SWJ community, not only due to the less novelty. (3) Quality of writing This article is not easy to follow, nor has a high quality of writing. In addition to typos (e.g., see Section 3.3, line 63, “target’=”), and non-standard mathematical notations, there are many ungrammatical sentences (e.g., see Section 1, para 5, line 1-3, or see Section 3.3, para 1, line 16-18). Also, this article is not very concise in describing the core work. This article did not provide any publicly available resources (e.g., source codes, demonstrations) for replication of experiments, even though public datasets (Emergent, Rumour Eval-2019 Task A+B) for the stance detection and veracity prediction were used. This article is lengthy, especially in terms of describing the architectures of different components of their proposed model. The descriptions or explanations are excessive, the reasons are as follows: (1) the descriptions can be replaced with respective clear architectures, such as clause section component in paragraph 3 of Section 3.4, article (relevant clauses), and claim encoder and decoder in Section 3.4.1 and Section 3.4.2. (2) The part that different components also use, like GRU, should be not described again. See paragraph 3 of Section 3.4, and Section 3.4.1. (3) It is suggested that all of the architecture diagrams in the article should be re-drawn since they are unable to give readers any detailed information about the proposed model and its several components in a direct way. (4) Please see paragraph 4 of Section 3.4, the authors repeatedly explain the principle and the attention mechanism. Similarly, see paragraph 5 of the same section, the softmax layer is repeated. In paragraph 2 of Section 3.2, the authors mentioned this work employs a pointer generator architecture with attention and copy mechanisms to create a claim-target topic-based generator. What is a pointer generator with attention and its architecture? Using only the single green box in Fig.2 and several lines to explain it is not sufficient. What are copy mechanisms used? Sorry, I can not find any formal descriptions about them. What is JSP in Fig 3.? Is it JSD (Jensen-Shannon Divergence)? The mathematical notations of this article are extremely not uniform and standard, and unclear. For example, In Section 3.1: [h1,…,ht] (See paragraph 7), g, j, k (See paragraph 8), l, F, j, Fl (see paragraph 9), q(k), alpha(k) (see paragraph 10, not the same with equation (3)). This issue exists throughout the article. The article lacks the most important architecture diagram of the multi-task learning and the soft parameter sharing network. It is suggested that the diagram be added, and also the formulas be added. In paragraphs 5 and paragraph 6 of Section 3.4, the authors mentioned the loss function but did not provide its formal definition, please add it. Moreover, the authors mentioned this model trained by cross-entropy, but the loss function is computed the cosine similarity between target topic embedding and hidden state of the t-th clause. How this model is trained? It is suggested that more details be provided. In paragraph 2 of Section 4.5, what is target topic aware target-specific based claim?  The reviewer believes that the paper is not related to the topics of the semantic web journal. This work is out of the scope of this journal since it does not use any existing or their own KGs.",
         "0.7708",
         "0",
         "4",
         "0.0488907203907203",
         "0.6574",
         "0.9305362701416016",
         "49.31",
         "9.7",
         "10.39",
         "13.0",
         "11.1",
         "89",
         "0",
         "0",
         "0",
         "0",
         "2.0",
         "4.0",
         "3.0",
         "False",
         "negative",
         "neutral",
         "Minimal",
         "somewhat specific",
         "2.0",
         "4.0",
         "3.0",
         "40.0",
         "50"
        ],
        [
         "528",
         "2827-4041",
         "Anonymous",
         "04/Apr/2022",
         "Major Revision",
         "1166",
         "Multi-Task Learning Framework for Stance Detection and Veracity Prediction",
         "As more people rely on online media, it becomes more challenging to identify trustworthy information. As a result of this increased complexity, stance detection and rumour detection have gained prominence. Although both tasks are highly correlated and should be performed concurrently, most existing models train them independently. Additionally, while each target topic may contain numerous conflicting claims, previous work treated each claim independently, resulting in conflict claims wrongly assigned with the same truth label. Because some lengthy rumour posts cover a wide range of topics, determining the positions of the posts can be done with a variety of target topics. Existing models may take a biased position toward the correct target topic or the incorrect target topic, resulting in an incorrect determination of veracity. The purpose of this article is to address these problems by proposing a framework for stance detection and veracity prediction that takes into account source credibility and compares the strength of arguments in order to forecast the truth. Experiments are conducted using two well-known datasets: Emergent and RumourEval-2019. On the gold-standard datasets, the results demonstrate that the proposed framework outperforms other methods",
         "284",
         "Multi-Task Learning Framework for Stance Detection and Veracity Prediction (1) originality The paper proposes an approach for stance detection and veracity prediction, with an emphasis on the benefit of handling both tasks together, instead of independently as in most existing approaches. The work also includes a framework that considers the credulity of the source as well as the strength of the arguments, while determining or forecasting the truth.  The domain at hand is very rich in terms of approaches and contributions. Therefore, it is quite difficult to propose a completely novel and original approach. In this context, the paper is incremental by considering previous approaches in the field and offering added value by combining stance detection and veracity prediction. Still, the authors have submitted an original piece of work.  The addressed topics have a long tradition in the Semantic Web community, especially when it comes to fact recognition and entity detection. However, this paper does not use semantic technologies as the core of the proposed approach. It is crucial that the authors state the connection between Semantic Web and their work. Otherwise, an AI or NLP journal would probably be a better option for a submission. (2) significance of the results The results of the evaluation and experiments show that the authors can demonstrate the expected improvement from combining the two aspects. Here the significance for the semantic web community should be clearly stated. This is definitively missing. Detailed comments: Introductions: „Because it is difficult and expensive to hire qualified journalists and other experts to verify published posts,“ – I do not believe that this is the main issue. Rumors can be released on purpose and with the growing numbers of websites, it is hardly possible to manually validate all. Furthermore, some content is event automatically or semi-automatically generated. The issue is way beyond finding good journalists. It is more that it cannot be handled manually. “This work addresses three issues identified from the literature that contribute to the failure of veracity prediction systems to achieve acceptable detection performance” – The statement is really strong and it can hardly be said that current solutions are a failure. Be more specific about the problem – are the systems not good enough or is the problem too complex. What is exactly the issue, also in relation to your work.  “As a result, the two tasks, stance detection and veracity prediction can be learned concurrently to maximise their utility.” – This cannot be stated as a fact in the introduction. Instead I would strongly suggest that this is defined as a hypothesis that is validated by the work presented in the paper. “previous models attempted to detect the general stance without considering the primary or the most concerned target topic.“ – Here it would be very helpful to introduce as example.  This would also help if there is an example that clearly shows how stance detection and veracity prediction when combined are actually more accurate. “Each claim's target topic is extracted independently. As a result, the target topics with the most similar embeddings to the primary target topic is selected for analysis alongside the target topic. Rumors from reliable sources are weighted heavily in the outcome, whereas rumours from unreliable sources are ignored.“ – This approach can be very tricky, since there can be bias even when it comes to true facts. People can have different view because of historical background, political views, religious beliefs and because of that talk about a fact in a different way. In that way bias would actually falsify the results. I would strongly suggest restructuring the introduction by stating a hypothesis, describing the aspects that will be investigated and the corresponding contributions. The focus of the contributions should be on the research work and not the implementation. Currently, the impression is that the paper presents an implementation of a framework. Furthermore, I would suggest adding a motivating example and removing any judgement (without clear proof) about reasons or state of the art. Related Work The overviews given in the summary tables are really nice and helpful. It takes a lot of work to create such summaries. Still, I would strongly suggest to better classify the related papers. What is of interest is what features are used in the approach and what is the specific target of each paper. You can still keep the measures but it would be very helpful to have some further comparisons, since you have done the analysis. “In general, there are four types of methods for truth discovery that have been used in previous research.:“ – it is not clear where this statement comes from. This needs to be motivated or rephrased. 2.5 Analysis Ideally, the content of this section should come directly based on the summary tables in the related work section. Otherwise the statements come as a bit of a surprise and are not motivated. 3.1 Overview This is not a suitable place to introduce the model. This should be done in a separate designated section. Fig. 1 – This is not the best place to introduce the model. It might also be useful to state the differences to multi-modal learning approaches, since the architecture seems to be very similar. “If the probability is >=0.5, then the source is selected as a candidate trustworthy source.“ How was this determined? “If the probability is >= 0.5, then the claim is selected as a candidate truth.“ How was this determined? (3) quality of writing. The paper can benefit from a bit of restructuring. This is especially true for the introduction and the experiments and results sections. Furthermore, it should be clearly separated between implementation decisions and work on the approach. Currently, there is a mix between the two from time to time. The line of argumentation should be improved. No statement should be made without clear motivation or saying that it is taken as an assumption. Currently, there are a number of statements, which are not clearly motivated.  Detailed comments: Section “Experiments and Results \" This is a bit too late to introduce research questions. I would suggest to move them to the introduction and in this section to say how these were specifically evaluated.  There seems to be a problem with the formula formatting (25) and (26) on page 14. vt1,i? Also (30). Why is vt2 not normalised with 1/n? Formula (50) – is this the correct way to define a concatenation? Same for (48) Double-check formula (65) „X1={s,f,h} ,“ “(e.g. …) and its supporting replies (e.g. …) are “ ?? “Manhattan LSTM model [105]is used because….”?? The formulas should be double-checked and put in the same format.  Some sections are repetitive, especially when it comes to the motivation of the work and the fundamentals used.  I would strongly suggest grouping the mathematical formulas into smaller blocks and to use a diagram or ideally an architecture to guide the reader. Otherwise, it is quite difficult to follow which formula preforms what function in what part of the big-picture.",
         "0.7774",
         "2",
         "1",
         "0.1183771929824561",
         "0.0982",
         "0.9158077239990234",
         "47.89",
         "10.3",
         "10.59",
         "13.0",
         "10.6",
         "101",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "1.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "2.0",
         "62.0",
         "62"
        ],
        [
         "529",
         "2848-4062",
         "Enrico Daga",
         "21/Sep/2021",
         "Accept",
         "162",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "60",
         "The authors have performed significant changes to the content, which significantly improve the article with respect to the previous submission. Following the four SWJ criteria for survey articles, the current version is indeed a good (1) introductory text, targeted at researchers, PhD students, or practitioners, to get started on the covered topic.  The addition of a methodology section gives reasonable justification for (2) how comprehensive and how balanced are the presentation and coverage. However, a few more details about the sources of the survey would be useful, especially if mentioning keywords and phrases used in the search (Scopus? Google Scholar? Microsoft Academia? …). In addition, it is still a bit opaque what is intended with \"refining and balancing the structure of the covered areas\" - end of Section 2. However, I consider these minor issues that can be fixed during the preparation of the camera-ready. Finally, the article is readable and clear (3) and the content is relevant to the community (4).",
         "0.8103",
         "1",
         "0",
         "0.1645833333333333",
         "0.1149",
         "0.6678649187088013",
         "31.31",
         "14.6",
         "17.41",
         "16.6",
         "15.5",
         "100",
         "0",
         "0",
         "0",
         "2",
         "4.0",
         "3.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "85.0",
         "85"
        ],
        [
         "530",
         "2848-4062",
         "Julia Bosque",
         "04/Oct/2021",
         "Accept",
         "503",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "73",
         "I reviewed a previous version of this manuscript, for which I recommended a major revision based on the need for a clearer motivation, scope and limitations of this effort, as well as on the structure and flow of the paper at that time. In this new version the authors have addressed all my highlighted concerns: - The motivation, scope and limitations are clearly defined - The interplay between the different sections is elaborated and illustrated with a workflow diagram that facilitates reading. There are numerous references to this workflow and interlinks between the sections, resulting in a cohesive document. - More context is provided in the introductory paragraphs of each section, and the project in which this effort is carried out is clearly introduced. The relation of each section/topic with respect to the overall topic of the survey is now explicit. - The authors have improved the categorization of tools and approaches. - The tables in the appendix summarize the main approaches, tools and resources surveyed according to the proposed classification.  Taking into account these modifications, I maintain the reasons upon which I based the recommendation for acceptance in terms of the criteria for surveys: - The topic of the paper, at the intersection of humanities and the Semantic Web, is interesting and relevant for the advancement in a line of research which poses numerous challenges. - The quality of writing is good and the survey is well balanced, with a broad coverage encompassing theoretical standpoints and approaches, tools, repositories and datasets. - The granularity and length are also appropriate for the text to serve as an introductory text. Minor comments for improvement: - The authors have provided details on the methodology for the survey, indicating the different stages in the generation and keywords used in literature search. There is no explicit reference to a filtering process after those keyword-based search results, was there any filtering step? If so, which criteria were applied? - In table 3, the included resources diverge in their nature, so the current list groups together LLOD Cloud, Lila Etymological Lexicon, LingHub, and Diachronic semantic lexicon of Dutch, etc. for example. I suggest including a mark here to distinguish which resources are particularly relevant for diachronic analysis, in contrast to general LLOD resources (e.g. Lila Etymological Lexicon vs. LLOD cloud and LingHub). - The authors of [12], referenced on p. 5, mention Lemon (Lexicon Model For Ontologies), and in their diagrams (in Github)  they seem to be using OntoLex-Lemon, not its ancestor. Throughout this survey \"OntoLex-Lemon\" is the term used to refer to the 2016 Specification as the outcome of the W3C Ontology-Lexica Community Group, so for that bib. reference I would recommend to replace the mention of \"Lemon\" with \"OntoLex-Lemon\" for consistency in the whole document. *Typos*: l.19, .p. 19, right column, \"A combined resource like this, allows...\" → remove comma p. 20, l. 1, right column → remove \"(linguistic)\", already covered by the first L in LLOD Appendix tables, Table 4. → word embeddings (add pl. \"s\")",
         "0.7741",
         "5",
         "1",
         "0.1697330447330447",
         "0.2025",
         "0.8522429466247559",
         "34.66",
         "13.3",
         "14.3",
         "15.2",
         "14.0",
         "108",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "3.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "4.0",
         "90.0",
         "90"
        ],
        [
         "531",
         "2848-4062",
         "Thierry Declerck",
         "05/Nov/2021",
         "Accept",
         "60",
         "LL(O)D and NLP Perspectives on Semantic Change for Humanities Research",
         "The paper presents an overview of the LL(O)D and NLP methods, tools and data for detecting and representing semantic change, with main application in humanities research. Its aim is to provide the starting points for the construction of a workflow and set of multilingual diachronic ontologies within the humanities use case of the COST Action \\textit{Nexus Linguarum, European network for Web-centred linguistic data science}, CA18209. The survey focuses on the essential aspects needed to understand the current trends and to build applications in this area of study.",
         "105",
         "Not really a lot to add. I see that the revised version of the submission was taking good care of former comments and suggestions. Just a minor point: 1) Ensure that footnotes are always placed after the punctuation signs (for consistency across the paper, se fn 2 and 3 which are not placed consistently). So, very few corrections to do.",
         "0.81",
         "0",
         "0",
         "0.0579999999999999",
         "0.0548",
         "0.6966200470924377",
         "64.71",
         "8.0",
         "10.0",
         "10.1",
         "8.0",
         "60",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "1.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "4.0",
         "80.0",
         "83"
        ],
        [
         "591",
         "2871-4085",
         "Guohui Xiao",
         "24/Sep/2021",
         "Accept",
         "23",
         "Semantics and Canonicalisation of SPARQL 1.1",
         "We define a procedure for canonicalising SPARQL 1.1 queries. Specifically, given two input queries that return the same solutions modulo variable names over any RDF graph (which we call congruent queries), the canonicalisation procedure aims to rewrite both input queries to a syntactically canonical query that likewise returns the same results modulo variable renaming. The use-cases for such canonicalisation include caching, optimisation, redundancy elimination, question answering, and more besides. To begin, we formally define the semantics of the SPARQL 1.1 language, including features often overlooked in the literature. We then propose a canonicalisation procedure based on mapping a SPARQL query to an RDF graph, applying algebraic rewritings, removing redundancy, and then using canonical labelling techniques to produce a canonical form. Unfortunately a full canonicalisation procedure for SPARQL 1.1 queries would be undecidable. We rather propose a procedure that we prove to be sound and complete for a decidable fragment of monotone queries under both set and bag semantics, and that is sound but incomplete in the case of the full SPARQL 1.1 query language. Although the worst case of the procedure is super-exponential, our experiments show that it is efficient for real-world queries, and that such difficult cases are rare.",
         "40",
         "The authors have successfully addressed all the issues pointed in the first round of the review. I am happy to recommend an acceptance.",
         "0.8696",
         "0",
         "0",
         "0.4",
         "0.155",
         "0.6552531719207764",
         "59.8",
         "7.8",
         "9.82",
         "0.0",
         "7.4",
         "23",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "5.0",
         "4.0",
         "5.0",
         "90.0",
         "95"
        ],
        [
         "592",
         "2871-4085",
         "Anonymous",
         "28/Sep/2021",
         "Accept",
         "133",
         "Semantics and Canonicalisation of SPARQL 1.1",
         "We define a procedure for canonicalising SPARQL 1.1 queries. Specifically, given two input queries that return the same solutions modulo variable names over any RDF graph (which we call congruent queries), the canonicalisation procedure aims to rewrite both input queries to a syntactically canonical query that likewise returns the same results modulo variable renaming. The use-cases for such canonicalisation include caching, optimisation, redundancy elimination, question answering, and more besides. To begin, we formally define the semantics of the SPARQL 1.1 language, including features often overlooked in the literature. We then propose a canonicalisation procedure based on mapping a SPARQL query to an RDF graph, applying algebraic rewritings, removing redundancy, and then using canonical labelling techniques to produce a canonical form. Unfortunately a full canonicalisation procedure for SPARQL 1.1 queries would be undecidable. We rather propose a procedure that we prove to be sound and complete for a decidable fragment of monotone queries under both set and bag semantics, and that is sound but incomplete in the case of the full SPARQL 1.1 query language. Although the worst case of the procedure is super-exponential, our experiments show that it is efficient for real-world queries, and that such difficult cases are rare.",
         "44",
         "This manuscript was submitted as 'full paper' and should be reviewed along the usual dimensions for research contributions which include (1) originality, (2) significance of the results, and (3) quality of writing. Please also assess the data file provided by the authors under “Long-term stable URL for resources”. In particular, assess (A) whether the data file is well organized and in particular contains a README file which makes it easy for you to assess the data, (B) whether the provided resources appear to be complete for replication of experiments, and if not, why, (C) whether the chosen repository, if it is not GitHub, Figshare or Zenodo, is appropriate for long-term repository discoverability, and (4) whether the provided data artifacts are complete. Please refer to the reviewer instructions and the FAQ for further information.",
         "0.7382",
         "0",
         "0",
         "0.174074074074074",
         "0.2893",
         "0.704759955406189",
         "20.76",
         "18.6",
         "20.24",
         "18.2",
         "20.5",
         "91",
         "0",
         "1",
         "2",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "yes",
         "positive",
         "neutral",
         "No Hedging",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "88.0",
         "90"
        ],
        [
         "593",
         "2871-4085",
         "Meng Wang",
         "08/Oct/2021",
         "Accept",
         "20",
         "Semantics and Canonicalisation of SPARQL 1.1",
         "We define a procedure for canonicalising SPARQL 1.1 queries. Specifically, given two input queries that return the same solutions modulo variable names over any RDF graph (which we call congruent queries), the canonicalisation procedure aims to rewrite both input queries to a syntactically canonical query that likewise returns the same results modulo variable renaming. The use-cases for such canonicalisation include caching, optimisation, redundancy elimination, question answering, and more besides. To begin, we formally define the semantics of the SPARQL 1.1 language, including features often overlooked in the literature. We then propose a canonicalisation procedure based on mapping a SPARQL query to an RDF graph, applying algebraic rewritings, removing redundancy, and then using canonical labelling techniques to produce a canonical form. Unfortunately a full canonicalisation procedure for SPARQL 1.1 queries would be undecidable. We rather propose a procedure that we prove to be sound and complete for a decidable fragment of monotone queries under both set and bag semantics, and that is sound but incomplete in the case of the full SPARQL 1.1 query language. Although the worst case of the procedure is super-exponential, our experiments show that it is efficient for real-world queries, and that such difficult cases are rare.",
         "54",
         "All my concerns were addressed in the new version. Great work！I recommend this paper for publication. Congrats to the authors.",
         "0.9474",
         "0",
         "0",
         "0.4681818181818182",
         "0.5258",
         "0.6541549563407898",
         "64.67",
         "5.9",
         "6.68",
         "7.8",
         "7.1",
         "20",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "5.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "5.0",
         "5.0",
         "5.0",
         "90.0",
         "90"
        ],
        [
         "616",
         "2814-4028",
         "Anonymous",
         "26/Aug/2021",
         "Reject",
         "978",
         "A Prospective Analysis of Security Vulnerabilities within Link Traversal-Based Query Processing",
         "The societal and economical consequences surrounding Big Data-driven platforms have increased the call for decentralized solutions. However, retrieving and querying data in more decentralized environments requires fundamentally different approaches, whose properties are not yet well understood. Link-Traversal-based Query Processing (LTQP) is a technique for querying over decentralized data networks, in which a client-side query engine discovers data by traversing links between documents. Since decentralized environments are potentially unsafe due to their non-centrally controlled nature, there is a need for client-side LTQP query engines to be resistant against security threats aimed at the query engine’s host machine or the query initiator’s personal data. As such, we have performed an analysis of potential security vulnerabilities of LTQP. This article provides an overview of security threats in related domains, which are used as inspiration for the identification of 10 LTQP security threats. Each threat is explained, together with an example, and one or more avenues for mitigations are proposed. We conclude with several concrete recommendations for LTQP query engine developers and data publishers as a first step to mitigate some of these issues. With this work, we start filling the unknowns for enabling querying over decentralized environments. Aside from future work on security, wider research is needed to uncover missing building blocks for enabling true decentralization.",
         "79",
         "Summary ======= The authors make the case for 10 points/vulnerabilities/security threats in the context of link-traversal-based querying that can lead to problems during query execution. The authors do so by making arguments based on literature and technologies from semantic-web and non-semantic web technologies. They conclude with recommendations for developers. Strong points ============= * The paper is timely, because with Solid, the substrate for which link-traversal-based querying, starts to become deployed * The compilation of the points is original * Link-traversal-based querying on the web, that is on data at least partially from potentially untrusted sources, indeed has peculiarities that need mitigation strategies. Weak points =========== * I miss a definition of the main point of this paper: security, with a delineation from safety. Some definitions of the two terms I found on the web make the difference in whether what goes wrong has been *deliberate*. Some of the paper's _security_ vulnerabilities are more safety problems for me, like Section 5.8 syntax errors (unintentionally put in by a human), or Section 5.6 links gone wrong (unintentionally put in by a RDF export from a database, see e.g. the DyLDO study [1]). * Unclear attack surface / vectors:   * For instance, Section 5.5 assumes a query engine that executes JavaScript before RDFa and JSON-LD is extracted from HTML. As far as I know, such engines are rare. Maybe it would be good to introduce different classes of engines first and their components. Engines that, e.g., only operate on Turtle/RDF+XML/N-Triples, would not be affected.   * In the introduction the authors say that the paper is about the integrity of a user's data. What is the notion of integrity applied here? Which vulnerabilities would result in changes to a user's data?   * Are the authors talking about the vulnerability of engines for federated SPARQL (Section 5.2) or engines for dereferencing URIs (Section 5.8)? * Missing related work or state-of-the-art technologies   * Section 5.8 talks about document corruption, to which the authors add un-available sources. Here, the authors again refer to the DyLDO study [1]. Thus, we have two points here: the meaning of an unavailable source, the meaning of a syntactically wrong document, both require research in my opinion, and a pointer to HTML browsers' Quirks modes is missing. On top, the authors miss a third point: inconsistent data, for which there are mitigation strategies as well.   * Section 5.1 talks about unauthoritative statements. There are papers on authoritative statements that have not been cited in the paper, e.g. [2]. I would be interested in the notion of trust that the authors apply in this section.   * Crawling the web of data has been investigated in [3,4,5], which would be relevant in related work. Moreover, The claim \"HTTP delays typically for the bottleneck in LTQP\" should be substantiated, e.g. using those works. What is an HTTP delay? From my experience HTTP can be fast, and PLD starvation (I think see [6]) is a bigger issue if you want to crawl politely. FWIW, polite crawling is mentioned at the end of 2.1.    * The authors extensively refer to their Comunica engine, but miss out on other engines that could process queries and follow links, including their own RESTDesc [7] and Linked Data-Fu [8]    * Agents that work on Linked Data, e.g. [9], also make use of link following    * Maybe, federated SPARQL with and without automated source selection is also in the scope for related work (Section 2.1) * Target audience of the paper are not researchers but developers and data publishers (see the recommendations in the conclusion and the abstract), so maybe the paper should be submitted to a non-academic venue? * How did the authors assess the difficulty of their mitigation strategies? * Regarding writing quality: While the English is well-written, for my taste the paper could use a more down-to-earth style. Verdict ======= I recommend the editors to reject the paper, as it is in a very premature stage. To me, most points raised are not really security vulnerabilities, though they are interesting points. Maybe involving a security expert and clearly defining security and safety and then working on the attack vectors for different engines for different interfaces helps to find out what are \"real\" threats to system security and what are \"just\" very important and interesting peculiarities in link-traversal-based querying that need mitigation. Moreover, important related work is missing. Yet, I highly encourage the authors to continue their work on *all* 10 points. Minor points ============ * \"its own personal\" -> \"their own personal\" (p.1) * I am unsure why query processing helps to *find* data (p.1) * \"LTQP is a relative young are of research\" vs. \"More than a decade ago, [...] LTQP has been introduced\" (both on p.2 - a contradiction?) * What are the \"global semantics\" of RDF? Please add a reference or explain (Section 2.1). * Reference [23] does not support the paragraph in which it had been mentioned (Section 2.2) * Reference [58] does not support the paragraph in which it had been mentioned (Section 5.3) * \"Unauthorized Statements\" (Table 4) vs. \"Unauthoritative Statements\" (the corresponding heading of Section 5.1) * The open-world assumption in my opinion does not imply free speech (Section 5.1) * HTTP GET Parameters would need a reference or a definition (Section 5.4) * \"limit duration\" -> \"limited duration\" (Section 5.5) * To keep track of all visited URIs is commonly done in crawlers (Section 5.6) [1] Käfer et al. \"Observing Linked Data Dynamics\", ESWC 2013 [2] Hogan et al. \"Scalable authoritative OWL reasoning for the web\" IJSWIS 2009 [3] Isele et al. \"LDSpider\" P&D ISWC 2010 [4] Röder et al. \"Squirrel\", ISWC 2020 [5] Käfer et al. \"DyLDO\", LDOW 2012 [6] Hogan et al. \"SWSE\", JWS 2011 [7] Verborgh et al. WS-REST, 2012 [8] Stadtmüller et al. \"Data-Fu\", WWW 2013 [9] Käfer et al. \"Programming User Agents...\", LDOW 2018",
         "0.7488",
         "10",
         "19",
         "0.1131349206349206",
         "0.209",
         "0.8954746723175049",
         "49.62",
         "9.6",
         "9.84",
         "11.7",
         "10.4",
         "69",
         "0",
         "1",
         "0",
         "0",
         "2.0",
         "4.0",
         "11.0",
         "False",
         "impolite",
         "neutral",
         "Moderate",
         "broad",
         "3.0",
         "4.0",
         "4.0",
         "60.0",
         "67"
        ],
        [
         "617",
         "2814-4028",
         "Anonymous",
         "07/Sep/2021",
         "Reject",
         "647",
         "A Prospective Analysis of Security Vulnerabilities within Link Traversal-Based Query Processing",
         "The societal and economical consequences surrounding Big Data-driven platforms have increased the call for decentralized solutions. However, retrieving and querying data in more decentralized environments requires fundamentally different approaches, whose properties are not yet well understood. Link-Traversal-based Query Processing (LTQP) is a technique for querying over decentralized data networks, in which a client-side query engine discovers data by traversing links between documents. Since decentralized environments are potentially unsafe due to their non-centrally controlled nature, there is a need for client-side LTQP query engines to be resistant against security threats aimed at the query engine’s host machine or the query initiator’s personal data. As such, we have performed an analysis of potential security vulnerabilities of LTQP. This article provides an overview of security threats in related domains, which are used as inspiration for the identification of 10 LTQP security threats. Each threat is explained, together with an example, and one or more avenues for mitigations are proposed. We conclude with several concrete recommendations for LTQP query engine developers and data publishers as a first step to mitigate some of these issues. With this work, we start filling the unknowns for enabling querying over decentralized environments. Aside from future work on security, wider research is needed to uncover missing building blocks for enabling true decentralization.",
         "91",
         "The authors present a study about potential security concerns while using the LTQP query engine on the web where documents can be noisy and malicious. Authors have drawn the similarity between the LTQP and web browsers and categorized a few of the attacks common on the web browser and how such attacks can potentially be executed in the LTQP framework. Overall the manuscript is readable with few typos. As LTQP  is a new research area and still under exploration (as mentioned by the authors), there is no quantitative or qualitative result present in the manuscript to judge the impact of the work.  As described below overall the work needs to be improved to (1) position it well with respect to the security aspect, and (2) provide motivations for some of the choices.  Weaknesses: 0. Work seems to be hypothetical in nature and to support the work the authors draw the connection between LTQP and the web browser. Most of the work is borrowed from the already known flaws in web browsers with its potential mitigation. Due to the high resemblance with already existing work and its hypothetical nature, the contribution seems incremental. 1. As mentioned by the author on (page 6) one of the assumptions is that the query engine makes use of Alice identify for authentication. Such a \"known identity\" assumption is too strong. In absence of such an assumption, the query should not be executed nor it should have access to the data. But, how this authentication will potentially be handled in the LTQP framework is unclear.  There is mention of authentication work under related work but there is no clarity on how that would be used by the LTQP engine. 2. There is no mention of the details about what criteria were used to decide the difficulty level (high/low/medium) of the attacks as well as the mitigations. Moreover, how does the \"high\", 'low', and 'medium' translate quantitatively? 3. Lacks motivation about why a fixed set of 10 attacks were chosen from a pool of attacks. What criteria were used for selection? Are these attacks more dangerous than the others and hence have high priority compared to others? Such high priority might hold true for web browsers but does it equally translate to LTQP? Is the presented list of attacks exhaustive with respect to LTQP? Strength: 0. Depending on the popularity and community willingness to accept the LTQP framework, the current manuscript can serve as an initial work/baseline/reference. Some suggestions: I believe the following point might be helpful to the authors to make the manuscript stronger.  0. To organize and prioritize attacks for the LTQP engine, authors can refer to cybersecurity data sources mentioned in Unified Cybersecurity Ontology [1]. These data sources are publically available and are of good quality. Attacks have a score associated with them to determine the nature and severity of it along with many other additional features. 1. Judging the difficulty of the mitigation can be hard, as there is no known implementation. Judging based on perception level might be vague. As a suggestion, it would be fine to list only the difficulty of the attack using established data sources.  Typos: 1. \"more decentralized\" -> \"decentralized\" . as it not clear how to compare decentralization system vs less decentralized system 2. \"true decentralization\" -> \"decentralization\" 3. On page 1 Second sentence has a gaurdian.com link associated but not cited nor is hyperlinked? I am not sure if that was intentional or by mistake. If intentional then it would be nice to make it more explicit 4. \"Solid leads to a a \" -> \"Solid leads to a\" 5. Page 2, \"illustrate difference threats with.\" -> \"illustrate difference threats.\" 6. What does \"...\" means for Table 1, 2 and 3? References  [1] Syed, Zareen, et al. \"UCO: A unified cybersecurity ontology.\" Workshops at the thirtieth AAAI conference on artificial intelligence. 2016. https://www.aaai.org/ocs/index.php/WS/AAAIW16/paper/viewPaper/12574",
         "0.7651",
         "15",
         "3",
         "0.0604817038307604",
         "0.0795",
         "0.8498835563659668",
         "47.59",
         "10.4",
         "11.27",
         "12.6",
         "10.6",
         "96",
         "0",
         "1",
         "0",
         "0",
         "3.0",
         "4.0",
         "2.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "80.0",
         "82"
        ],
        [
         "618",
         "2814-4028",
         "Anonymous",
         "16/Oct/2021",
         "Major Revision",
         "552",
         "A Prospective Analysis of Security Vulnerabilities within Link Traversal-Based Query Processing",
         "The societal and economical consequences surrounding Big Data-driven platforms have increased the call for decentralized solutions. However, retrieving and querying data in more decentralized environments requires fundamentally different approaches, whose properties are not yet well understood. Link-Traversal-based Query Processing (LTQP) is a technique for querying over decentralized data networks, in which a client-side query engine discovers data by traversing links between documents. Since decentralized environments are potentially unsafe due to their non-centrally controlled nature, there is a need for client-side LTQP query engines to be resistant against security threats aimed at the query engine’s host machine or the query initiator’s personal data. As such, we have performed an analysis of potential security vulnerabilities of LTQP. This article provides an overview of security threats in related domains, which are used as inspiration for the identification of 10 LTQP security threats. Each threat is explained, together with an example, and one or more avenues for mitigations are proposed. We conclude with several concrete recommendations for LTQP query engine developers and data publishers as a first step to mitigate some of these issues. With this work, we start filling the unknowns for enabling querying over decentralized environments. Aside from future work on security, wider research is needed to uncover missing building blocks for enabling true decentralization.",
         "130",
         "The paper tackles the problem of link traversal-based query processing and presents a prospective assessment of the potential security vulnerabilities of this type of query processing. The authors analyze ten security threads and propose mitigation strategies with a level of difficulty. Each thread is discussed in a use case where data vaults store data of any type, published on the Web, and are completely controlled by the owner.  One of the users has malicious intentions which are unknown from the others, and the vulnerabilities are defined based on existing cases in other domains. The article concludes with recommendations for linked traversal query processing developers and data publishers.  Positive Points -) An exhaustive analysis of vulnerabilities that may exist whenever linked traversal query processing is performed over distributed linked data. -) A clear illustration of each analyzed case with the running example. -) Conscientious recommendation to avoid and mitigate the discussed vulnerabilities. Negative Points -) Although the paper resorts to simple examples to explain the potential security issues, the reported analysis relies on a group of vague concepts. For example, in section 2.2, the vulnerability of RDF query processing is presented in terms of injection attacks, parameterized queries, and query parse trees. A detailed description of these concepts is required to enhance readability.  -) There is no justification of methodology followed to identify these ten vulnerabilities. It is not clear if a systematic literature reviewed process was followed to uncover them. The evaluation methodology must be defined to ensure reproducibility and understanding of the levels of completeness of the analyzed cases,  -) Despite the paper refers to linked traversal query processing, it does not concretely show which of the existing approaches is in danger of these vulnerabilities. The authors should also indicate if these vulnerabilities threaten existing real-world methods, e.g., SPARQL federated query engines or SPARQL endpoints. If so, include references.  -) Criteria followed in deciding the degree of difficulty are not discussed. Moreover, the meaning of the values: Easy, Medium, and Hard is not defined. It is required to clearly describe the process to be followed to mitigate each vulnerability and how the values of difficulty are determined based on these processes. -) The execution of SPARQL queries comprising the triple pattern ?s ?p ?o,  usually is limited by timeouts specified in the configuration of the SPARQL endpoint. The categories of injection attacks considered in this analysis are not clear. Also, it is not justified in which type of query engines this query is an injection attack. Please, indicate concrete examples.  -) The article contains several unprecise statements and ignores related work conducted for several decades in graph databases. For example, the paper states that “LTQP is a relatively new area of research”. However, query processing over graph databases has been studied for more than four decades. Please, check the vast amount of work by Alberto Mendelzon or Claudio Gutierrez. The authors should postulate a more specific statement about the query processing problem to which they refer in this paper.    Giansalvatore Mecca, Alberto O. Mendelzon, Paolo Merialdo: Efficient Queries over Web Views. IEEE Trans. Knowl. Data Eng. 14(6): 1280-1298 (2002) Gustavo O. Arocena, Alberto O. Mendelzon, George A. Mihaila: Query Languages for the Web. QL 1998 Alberto O. Mendelzon, George A. Mihaila Tova Milo: Querying the World Wide Web. PDIS 1996: 80-91",
         "0.7843",
         "5",
         "1",
         "0.025286272866918",
         "0.1431",
         "0.9223957061767578",
         "32.7",
         "12.0",
         "11.62",
         "13.3",
         "11.9",
         "99",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "8.0",
         "False",
         "negative",
         "neutral",
         "Moderate",
         "somewhat specific",
         "3.0",
         "4.0",
         "3.0",
         "68.0",
         "68"
        ],
        [
         "631",
         "2844-4058",
         "Anonymous",
         "28/Jul/2021",
         "Accept",
         "133",
         "MIDI2vec: Learning MIDI Embeddings for Reliable Prediction of Symbolic Music Metadata",
         "An important problem in large symbolic music collections is the low availability of high-quality metadata, which is essential for various information retrieval tasks. Traditionally, systems have addressed this by relying either on costly human annotations or on rule-based systems at a limited scale.\\nRecently, embedding strategies have been exploited for representing latent factors in graphs of connected nodes. In this work, we propose MIDI2vec, a new approach for representing MIDI files as vectors based on graph embedding techniques. Our strategy consists of representing the MIDI data as a graph, including the information about tempo, time signature, programs and notes. Next, we run and optimise node2vec for generating embeddings using random walks in the graph. We demonstrate that the resulting vectors can successfully be employed for predicting the musical genre and other metadata such as the composer, the instrument or the movement. In particular, we conduct experiments using those vectors as input to a Feed-Forward Neural Network and we report good\\ncomparable accuracy scores in the prediction with respect to other approaches relying purely on symbolic music,\\navoiding feature engineering and producing highly scalable and reusable models with low dimensionality.\\nOur proposal has real-world applications in automated metadata tagging for symbolic music, for example in digital libraries for musicology, datasets for machine learning, and knowledge graph completion.",
         "9",
         "This manuscript was submitted as 'full paper' and should be reviewed along the usual dimensions for research contributions which include (1) originality, (2) significance of the results, and (3) quality of writing. Please also assess the data file provided by the authors under “Long-term stable URL for resources”. In particular, assess (A) whether the data file is well organized and in particular contains a README file which makes it easy for you to assess the data, (B) whether the provided resources appear to be complete for replication of experiments, and if not, why, (C) whether the chosen repository, if it is not GitHub, Figshare or Zenodo, is appropriate for long-term repository discoverability, and (4) whether the provided data artifacts are complete. Please refer to the reviewer instructions and the FAQ for further information.",
         "0.7382",
         "0",
         "0",
         "0.174074074074074",
         "0.2893",
         "0.6956272721290588",
         "20.76",
         "18.6",
         "20.24",
         "18.2",
         "20.5",
         "91",
         "0",
         "1",
         "2",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "yes",
         "positive",
         "neutral",
         "No Hedging",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "80.0",
         "84"
        ],
        [
         "632",
         "2844-4058",
         "Anonymous",
         "04/Aug/2021",
         "Accept",
         "7",
         "MIDI2vec: Learning MIDI Embeddings for Reliable Prediction of Symbolic Music Metadata",
         "An important problem in large symbolic music collections is the low availability of high-quality metadata, which is essential for various information retrieval tasks. Traditionally, systems have addressed this by relying either on costly human annotations or on rule-based systems at a limited scale.\\nRecently, embedding strategies have been exploited for representing latent factors in graphs of connected nodes. In this work, we propose MIDI2vec, a new approach for representing MIDI files as vectors based on graph embedding techniques. Our strategy consists of representing the MIDI data as a graph, including the information about tempo, time signature, programs and notes. Next, we run and optimise node2vec for generating embeddings using random walks in the graph. We demonstrate that the resulting vectors can successfully be employed for predicting the musical genre and other metadata such as the composer, the instrument or the movement. In particular, we conduct experiments using those vectors as input to a Feed-Forward Neural Network and we report good\\ncomparable accuracy scores in the prediction with respect to other approaches relying purely on symbolic music,\\navoiding feature engineering and producing highly scalable and reusable models with low dimensionality.\\nOur proposal has real-world applications in automated metadata tagging for symbolic music, for example in digital libraries for musicology, datasets for machine learning, and knowledge graph completion.",
         "16",
         "All my comments have been properly addressed",
         "1.0",
         "0",
         "0",
         "0.0",
         "0.1571",
         "0.6101716756820679",
         "64.37",
         "6.0",
         "8.51",
         "0.0",
         "7.6",
         "7",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "5.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "5.0",
         "5.0",
         "5.0",
         "95.0",
         "95"
        ],
        [
         "633",
         "2844-4058",
         "Lyndon Nixon",
         "20/Aug/2021",
         "Accept",
         "31",
         "MIDI2vec: Learning MIDI Embeddings for Reliable Prediction of Symbolic Music Metadata",
         "An important problem in large symbolic music collections is the low availability of high-quality metadata, which is essential for various information retrieval tasks. Traditionally, systems have addressed this by relying either on costly human annotations or on rule-based systems at a limited scale.\\nRecently, embedding strategies have been exploited for representing latent factors in graphs of connected nodes. In this work, we propose MIDI2vec, a new approach for representing MIDI files as vectors based on graph embedding techniques. Our strategy consists of representing the MIDI data as a graph, including the information about tempo, time signature, programs and notes. Next, we run and optimise node2vec for generating embeddings using random walks in the graph. We demonstrate that the resulting vectors can successfully be employed for predicting the musical genre and other metadata such as the composer, the instrument or the movement. In particular, we conduct experiments using those vectors as input to a Feed-Forward Neural Network and we report good\\ncomparable accuracy scores in the prediction with respect to other approaches relying purely on symbolic music,\\navoiding feature engineering and producing highly scalable and reusable models with low dimensionality.\\nOur proposal has real-world applications in automated metadata tagging for symbolic music, for example in digital libraries for musicology, datasets for machine learning, and knowledge graph completion.",
         "32",
         "I have reviewed the updated paper as well as the authors' comments to the reviewers. I am satisfied that the authors have resolved all of my concerns in their updated submission.",
         "0.7742",
         "0",
         "0",
         "0.5",
         "0.1858",
         "0.6703689694404602",
         "64.2",
         "8.2",
         "11.36",
         "0.0",
         "8.8",
         "31",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "5.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "5.0",
         "95.0",
         "95"
        ],
        [
         "634",
         "2801-4015",
         "Anonymous",
         "14/Jun/2021",
         "Accept",
         "42",
         "Urban IoT Ontologies for Sharing and Electric Mobility",
         "Cities worldwide are facing the challenge of digital information governance: different and competing service providers operating Internet of Things (IoT) devices often produce and maintain large amounts of data related to the urban environment. As a consequence, the need for interoperability arises between heterogeneous and distributed information, to enable city councils to make data-driven decisions and to provide new and effective added value services to their citizens. In this paper, we present the Urban IoT suite of ontologies, a common conceptual model to harmonise the data exchanges between municipalities and service providers, with specific focus on the sharing mobility and electric mobility domains.",
         "25",
         "The paper is very clear and well-written. All the issues have been solved and I consider that the ontologies and their motivation are clearly described. Moreover, decisions on ontology were also added to the paper. It is high quality and interesting paper.",
         "0.6977",
         "0",
         "0",
         "0.2225",
         "0.1149",
         "0.7622597217559814",
         "52.36",
         "8.6",
         "10.87",
         "11.7",
         "7.9",
         "42",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "5.0",
         "4.0",
         "3.0",
         "90.0",
         "90"
        ],
        [
         "635",
         "2801-4015",
         "Maxime Lefrançois",
         "21/Jun/2021",
         "Accept",
         "45",
         "Urban IoT Ontologies for Sharing and Electric Mobility",
         "Cities worldwide are facing the challenge of digital information governance: different and competing service providers operating Internet of Things (IoT) devices often produce and maintain large amounts of data related to the urban environment. As a consequence, the need for interoperability arises between heterogeneous and distributed information, to enable city councils to make data-driven decisions and to provide new and effective added value services to their citizens. In this paper, we present the Urban IoT suite of ontologies, a common conceptual model to harmonise the data exchanges between municipalities and service providers, with specific focus on the sharing mobility and electric mobility domains.",
         "32",
         "The authors took into account all my comments on the previous version of this article, and also the other reviewers' comments. One last minor issue: acronym SOSA is defined p10, but used before. I do recommend this article for publication in the Semantic Web Journal.",
         "0.8605",
         "0",
         "0",
         "-0.0854166666666666",
         "0.1858",
         "0.7286391854286194",
         "47.79",
         "10.3",
         "12.22",
         "12.5",
         "9.4",
         "45",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "5.0",
         "4.0",
         "5.0",
         "90.0",
         "90"
        ],
        [
         "636",
         "2801-4015",
         "Emilia Lenzi",
         "21/Jul/2021",
         "Accept",
         "460",
         "Urban IoT Ontologies for Sharing and Electric Mobility",
         "Cities worldwide are facing the challenge of digital information governance: different and competing service providers operating Internet of Things (IoT) devices often produce and maintain large amounts of data related to the urban environment. As a consequence, the need for interoperability arises between heterogeneous and distributed information, to enable city councils to make data-driven decisions and to provide new and effective added value services to their citizens. In this paper, we present the Urban IoT suite of ontologies, a common conceptual model to harmonise the data exchanges between municipalities and service providers, with specific focus on the sharing mobility and electric mobility domains.",
         "62",
         "This is the second revision of the article “Urban IoT Ontologies for Sharing and Electric Mobility”.  The paper describes a modular suite of ontologies representing data gathered from Urban IoT devices used in urban mobility, finally producing a conceptual model to harmonize data exchanges between municipalities and service providers, with a specific focus on sharing and electric mobility domains. The paper also describes the methodology followed for the development of the ontology and contains a set of examples and references to additional materials to better understand installation, queries, and evaluation of the model. In the previous revision I emphasized the clarity of the exposition, and the relevance of the covered topics. In fact, no major changes to the structure of the paper were required, since it was already well organized. As far as the writing is concerned, therefore, authors basically corrected the typos and missing references that had been highlighted in the review. However, in my previous review, I underlined some shortcomings in the section of result evaluation dealing with Completeness. The authors have now added  the file CompetencyQuestion_Completeness.xlsx to the repository, including numerous Competency Question examples on most of the classes of the ontology. This is indeed a useful tool to test the Completeness of the model, therefore my only advice is to replace the full file with a link to a google sheet in read-only mode. I suggest this because from git hub it is not possible to view an xlsx file directly, unless you install git hub desktop: you can only download the excel locally, which may not be the ideal solution for users and information security. As for the long-term stable URL for resources, these are all organized in the git hub repository, introduced by a bilingual read_me. Moreover, the subfolders contain read_me description in English and/or properly commented code. The contents of each file are clear and consistent with the descriptions. I give a more than positive assessment to the material provided, and the same suggestion made for the  CompetencyQuestion_Completeness.xlsx file applies to all the other xlsx files. This new paper also complies with all my other suggestions. In conclusion, my final recommendation is to accept the paper. Indeed, such an example of integration of ontologies and the use of existing vocabularies meets the needs of the users it refers to and clearly describes the context of reference, resulting in a good quality and relevance model. Moreover, its modularity also allows for future extension. Therefore, although its originality is not extraordinary, I appreciate not only the effort at the technical level, but also the detail and care in organizing heterogeneous data in the repository, and in explaining the problems and challenges faced and the results obtained. In fact, the work is complete and well documented.",
         "0.7793",
         "0",
         "0",
         "0.0946923503325942",
         "0.7713",
         "0.9263935089111328",
         "33.34",
         "13.8",
         "15.58",
         "15.8",
         "14.3",
         "103",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "positive",
         "neutral",
         "Minimal",
         "somewhat specific",
         "5.0",
         "4.0",
         "5.0",
         "92.0",
         "92"
        ],
        [
         "649",
         "2795-4009",
         "Jouni Tuominen",
         "04/Jun/2021",
         "Accept",
         "514",
         "A Shape Expression approach for assessing the quality of Linked Open Data in Libraries",
         "Cultural heritage institutions are exploring Semantic Web technologies to publish and enrich their catalogues. Several initiatives, such as Labs, are based on the creative and innovative reuse of the materials published by cultural heritage institutions. In this way, quality has become a crucial aspect to identify and reuse a dataset for research. In this article, we propose a methodology to create Shape Expressions definitions in order to validate LOD datasets published by libraries. The methodology was then applied to four use cases based on datasets published by relevant institutions. It intends to encourage institutions to use ShEx to validate LOD datasets as well as to promote the reuse of LOD, made openly available by libraries.\\n",
         "31",
         "This manuscript was submitted as 'full paper' and should be reviewed along the usual dimensions for research contributions which include (1) originality, (2) significance of the results, and (3) quality of writing. Please also assess the data file provided by the authors under “Long-term stable URL for resources”. In particular, assess (A) whether the data file is well organized and in particular contains a README file which makes it easy for you to assess the data, (B) whether the provided resources appear to be complete for replication of experiments, and if not, why, (C) whether the chosen repository, if it is not GitHub, Figshare or Zenodo, is appropriate for long-term repository discoverability, and (4) whether the provided data artifacts are complete. Please refer to the reviewer instructions and the FAQ for further information. The authors present a compact, focused experiment on applying ShEx validation to libraries' datasets to foster data re-use, with four exemplifying use cases on datasets provided by three individual libraries (and one non-library data). The presented methodology is quite straightforward application of ShEx. From purely technological perspective, the originality and significance of the contribution is not particularly high, but especially for researchers and practitioners working with (linked) data in GLAM institutions the paper would be relevant. Compared to the previous version of the paper: the authors have made improvements on the paper, extending it sufficiently on sections that needed further discussion. The comments I made in my previous review have been addressed sufficiently. The quality of the writing is good. The data file provided by the authors under “Long-term stable URL for resources” (A) is well organized and contains a README file, (B) appears to be complete for replication of experiments (based on the README file, file listing, and looking at couple of individual data files), (C) is stored on Zenodo, and (4) appears to provide complete data artifacts (based on the README file, file listing, and looking at couple of individual data files). I have one comment: - Page 14 \"Regarding the NLF dataset, a common problem is related with the property rdf:langString used for language-tagged string values that are validated against xsd:string\" - In such cases, why did you constrain the property value's datatype to \"xsd:string\" - instead of \"LITERAL\" (https://shex.io/shex-semantics/index.html#shexc) in the ShEx definition? For example, concerning NLF dataset's class Person, you have constrained the property schema:name's value to xsd:string (https://github.com/hibernator11/ShEx-DLs/blob/1.1/nlf/nlf-person.shex#L12). In the NLF data model the range of schema:name is defined as \"Literal\" (https://www.kiwi.fi/display/Datacatalog/Fennica+RDF+data+model), and in the schema.org vocabulary the range of schema:name is defined loosely: \"schema:name schema:rangeIncludes schema:Text\" (https://schema.org/version/latest/schemaorg-current-https.ttl). I would suggest loosening the constraint. Minor remarks: - Page 14: \"Table 6 provides an overview of the data quality evaluation. All the assessed repositories obtained a high score, notably the BNB and the BnF.\" - Based on Table 6, NLF obtained as high score (mconRelat) as BnF. Mention NLF as well? - Page 14: \"Regarding the NLF dataset, a common problem is related with the property rdf:langString used for language-tagged string values that are validated against xsd:string\" - rdf:langString is not a property, but a datatype.",
         "0.7396",
         "0",
         "4",
         "0.0922263520792932",
         "0.3825",
         "0.8461868762969971",
         "32.22",
         "14.2",
         "14.4",
         "15.8",
         "17.9",
         "91",
         "0",
         "1",
         "2",
         "0",
         "4.0",
         "5.0",
         "1.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "5.0",
         "78.0",
         "78"
        ],
        [
         "650",
         "2795-4009",
         "Katherine Thornton",
         "30/Jul/2021",
         "Accept",
         "257",
         "A Shape Expression approach for assessing the quality of Linked Open Data in Libraries",
         "Cultural heritage institutions are exploring Semantic Web technologies to publish and enrich their catalogues. Several initiatives, such as Labs, are based on the creative and innovative reuse of the materials published by cultural heritage institutions. In this way, quality has become a crucial aspect to identify and reuse a dataset for research. In this article, we propose a methodology to create Shape Expressions definitions in order to validate LOD datasets published by libraries. The methodology was then applied to four use cases based on datasets published by relevant institutions. It intends to encourage institutions to use ShEx to validate LOD datasets as well as to promote the reuse of LOD, made openly available by libraries.\\n",
         "87",
         "The paper A Shape Expression approach for assessing the quality of Linked Open Data in Libraries is a strong candidate for publication in the Special Issue Cultural Heritage 2021. I recommend that it is ready to be accepted for publication. The manuscript is original in that it is the first discussion of validating bibliographic data in RDF using ShEx. Many interactive examples are presented and readers can try out ShEx validation for themselves to more fully understand the points the authors make in the paper.  The importance of this paper is that it addresses a practical application of semantic web technologies to a real-life workflow issue of validation of bibliographic data in RDF. The usefulness of this paper is high in that the online validation examples are practical for others to consult and see in action. Data from several organizations can be validated using the pre-composed manifests and schemas. This will help readers understand the utility of creating quality assessment pipelines in additional contexts.  The relevance of this paper is very high because many libraries are interested in converting some of their bibliographic data to RDF and are looking for useful tooling.  The stability of the validation workflow depends on an external tool, the ShEx2 Simple Online Validator. This tool has been available on the web for several years, if it remains available then the example manifests and schemas will continue to be working examples. In my opinion many readers interested in the Special Issue on Cultural Heritage and the Semantic Web will find this paper valuable.",
         "0.7855",
         "0",
         "0",
         "0.2496247619047619",
         "0.1858",
         "0.928847312927246",
         "32.83",
         "14.0",
         "15.1",
         "16.4",
         "13.8",
         "104",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "5.0",
         "4.0",
         "5.0",
         "94.0",
         "True"
        ],
        [
         "651",
         "2789-4003",
         "Anonymous",
         "04/Jun/2021",
         "Major Revision",
         "431",
         "Formality and Accessibility in Ontology Representation and Reasoning: A Diagrammatic Approach",
         " Ontologies are often developed and used by a diverse range of stakeholders and domain experts with different levels of familiarity with symbolic notations that ontologies are expressed in. In order to make these notations accessible to all stakeholders, the ontology community has relied on  visualisation and diagrammatic notations.  However, due to lack of formality, these visualisations are often used only for ontology representation, but do not deal with ontology reasoning, which is essential for harnessing the full benefit of using ontologies.  To address this shortcoming, our novel work shows how to enable reasoning in an existing fully formalised diagrammatic language, namely Concept Diagrams (CD), that is designed for visualising and specifying ontologies. We unify diagrammatic representation and reasoning for ontologies for the first time. Furthermore, we put the accessibility of reasoning at the forefront by conducting extensive empirical studies that guide the design and implementation of iCon, a reasoning engine for ontology engineering.  In addition to accessibility, we evaluate the theoretical aspects of our approach as well as show its domain independence and generality for use in real world applications. ",
         "43",
         "The paper presents an approach for visually explain inferences using Concept Diagrams (CD), which is an existing language for specifying ontologies. The paper also describes iCon, which is the tool that supports such visualisation approach. The authors included several appendix sections that include the CD language, the rules used to support the presented approach and additional explanation related to the use cases and the evaluation.  The paper is well-written and I also find useful the inference visualisation.  However, I think that the current version of the manuscript still needs some improvements and explanations:  - At the beginning of the introduction section (Section 1), the authors describe ontology visualisation and expose some existing tools that deal with this topic. From that first paragraph, I would expect iCon to be an ontology visualisation tool that also supports reasoning. However, if I understood correctly after reading the manuscript, the proposed approach is not oriented to ontology visualisation but to explain the inference related to one ontology axiom. Therefore, it cannot be used for visualising the whole ontology. - I also think that the authors should expose more clearly what is the contribution of the paper since the CD language was already presented in a previous paper.  - There is a lot of information that is only included in the Appendix sections, which hinders the readability of the paper. Could authors consider moving some of this information to the main sections? For example, in section 4.2 (page 6) there is no information about the inferences rules since they are all presented in Appendix B. - Section 7.1. Are there any differences between the results obtained from experts in ontology development and those that are not experts? I think that this information is useful to measure the usability of the approach. It is useful for all kind of users? or only for those that are experts in logics and ontologies? - In the Related Work section (Section 8) the authors do not mention Protégé plugins like VOWL or OWLAx which, since they are integrated into an ontology editor, also supports somehow the reasoning task (related to the claims stated in Section 1) although it is true that Protégé does not use the visual notation for explaining inferences. - In the conclusions section, the authors state that \"we proposed a unified approach for ontology representation, specification and reasoning.\". However, it is unclear for me how to represent and specify the ontology with the reasoning approach proposed in this paper.  If I understood correctly, the contribution of this paper is the visualisation of inference rules for ontology axioms.",
         "0.7637",
         "1",
         "0",
         "0.1478260869565217",
         "0.1429",
         "0.9235461950302124",
         "34.05",
         "13.5",
         "12.6",
         "15.1",
         "13.8",
         "99",
         "1",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "1.0",
         "yes",
         "positive",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "3.0",
         "72.0",
         "80"
        ],
        [
         "652",
         "2789-4003",
         "Anonymous",
         "05/Jul/2021",
         "Reject",
         "558",
         "Formality and Accessibility in Ontology Representation and Reasoning: A Diagrammatic Approach",
         " Ontologies are often developed and used by a diverse range of stakeholders and domain experts with different levels of familiarity with symbolic notations that ontologies are expressed in. In order to make these notations accessible to all stakeholders, the ontology community has relied on  visualisation and diagrammatic notations.  However, due to lack of formality, these visualisations are often used only for ontology representation, but do not deal with ontology reasoning, which is essential for harnessing the full benefit of using ontologies.  To address this shortcoming, our novel work shows how to enable reasoning in an existing fully formalised diagrammatic language, namely Concept Diagrams (CD), that is designed for visualising and specifying ontologies. We unify diagrammatic representation and reasoning for ontologies for the first time. Furthermore, we put the accessibility of reasoning at the forefront by conducting extensive empirical studies that guide the design and implementation of iCon, a reasoning engine for ontology engineering.  In addition to accessibility, we evaluate the theoretical aspects of our approach as well as show its domain independence and generality for use in real world applications. ",
         "74",
         "The article attacks a crucial, central and timely research question (accessible knowledge representation & reasoning) by combining existing approaches (formal diagrammatic languages, diagrammatic reasoning, visual representation of proofs). I was very enthusiastic about the article's angle at first, as it proposes an ambitious and innovative research direction. The topic ideally fits SWJ. The core of the presented results is an implementation and empirical evaluation of an interactive theorem prover for knowledge bases/ontologies. The underlying theoretical framework extends existing work on Concept Diagrams (CD) and the reasoning framework builds on and extends the existing Speedith framework (originally for Spider Diagrams, a \"subset\" of CD). The work is thus original but does not meet the level of innovation and ambition supposedly required to tackle the raised underlying research questions. The focus and research horizon of the article is very confined. It focuses on a very limited subset of ontologies (OWL-ish ones or even OWL 2 RL) and a lot of the article's statements (viz. p19/48 [we are] \"unifying diagrammatic representation and reasoning for ontologies for the first time\") may only work in this very restricted setting. A proper embedding of the work in the field of diagrammatic knowledge representation and reasoning for ontologies (e.g. including the work of C.S. Peirce, Sowa's Knowledge Graphs and successors, Guizzardi et al.'s OntoUML,... -- all these proposed an unifying approach prior) is missing. This would help to better highlight the real original points of the article.  A contrasting look on the currently rising field of explainable AI that tackles a similar question in a different domain, would also support the articles timeliness. Even if the underlying research question and the proposed solution angle are certainly highly significant, the proposed results are not able to convince at the current stage.  This is mainly due to the missing clear direction of the article: the core concepts for evaluation (e.g. \"accessibility\") are never clearly defined (in a measurable way) and thus the proposed empirical evaluation is not traceable and transparently comprehensible.  For an empirical research article (as the authors would classify their paper themselves), additional details on the study and especially its participants, their background and their level of \"accessibility\" is missing. The proposed studies are not easily reproducible and seem artificial/academic but at least inspired/based on examples from real-world knowledge engineering. The evaluation mainly focuses on the proposed representation of micro-step diagrammatic proofs - ignoring the obvious rival of \"explainable\" micro-step symbolic proofs. Thus, the proposed supremacy of diagrammatic proofs in the given studies could be easily doubted.  For a concept/methodology paper (which is not really intended by the authors but would be necessary to make a clear distinction between the formalisms), formal proofs of the given statements (soundness etc.) are missing. Similarly the presentation of Concept Diagrams is neither sufficiently formal nor adequately intuitive for readers to follow the proposed argumentation.  Here, it would be desirable that the authors make a clear decision on WHAT they want to present and HOW they want to present it in a way that is self-contained and written with  the SWJ audience in mind. Thus, I opt for rejecting the paper in its current state. However, a substantial revision (i.e. a complete rewrite targeting the points raised above and which comprises certainly more than a major revision here) could proof a substantial scientific contribution worth publishing in the future.",
         "0.784",
         "0",
         "0",
         "0.1161662631154156",
         "0.129",
         "0.9306662678718568",
         "26.0",
         "14.6",
         "14.41",
         "15.8",
         "15.4",
         "96",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "6.0",
         "False",
         "negative",
         "neutral",
         "Moderate",
         "neutral",
         "3.0",
         "2.0",
         "2.0",
         "60.0",
         "70"
        ],
        [
         "653",
         "2789-4003",
         "Anonymous",
         "28/Jul/2021",
         "Reject",
         "1157",
         "Formality and Accessibility in Ontology Representation and Reasoning: A Diagrammatic Approach",
         " Ontologies are often developed and used by a diverse range of stakeholders and domain experts with different levels of familiarity with symbolic notations that ontologies are expressed in. In order to make these notations accessible to all stakeholders, the ontology community has relied on  visualisation and diagrammatic notations.  However, due to lack of formality, these visualisations are often used only for ontology representation, but do not deal with ontology reasoning, which is essential for harnessing the full benefit of using ontologies.  To address this shortcoming, our novel work shows how to enable reasoning in an existing fully formalised diagrammatic language, namely Concept Diagrams (CD), that is designed for visualising and specifying ontologies. We unify diagrammatic representation and reasoning for ontologies for the first time. Furthermore, we put the accessibility of reasoning at the forefront by conducting extensive empirical studies that guide the design and implementation of iCon, a reasoning engine for ontology engineering.  In addition to accessibility, we evaluate the theoretical aspects of our approach as well as show its domain independence and generality for use in real world applications. ",
         "97",
         "*** Summary: *** The paper \"Formality and Accessibility in Ontology Representation and Reasoning: A Diagrammatic Approach\" gives itself an ambitious goal, namely to \"unify diagrammatic representation and reasoning for ontologies for the first time\".  In line with such ambition, it covers an extremely wide spectrum of angles on diagrammatic reasoning for ontologies, namely describes a diagrammatic language (Section 2), reasoning for that language (Section 3), a description of a prototype implementation for that language (Section 4 and 5), a description of two different modelling case studies (Section 6), the description of an empirical study to evaluate how participants comprehend proofs given in the language (Section 7), and finally related and future work (Sections 8 and 9).  The study of diagrammatic languages indeed provides a welcome alternative angle to ontology representation and reasoning. In particular, one of the central topics of the paper, namely the use of diagrammatic representation and reasoning during debugging involving 'non-experts', seems indeed promising and worthwhile. It is also clear that the authors have done substantial previous work on the topic. However, to sum up the more detailed comments below, the present paper provides an unbalanced presentation of too many topics and is not recommended for acceptance in this form. I would recommend the authors to reshape the paper to focus on the novel contributions and provide the necessary background in a more focused yet technically self-contained way. In short: - the technical parts are on the one hand mostly not new (the CD formalism has been published previously), and what is presented in terms of technical material is sometimes ill-motivated and lacks discussion or detail.  - too many details are moved into the appendix, with an often underspecified reference/instructions. This has the effect that the main paper can appear partly incomprehensible (i.e. not self-contained) whereas the details provided in the appendix lack context and discussion. - it appears that the only essentially new contribution is the user study carried out which is based on 10 participants inspecting only 4 hand-created proofs. Even though providing some interesting insights, the study seems rather limited in scope, particularly since it is carried out with 'logic experts'.  - typical advantages often discussed in the context of diagrammatic reasoning, such as intuitiveness, psychological/cognitive advantages, or 'free rides' in reasoning, are mentioned but not discussed in detail for the CD formalism.  - several of the presented aspects, such as the extend of coverage of the OWL 2 RL profile, seem rather preliminary. In particular, even though covering (fragments of) standard DL-based languages, no systematic comparison or translation of that standard syntax and semantics is given in the main text. This is particularly problematic for the typical Semantic Web Journal reader who is likely acquainted with DL but not with CD.  Can a precise soundness and completeness result for a specific fragment be given? *** Some Detailed Comments *** Section 1: it would be nice to extend the introduction with some more background on diagrammatic traditions (Venn/Peirce/Euler etc) vs symbolic, and a more extended pitch why the diagrammatic might provide a valuable alternative and, on certain levels, something superior over the standard linear symbolic approach.  Section 2: the introduction of the language remains cryptic. An extended example (from the `crip sheet'?) would be useful to guide the reader to understand the formalism. The syntactic elements of the diagrams need to be more carefully introduced and their semantics explained. Ideally, a direct correlation to DL is given. For instance, saying that `Solid arrows mean that the source is related to only the target' is too vague as a definition, even when knowing that the `only' stems from DL talk. Another example: `Closed curves give rise to zones that are regions inside some or none of the curves and outside the remaining curves'. This is not sufficient as an introduction of the concept of 'closed curves'- are 'unclosed curves' admitted? Etc. Section 3: you implement 24 out of 80 rules for the RL profile; the choice should be better motivated and the limitations explained. You equate `more granular' with `atomic' with `more likely to be explanatory' - where is the evidence for this? Tiny reasoning steps are not always easier. In fact, in many of the diagrammatic examples you give, an experienced reader can 'see' the inference immediately (eg Fig 4) whereas going through all the steps of the proof is tedious and not providing a `high-level' explanation.  Switching between Euler and Venn representations needs more motivation. Why is this kind of ambiguity not undesirable? Also, explain your naming schema such as `cax-dw'.  Section 4/5: it could be more immediate that this is an interactive system, otherwise ok as a summary of the iCon system.  In Section 5, we find a brief discussion of the one-to-many mapping of symbolic rules to sequences of diagrammatic rules. It remains somewhat hand-waiving. For instance, you say that there are 'infinitely many' valid inferences that can be constructed that do 'not resemble' an OWL 2 RL inference: what does this imply? Section 6 discusses two use cases. It discusses how diagrammatic proofs can be given for certain relevant inferences. If the expressivity of the language is understood, it is rather clear that something like this can be done. I would consider this rather workshop paper material.  \t Section 7: I think the distinction between 'theorem proving' community and 'mathematicians' is rather misleading and wrong. Sequences and trees are used in both. The study seems useful to improve the design of the system, but rather limited to understand the general psychology and cognition involved in the formalism given the advanced knowledge of the participants. In terms of method, it is not clear what baseline would be used to measure the relative `accessibility' or `comprehensibility' if no alternative formalisation was provided.  Appendix: as commented before, some of the material should be in the main text, some other material would need to be enriched with discussion.  Part A contains a number of detailed technical definitions. It remains unclear a) which ones are novel, if any, b) which ones are needed in the main text, because they are not referenced in detail.  The central definitions come here without any discussion. Moreover, even though definitions such as Def 1 seem extremely detailed (having 12 parts), they are at the same time rather underspecified and lacking discussion. Are curves geometric objects or abstracts? Are shades just attributes of zones?  A location is a set of zones? Why is the `equality' not transitive? What is the circle in part 8? Where do you define \\mathcal{L}_S etc? Spider labels? Where have you introduced that distinction? Is Def 3 not exactly the same as a DL interpretation? Discuss that. And so on.  The 'crib sheet' (or parts of it) might be a good way to introduce the formalism also in the main paper, ideally with a symbolic translation to a standard formalism such as DL. Typo: to replace current abstract -> to replace the current abstract",
         "0.792",
         "3",
         "0",
         "0.1568560127188445",
         "0.0667",
         "0.943989872932434",
         "35.78",
         "12.9",
         "12.43",
         "14.3",
         "13.1",
         "84",
         "0",
         "0",
         "0",
         "0",
         "2.0",
         "4.0",
         "3.0",
         "True",
         "negative",
         "impolite",
         "Heavy",
         "very broad",
         "2.0",
         "4.0",
         "3.0",
         "60.0",
         "70"
        ],
        [
         "723",
         "2721-3935",
         "Houcemeddine Turki",
         "18/Feb/2021",
         "Major Revision",
         "473",
         "Fact Checking in Knowledge Graphs by Logical Consistency",
         "Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction systems that automatically extract factual statements from unstructured textual data to populate existing knowledge graphs. Traditional fact checking by experts is increasingly difficult to keep pace with the volume of newly created information in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. In this paper, our goal is to 1) mine weighted logical rules from a knowledge graph, 2) to find positive and negative evidential paths in a knowledge graph for a given factual statement by the mined rules, and 3) to calculate a truth score for a given statement by an unsupervised ensemble of the found evidential paths. For example, we can determine the statement \"The United States is the birth place of Barack Obama\" as truthful since there is the positive evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) in a knowledge graph, and it is logically consistent with the given statement. On the contrary, we can determine the factual statement \"Canada is the nationality of Barack Obama\" as untruthful since there is the negative evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) ∧ (United States, ≠ , Canada) in a knowledge graph, and it is logically contradictory to the given statement. For evaluation, we constructed a novel evaluation dataset by labeling true or false labels on the factual statements extracted from Wikipedia texts by the state-of-the-art BERT-based relation extractor. Our evaluation results show that the proposed weighted logical rule-based approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC, and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two publicly available datasets. The source code and evaluation dataset proposed in this paper is open-source and available at https://github.com/machinereading/KV-rule and https://github.com/machinereading/KV-eval-dataset each.",
         "4",
         "This manuscript presents a novel rule-based approach for fact checking in knowledge graphs based on mining textual resources. The work provides new evidences that rule-based approaches can provide more precise evaluation of the accuracy of statements in knowledge graphs and can enhance the efficiency of embedding-based methods when combined with them. The availability of source codes and datasets in GitHub is an advantage for this work as this will allow the reproducibility of the described experimental study. However, there are several matters within the paper that should be addressed to ameliorate its final output: (i) Introduction: The \"Introduction\" seems to be a summary of \"Related Studies in Fact Checking\" rather than a proper introduction and contextualization of the paper. I propose to expand the part about misinformation fighting in the introduction to give better context for the development of this research paper. The authors can benefit from previous research papers about fact checking in general to develop the introduction of the paper. Several points in the introduction should be moved to Related Studies in Fact Checking. (ii) The paper did not emphasize the advantages of rule-based approaches when compared to embedding-based methods beyond having a better precision. Effectively, there are many other advantages of rule-based approaches. For example, the results of rule-based approaches can be more explainable than the ones of embedding-based approaches. Such advantages should be expanded and highlighted in the research paper. (iii) The paper did not emphasize the importance of having the datasets and source codes available in a specific GitHub repository. The authors should specify that this practice allows reproducibility and further development of the work by peers, particularly in the conclusion. (iv) The paper did not discuss the concept of reification in knowledge graphs. Effectively, several knowledge graphs add qualifiers to triples to provide a characteristic of the statements (i.e. {(s,p,o), p, o}. The authors should discuss the usefulness of the method to verify the qualifiers of the statements in the Discussion or as a future direction for this work. (v) The paper should evocate the robustness of the rule-based approach they proposed to adversarial attacks. This can be an advantage of the approach. (vi) There are several typos in the research paper (e.g. \"UC Berkely\" should be \"UC Berkeley\"). The authors should proofreading the paper to eliminate such deficiencies. (vii) The authors can expand the Discussion of the work (Part 5) to explain the strengths of KStream, KLinker, COPPAL, RUDIK, and PredPath that contributed to their efficiency as reported in the Experimental Study according to previous research papers. This can explicate the reasons of why the method developed by the authors was more efficient. (viii) The authors should provide future directions for the development of this work in the conclusion. Given this, I propose to accept this paper for publication after these six major revisions are applied.",
         "0.7464",
         "1",
         "0",
         "0.1097294372294372",
         "0.2025",
         "0.9120528101921082",
         "36.08",
         "12.7",
         "12.27",
         "13.7",
         "13.7",
         "97",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "1.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "2",
         "4.0",
         "3.0",
         "4.0",
         "75.0",
         "83"
        ],
        [
         "724",
         "2721-3935",
         "Anonymous",
         "18/Mar/2021",
         "Major Revision",
         "463",
         "Fact Checking in Knowledge Graphs by Logical Consistency",
         "Misinformation spreads across media, community, and knowledge graphs in the Web by not only human agents but also information extraction systems that automatically extract factual statements from unstructured textual data to populate existing knowledge graphs. Traditional fact checking by experts is increasingly difficult to keep pace with the volume of newly created information in the Web. Therefore, it is important and necessary to enhance the computational ability to determine whether a given factual statement is truthful or not. In this paper, our goal is to 1) mine weighted logical rules from a knowledge graph, 2) to find positive and negative evidential paths in a knowledge graph for a given factual statement by the mined rules, and 3) to calculate a truth score for a given statement by an unsupervised ensemble of the found evidential paths. For example, we can determine the statement \"The United States is the birth place of Barack Obama\" as truthful since there is the positive evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) in a knowledge graph, and it is logically consistent with the given statement. On the contrary, we can determine the factual statement \"Canada is the nationality of Barack Obama\" as untruthful since there is the negative evidential path (Barack Obama, birthPlace, Hawaii) ∧ (Hawaii, country, United States) ∧ (United States, ≠ , Canada) in a knowledge graph, and it is logically contradictory to the given statement. For evaluation, we constructed a novel evaluation dataset by labeling true or false labels on the factual statements extracted from Wikipedia texts by the state-of-the-art BERT-based relation extractor. Our evaluation results show that the proposed weighted logical rule-based approach outperforms the state-of-the-art unsupervised approaches significantly by up to 0.12 AUC-ROC, and even outperforms the supervised approach by up to 0.05 AUC-ROC not only in our dataset but also in the two publicly available datasets. The source code and evaluation dataset proposed in this paper is open-source and available at https://github.com/machinereading/KV-rule and https://github.com/machinereading/KV-eval-dataset each.",
         "32",
         "The paper presents a weighted logical positive and negative rules-based approach to check logical consistency of triples in a knowledge graph.  The paper has multiple flaws in terms of writing (please, consider English proofreading for a future submission), but also in terms of its structure and form (see remarks below). Comparing rule-based and statistical approaches for graph completion is very useful. However, I was disappointed by table 1, which contains only three very obvious comparison criteria. I don’t find that very informative (and is totally redundant with the text in the corresponding paragraphe) and would strongly encourage a more in-depth analysis of the differences (pros and cons) of the two types of methods. On a related note, I find the related work section difficult to follow. It probably can be improved by structuring better the different approaches, defining a clear basis for comparison between them. Also, and importantly, the section lacks a clear positioning of the proposed approach as compared to those reviewed in this section. I also fail to see the purpose of presenting embeddings-based approaches since they are not applied in this work, as far as i can see. I fail to see the originality of the presented approach, my impression is that it builds largely on existing techniques (e.g. generation of negative samples, rule mining and the like). The overall structure of the paper can be improved significantly. It currently contains multiple redundant parts (e.g. large parts of section 3 are repetitive wrt what has been said already in the introduction or elsewhere in the paper). While the overall approach is explained clearly, I think that relatively straightforward ideas are described in way too much details (like for example the negative examples sampling).  The results do not report anything about the computational complexity of the method, while an argument is made in the introduction about assisting human/manual fact-checking at scale. Also, the number of predicates in the datasets that are used in the studies appears very small for the approach to be able to account for a real-world scenario. More surprisingly, the evaluation results are reported only on a handful of predicates. Therefore I am doubtful about the applicability/generalizability of the proposed approach in a more realistic scenarios and at scale. Minor: across media, community, and —> across media, communities, and -  Misinformation in the Web —>  Misinformation on the Web -  in media and community makes -->  in media and communities makes -  This problem is common and getting worse in modern digital society - this statement somehow needs support -  which is logically contradict —>  which logically contradicts -  we did not contain those triples already contained in K-Box —>  we did not include those triples already contained in K-Box - there’s a screenshot issue with fig. 7",
         "0.7582",
         "1",
         "0",
         "0.036034151034151",
         "0.3415",
         "0.8945873379707336",
         "31.62",
         "14.5",
         "15.34",
         "15.6",
         "15.3",
         "99",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "3.0",
         "no",
         "neutral",
         "5",
         "2",
         "5",
         "3.0",
         "4.0",
         "3.0",
         "60.0",
         "80"
        ]
       ],
       "shape": {
        "columns": 38,
        "rows": 131
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paper_id</th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_suggestion</th>\n",
       "      <th>length_words</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>days_to_submit</th>\n",
       "      <th>review_text</th>\n",
       "      <th>mattr</th>\n",
       "      <th>...</th>\n",
       "      <th>llm_citation_usage</th>\n",
       "      <th>llm_sentiment_polarity</th>\n",
       "      <th>llm_politeness</th>\n",
       "      <th>llm_hedging</th>\n",
       "      <th>llm_specificity</th>\n",
       "      <th>llm_domain_terms</th>\n",
       "      <th>llm_relevance_alignment</th>\n",
       "      <th>llm_readability</th>\n",
       "      <th>llm_overall_quality</th>\n",
       "      <th>llm_overall_score_100</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>152</th>\n",
       "      <td>3582-4796</td>\n",
       "      <td>Maria-Esther Vidal</td>\n",
       "      <td>25/Nov/2023</td>\n",
       "      <td>Accept</td>\n",
       "      <td>26</td>\n",
       "      <td>PAPyA: a Library for Performance Analysis of S...</td>\n",
       "      <td>Prescriptive Performance Analysis (PPA) has sh...</td>\n",
       "      <td>8</td>\n",
       "      <td>The authors have addressed my comments and rec...</td>\n",
       "      <td>0.8462</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>No Hedging</td>\n",
       "      <td>very specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>153</th>\n",
       "      <td>3582-4796</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>24/Dec/2023</td>\n",
       "      <td>Accept</td>\n",
       "      <td>8</td>\n",
       "      <td>PAPyA: a Library for Performance Analysis of S...</td>\n",
       "      <td>Prescriptive Performance Analysis (PPA) has sh...</td>\n",
       "      <td>37</td>\n",
       "      <td>The authors have taken care of my comments.</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>90.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>3552-4766</td>\n",
       "      <td>Alexandry Augustin</td>\n",
       "      <td>02/Oct/2023</td>\n",
       "      <td>Accept</td>\n",
       "      <td>10</td>\n",
       "      <td>Dura-Europos Stories: Developing Interactive S...</td>\n",
       "      <td>We introduce Dura-Europos Stories, a multimedi...</td>\n",
       "      <td>7</td>\n",
       "      <td>Thank you for amending the manuscript with my ...</td>\n",
       "      <td>1.0000</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>3552-4766</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>19/Oct/2023</td>\n",
       "      <td>Accept</td>\n",
       "      <td>102</td>\n",
       "      <td>Dura-Europos Stories: Developing Interactive S...</td>\n",
       "      <td>We introduce Dura-Europos Stories, a multimedi...</td>\n",
       "      <td>24</td>\n",
       "      <td>Upon reviewing the current version of the manu...</td>\n",
       "      <td>0.7371</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>No Hedging</td>\n",
       "      <td>very specific</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>3512-4726</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>04/Oct/2023</td>\n",
       "      <td>Reject</td>\n",
       "      <td>457</td>\n",
       "      <td>Knowledge Level Tags: Applied to Collaborative...</td>\n",
       "      <td>This article aims to present a tag recommendat...</td>\n",
       "      <td>68</td>\n",
       "      <td>The paper addresses a problem that Twitter res...</td>\n",
       "      <td>0.7840</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>negative</td>\n",
       "      <td>impolite</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>3</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1725</th>\n",
       "      <td>619-1827</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>03/May/2014</td>\n",
       "      <td>Reject</td>\n",
       "      <td>804</td>\n",
       "      <td>Module Extraction for Efficient Object Query o...</td>\n",
       "      <td>The extraction of logically-independent fragme...</td>\n",
       "      <td>100</td>\n",
       "      <td>The submission addresses the problem of partit...</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>...</td>\n",
       "      <td>False</td>\n",
       "      <td>negative</td>\n",
       "      <td>impolite</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>520-1720</td>\n",
       "      <td>Natasha Noy</td>\n",
       "      <td>22/Jul/2013</td>\n",
       "      <td>Accept</td>\n",
       "      <td>26</td>\n",
       "      <td>EARTh: an Environmental Application Reference ...</td>\n",
       "      <td>The paper aims at providing a description of E...</td>\n",
       "      <td>3</td>\n",
       "      <td>This revision addresses my concerns. I am part...</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1780</th>\n",
       "      <td>484-1680</td>\n",
       "      <td>Anonymous</td>\n",
       "      <td>15/Jun/2013</td>\n",
       "      <td>Reject</td>\n",
       "      <td>368</td>\n",
       "      <td>Facilitating Data Discovery by Connecting Rela...</td>\n",
       "      <td>In this study, we investigate two approaches t...</td>\n",
       "      <td>31</td>\n",
       "      <td>The paper presents and compares RDF/XML (in th...</td>\n",
       "      <td>0.7586</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>72</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1781</th>\n",
       "      <td>484-1680</td>\n",
       "      <td>Ghislain Hachey</td>\n",
       "      <td>17/Jun/2013</td>\n",
       "      <td>Reject</td>\n",
       "      <td>665</td>\n",
       "      <td>Facilitating Data Discovery by Connecting Rela...</td>\n",
       "      <td>In this study, we investigate two approaches t...</td>\n",
       "      <td>33</td>\n",
       "      <td>This paper investigates two different approach...</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>...</td>\n",
       "      <td>yes</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>484-1680</td>\n",
       "      <td>Ian Dickinson</td>\n",
       "      <td>18/Jun/2013</td>\n",
       "      <td>Reject</td>\n",
       "      <td>640</td>\n",
       "      <td>Facilitating Data Discovery by Connecting Rela...</td>\n",
       "      <td>In this study, we investigate two approaches t...</td>\n",
       "      <td>34</td>\n",
       "      <td>This paper has a number of minor flaws, but my...</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>...</td>\n",
       "      <td>no</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>131 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       paper_id            reviewer  review_date review_suggestion  \\\n",
       "152   3582-4796  Maria-Esther Vidal  25/Nov/2023            Accept   \n",
       "153   3582-4796           Anonymous  24/Dec/2023            Accept   \n",
       "196   3552-4766  Alexandry Augustin  02/Oct/2023            Accept   \n",
       "197   3552-4766           Anonymous  19/Oct/2023            Accept   \n",
       "204   3512-4726           Anonymous  04/Oct/2023            Reject   \n",
       "...         ...                 ...          ...               ...   \n",
       "1725   619-1827           Anonymous  03/May/2014            Reject   \n",
       "1766   520-1720         Natasha Noy  22/Jul/2013            Accept   \n",
       "1780   484-1680           Anonymous  15/Jun/2013            Reject   \n",
       "1781   484-1680     Ghislain Hachey  17/Jun/2013            Reject   \n",
       "1782   484-1680       Ian Dickinson  18/Jun/2013            Reject   \n",
       "\n",
       "      length_words                                              title  \\\n",
       "152             26  PAPyA: a Library for Performance Analysis of S...   \n",
       "153              8  PAPyA: a Library for Performance Analysis of S...   \n",
       "196             10  Dura-Europos Stories: Developing Interactive S...   \n",
       "197            102  Dura-Europos Stories: Developing Interactive S...   \n",
       "204            457  Knowledge Level Tags: Applied to Collaborative...   \n",
       "...            ...                                                ...   \n",
       "1725           804  Module Extraction for Efficient Object Query o...   \n",
       "1766            26  EARTh: an Environmental Application Reference ...   \n",
       "1780           368  Facilitating Data Discovery by Connecting Rela...   \n",
       "1781           665  Facilitating Data Discovery by Connecting Rela...   \n",
       "1782           640  Facilitating Data Discovery by Connecting Rela...   \n",
       "\n",
       "                                               abstract  days_to_submit  \\\n",
       "152   Prescriptive Performance Analysis (PPA) has sh...               8   \n",
       "153   Prescriptive Performance Analysis (PPA) has sh...              37   \n",
       "196   We introduce Dura-Europos Stories, a multimedi...               7   \n",
       "197   We introduce Dura-Europos Stories, a multimedi...              24   \n",
       "204   This article aims to present a tag recommendat...              68   \n",
       "...                                                 ...             ...   \n",
       "1725  The extraction of logically-independent fragme...             100   \n",
       "1766  The paper aims at providing a description of E...               3   \n",
       "1780  In this study, we investigate two approaches t...              31   \n",
       "1781  In this study, we investigate two approaches t...              33   \n",
       "1782  In this study, we investigate two approaches t...              34   \n",
       "\n",
       "                                            review_text   mattr  ...  \\\n",
       "152   The authors have addressed my comments and rec...  0.8462  ...   \n",
       "153         The authors have taken care of my comments.  1.0000  ...   \n",
       "196   Thank you for amending the manuscript with my ...  1.0000  ...   \n",
       "197   Upon reviewing the current version of the manu...  0.7371  ...   \n",
       "204   The paper addresses a problem that Twitter res...  0.7840  ...   \n",
       "...                                                 ...     ...  ...   \n",
       "1725  The submission addresses the problem of partit...  0.7587  ...   \n",
       "1766  This revision addresses my concerns. I am part...  0.9600  ...   \n",
       "1780  The paper presents and compares RDF/XML (in th...  0.7586  ...   \n",
       "1781  This paper investigates two different approach...  0.8030  ...   \n",
       "1782  This paper has a number of minor flaws, but my...  0.7908  ...   \n",
       "\n",
       "      llm_citation_usage  llm_sentiment_polarity  llm_politeness  llm_hedging  \\\n",
       "152                  yes                positive          polite   No Hedging   \n",
       "153                 True                positive          polite      Minimal   \n",
       "196                  yes                 neutral         neutral      Minimal   \n",
       "197                  yes                positive          polite   No Hedging   \n",
       "204                   no                negative        impolite        Heavy   \n",
       "...                  ...                     ...             ...          ...   \n",
       "1725               False                negative        impolite        Heavy   \n",
       "1766                True                 neutral         neutral      Minimal   \n",
       "1780                  no                 neutral         neutral     Moderate   \n",
       "1781                 yes                 neutral         neutral      Minimal   \n",
       "1782                  no                negative         neutral     Moderate   \n",
       "\n",
       "        llm_specificity  llm_domain_terms  llm_relevance_alignment  \\\n",
       "152       very specific               3.0                      5.0   \n",
       "153   somewhat specific               4.0                      5.0   \n",
       "196   somewhat specific               4.0                      5.0   \n",
       "197       very specific               5.0                      5.0   \n",
       "204                   3               2.0                      1.0   \n",
       "...                 ...               ...                      ...   \n",
       "1725                  5               2.0                      1.0   \n",
       "1766  somewhat specific               4.0                      3.0   \n",
       "1780  somewhat specific               2.0                      4.0   \n",
       "1781  somewhat specific               3.0                      4.0   \n",
       "1782            neutral               3.0                      4.0   \n",
       "\n",
       "      llm_readability  llm_overall_quality  llm_overall_score_100  \n",
       "152               4.0                 90.0                     90  \n",
       "153               5.0                 90.0                     95  \n",
       "196               3.0                 80.0                     82  \n",
       "197               5.0                 95.0                     95  \n",
       "204               2.0                 15.0                     20  \n",
       "...               ...                  ...                    ...  \n",
       "1725              3.0                 40.0                     20  \n",
       "1766              5.0                 85.0                     85  \n",
       "1780              3.0                 64.0                     72  \n",
       "1781              5.0                 68.0                     74  \n",
       "1782              4.0                 42.0                     44  \n",
       "\n",
       "[131 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "# Randomly select 50 unique paper IDs from each file\n",
    "selected_paper_ids_file1_sample = random.sample(list(selected_paper_ids_file1), 50)\n",
    "selected_paper_ids_file2_sample = random.sample(list(selected_paper_ids_file2), 50)\n",
    "\n",
    "# Filter the original dataframes to include all rows for the selected paper IDs\n",
    "df_50_sample_file1 = file1[file1['title'].isin(selected_paper_ids_file1_sample)]\n",
    "df_50_sample_file2 = file2[file2['paper_id'].isin(selected_paper_ids_file2_sample)]\n",
    "\n",
    "# Display the resulting dataframes\n",
    "display(df_50_sample_file1)\n",
    "display(df_50_sample_file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_273169/4254898834.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_50_sample_file1['venue'] = 'f1000'\n",
      "/tmp/ipykernel_273169/4254898834.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_50_sample_file2['venue'] = 'semanticweb'\n"
     ]
    },
    {
     "data": {
      "application/vnd.microsoft.datawrangler.viewer.v0+json": {
       "columns": [
        {
         "name": "index",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "reviewer",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_date",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "review_suggestion",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "length_words",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "title",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "abstract",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "days_to_submit",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "review_text",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "mattr",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "question_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "citation_count",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "sentiment_polarity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "politeness_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "similarity_score",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_reading_ease",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "flesch_kincaid_grade",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "gunning_fog",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "smog_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "automated_readability_index",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "hedge_C",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_D",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_E",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_I",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "hedge_N",
         "rawType": "int64",
         "type": "integer"
        },
        {
         "name": "llm_length_effort",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_lexical_diversity",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_questions_raised",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_citation_usage",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_sentiment_polarity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_politeness",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_hedging",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_specificity",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "llm_domain_terms",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_relevance_alignment",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_readability",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_overall_quality",
         "rawType": "float64",
         "type": "float"
        },
        {
         "name": "llm_overall_score_100",
         "rawType": "object",
         "type": "string"
        },
        {
         "name": "venue",
         "rawType": "object",
         "type": "string"
        }
       ],
       "conversionMethod": "pd.DataFrame",
       "ref": "71db45c8-7f3c-4443-a4e7-c425d5f6d674",
       "rows": [
        [
         "0",
         "shaimaa Mohamed Amin",
         "29 Jul 2024",
         "Approved With Reservations",
         "1557",
         "Estimating the efficacy of Newborn-Communication, Health, Feeding and Swallowing Education Program (N-CHFSEP) for primiparous mothers",
         "Background Primiparous mothers face diverse challenges during pregnancy and post-childbirth. There is a lack of comprehensive educational programs for primiparous mothers on maternal functioning and newborn care. This study aimed to explore the efficacy of a developed educational program on the attitude of primiparous mothers towards newborn communication, general health, feeding and swallowing. The objectives were (1) to develop an attitude questionnaire (AQ), a parent education program, and a feedback questionnaire (FQ); and (2) to estimate the efficacy of the education program pre- and post-delivery.  Methods Ninety-eight primiparous mothers without any obstetric history, proficient in English or Kannada, and delivering healthy newborns were recruited for the study. Phase 1 involved the development and validation of AQ, the parent education program [Newborn Communication, Health, Feeding and Swallowing Education Program (N-CHFSEP)], and FQ; while Phase 2 comprised of administering them on the mothers. Both quantitative (descriptive statistics, paired t-test, and chi-square test) and qualitative analysis were done on the parameters of interest.  Results The results of the study demonstrated a notable increase in the number of mothers (not all) reporting heightened confidence levels following receiving the N-CHFSEP (which was observed in all the domains). This observed change (pre and post) was statistically significant as per paired t-test analysis (p <0.05) indicating a significant increase in confidence levels post-N-CHFSEP intervention, as well as recognizing warning signs related to the same. Sociodemographic factors such as age, education, occupation, and family type were reported to have a significant effect (p <0.05) on maternal confidence levels before and after N-CHFSEP administration. Feedback from participants highlighted the effectiveness of the program in enhancing knowledge and awareness, while also suggesting areas for improvement.  Conclusions This study demonstrates the effectiveness of N-CHFSEP in enhancing primiparous mothers' confidence in newborn care, thereby improving maternal and infant health.",
         "20",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Dear [editor ], I hope this message finds you well. I wanted to extend my sincere gratitude to you for sending me the article for review. I truly appreciate the opportunity to contribute to the process and offer my insights. I've gone through the article and I have some constructive feedback that I believe could enhance the overall quality and impact of the piece. Title: Your research title is clear and informative, but it can be made more concise and engaging. Here are a few suggestions to refine and enhance the title: Evaluating the Efficacy of the Newborn Communication, Health, Feeding, and Swallowing Education Program (N-CHFSEP) for First-Time Mothers  Assessing the Impact of the N-CHFSEP on Newborn Care Among Primiparous Mothers Effectiveness of the N-CHFSEP in Enhancing Newborn Care Skills for Primiparous Mothers  Abstract  Background: The background section effectively outlines the problem that primiparous mothers face challenges during pregnancy and post-childbirth. However, the statement \"There is a lack of comprehensive educational programs for primiparous mothers on maternal functioning and newborn care\" could benefit from citation of existing literature to support this claim. Additionally, specifying what aspects of \"maternal functioning\" are included could provide clarity. Objectives: The objectives are clearly stated and logically divided into two main goals: development of tools (attitude questionnaire, education program, feedback questionnaire) and evaluation of the program's efficacy. This separation is clear and helpful for readers to understand the study’s aims. Methods: The methods section is concise but detailed enough to understand the study design. However, it could be improved by specifying the inclusion criteria more precisely (e.g., \"primiparous mothers without any obstetric history\" could specify what kind of history excludes participants). Additionally, mentioning the duration of the study and the specific content covered in the N-CHFSEP could provide more context. Results: The results section effectively communicates the main findings, highlighting the statistically significant increase in maternal confidence levels post-intervention. The use of both quantitative and qualitative analysis is a strength. However, the phrase \"a notable increase in the number of mothers (not all)\" is vague and could be more precise. For example, specifying the percentage of mothers who reported increased confidence would provide more concrete data. Additionally, discussing the specific sociodemographic factors in more detail would enhance understanding of their impact. Conclusions: The conclusions succinctly summarize the study's implications, emphasizing the program's effectiveness in enhancing maternal confidence. However, it would be beneficial to briefly mention any limitations of the study or suggest directions for future research to provide a more balanced view. Keywords: The keywords are relevant and cover the main topics of the study. However, adding keywords like \"confidence,\" \"maternal education,\" and \"program evaluation\" might improve the searchability of the study.  Introduction: The introduction provides a comprehensive overview of the challenges faced by primiparous mothers and underscores the importance of educational programs to support them. Here are some suggestions to refine and strengthen the introduction:  Clarity and Focus: The introduction covers a broad range of issues and studies, which can make it somewhat dense. Consider focusing more sharply on the main problem and the gap your study aims to fill. For example: Highlight the specific challenges primiparous mothers face and how these impact newborn care. Clearly state the need for a comprehensive educational program that addresses these challenges.  Structure: First Paragraph: Introduce the general context of pregnancy and childbirth, emphasizing the unique challenges for primiparous mothers. Second Paragraph: Discuss the importance of maternal confidence, knowledge, and attitudes, and their impact on newborn care. Third Paragraph: Present the specific gaps in current educational programs, citing key studies that demonstrate the need for comprehensive support. Fourth Paragraph: Highlight existing educational programs and their limitations, particularly focusing on the need for a holistic approach. Fifth Paragraph: Conclude by summarizing the need for your study and its objectives.  Citations and Evidence: Ensure all claims are supported by citations. For example, when discussing the impact of maternal confidence or the effectiveness of various programs, provide specific references. Use consistent and current references to strengthen the credibility of your argument.  Flow and Readability: Improve readability by breaking long sentences into shorter, more concise ones. Use transition phrases to connect ideas and ensure a smooth flow from one paragraph to the next.  Specific Suggestions: Opening Sentence: \"Pregnancy and childbirth represent significant milestones in a woman's life, permanently altering her identity and way of living in a continuous and dynamic manner.\" Second Sentence: \"Primiparous mothers (first-time mothers) face a wide range of emotions including joy, excitement, and anxiety, alongside overwhelming and stressful experiences such as routine newborn care, breastfeeding difficulties, lack of sleep, and physically taxing household duties.\" Importance of Maternal Confidence: \"Reduced levels of confidence in primiparous mothers compared to multiparous mothers negatively impact their ability to provide infant care.\" Developmental Milestones: \"Effective identification of developmental milestones by caregivers facilitates early interventions, improving overall health outcomes.\" Educational Programs: \"Although numerous educational programs exist, there is a lack of a holistic approach that comprehensively addresses newborn communication, feeding, swallowing, and general health.\"  Conclusion of Introduction: Summarize Gaps and Objectives: \"Despite the availability of various educational initiatives, there is a noticeable gap in comprehensive programs that address all critical areas of newborn development. This study aims to develop and validate a comprehensive educational program and assess its efficacy in enhancing maternal confidence and knowledge among primiparous mothers.\"  Methods  Study Design and Ethics: Clarity: This section is clear and provides essential information about the study design and ethical approvals. Detail: Including the registration number and ethical approval details adds credibility. Mentioning the adherence to the CONSORT checklist and Declaration of Helsinki is crucial. Participants: Clarity: The paragraph provides detailed demographic data which is good for understanding the sample population. Structure: Breaking this into two paragraphs might enhance readability - one for sample size calculation and the other for demographic details. Detail: Including the sample size formula and demographic breakdown is thorough and helpful. Inclusion and Exclusion Criteria: Clarity: The criteria are clearly listed, which helps in understanding the participant selection process. Structure: The criteria are clearly separated into inclusion and exclusion, making it easy to follow. Detail: Including the proficiency in English or Kannada is important for understanding participant communication abilities. Procedure: The present study was conducted in 2 phases. Phase 1 included the development of an (a) attitude questionnaire, (b) parent education program, and (3) feedback questionnaire; while Phase 2 included the administration of the questionnaires and the education program on the participants, followed by data analysis of the retrieved data. Clarity: The procedure is outlined, indicating a clear structure to the study. Detail: Describing the phases helps in understanding the study's flow. Development of Tools: a) Attitude questionnaire (AQ): Clarity: The development process of the AQ is well-explained, detailing the domains and types of questions. Detail: Including specific item numbers and their domains adds precision. b) Parent Education Program : Clarity: The development process of the N-CHFSEP is described in detail. Detail: Mentioning the consultation with experts adds credibility. c) Feedback Questionnaire (FQ): Clarity: The development process of the FQ is clear and detailed. Detail: Including the types of questions adds precision. Discussion  The discussion section of this study provides a comprehensive analysis of the impact of the Newborn Communication, Hearing, Feeding, and Swallowing Education Program (N-CHFSEP) on the confidence levels of primiparous mothers, emphasizing key areas such as communication, feeding-swallowing skills, and newborn health. While the study effectively highlights the statistical significance of increased confidence post-intervention and relates these findings to previous research, it could benefit from a more concise presentation. The detailed breakdown of influencing variables (age, education, family type, and occupation) is insightful, yet the narrative occasionally becomes repetitive, potentially diluting the focus. Additionally, the discussion extensively references existing literature to contextualize findings, which is commendable, but a more balanced approach with critical reflections on the study's limitations, such as the lack of a control group and the short-term assessment of the intervention's impact, would enhance the overall analysis. The feedback from mothers and the suggestion for practical demonstrations underscore the need for a hands-on approach in educational programs, a point that could be more prominently integrated into the discussion. Overall, while the discussion is thorough and well-supported by data, a more streamlined and critically reflective narrative would strengthen its impact Please address conclusion,  limitations & implications  of the study  Once again, thank you for entrusting me with this task. I look forward to our continued collaboration and to seeing the final version of the article. Warm regards, Shaimaa Mohamed Amin  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? No",
         "0.7872",
         "1",
         "0",
         "0.1835304054054053",
         "0.9542",
         "0.9364086389541626",
         "17.44",
         "15.8",
         "13.86",
         "16.9",
         "17.6",
         "102",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "4.0",
         "3.0",
         "True",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "4.0",
         "3.0",
         "83.0",
         "83",
         "f1000"
        ],
        [
         "1",
         "Amogh Verma",
         "03 Sep 2024",
         "Approved With Reservations",
         "653",
         "Estimating the efficacy of Newborn-Communication, Health, Feeding and Swallowing Education Program (N-CHFSEP) for primiparous mothers",
         "Background Primiparous mothers face diverse challenges during pregnancy and post-childbirth. There is a lack of comprehensive educational programs for primiparous mothers on maternal functioning and newborn care. This study aimed to explore the efficacy of a developed educational program on the attitude of primiparous mothers towards newborn communication, general health, feeding and swallowing. The objectives were (1) to develop an attitude questionnaire (AQ), a parent education program, and a feedback questionnaire (FQ); and (2) to estimate the efficacy of the education program pre- and post-delivery.  Methods Ninety-eight primiparous mothers without any obstetric history, proficient in English or Kannada, and delivering healthy newborns were recruited for the study. Phase 1 involved the development and validation of AQ, the parent education program [Newborn Communication, Health, Feeding and Swallowing Education Program (N-CHFSEP)], and FQ; while Phase 2 comprised of administering them on the mothers. Both quantitative (descriptive statistics, paired t-test, and chi-square test) and qualitative analysis were done on the parameters of interest.  Results The results of the study demonstrated a notable increase in the number of mothers (not all) reporting heightened confidence levels following receiving the N-CHFSEP (which was observed in all the domains). This observed change (pre and post) was statistically significant as per paired t-test analysis (p <0.05) indicating a significant increase in confidence levels post-N-CHFSEP intervention, as well as recognizing warning signs related to the same. Sociodemographic factors such as age, education, occupation, and family type were reported to have a significant effect (p <0.05) on maternal confidence levels before and after N-CHFSEP administration. Feedback from participants highlighted the effectiveness of the program in enhancing knowledge and awareness, while also suggesting areas for improvement.  Conclusions This study demonstrates the effectiveness of N-CHFSEP in enhancing primiparous mothers' confidence in newborn care, thereby improving maternal and infant health.",
         "56",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study evaluates the effectiveness of a tailored educational program, the Newborn-Communication, Health, Feeding, and Swallowing Education Program (N-CHFSEP), in enhancing the confidence of primiparous mothers in newborn care. The research addresses a significant gap in maternal education, particularly in the context of first-time mothers who face unique challenges in caring for their newborns. Strengths: Relevance and Impact: The study addresses a highly relevant topic in maternal and child health. The focus on primiparous mothers and the development of a comprehensive educational program is commendable, particularly in regions where such resources may be limited. Methodological Rigor: The development and validation of the study tools (Attitude Questionnaire, Feedback Questionnaire, and N-CHFSEP) are well-detailed and supported by content validation from experts in pediatrics and speech-language pathology. Statistically Significant Findings: The study presents statistically significant improvements in maternal confidence levels across communication, feeding-swallowing, and general health domains, which suggests that the N-CHFSEP is an effective intervention. Practical Implications: The study provides valuable insights for healthcare providers and policymakers, highlighting the importance of structured educational programs for new mothers. Weaknesses: Study Design: The absence of a control group limits the ability to attribute the observed improvements in confidence levels solely to the N-CHFSEP intervention. This is a significant limitation that should be addressed in future studies. The single-arm pre-post study design, while valid for exploratory research, does not provide the level of rigor necessary to establish causality. Generalizability: The sample is limited to primiparous mothers in a specific region, and the exclusion of multiparous mothers may limit the generalizability of the findings to the broader population. Expanding the sample to include a more diverse demographic would strengthen the study. Short-term Assessment: The study measures outcomes immediately post-intervention, leaving questions about the long-term retention of knowledge and skills. A follow-up assessment at 6 months or beyond would provide a more comprehensive understanding of the program's sustained impact. Limited Qualitative Data: While quantitative data is well-represented, the qualitative feedback from participants is not fully explored. Incorporating more qualitative insights could provide a richer context to the statistical findings and highlight areas for improvement in the program. Recommendations for Publication: Revisions: I recommend that the authors address the limitations in their discussion section by clearly acknowledging the absence of a control group and the implications for the study's findings. Additionally, suggestions for future research should be included, particularly regarding long-term follow-up and expanding the sample population. Potential for Improvement: The study would benefit from a more in-depth analysis of the qualitative data collected, as this could provide valuable insights into the participants' experiences and the practical application of the program. Additionally, including recommendations for enhancing the program, such as integrating practical demonstrations, would be beneficial. Suitability for Indexing: Despite its limitations, the study contributes valuable insights into maternal education and has practical implications for improving maternal and infant health. I believe the manuscript is suitable for indexing with revisions. However, the authors should emphasize that this is a preliminary study, laying the groundwork for more rigorous future research.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7955",
         "1",
         "0",
         "0.2008718133718133",
         "0.2025",
         "0.920393705368042",
         "8.47",
         "17.1",
         "15.88",
         "17.2",
         "18.5",
         "88",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "4.0",
         "2.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "84.0",
         "84.0",
         "f1000"
        ],
        [
         "2",
         "Selmy Awad",
         "28 Dec 2024",
         "Approved With Reservations",
         "174",
         "Case Report: A giant ruptured splenic hydatic cyst in a patient with a complete situs inversus: Diagnostic challenge and intra-operative difficulties",
         "The splenic localization of hydatid cysts is extremely rare. A 50-year-old obese female who consults with a painful and febrile syndrome of the right hypochondrium. Abdominal ultrasound and a CT scan computed tomography revealed a complete situs inversus, a mass of the right hypochondrium measuring 152 mm with membrane detachment, and infiltration of the surrounding fat, evoking a type II complicated splenic hydatic cyst. The patient was operated on in an emergency via midline laparotomy. Exploration revealed situs inversus, an angiant cyst of the spleen. Exposition of the splenic pedicle is difficult. The samples were then infected. Total splenectomy was performed. The postoperative period was unproblematic, and the patient was discharged with antibiotic and antiparasitic treatment and habitual vaccination.",
         "24",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Thanks for the novel case as an incidence and location. many typos and grammar mistakes are abundant. What is the role of medical treatment in preoperative preparation and post-operative regimens? please follow the standards for writing case reports  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Yes  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? No  Is the case presented with sufficient detail to be useful for other practitioners? Partly",
         "0.7693",
         "1",
         "0",
         "0.1114035087719298",
         "0.6587",
         "0.589046061038971",
         "23.97",
         "15.3",
         "17.92",
         "16.5",
         "16.9",
         "97",
         "0",
         "1",
         "0",
         "0",
         "3.0",
         "4.0",
         "2.0",
         "False",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "3.0",
         "60.0",
         "60",
         "f1000"
        ],
        [
         "3",
         "Silvio Buscemi",
         "07 Jan 2025",
         "Approved",
         "280",
         "Case Report: A giant ruptured splenic hydatic cyst in a patient with a complete situs inversus: Diagnostic challenge and intra-operative difficulties",
         "The splenic localization of hydatid cysts is extremely rare. A 50-year-old obese female who consults with a painful and febrile syndrome of the right hypochondrium. Abdominal ultrasound and a CT scan computed tomography revealed a complete situs inversus, a mass of the right hypochondrium measuring 152 mm with membrane detachment, and infiltration of the surrounding fat, evoking a type II complicated splenic hydatic cyst. The patient was operated on in an emergency via midline laparotomy. Exploration revealed situs inversus, an angiant cyst of the spleen. Exposition of the splenic pedicle is difficult. The samples were then infected. Total splenectomy was performed. The postoperative period was unproblematic, and the patient was discharged with antibiotic and antiparasitic treatment and habitual vaccination.",
         "34",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The case described is very interesting and well-written. I have some general considerations for you below. It is appropriate to discuss cystic echinococcosis in female with obesity. Given the unique nature of this case with situs inversus, including descriptive arrows in the CT images is essential and reassuring. This will provide clear visual guidance for the reader, enhancing their confidence in the case report. Please elaborate on the antiparasitic treatment used, including the specific regimen followed (it is important to continue the treatment after the cyst spontaneously ruptures to avoid possible dissemination). It is essential to document the changes in antibody titers and blood chemistry tests following surgical treatment and therapy (it would be appropriate to document how in the article, that could also be mentioned: Ref 1). This will not only inform the reader but also enhance their knowledge about the progression of the disease.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Partly  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Partly  Is the case presented with sufficient detail to be useful for other practitioners? Partly",
         "0.7857",
         "1",
         "0",
         "0.1403645833333333",
         "0.3225",
         "0.7798862457275391",
         "24.27",
         "15.2",
         "16.6",
         "16.6",
         "16.3",
         "94",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "92.0",
         "92",
         "f1000"
        ],
        [
         "4",
         "Nitin Liladhar Rane",
         "17 Oct 2024",
         "Approved",
         "239",
         "What we know and what should we know about the future of blockchain in finance",
         "Background In response to the transformative impact of blockchain technology on economic and financial landscapes, there is a critical need for a review study that analyses the knowledge landscape from diverse perspectives.  Methods This research VOSviewer, and Bibliometrix to undertake a bibliometric analysis of the expanding literature related to blockchain technology within the financial sector. Through a examination of 500 published articles, the study identifies insightful trends, patterns, and emerging domains on a global scale.  Results The findings highlight the advancing trajectory of blockchain research in finance, with a notable concentration of studies originating from the United States and China, both in terms of total publications and citations. Key thematic clusters identified include “smart contracts,” “financial institutions,” “initial coin offerings,” and “big data analytics.” Intersections with financial risk management, digital transformation, and the integration of big data analytics with artificial intelligence and machine learning are particularly noteworthy, marking focal points of exploration.  Conclusions While affirming the potential of blockchain, the analysis also sheds light on persistent impediments hindering its widespread adoption and utilization. This study not only contributes to the current understanding of blockchain in finance but also serves as a valuable resource for future researchers. It guides systematic reviews by pinpointing prominent journals and influential authors within the dynamic field of blockchain finance, thereby fostering a deeper understanding and facilitating further exploration in this evolving field.",
         "35",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  \"What we know and what should we know about the future of blockchain in finance\" Authors' have made a good attempt by highlighting the advancing trajectory of blockchain research in finance, with a notable concentration of studies originating from the United States and China, both in terms of total publications and citations. Key thematic clusters identified include “smart contracts,” “financial institutions,” “initial coin offerings,” and “big data analytics.” Intersections with financial risk management, digital transformation, and the integration of big data analytics with artificial intelligence and machine learning are particularly noteworthy, marking focal points of exploration.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.763",
         "1",
         "0",
         "0.13546918767507",
         "0.1303",
         "0.9726446270942688",
         "21.84",
         "16.2",
         "19.43",
         "17.7",
         "18.5",
         "97",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "5.0",
         "4.0",
         "3.0",
         "92.0",
         "92",
         "f1000"
        ],
        [
         "5",
         "Rajinder K. Sharma",
         "17 Jan 2025",
         "Approved With Reservations",
         "268",
         "Case Report: The Sausage Technique using Anorganic Bovine Bone Mineral for Horizontal Bone Augmentation at the Crestal Part of a Posterior Mandibular Ridge: A Case Report.",
         "Following tooth extraction, the alveolar bone goes through a natural remodeling process resulting in a significant bone resorption which may complicate dental implant placement without prior bone augmentation treatment. The sausage technique is a modified guided bone regeneration (GBR) method that has been successfully used for horizontal bone augmentation. This technique was developed to increase the bone growth at the alveolar crest. Although the sausage technique uses a combination of autograft chips and xenograft particles with a native collagen membrane, several studies have questioned whether adding autograft chips is essential for bone formation with guided bone regeneration. Moreover, harvesting the bone graft may increase the donor site morbidity and patient discomfort. This case report aimed to investigate the bone gain radiologically when the sausage technique was applied to treat a healthy, thirty-year-old patient with a horizontal defect in the posterior mandibular region using anorganic bovine bone mineral (ABBM) particles with Jason membrane, assess the implant primary stability in the augmented ridge, and present the surgical procedure steps in details. After nine months of healing, the cone-beam computed tomography (CBCT) revealed approximately 4.32 mm of bone gain at the alveolar crest in the buccal-lingual direction. The graft particles were well integrated into the newly formed bone. Two implants were inserted with an insertion torque of 35 N/cm. The ISQ values were 76 for the most anterior implant and 78 for the posterior implant. Within the limitations of this case report, the sausage technique using ABBM particles without autograft chips was an effective approach in achieving the prerequisite bone width at the crest in cases with horizontal bone defects.",
         "164",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The case report is about horizontal bone augmentation through staged GBR using the sausage technique to facilitate implant placement. Please consider the following points to improve the quality of discussion section. 1. How the surgical procedure is different from the procedure proposed by Istvan Urban and colleagues, except the exclusion of autogenous graft. 2. What are the alternatives to bone augmentation to facilitate implant placement in this case. Please describe briefly the merits and limitations. 3. What are the probable outcomes of attempted bone augmentation in this case? And how the bone augmentation was ascertained? 4. What are the  long-term complications associated with fragmented bone graft materials?  5. Is the procedure described in this case relevant for improving the success of implant placement?  6.Ethical considerations for use of materials with animal origin.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Yes  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? No  Is the case presented with sufficient detail to be useful for other practitioners? Yes",
         "0.7475",
         "6",
         "0",
         "0.0722222222222222",
         "0.0515",
         "0.8633317947387695",
         "27.93",
         "13.8",
         "15.37",
         "15.5",
         "14.9",
         "100",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "3.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "5.0",
         "75.0",
         "83",
         "f1000"
        ],
        [
         "6",
         "Yankai Xia",
         "30 Aug 2024",
         "Approved With Reservations",
         "605",
         "Neurotoxicity of nanoplastics: A review",
         "With the increase in plastic waste in the environment, it is undeniable that humans and most organisms are exposed to plastic particles of various sizes, including nanoplastics (NPs). Humans are at risk owing to various routes of entry, including ingestion, inhalation, and dermal contact. While the toxicity of NPs is still debatable due to the scarcity of resources and research, most studies have concluded that NPs may exert toxicity, which exacerbates their neurotoxicity potential. Earlier studies concluded that NPs can cause oxidative stress, which results in apoptosis of neuronal cells. Some studies have shown that NPs can affect fundamental cell functions by inducing physical stress through deposition. Furthermore, studies on in vivo models exposed to NPs have demonstrated behavioral changes that are presumably due to alterations in acetylcholinesterase activity and neurotransmitter levels. This review discusses studies conducted on the neurotoxic potential of NPs and their effects, which are dependent on several parameters, including size and type of NPs, exposure concentration, duration, and various models at risk of NP exposure. Furthermore, speculations on how NPs are related to neurotoxicity are also discussed.",
         "49",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The review addresses the increasingly relevant topic of the neurotoxic potential of nanoplastics (NPs) in the context of escalating plastic pollution, effectively summarizing key findings from the literature with an emphasis on the various exposure routes and associated risks. However, the manuscript would benefit from a more comprehensive synthesis of the existing literature, particularly in addressing the inconsistencies and gaps in current research, while also providing a clearer articulation of the limitations of current research methodologies and offering suggestions for future studies. Additionally, a discussion of the broader implications for public health and potential regulatory frameworks would strengthen the manuscript's contribution to the field. Overall, the review could be further improved by deepening the analysis of existing studies and providing a more critical perspective on the current state of knowledge. I recommend that the authors consider resubmitting after making significant improvements. Major comments While the review discusses various detection and quantification methods for NPs, a more detailed critique of the limitations of these methodologies is needed. This should include an examination of the challenges related to detecting NPs in environmental samples versus laboratory conditions, as well as the implications these limitations have for interpreting research findings. The manuscript needs a more critical analysis of key research gaps, especially concerning the inconsistencies in findings related to the mechanisms of NP-induced neurotoxicity. Strengthening this section with a more detailed comparison of the outcomes across different experimental models and conditions would greatly enhance the review's contribution. The discussion on the mechanisms of NP-induced neurotoxicity is crucial. For instance, exploring the specific biochemical pathways through which NPs interact with cellular components at a molecular level would provide a more comprehensive understanding.  The role of protein corona formation in neurotoxicity, mentioned towards the end, should be integrated earlier in the manuscript to establish a clear connection between NP exposure and neurodegenerative diseases. While the manuscript covers many trending topics, it often treats them in isolation, which leads to a lack of coherence. An integrated approach that links these topics and demonstrates their interconnections would greatly improve the flow and continuity of the review. Minor comments The manuscript relies heavily on older studies, with relatively few references from the past three years. Incorporating more recent studies will ensure that the review reflects the current state of research and provides a comprehensive overview of the field. In some sections, particularly those discussing in vivo studies, the outcomes are not always clearly connected to the broader implications for neurotoxicity. It would be helpful to more explicitly link the results of these studies to the potential mechanisms of NP-induced neurotoxicity and their relevance to human health. The conclusion primarily restates the findings discussed throughout the review but does not provide a comprehensive synthesis of the key takeaways. The summary of neurotoxicity of NPs in different models presented in Table 1 is not comprehensive and should be thoroughly enumerated. The language of the manuscript should be polished.  Is the topic of the review discussed comprehensively in the context of the current literature? Partly  Are all factual statements correct and adequately supported by citations? Yes  Is the review written in accessible language? Partly  Are the conclusions drawn appropriate in the context of the current research literature? Partly",
         "0.8004",
         "1",
         "0",
         "0.1484375",
         "0.1633",
         "0.8763298392295837",
         "13.99",
         "17.1",
         "17.25",
         "17.7",
         "18.6",
         "92",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "6.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "2",
         "4.0",
         "3.0",
         "4.0",
         "62.0",
         "62",
         "f1000"
        ],
        [
         "7",
         "Amitava Mukherjee",
         "25 Nov 2024",
         "Approved With Reservations",
         "538",
         "Neurotoxicity of nanoplastics: A review",
         "With the increase in plastic waste in the environment, it is undeniable that humans and most organisms are exposed to plastic particles of various sizes, including nanoplastics (NPs). Humans are at risk owing to various routes of entry, including ingestion, inhalation, and dermal contact. While the toxicity of NPs is still debatable due to the scarcity of resources and research, most studies have concluded that NPs may exert toxicity, which exacerbates their neurotoxicity potential. Earlier studies concluded that NPs can cause oxidative stress, which results in apoptosis of neuronal cells. Some studies have shown that NPs can affect fundamental cell functions by inducing physical stress through deposition. Furthermore, studies on in vivo models exposed to NPs have demonstrated behavioral changes that are presumably due to alterations in acetylcholinesterase activity and neurotransmitter levels. This review discusses studies conducted on the neurotoxic potential of NPs and their effects, which are dependent on several parameters, including size and type of NPs, exposure concentration, duration, and various models at risk of NP exposure. Furthermore, speculations on how NPs are related to neurotoxicity are also discussed.",
         "136",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The review presents an exhaustive coverage of the neurotoxic effects of nanoplastics. The authors have done a commendable job of collecting literature and making a balanced presentation. However, I suggest the following points. 1. Introduction: The introduction is rather about the issues with plastic pollution, kindly introduce the importance and relevance of the neurotoxicity of the plastics here and also add a brief outline of the topics covered in the Review. Given that already a sizeable number of reviews are available on the topic of plastic pollution, please make this part brief and bring out the title of the work, \"neurotoxicity\" here. 2. Under Nanopalstics please revise the discussion on sources of the NPs relevant to human uptake and toxicity. Please connect this part with the main thread of the review. This is also much discussed in the literature already, and so with appropriate citations, the authors can shorten the description here. In the detection and quantification clearly distinguish and discuss the in vitro and in vivo detection and challenges associated briefly. The differences between MPs and Nps is a misfit in the review and out of context, in the introduction section itself one or two lines can be added with specific references for interested readers. 3. In the \"potential routes of NP exposure to Humans\" please avoid adding mechanisms of interaction/effects in this section, stick to the sources. Intracellular fate and bio-corona again may not fit well as a separate section, please integrate them briefly into the section on \"uptake\" and make their relevance clear for neurotoxicity effects. 4. Instead of sensitivity of the brain to oxidative stress discuss the various modes of action of the plastic particles mentioning why ROS is considered predominant one.. add relevance to plastic particles here briefly explain the effects of multiple chemical types, and possibly leaching of additives briefly. 5. Looking at the length of the review roughly 30% is covered on neurotoxicity, please elaborate on mechanisms of action, effects of plastic types, and size-based effects of nano plastics with specifics on neurotoxicity. I assume the literature is replete with studies with polystyrene NPs but please see whether the effects of other plastic types can be added and the effects of weathered or environment-derived ones. 6. Add a section on current gaps and challenges in these studies. 7. Please add a section on methods of review, year range selected, inclusion/exclusion criteria adopted search engines used, and so on. Please add this after the introduction section. This is an important miss in the article.  Is the topic of the review discussed comprehensively in the context of the current literature? Partly  Are all factual statements correct and adequately supported by citations? Partly  Is the review written in accessible language? Yes  Are the conclusions drawn appropriate in the context of the current research literature? Partly",
         "0.7593",
         "8",
         "0",
         "0.1164814814814814",
         "0.4415",
         "0.915136992931366",
         "32.73",
         "14.0",
         "14.32",
         "14.9",
         "15.0",
         "92",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "4.0",
         "3.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "5.0",
         "4.0",
         "3.0",
         "86.0",
         "86.0",
         "f1000"
        ],
        [
         "8",
         "Bhamini Krishna Rao",
         "12 Jul 2024",
         "Approved",
         "763",
         "Parents’ satisfaction with physiotherapy services for neuropediatric outpatients in government and private hospitals in the United Arab Emirates: a cross-sectional study",
         "Background Healthcare, like other industries, emphasizes performance, quality, and consumer experience while also attempting to reduce costs. However, high-quality healthcare remains paramount for vulnerable and ill patients. This study aimed to investigate parents' and caregivers' level of satisfaction with physiotherapy services provided to neuropediatric outpatients on the United Arab Emirates (UAE).  Methods This descriptive cross-sectional study included 103 parents/caregivers of children with neurological disabilities that were randomly selected from different Emirates Health Services Hospitals in the UAE. Data was collected using the long-form Patient Satisfaction Questionnaire (PSQ-III).  Results The overall mean satisfaction was 159±7.73 (out of 250 points). Communication (20.36/25), interpersonal factors (20.17/35), and doctor-patient time (20.17/35) had the highest mean satisfaction scores (8.06/10). The lowest mean satisfaction scores were for access/availability/convenience (34.60/60), technical quality (33.17/50), and economic elements (23.83/40).  Conclusion Despite participants’ overall satisfaction scores being positive, some service domains require improvement to improve satisfaction, specifically the access/availability/convenience, technical quality, and economic elements. These areas should be prioritized by service providers and managers to improve patients’ experiences and clinical outcomes.",
         "8",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The manuscript titled \"Parents’ satisfaction with physiotherapy services for neuropediatric outpatients in government and private hospitals in the United Arab Emirates: a cross-sectional study\" presents a valuable exploration of parental satisfaction with physiotherapy services for children with neurological disabilities in the UAE. The study design, which utilizes a cross-sectional correlational approach, is appropriate for the research objectives and provides a comprehensive overview of the satisfaction levels among parents and caregivers.  The methods section is detailed and well-structured, clearly outlining the study design, participant recruitment, data collection, and analysis procedures. The choice of the Patient Satisfaction Questionnaire (PSQ-III) is justified and its reliability is well-documented, making it a suitable tool for this study. The ethical considerations are thoroughly addressed, ensuring the integrity and ethical soundness of the study. However, providing more details on the sampling process, including the selection criteria and any potential biases, would enhance the transparency and replicability of the methodology. The results are presented clearly and concisely, with comprehensive tables that effectively illustrate the key findings. The analysis is robust, and the interpretation of the data is logical and consistent with the study's objectives. The sociodemographic characteristics of the participants are well-documented, providing important context for understanding the results. The correlation analysis between demographic variables and satisfaction scores is particularly useful, highlighting the factors that influence parental satisfaction. Including more detailed subgroup analyses could provide additional insights into these factors. The discussion effectively interprets the results in the context of existing literature, highlighting both the strengths and areas needing improvement in the physiotherapy services. The identification of areas requiring improvement, such as access, technical quality, and economic elements, is particularly valuable for informing future service enhancements. The discussion could be further enriched by exploring potential strategies for addressing these areas and by discussing the implications of the findings for policy and practice in more detail. Additionally, a comparison with similar studies in other regions could provide a broader perspective on the findings and underscore the study's relevance in a global context. In conclusion, this study sheds light on the crucial aspect of parents' satisfaction with physiotherapy treatment for neuropediatric outpatients in the UAE. The findings underscore the overall positive satisfaction reported by parents and caregivers regarding various aspects of physiotherapy services, particularly in communication, interpersonal factors, and doctor-patient time. However, it is evident that there are areas in need of improvement, notably access, technical quality, and economic elements. These findings emphasize the importance of continuous assessment and enhancement of healthcare services to meet the evolving needs of patients and their families. Addressing the identified areas of concern is paramount to enhancing patient experiences and ultimately improving clinical outcomes. Therefore, it is imperative for service providers and managers to prioritize these domains in their efforts to optimize the quality of care provided to neuropediatric outpatients and ensure the delivery of patient-centered healthcare in the UAE. Suggestions for Improvement: The abstract can be reorganized to suit the title of the study by giving importance to parents whose children receive long term rehabilitation services. The introduction can emphasize more on how caregiving is difficult in neuropediatric population rather than giving too much importance to general aspects of patient satisfaction Provide more details on the sampling process and potential biases in the methods section. Include more detailed subgroup analyses in the results section to provide additional insights into factors influencing satisfaction. The results section can highlight parents' or caregivers' characteristics and then compare it with the patient satisfaction scores. Explore potential strategies for improving areas of low satisfaction in the discussion. Compare findings with similar studies in other regions to provide a broader context. Include specific recommendations for future research and practice in the conclusion. Recommendation: Approve for indexing with minor revisions.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7771",
         "1",
         "0",
         "0.1780205905205905",
         "0.0999",
         "0.9188451766967772",
         "7.66",
         "17.5",
         "16.92",
         "18.3",
         "18.8",
         "89",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "5.0",
         "1.0",
         "yes",
         "positive",
         "polite",
         "Moderate",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "80.0",
         "82",
         "f1000"
        ],
        [
         "9",
         "Ehab Mohamed Abd El-Kaf",
         "30 Jul 2024",
         "Approved",
         "532",
         "Parents’ satisfaction with physiotherapy services for neuropediatric outpatients in government and private hospitals in the United Arab Emirates: a cross-sectional study",
         "Background Healthcare, like other industries, emphasizes performance, quality, and consumer experience while also attempting to reduce costs. However, high-quality healthcare remains paramount for vulnerable and ill patients. This study aimed to investigate parents' and caregivers' level of satisfaction with physiotherapy services provided to neuropediatric outpatients on the United Arab Emirates (UAE).  Methods This descriptive cross-sectional study included 103 parents/caregivers of children with neurological disabilities that were randomly selected from different Emirates Health Services Hospitals in the UAE. Data was collected using the long-form Patient Satisfaction Questionnaire (PSQ-III).  Results The overall mean satisfaction was 159±7.73 (out of 250 points). Communication (20.36/25), interpersonal factors (20.17/35), and doctor-patient time (20.17/35) had the highest mean satisfaction scores (8.06/10). The lowest mean satisfaction scores were for access/availability/convenience (34.60/60), technical quality (33.17/50), and economic elements (23.83/40).  Conclusion Despite participants’ overall satisfaction scores being positive, some service domains require improvement to improve satisfaction, specifically the access/availability/convenience, technical quality, and economic elements. These areas should be prioritized by service providers and managers to improve patients’ experiences and clinical outcomes.",
         "26",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This manuscript makes a valuable contribution to understanding parental satisfaction with physiotherapy services for children with neurological disabilities in the UAE. The study highlights the local importance and relevance of this issue and provides useful insights for healthcare providers seeking to improve service quality. Overall, this manuscript provides a comprehensive overview of parental satisfaction with physiotherapy services for children with neurological disabilities in the UAE. Enhancing the introduction with additional references, clarifying secondary objectives, and providing more details on the sampling process and subgroup analyses would further improve the manuscript. Here are a detailed review of the sections. 1. The introduction is clear and effectively sets the stage for the study, emphasizing the importance of patient satisfaction in healthcare within the UAE's evolving landscape. While the background information on patient satisfaction is comprehensive, adding recent studies on similar settings would enhance this section. 2. The goals and objectives of the study are well-stated and align with the introduction. The aim to investigate parents' satisfaction with physiotherapy services for neuropediatric patients is clear. However, clarifying any secondary objectives would provide a more complete picture of the study's scope. 3. The methods section is detailed and well-organized, outlining the study design, participant recruitment, data collection, and analysis procedures. The use of the Patient Satisfaction Questionnaire (PSQ-III) is well-justified, and ethical considerations are thoroughly addressed. More details on the sampling process, including selection criteria and potential biases, would improve transparency and replicability. 4. Results are presented clearly with tables that effectively illustrate key findings. The mean satisfaction scores for different service domains are well-documented, and the statistical analysis is sound. Including more detailed demographic data and subgroup analyses would provide additional context and highlight factors influencing parental satisfaction. 5. The discussion interprets the results well, relating them to existing literature and emphasizing the study's local significance. Identifying areas for improvement, such as access, technical quality, and economic elements, is valuable. The discussion could be enriched by exploring strategies for addressing these areas and discussing the implications for policy and practice in more detail. 6. Comparing the findings with similar studies in other regions would offer a broader perspective. 7. The conclusion succinctly summarizes the main findings and their implications, emphasizing the need for ongoing assessment and improvement of physiotherapy services. Including specific recommendations for future research and practice would strengthen the conclusion.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.792",
         "8",
         "0",
         "0.1634672619047619",
         "0.0999",
         "0.9228382706642152",
         "19.06",
         "15.1",
         "15.82",
         "16.9",
         "17.3",
         "98",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "somewhat specific",
         "4.0",
         "5.0",
         "5.0",
         "85.0",
         "85",
         "f1000"
        ],
        [
         "10",
         "Jennifer Gaddy",
         "07 Aug 2024",
         "Approved",
         "464",
         "GBS vaccines in the UK: a round table discussion",
         "Background Group B streptococcus (GBS) remains a leading cause of infant sepsis, meningitis and death despite intrapartum antibiotic prophylaxis. A vaccine is urgently required, and two candidates are in advanced clinical trials. For successful GBS vaccine implementation, especially if a vaccine is licensed based on an immunological threshold, there must be cross-sector engagement, effective advocacy, robust plans for phase IV studies and equitable access.  Meeting A round-table discussion, held at St George’s University of London, reviewed the current position of GBS vaccines in the UK context, focusing on phase IV plans, convening a diverse group of stakeholders from across the UK, with a role in GBS vaccine licensure, advocacy, implementation or effectiveness evaluation. Presentations outlined the latest UK epidemiology, noting the rising infant invasive GBS (iGBS) infection rates from 1996 to 2021 for both early and late onset disease, with the highest disease rates in Black infants (1.1/1000 livebirths vs white infants (0.81/1000 livebirths). Potential coverage of the candidate vaccines was high (>95%). Regulatory input suggested that EU regulators would consider waiving the need for a pre-licensure efficacy study if a putative correlate of protection could be adequately justified. Phase IV study methodologies for a GBS vaccine were considered, largely based on previous UK maternal vaccine assessments, such as a nationwide cohort study design using a vaccine register and a maternal services dataset. Other strategies were also discussed such as a cluster or stepped-wedge randomised trial to evaluate implementation outcomes. Opportunities for advocacy, education and engagement with additional key partners were discussed and identified.  Conclusions With an approved GBS vaccine a near possibility, planning of phase IV studies and identification of critical barriers to implementation are urgently needed. Cross-sector engagement is essential and will facilitate a successful pathway.",
         "78",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The manuscript by Natasha Thorn and colleagues entitled, “GBS vaccines in the UK: a round table discussion” presents a compelling discussion of the status of a protective vaccine against Group B Streptococcus, an important perinatal pathogen.  This manuscript is full of important information about disease risk from GBS infection and gaps in current treatment and prevention strategies.  There are many positive aspects about this manuscript that I would like to highlight.  First, the authors are extremely deliberate in their use of language, specifically referring to “pregnant patients” and “pregnant people”.  This is a subtle but important aspect of discussing these populations without introducing highly gendered language. Excellent work. The inclusion of stakeholders in the community such as Midwives was also a strength as these providers have the capacity to meet individuals who may be unaware of GBS risk and/or vaccine hesitant.  Buy-in from these groups will help with deployment in the future. Comparing/contrasting efficacy of other vaccination programmes deployed in pregnant patients was also a strength of this manuscript. I have a few comments to improve the quality of the manuscript. 1.  The authors mention AMR very briefly in the second paragraph of the Introduction.  It would be helpful to expand this section to acknowledge that the standard first line therapeutic choice for GBS is penicillin, but up to 10% of populations report penicillin hypersensitivity. Second line choice is often erythromycin or clindamycin and emerging clinical strains are exhibiting high resistance to these drugs (about 40% of strains are resistant).  2.  First line of the Introduction.  The authors refer to Group B streptococcus and italicize the word “streptococcus” but leave it lowercase.  If the authors are referring to the genus, this word should be capitalized and italicized. If they are referring to general morphology and arrangement of bacteria it can be lowercase but should not be italicized.  Most common references to GBS use the former (genus nomenclature).  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? No source data required  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7773",
         "4",
         "0",
         "0.1642103729603729",
         "0.6746",
         "0.9360240697860718",
         "34.97",
         "13.2",
         "15.48",
         "15.5",
         "14.7",
         "98",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "3.0",
         "yes",
         "positive",
         "polite",
         "No Hedging",
         "very specific",
         "5.0",
         "4.0",
         "3.0",
         "93.0",
         "93",
         "f1000"
        ],
        [
         "11",
         "Lisa Hanson",
         "27 Aug 2024",
         "Approved",
         "270",
         "GBS vaccines in the UK: a round table discussion",
         "Background Group B streptococcus (GBS) remains a leading cause of infant sepsis, meningitis and death despite intrapartum antibiotic prophylaxis. A vaccine is urgently required, and two candidates are in advanced clinical trials. For successful GBS vaccine implementation, especially if a vaccine is licensed based on an immunological threshold, there must be cross-sector engagement, effective advocacy, robust plans for phase IV studies and equitable access.  Meeting A round-table discussion, held at St George’s University of London, reviewed the current position of GBS vaccines in the UK context, focusing on phase IV plans, convening a diverse group of stakeholders from across the UK, with a role in GBS vaccine licensure, advocacy, implementation or effectiveness evaluation. Presentations outlined the latest UK epidemiology, noting the rising infant invasive GBS (iGBS) infection rates from 1996 to 2021 for both early and late onset disease, with the highest disease rates in Black infants (1.1/1000 livebirths vs white infants (0.81/1000 livebirths). Potential coverage of the candidate vaccines was high (>95%). Regulatory input suggested that EU regulators would consider waiving the need for a pre-licensure efficacy study if a putative correlate of protection could be adequately justified. Phase IV study methodologies for a GBS vaccine were considered, largely based on previous UK maternal vaccine assessments, such as a nationwide cohort study design using a vaccine register and a maternal services dataset. Other strategies were also discussed such as a cluster or stepped-wedge randomised trial to evaluate implementation outcomes. Opportunities for advocacy, education and engagement with additional key partners were discussed and identified.  Conclusions With an approved GBS vaccine a near possibility, planning of phase IV studies and identification of critical barriers to implementation are urgently needed. Cross-sector engagement is essential and will facilitate a successful pathway.",
         "98",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  *Very well written article. Statistics and references are up to date and appropriate. Tables are very effective. A few suggestions for clarity. *\"more crowded pregnancy vaccine space\" is unclear. *In the GBS3 trial description, more clarity is needed as to why participants in the routine testing arms receive either rapid PCR IP (versus 35-37 weeks). A reference here about the sensitivity and utiliy of rapid IP testing is needed-as this is not a usual strategy in culture-based EOGBS prevention approach recommended by the CDC and now ACOG (2019). *Table 3. The points about midwives having hesitancy to offer vaccines was interesting, as this is not the case in the USA. *Table 4 is redundant of the text on Potential Phase IV study designs.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? No source data required  Are the conclusions drawn adequately supported by the results? Yes",
         "0.774",
         "2",
         "1",
         "0.2182758620689655",
         "0.0999",
         "0.8594522476196289",
         "37.4",
         "12.2",
         "14.61",
         "14.5",
         "12.6",
         "95",
         "0",
         "2",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "3",
         "4.0",
         "5.0",
         "3.0",
         "86.0",
         "86",
         "f1000"
        ],
        [
         "12",
         "Hannah R Frost",
         "10 Sep 2024",
         "Approved",
         "385",
         "GBS vaccines in the UK: a round table discussion",
         "Background Group B streptococcus (GBS) remains a leading cause of infant sepsis, meningitis and death despite intrapartum antibiotic prophylaxis. A vaccine is urgently required, and two candidates are in advanced clinical trials. For successful GBS vaccine implementation, especially if a vaccine is licensed based on an immunological threshold, there must be cross-sector engagement, effective advocacy, robust plans for phase IV studies and equitable access.  Meeting A round-table discussion, held at St George’s University of London, reviewed the current position of GBS vaccines in the UK context, focusing on phase IV plans, convening a diverse group of stakeholders from across the UK, with a role in GBS vaccine licensure, advocacy, implementation or effectiveness evaluation. Presentations outlined the latest UK epidemiology, noting the rising infant invasive GBS (iGBS) infection rates from 1996 to 2021 for both early and late onset disease, with the highest disease rates in Black infants (1.1/1000 livebirths vs white infants (0.81/1000 livebirths). Potential coverage of the candidate vaccines was high (>95%). Regulatory input suggested that EU regulators would consider waiving the need for a pre-licensure efficacy study if a putative correlate of protection could be adequately justified. Phase IV study methodologies for a GBS vaccine were considered, largely based on previous UK maternal vaccine assessments, such as a nationwide cohort study design using a vaccine register and a maternal services dataset. Other strategies were also discussed such as a cluster or stepped-wedge randomised trial to evaluate implementation outcomes. Opportunities for advocacy, education and engagement with additional key partners were discussed and identified.  Conclusions With an approved GBS vaccine a near possibility, planning of phase IV studies and identification of critical barriers to implementation are urgently needed. Cross-sector engagement is essential and will facilitate a successful pathway.",
         "112",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Thank you for the invitation to review the manuscript \"GBS vaccines in the UK: a round table discussion\" by Thorn et al., it was an interesting and informative read. The article provides a concise and well-rounded update to the current status of GBS Vaccines, including an appropriate focus on knowledge gaps and barriers to success with useful recommendations for how to address them. It is particularly interesting to have an update on important ongoing or planned trials, which is not normally available in the literature until >1 year after the completion of the trial. I appreciate the focus on forward planning around vaccine uptake and phase IV trials, and keeping in mind lessons from COVID-19 and other vaccines given in pregnancy.  I have a few minor comments which may improve readability of the manuscript. 1) There is some repetition of points throughout, likely due to the nature of the manuscript as proceedings of a meeting. The authors could clean up the narrative, for example on page four, two subsequent paragraphs have the same conclusion regarding the need for improved surveillance.  2) Different acronyms are used to refer to the same thing (e.g. EOGBS, EOD and EO disease are all used in the first page) and some acronyms are never expanded (e.g. UR when discussing case estimates).  3) It would be good to have references and links provided for the burden of disease data used, acknowledging that some data is as yet unpublished.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7937",
         "2",
         "0",
         "0.1619918699186991",
         "0.8514",
         "0.8808193206787109",
         "42.41",
         "12.4",
         "14.77",
         "14.9",
         "13.6",
         "98",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "92.0",
         "92",
         "f1000"
        ],
        [
         "13",
         "Rosana Rocha Barros",
         "26 Sep 2024",
         "Approved",
         "258",
         "GBS vaccines in the UK: a round table discussion",
         "Background Group B streptococcus (GBS) remains a leading cause of infant sepsis, meningitis and death despite intrapartum antibiotic prophylaxis. A vaccine is urgently required, and two candidates are in advanced clinical trials. For successful GBS vaccine implementation, especially if a vaccine is licensed based on an immunological threshold, there must be cross-sector engagement, effective advocacy, robust plans for phase IV studies and equitable access.  Meeting A round-table discussion, held at St George’s University of London, reviewed the current position of GBS vaccines in the UK context, focusing on phase IV plans, convening a diverse group of stakeholders from across the UK, with a role in GBS vaccine licensure, advocacy, implementation or effectiveness evaluation. Presentations outlined the latest UK epidemiology, noting the rising infant invasive GBS (iGBS) infection rates from 1996 to 2021 for both early and late onset disease, with the highest disease rates in Black infants (1.1/1000 livebirths vs white infants (0.81/1000 livebirths). Potential coverage of the candidate vaccines was high (>95%). Regulatory input suggested that EU regulators would consider waiving the need for a pre-licensure efficacy study if a putative correlate of protection could be adequately justified. Phase IV study methodologies for a GBS vaccine were considered, largely based on previous UK maternal vaccine assessments, such as a nationwide cohort study design using a vaccine register and a maternal services dataset. Other strategies were also discussed such as a cluster or stepped-wedge randomised trial to evaluate implementation outcomes. Opportunities for advocacy, education and engagement with additional key partners were discussed and identified.  Conclusions With an approved GBS vaccine a near possibility, planning of phase IV studies and identification of critical barriers to implementation are urgently needed. Cross-sector engagement is essential and will facilitate a successful pathway.",
         "128",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Revision of the manuscript GBS vaccines in the UK: a round table discussion The manuscript is a comprehensive report of the round table held at St George University of London, that discussed the state of the art of GBS vaccines and planned phase IV trials. The manuscript brings the talks of different specialists, covering various issues regarding GBS vaccine background, vaccine implementation, and the follow-up after the beginning of vaccination. Overall, the text is very well-written and I have only an observation, as follows. Page 3 2nd paragraph. “IAP is not always deliverable, results in high antibiotic exposure...” This sentence seems a bit unclear. I suggest that the authors improve it.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? No source data required  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7639",
         "2",
         "0",
         "0.1280357142857143",
         "0.2025",
         "0.8627001643180847",
         "27.42",
         "14.0",
         "15.27",
         "15.2",
         "14.0",
         "102",
         "0",
         "0",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "3",
         "4.0",
         "3.0",
         "5.0",
         "90.0",
         "90",
         "f1000"
        ],
        [
         "14",
         "Dharma Varapula",
         "21 Aug 2024",
         "Approved With Reservations",
         "606",
         "Negligible effects of read trimming on the accuracy of germline short variant calling in the human genome",
         "Background Next generation sequencing (NGS) has become a standard tool in the molecular diagnostics of Mendelian disease, and the precision of such diagnostics is greatly affected by the accuracy of variant calling from sequencing data. Recently, we have comprehensively evaluated the performance of multiple variant calling pipelines. However, no systematic analysis of the effects of read trimming on variant discovery with modern variant calling software has yet been performed.  Methods In this work, we systematically evaluated the effects of adapters on the performance of 8 variant calling and filtering methods using 14 standard reference Genome-in-a-Bottle (GIAB) samples. Variant calls were compared to the ground truth variant sets, and the effect of adapter trimming with different tools was assessed using major performance metrics (precision, recall, and F1 score).  Results We show that adapter trimming has no effect on the accuracy of the best-performing variant callers (e.g., DeepVariant) on whole-genome sequencing (WGS) data. For whole-exome sequencing (WES) datasets subtle improvement of accuracy was observed in some of the samples. In high-coverage WES data (~200x mean coverage), adapter removal allowed for discovery of 2-4 additional true positive variants in only two out of seven datasets tested. Moreover, this effect was not dependent on the median insert size and proportion of adapter sequences in reads. Surprisingly, the effect of trimming on variant calling was reversed when moderate coverage (~80-100x) WES data was used. Finally, we show that some of the recently developed machine learning-based variant callers demonstrate greater dependence on the presence of adapters in reads.  Conclusions Taken together, our results indicate that adapter removal is unnecessary when calling germline variants, but suggest that preprocessing methods should be carefully chosen when developing and using machine learning-based variant analysis methods.",
         "96",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  In this report, Barbitoff, Y. and Predeus, A. have described a study investigating if read trimming, specifically adapter trimming, affects variant calling accuracy using commonly employed variant callers. The authors find this investigation to be of significant value citing there is no prior systematic study exploring the impact of read trimming on variant calling accuracy. In the study, WES and WGS datasets from seven GIAB samples were processed using six different variant callers (DeepVariant, GATK HaplotypeCaller, Freebayes, Strelka2, Octopus, and Clair3) to measure the effect of read trimming performed prior to the variant calling. The authors show comparative metrics (differences between trimmed and untrimmed variant caller performance metrics – recall, precision and F1 scores) and find no substantial differences in variant calling performance, except in the case of 200x coverage WES. Subsequently, the authors downsampled the data to produce a simulated 80x WES dataset expecting a greater likelihood for an  increased impact of read trimming on variant calling accuracy. This simulated dataset too did not show significant impact due to read trimming. Further, the authors found no correlation between extent of adapter base contamination and impact of read trimming on variant caller performance metrics. Additionally, the authors ran the pipelines with different variant callers and found minimal impacts due to read trimming upstream. My comments below: The adapter base percentage variation ranged from 8.1% to 35.2%. Please comment if this is an expected range for WES datasets. Also, please mention the coverage of the WES dataset in the caption for Fig 1. How does one assess the changes in performance metrics to be significant or not (Fig 1b and 1c)? Recall and precision score metrics in Figure 1b for Indels in WES datasets show deviations from the mean and these are not explained thoroughly. If this variance is to be expected, is it likely that the sample set n of 7 is too low? Or is the data heteroscedastic? In my view, the observations made on data presented in Figure 1e are not sufficiently explained. Discussion section on this aspect is a rehash of the content in the Results section. Read trimming is often a lower time-cost step compared to the variant calling step. It would benefit the reader (and the authors) greatly if there was a more detailed explanation why this is an important decision to make, which this study is aimed to inform us better for. Data redundancy and potential loss of raw data (if only single copy retained) appear to be valid reasons on the surface, a more complete justification is need in my view. Review of prior literature work can be more exhaustive.  I was unable to access or review the Supplementary information, so it has not been included in my review. Please update in revised version  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7883",
         "1",
         "0",
         "0.0970054945054944",
         "0.2663",
         "0.9262039661407472",
         "35.37",
         "13.0",
         "13.18",
         "14.3",
         "13.4",
         "91",
         "0",
         "0",
         "1",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "3.0",
         "80.0",
         "83",
         "f1000"
        ],
        [
         "15",
         "Xihao Li",
         "14 Oct 2024",
         "Approved With Reservations",
         "383",
         "Negligible effects of read trimming on the accuracy of germline short variant calling in the human genome",
         "Background Next generation sequencing (NGS) has become a standard tool in the molecular diagnostics of Mendelian disease, and the precision of such diagnostics is greatly affected by the accuracy of variant calling from sequencing data. Recently, we have comprehensively evaluated the performance of multiple variant calling pipelines. However, no systematic analysis of the effects of read trimming on variant discovery with modern variant calling software has yet been performed.  Methods In this work, we systematically evaluated the effects of adapters on the performance of 8 variant calling and filtering methods using 14 standard reference Genome-in-a-Bottle (GIAB) samples. Variant calls were compared to the ground truth variant sets, and the effect of adapter trimming with different tools was assessed using major performance metrics (precision, recall, and F1 score).  Results We show that adapter trimming has no effect on the accuracy of the best-performing variant callers (e.g., DeepVariant) on whole-genome sequencing (WGS) data. For whole-exome sequencing (WES) datasets subtle improvement of accuracy was observed in some of the samples. In high-coverage WES data (~200x mean coverage), adapter removal allowed for discovery of 2-4 additional true positive variants in only two out of seven datasets tested. Moreover, this effect was not dependent on the median insert size and proportion of adapter sequences in reads. Surprisingly, the effect of trimming on variant calling was reversed when moderate coverage (~80-100x) WES data was used. Finally, we show that some of the recently developed machine learning-based variant callers demonstrate greater dependence on the presence of adapters in reads.  Conclusions Taken together, our results indicate that adapter removal is unnecessary when calling germline variants, but suggest that preprocessing methods should be carefully chosen when developing and using machine learning-based variant analysis methods.",
         "150",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study provides a systematic evaluation of the effect of adapter trimming on the accuracy of germline short variant calling in the human genome, utilizing both whole-genome sequencing (WGS) and whole-exome sequencing (WES) datasets. The comparison of multiple variant calling tools, with and without adapter trimming, reveals minimal impact on WGS data but suggests modest improvements in certain WES samples, particularly in indel detection. The study concludes that while adapter trimming may not be essential for WGS, it shows some benefits for specific WES cases. The manuscript is well-written and clear, making it accessible for readers. Below are a few comments for the authors to consider: The authors mention that “adapter trimming had very limited effects on both precision and recall.” It would be helpful to clarify and quantify the threshold for \"limited.\" Providing a statistical measure, such as a p-value or confidence interval, would strengthen the interpretation of the findings. Additional explanation is needed for the samples that showed positive effects in Figure 1. Clarifying why these samples differ from the others would help contextualize the observed improvements. The authors are encouraged to elaborate on the reasons why results differ between SNP and indel calling. Further discussion on potential underlying mechanisms would enhance understanding. The statement that “trimming may even decrease the accuracy of analysis” warrants further discussion. Exploring potential reasons behind this observation could provide valuable insights into the circumstances in which trimming could be detrimental.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.8028",
         "1",
         "0",
         "0.1083887657058388",
         "0.072",
         "0.9649744629859924",
         "26.61",
         "14.3",
         "15.41",
         "15.7",
         "15.6",
         "96",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "3",
         "4.0",
         "5.0",
         "4.0",
         "92.0",
         "92",
         "f1000"
        ],
        [
         "16",
         "Epari Venkatarao",
         "07 Jun 2024",
         "Not Approved",
         "398",
         "A cross-sectional study of neutrophil to lymphocyte ratio as a prognostic marker in acute organophosphorus poisoning in a tertiary care hospital in Central India",
         "Background Acute organophosphorus poisoning remains a significant public health concern, with variable clinical outcomes. Prognostic markers are crucial for patient management and risk stratification. This study aims to investigate the Neutrophil Lymphocyte Ratio (NLR) as a potential prognostic marker and its associations with severity and clinical outcomes in acute organophosphorus poisoning.  Methods This cross-sectional observational study will be conducted over two years, involving patients presenting with acute organophosphorus poisoning in the Medicine Ward and Intensive Care Unit of DMIHER Wardha. Informed consent will be obtained, and detailed clinical assessments, laboratory investigations, and NLR calculations will be performed. The Nambaet, Peradeniya, and Bardin classification scales will be used to measure severity. Statistical methods will be applied to explore the relationships between NLR, clinical parameters, and clinical outcomes, including descriptive statistics, bivariate analysis, correlation analysis, multivariate regression, and ROC analysis.  Expected Results The study is anticipated to elucidate the role of NLR as a prognostic marker in acute organophosphorus poisoning. Initial assessments and correlations between NLR and clinical parameters will be presented. The predictive capability of NLR for clinical outcomes, including the need for ventilatory support and length of hospital stay, will be explored. Agreement and discrepancies between the classification scales will be evaluated.",
         "43",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This is a protocol for publication before the research is being conducted. It talks about finding the ability of NLR as a prognostic indicator in organophosphorus poisoning. NLR as a prognostic indicator has been studied extensively in recent times in various other clinical conditions including cancer. Hence, the ROL should look into this including the methodology followed to find its prostic value, which will add further knowledge to the existing body of knowledge. The outcome variables of the study should be well defined before conducting the research. This will help in the designing the study and calculation of an appropriate sample size. The sample size should be calculated using AUC in ROC analysis from published literature. The outcome measures defined by the study's objectives will determine the role of appropriate statistical methods. The authors have not been able to spell out the outcome measures properly. Hence, the specificity of the use of statistical methods seems vague. This can lead to confusion at a later stage after data collection. Dummy tables and dummy analysis before the execution of the study will be useful. The Review of Literature (ROL) lacks a finding of NLR as an inflammatory marker. There is literature available on NLR as a prognostic marker in cancer. The authors have proposed data collection at a single time point, which will have a bias in the analysis as factors like time-to-intervention, dose-response, quality of care, etc., can not be accounted for in the analysis.  Finally, the sample size calculation is inappropriate as the study is NOT trying to find the prevalence of death among organophosphorus poisoning cases with NLR >12, rather with appropriate ROL, sample size calculation method has to be revisited.  Is the rationale for, and objectives of, the study clearly described? Yes  Is the study design appropriate for the research question? No  Are sufficient details of the methods provided to allow replication by others? Partly  Are the datasets clearly presented in a useable and accessible format? Not applicable",
         "0.7682",
         "1",
         "0",
         "0.1282840722495895",
         "0.1041",
         "0.8034374713897705",
         "36.18",
         "12.7",
         "13.77",
         "14.4",
         "13.0",
         "98",
         "0",
         "0",
         "0",
         "0",
         "2.0",
         "4.0",
         "3.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "2.0",
         "3.0",
         "40.0",
         "42",
         "f1000"
        ],
        [
         "17",
         "Deepak Kumar",
         "22 Aug 2024",
         "Not Approved",
         "479",
         "A cross-sectional study of neutrophil to lymphocyte ratio as a prognostic marker in acute organophosphorus poisoning in a tertiary care hospital in Central India",
         "Background Acute organophosphorus poisoning remains a significant public health concern, with variable clinical outcomes. Prognostic markers are crucial for patient management and risk stratification. This study aims to investigate the Neutrophil Lymphocyte Ratio (NLR) as a potential prognostic marker and its associations with severity and clinical outcomes in acute organophosphorus poisoning.  Methods This cross-sectional observational study will be conducted over two years, involving patients presenting with acute organophosphorus poisoning in the Medicine Ward and Intensive Care Unit of DMIHER Wardha. Informed consent will be obtained, and detailed clinical assessments, laboratory investigations, and NLR calculations will be performed. The Nambaet, Peradeniya, and Bardin classification scales will be used to measure severity. Statistical methods will be applied to explore the relationships between NLR, clinical parameters, and clinical outcomes, including descriptive statistics, bivariate analysis, correlation analysis, multivariate regression, and ROC analysis.  Expected Results The study is anticipated to elucidate the role of NLR as a prognostic marker in acute organophosphorus poisoning. Initial assessments and correlations between NLR and clinical parameters will be presented. The predictive capability of NLR for clinical outcomes, including the need for ventilatory support and length of hospital stay, will be explored. Agreement and discrepancies between the classification scales will be evaluated.",
         "119",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Dear Editor I have gone through the manuscript (study protocol) titled “A cross-sectional study of neutrophil to lymphocyte ratio as a prognostic marker in acute organophosphorus poisoning in a tertiary care hospital in Central India”. Following are my comments for consideration (Major Revision) Several studies are already available which showed the role of neutrophil-to-lymphocyte ratio (NLR) as a prognostic marker in acute organophosphorus poisoning with detailed method/protocol (https://www.sciencedirect.com/science/article/abs/pii/S0736467914005034 file:///C:/Users/Dr%20Deepak%20Kumar/Downloads/5-OA-Basanta+Gauli.pdf, https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8284330/ ). Please elaborate.  Under study status it is mentioned as “The study has yet to start after the publication of the protocol; we will start recruitment in the study.”  However, under study design it is mentioned as  “Data will be collected at a single time point setup for the 2023-2024 period.” Considering the fact that it is mid-August 2024, when will the authors start the work and complete it within 2023-2024 period. So kindly revise the relevant content in the manuscript and its ethical approval accordingly.  Include the statement that the work will be carried out following the tenets of the Helsinki Declaration.  How the diagnosis of organophosphorus pesticide exposure will be carried out? Or in other words which method was used to find out the confirmed cases of  OP poisoning? How the authors confirm the inclusion and exclusion criteria. Which parameter will be considered for this?  Estimation of AChE activity is of the method for understanding OP poisoning. However, both organophosphorus (OP) and organocarbamates (OC) inhibit AChE activity (https://pubmed.ncbi.nlm.nih.gov/37805177/ ). Then how do the authors distinguish OP cases from OC. Please address this issue. This should be properly mentioned in the protocol. Under objectives, it is mentioned as under “To investigate whether the Neutrophil to Lymphocyte Ratio is correlated with the dose of atropine administered to patients with acute organophosphorus poisoning.” In cases where organophosphate poisoning is on the differential but not confirmed, a trial of atropine is generally administered (https://www.ncbi.nlm.nih.gov/books/NBK470430/#:~:text=If%20organophosphate%20poisoning%20is%20on,suspicion%20of%20AChE%20inhibitor%20poisoning. ). Then how do the investigators access the control NLR value (i.e., value before administration of atropine). Please discuss.  Mention which clinical/biochemical parameters will be considered for assessment.  Kindly include the following in the exclusion criteria: The patients who are on steroids, pregnant patients, and patients with blood disorders (https://www.jcmc.com.np/jcmc/index.php/jcmc/article/download/1311/836 ).  Thanks  Is the rationale for, and objectives of, the study clearly described? Yes  Is the study design appropriate for the research question? Partly  Are sufficient details of the methods provided to allow replication by others? Yes  Are the datasets clearly presented in a useable and accessible format? Partly",
         "0.7713",
         "4",
         "5",
         "0.1888736263736263",
         "0.6118",
         "0.9150463342666626",
         "28.23",
         "13.7",
         "14.37",
         "15.0",
         "18.3",
         "92",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "3.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "no hedging (minimal)",
         "3",
         "4.0",
         "3.0",
         "4.0",
         "82.0",
         "82",
         "f1000"
        ],
        [
         "18",
         "Vivek Gupta",
         "07 Feb 2024",
         "Approved",
         "273",
         "To study the utility of tumor budding as a histopathological marker in comparison to various histopathological parameters and TNM staging in breast carcinoma",
         "Background Breast cancer is the leading cause of death in Indian females. Detection of breast cancer in later stages leads to poorer prognosis and therefore decreases patient survival. Various new modalities such as mammography and USG guided FNACs are developed and many new markers are available to diagnose breast cancer; however, tumour budding is a cost-effective method which can be helpful in early diagnosis. Tumour buds are found to have a positive correlation with various histopathological prognostic markers in breast cancer. The present study will be conducted to evaluate tumour buds as a prognostic marker in breast cancer. This study aims to compare tumour budding with histopathological prognostic markers, TNM staging and IHC phenotypes.  Methods The study will be observational, cross- sectional, and prospective, will include 60 cases and will be conducted at Jawaharlal Nehru Medical College (JNMC) Wardha in the Pathology Department.  Results Data will be collected and combined together over a period of two years and will be analysed statistically for tumour budding as a marker and its correlation with breast prognosis.",
         "23",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The rationale for the study is well-defined and has clarity. It highlights the gap in the literature and the research question. The objectives are in sequence and lead to clarity in assessing the tumor bud in breast carcinoma. Objective 4 needs to be reframed to “Assessing the tumor bud status in carcinoma breast.” The histopathological examination may be removed as the same has already been mentioned in earlier objectives. The study design is apt for study. It mentions inclusion and exclusion. They have graded tumor budding as ≤ 4/10 HPF – low tumor budding and > 4/10 HPF – high tumor budding. However, it can be graded as ≤ 4/10 HPF, 4 – 9/10 HPF, and >10/10 HPF. An optimal cut-off for the number of tumor budding and lymph node metastasis can also be correlated. The protocol provides sufficient details for the evaluation of tumor budding. Microscopic pictures of high and low tumor buds can be more effective.  Is the rationale for, and objectives of, the study clearly described? Yes  Is the study design appropriate for the research question? Yes  Are sufficient details of the methods provided to allow replication by others? Yes  Are the datasets clearly presented in a useable and accessible format? Not applicable",
         "0.6864",
         "1",
         "0",
         "0.1460919540229885",
         "0.0999",
         "0.847241997718811",
         "47.08",
         "10.6",
         "12.87",
         "13.2",
         "11.5",
         "101",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "4.0",
         "4.0",
         "3.0",
         "80.0",
         "85",
         "f1000"
        ],
        [
         "19",
         "Yan Naung Soe",
         "15 May 2023",
         "Not Approved",
         "656",
         "Towards achieving lightweight intrusion detection systems in Internet of Things, the role of incremental machine learning: A systematic literature review",
         "While the benefits of IoT cannot be overstated, its computational constraints make it challenging to deploy security methodologies that have been deployed in traditional computing systems. The benefits and computational constraints have made IoT systems attractive to cyber-attacks. One way to mitigate these attacks is to detect them. In this study, a Systematic Literature Review (SLR) has been conducted to analyze the role of incremental machine learning in achieving lightweight intrusion detection for IoT systems. The study analyzed existing incremental machine learning approaches used in designing intrusion detection systems for IoT ecosystems, emphasizing the incremental methods used in detecting intrusions, the datasets used to evaluate these methods, and how the method achieves lightweight status. The SLR outlined the contributions of each study, focusing on their strengths and gaps, the datasets used, and the incremental machine learning model used. This study revealed that incremental learning approaches in detecting intrusion in IoT systems are in their infant stage. Over 12 years, from 2010 to 2022, a total of twenty-one (21) studies were carried out in IDSs using incremental machine learning, with eight (8) studies carried out in IoT systems. In addition to reviewing the literature, we offer suggestions for improving existing solutions and achieving lightweight IDS for IoT systems. We also discussed some problems with making lightweight IDS for IoT systems and areas where more research could be done in the future.",
         "172",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors conducted a review for the lightweight purpose of IoT-based introduction detection systems. It is interesting, but the following concerns have to be addressed. Many typos are found.  In the abstract, you mentioned that your review is based on the 21 IDS research works. It is not enough to review a specific work. There are many related works in recent years. More references are necessary.  In Table-5, the authors listed the sources/publishers of their references. Many lightweight IoT-IDS could be easily found by exploring these publishers' web sources. E.g., the authors can explore many articles in their sources, like MDPI, ACM Digital Library, and so on. In Table-6, why can “only zero article in ACM” be considered as your quality assessment criteria?  According to the title and abstract, you focus on the lightweight purpose in the detection systems, but you mentioned only 7 lightweight models. Also, you have to check them again, are these really lightweight systems? The authors organized some lightweight models in Table 8, even if the referenced works are not deeply checked, the question arises, how could some of them be lightweight? E.g., in Table 8, in the reference [30], how it would be lightweight with computational complexity? And also, the reference [28], is it lightweight with memory consumption?  According to your abstract, you mentioned that you analyzed the systems regarding 4 kinds of criteria. But your research questions almost did not reflect them. In addition, these are not also correct. In the abstract, the authors described \"The study analyzed 1) existing incremental machine learning approaches used in designing intrusion detection systems for IoT ecosystems, 2) emphasizing the incremental methods used in detecting intrusions, 3) the datasets used to evaluate these methods, and 4) how the method achieves lightweight status. In the \"Research questions\" section, the authors generated 4-questions, such as RQ1: What is the primary contribution of the paper? RQ2: What incremental or online machine learning algorithm was used in this study? RQ3: How does the proposed method handle data, feature, or concept drift? RQ4: How does the proposed IDS handle the computational constraints of IoT systems? Is there any relation between these two parts? More importantly, even showing these facts in these parts, there is no significant explanation in this review, especially on the lightweight purpose. If so, why did the authors put the important concern in IoT-IDS, \"lightweight/handling the computational constraints\" in these parts, such as the title, abstract, and research questions?  According to your references list, you put many published reviews and survey works. It would be better if you study them again how to arrange the contents in the review works.  The citation styles are also different. E.g., the reference numbers 7 and 8. Other references are also facing the same issue. In addition, the reference indexing style in tables is confusing.  In the conclusion, you describe that you analyzed comprehensively ML-based intrusion detection systems. However, in the current version, the manuscript seems just a report that you have studied. The overall comment is that you have to improve your manuscript significantly, to be following the style of review works, to be focusing on the facts in the title and abstract, and be arranged as a well-structured manuscript.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Partly  Are sufficient details of the methods and analysis provided to allow replication by others? No  Is the statistical analysis and its interpretation appropriate? Partly  Are the conclusions drawn adequately supported by the results presented in the review? Partly",
         "0.7573",
         "1",
         "2",
         "0.1519965277777778",
         "0.0294",
         "0.9109573364257812",
         "46.78",
         "10.7",
         "11.7",
         "13.0",
         "12.3",
         "97",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "5.0",
         "False",
         "negative",
         "neutral",
         "Moderate",
         "2",
         "4.0",
         "3.0",
         "3.0",
         "24.0",
         "36",
         "f1000"
        ],
        [
         "20",
         "Gatot Soepriyanto",
         "30 Jun 2023",
         "Approved With Reservations",
         "400",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "220",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The study investigate whether financial distress, earnings management and audit quality as determinants/moderating variable for financial statements fraud in Indonesian listed firms during 2015 to 2019 period. The authors focused on infrastructure, utility and transportation sectors. In general, the study has been designed adequately to tackle the research questions and issues posed by the authors. However, there are some elements need to be addressed to improve the paper: Whilst the study provide adequate research background and institutional setting, it did not mention on why the study focuses on infrastructure, utility and transportation sectors? Is there any specific issues on that sector that related to financial statements fraud? In addition to that, why the study chooses 2015-2019 period?  The study should also discuss the reason choosing F-Score as its main measure for financial statement fraud. Why, for example, the study did not use, Beneish M-Score? Or other accounting irregularities measures in the literature?  The study needs to provide descriptive statistics table, so the reader can gauge and understand the dataset better. This should be provided before the authors arrive with the hypothesis discussion;  Given the study uses panel data (multi years, across different firms), is there any attempt to mitigate the issues of panel data regression? For example, using year-fixed effects or even using panel data regression analysis?  The manuscript need to be checked in terms of the quality of English write up. The title for example, is a little bit confusing, as it did not really represent what the study want to achieve in general.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7771",
         "1",
         "0",
         "0.1174549549549549",
         "0.0168",
         "0.9143848419189452",
         "26.81",
         "14.2",
         "14.1",
         "14.9",
         "14.6",
         "96",
         "0",
         "0",
         "2",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "no",
         "negative",
         "neutral",
         "Minimal",
         "3",
         "4.0",
         "3.0",
         "4.0",
         "60.0",
         "66",
         "f1000"
        ],
        [
         "21",
         "Toni Šušak",
         "25 Mar 2024",
         "Approved With Reservations",
         "909",
         "Financial distress, earning management, financial statement fraud and audit quality as a moderating variable: listed companies on the Indonesia Stock Exchange",
         "Background: Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases. Companies create fraudulent financial statements for a variety of reasons, including financial challenges and debt payment delays. Financial fraud is created by five factors: pressure, opportunity, rationalization, capability, and arrogance. Methods: The purpose of this study is to see whether audit quality (AQ) has a moderating effect on the relationship between financial distress (FD) and earning management (EM) to financial statement fraud (FSF) in infrastructure, utility, and transportation companies listed on the Indonesia Stock Exchange during the years 2015 to 2019. The data sources are the www.idx.go.id and the company’s annual reports. Purposive sampling was used to collect data from thirty companies over the course of five years, totaling 150 observations. Moderating regression analysis (MRA) was used in data analysis. Result and conclusions: The hypothesis testing revealed that FD and EM have a significant impact on FSF.  AQ is able to moderate the relationship between FD to FSF but unable to moderate the relationship between EM to FSF.",
         "489",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Despite the interesting idea for research, the paper has its shortcomings: ** The title of the paper is too long, it should be shortened. ** Throughout entire paper (including the title) the term “earning management” is used instead of “earnings management”. ** [Page 1] “Accounting practices, profit bubbles, information manipulation and deception, and earning management are all examples of fraudulent financial statement cases”. – Earnings management is not necessarily fraudulent behavior. Why are accounting practices and profit bubbles listed as fraudulent? ** [Page 1] The website www.idx.go.id cannot be reached. The better option was to write the name of the source instead of a website. ** [Page 3] The name of the company is not Xeroc, it is Xerox. ** [Page 3] “Fraud is practice that involves the use of deception to acquire unfair or unlawful advantages by one or more individuals. This means that fraud is an act committed by specific people, whether intentionally or unintentionally, to benefit themselves and others.” – How can a fraud be unintentional? ** [Page 3] “Earnings management (EM) is profit engineering carried out by managing revenues (cash inflows) and expenses (cash outflows) to ensure that the company's operations generate net operating profit.” – Revenues are not synonym of cash inflows, nor are expenses synonym of cash outflows. ** [Page 3] F-score should be written with capital F. ** [Page 3] “Principal” should be written instead of “principle”. ** [Page 4] “Asymmetric information” or “Information asymmetry” should be written instead of “Asymmetry information”. ** [Page 4] “Donald Cressey” should be written instead of “Donald Cressy”. ** [Page 6] “Financial statements” should be written instead of “financial statistics”. ** [Page 6] “The study's subjects are companies in the infrastructure, utilities, and transportation sectors that have been listed on the Indonesia Stock Exchange during five years observation.” – What is the reason for choosing these sectors? ** [Page 6] If panel regression model is used, methodology and applied tests should be elaborated. ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 6] “If a corporation has more than one fraud score model, it is assumed that it will commit fraud.” – Should it be written “If a corporation has F-score value more than one…”? ** [Page 7] “EM is classified as a form of fraud.” – Earnings management is not necessarily fraudulent behavior. ** [Page 7] DACC formula has duplicated content.Instead of DACCit = TAit/Ait-1*TAit/Ait-1 - NDACCit it should be written DACCit = TAit/Ait-1 - NDACCit. TAit/Ait-1 is duplicated in the formula. The same remark is applicable to: ** [Page 6] RSST Accrual formula has duplicated content. ** [Page 7] Jones model formula should be included in the paper and elaborated. ** [Page 7] “Big Four” should be written with both capital letters (not “big four”). ** [Page 7] α, β, and ε is doubled in the explanations of formulas. ** [Page 8] Besides test variables, it is advisable to include additional control variables in the multiple regression model. ** [Page 8] “1. The constant is 0.258, indicating that the FSF is 0.193 if FD and EM are both zero. FSF does not occur in the research sample since the F-score is less than 1.” – Instead of “if FD and EM are both zero” it should be written “if all other variables are zero” given that AQ is also part of the model. ** [Page 8] “2. The FD coefficient is 0.791, which means that if the level of FD rises by one, the level of FSF rises by one as well.” – Instead of “the level of FSF rises by one as well” it should be written “the value of FSF rises by 0.791”. Ceteris paribus assumption should be stated. ** [Page 8] “3. EM's coefficient is 0.830. This means that if the management uses EM, the possibility of FSF will increase by 0.830.” – Instead of “if the management uses EM, the possibility of FSF will increase by 0.830.” it should be written “if the value of EM increases by 0.1, the value of FSF will increase by 0.083”. Ceteris paribus assumption should be stated. ** [Page 8] Variable explanations for moderating regression should be revised according to the previous three comments. ** [Page 10] “Industrial industry” should be corrected. ** Paper lacks descriptive statistics of the research sample. ** Robustness analysis could be conducted using alternative fraud measures. ** This paper would benefit from some closer proofreading. It may be useful to engage a professional English language editor. There is abundance of grammatical and typo errors (e.g. “diffucties”, “condisions”, “modeartes”, “criteras”, “coefiesient”, “shareloder” etc.).  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.6798",
         "5",
         "0",
         "0.1225925925925925",
         "0.072",
         "0.8569852709770203",
         "50.12",
         "9.4",
         "10.63",
         "12.4",
         "10.8",
         "98",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "6.0",
         "no",
         "neutral",
         "neutral",
         "minimal",
         "4",
         "3.0",
         "3.0",
         "3.0",
         "60.0",
         "60",
         "f1000"
        ],
        [
         "22",
         "Sergio Luis Náñez Alonso",
         "05 Dec 2022",
         "Approved",
         "490",
         "Cross-sectional data on stablecoin characteristics",
         "The article presents a dataset on the characteristics of stablecoins. Stablecoins represent a relatively young but increasingly important branch of the cryptocurrency market. Although they all share the same goal of maintaining a stable value in the digital market, they form a highly heterogeneous group. They differ in terms of collateral and stabilization mechanism, peg, availability of the technical documentation, presence on crypto exchanges or age. The dataset is cross-sectional and was created based on internet research. Individual information was collected from websites of the stablecoin projects and a crypto-data aggregator, and to a lesser extent from other auxiliary sources (websites related to finance and cryptocurrencies). The dataset is unique as there are no publicly available databases encompassing the features of stablecoins. It can be used in all stablecoin-related analyses to characterise the examined coins and to investigate the relationship between cryptocurrency market developments and stablecoin features.",
         "49",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The data note under review presents a brief introduction to the characterization of digital currencies called Stablecoins. This has allowed the authors to build up a novel database on stablecoins, mainly by searching the Internet. It is therefore a brief scientific review of the current state of the art on stablecoins, proposing a database that can be used by other researchers in their studies. It is in this last point that the value of the study lies. After reviewing the data note, it can be qualified as highly original, given that there are no other cross-sectional databases available for consultation by potential cryptocurrency researchers. This means that the contribution to scholarship is also high.  Regarding the structure, the data note under evaluation is of the short-paper type, so the introduction is sufficient.  There are a few issues that should be improved by the authors: In the methodology section, the authors should refer to previous database generation studies with their limitations. In the data description section, the authors should indicate a valid reason why only 30 Stablecoins were selected. In other words, originality in the attempt to construct this database is appreciated. The methodology details the criteria for selecting the sample of 30 stablecoins based on the information that appears in CoinMarketCap, the websites of the stablecoins themselves and other websites (at this point, they could mention some, perhaps including references). I understand that of the 98 listed on CoinMarketCap as of May 2022, many were excluded (down to 30) for the reasons stated. I don't know if Terra USD is no longer classified as a stablecoin after the crash that month (it dropped 40% in value). Do you guys consider keeping it in the sample? If so, I would like you to explain. I find table 1 very interesting as it raises 14 characteristics (a sufficient number) and a description of these. It is a research note that adds value to academic research on this topic. I recommend, however, to expand the references, either in the text or in Table 1, as there are many publications on stablecoins, in order to characterize stablecoins with previous studies and authors. Finally, I thank you for inviting me to review this data note. I found it relevant and interesting.  Is the rationale for creating the dataset(s) clearly described? Yes  Are the protocols appropriate and is the work technically sound? Yes  Are sufficient details of methods and materials provided to allow replication by others? Yes  Are the datasets clearly presented in a useable and accessible format? Yes",
         "0.7868",
         "1",
         "0",
         "0.118260582010582",
         "0.8817",
         "0.9205379486083984",
         "43.12",
         "12.1",
         "14.21",
         "14.8",
         "13.2",
         "97",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "5.0",
         "1.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "5.0",
         "4.0",
         "80.0",
         "86",
         "f1000"
        ],
        [
         "23",
         "Rekha Pillai",
         "03 Feb 2023",
         "Approved",
         "370",
         "Cross-sectional data on stablecoin characteristics",
         "The article presents a dataset on the characteristics of stablecoins. Stablecoins represent a relatively young but increasingly important branch of the cryptocurrency market. Although they all share the same goal of maintaining a stable value in the digital market, they form a highly heterogeneous group. They differ in terms of collateral and stabilization mechanism, peg, availability of the technical documentation, presence on crypto exchanges or age. The dataset is cross-sectional and was created based on internet research. Individual information was collected from websites of the stablecoin projects and a crypto-data aggregator, and to a lesser extent from other auxiliary sources (websites related to finance and cryptocurrencies). The dataset is unique as there are no publicly available databases encompassing the features of stablecoins. It can be used in all stablecoin-related analyses to characterise the examined coins and to investigate the relationship between cryptocurrency market developments and stablecoin features.",
         "109",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The article is novel. The rationale for creating the aforesaid data set is clearly outlined. The authors have collected Individual information from websites of the stablecoin projects and a crypto-data aggregator and they have clearly mentioned about the limited availability of stablecoin related information available on the public domain. It can be considered as an exploratory study as it unearths the stable coin dimensions, a less researched topic but one of high significance.  Future studies can build on the same and this is the main contribution of the paper. The data set is clearly presented in a useable and accessible format. It is clearly evident that no other cross- sectional studies of a similar nature has been conducted till date. However, as a suggestion, you may also justify the rationale behind why only 30 stable coins were selected, although the attempt is highly appreciated. You have clearly highlighted the rationale in excluding certain stable coins but you may elaborate on the total available, ones included and those excluded for providing a comprehensive picture.  As a recommendation to improve the paper, a brief literature review in a tabular form which only contains author names, year and key findings can add value. The paper may include a concluding paragraph, wrapping up the study with some future research/practical implications. Limitations of the study can be highlighted and suggest potential use of aforesaid data collected as recommendations for future research.  Finally thank you for giving this opportunity to review the paper and I hope the comments will be taken positively.  Is the rationale for creating the dataset(s) clearly described? Yes  Are the protocols appropriate and is the work technically sound? Yes  Are sufficient details of methods and materials provided to allow replication by others? Yes  Are the datasets clearly presented in a useable and accessible format? Yes",
         "0.7936",
         "1",
         "0",
         "0.0986591129958477",
         "0.6119",
         "0.8915177583694458",
         "33.65",
         "13.7",
         "16.02",
         "15.8",
         "14.7",
         "97",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "3",
         "4.0",
         "5.0",
         "4.0",
         "92.0",
         "92",
         "f1000"
        ],
        [
         "24",
         "Brian M Gurbaxani",
         "23 Aug 2023",
         "Approved With Reservations",
         "376",
         "Challenges in specifying parameter values for COVID-19 simulation models",
         "A recent modelling paper on the coronavirus disease 2019 (COVID-19) epidemic in the US (Bartsch et al.) suggested that maintaining face mask use until a high vaccine coverage (70–90%) is achieved is generally cost-effective or even cost-saving in many of the scenarios considered. Their conclusion was based on the assumed effectiveness of continued face mask use, cited from a study that reported an 18% reduction in the effective reproduction number associated with the introduction of state-level mask mandate policies in the US in the summer of 2020. However, using this value implicitly assumes that the effect of face mask use in 2021 through 2022 is the same as that of summer 2020, when stringent nonpharmaceutical interventions were in place. The effectiveness of universal mask wearing in 2021–2022 is probably more uncertain than considered in Bartsch et al. and rigorous sensitivity analysis on this parameter is warranted.",
         "336",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors take issue with the fixed, 18% efficacy figure for face masks in the economic evaluation of masks usage post-vaccination paper by Bartsch et al., and of course they are correct: the efficacy isn’t fixed, and it depends on a lot of factors. So the question is: if face mask impact on Rt is a function of 1) social behaviour (e.g. contact rates), 2) quality and quantity of face mask usage, and 3) intrinsic properties of the viral variant circulating (R0)1, and you’re trying to quantify the economic impact of maintaining facemask use during and after a vaccine campaign using a calibration of facemask impact on Rt from an earlier time when all 3 of those factors might be different, then couldn’t your economic impact assessment be off? Yes, it could. I’m not sure that the author’s suggestion of simply widening the uncertainty in the parameter value from 5 to 50% and doing a sensitivity analysis is going to do much good, however, because it won’t answer the policy questions people have, and will leave everyone more uncertain. I think it is possible, through modeling, to recalibrate the impact of facemasks on Rt for more recent times, when better quality masks are more widely available, but the variants are more easily transmissible as well, and society has less of a pandemic, lockdown mentality1,2. One could then present the results of different time periods corresponding to the spread of different variants, but with more certainty, and let the reader decide which scenario is more likely.  Is the rationale for commenting on the previous publication clearly described? Yes  Are any opinions stated well-argued, clear and cogent? Yes  Are arguments sufficiently supported by evidence from the published literature or by new data and results? Partly  Is the conclusion balanced and justified on the basis of the presented arguments? Yes",
         "0.7963",
         "1",
         "0",
         "0.1586038961038961",
         "0.1443",
         "0.902733564376831",
         "33.68",
         "15.7",
         "18.69",
         "17.3",
         "17.7",
         "96",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "2.0",
         "True",
         "neutral",
         "polite",
         "Moderate",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "72.0",
         "72",
         "f1000"
        ],
        [
         "25",
         "José L Herrera-Diestra",
         "07 Sep 2023",
         "Approved",
         "220",
         "Challenges in specifying parameter values for COVID-19 simulation models",
         "A recent modelling paper on the coronavirus disease 2019 (COVID-19) epidemic in the US (Bartsch et al.) suggested that maintaining face mask use until a high vaccine coverage (70–90%) is achieved is generally cost-effective or even cost-saving in many of the scenarios considered. Their conclusion was based on the assumed effectiveness of continued face mask use, cited from a study that reported an 18% reduction in the effective reproduction number associated with the introduction of state-level mask mandate policies in the US in the summer of 2020. However, using this value implicitly assumes that the effect of face mask use in 2021 through 2022 is the same as that of summer 2020, when stringent nonpharmaceutical interventions were in place. The effectiveness of universal mask wearing in 2021–2022 is probably more uncertain than considered in Bartsch et al. and rigorous sensitivity analysis on this parameter is warranted.",
         "351",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  I consider that the case made by the authors in this correspondence are valid and important. Changes in the conditions that lead to the 18% reduction of Rt are certainly a combination of all measures implemented in 2020, and may not be directly applicable in 2021-2022. I agree that a \"rigorous sensitivity analysis\" might be a good starting point. However, besides this sensitivity analysis, more elaborated methods need to be developed to assess more accurately the influence of the different interventions that were in play in the summer of 2020, and which of these interventions could be reasonably extrapolated to 2021-2022.  Is the rationale for commenting on the previous publication clearly described? Yes  Are any opinions stated well-argued, clear and cogent? Yes  Are arguments sufficiently supported by evidence from the published literature or by new data and results? Partly  Is the conclusion balanced and justified on the basis of the presented arguments? Yes",
         "0.7723",
         "1",
         "0",
         "0.1663711288711289",
         "0.1953",
         "0.7168864607810974",
         "29.79",
         "15.2",
         "18.49",
         "17.4",
         "16.9",
         "103",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "3.0",
         "yes",
         "neutral",
         "polite",
         "Moderate",
         "somewhat specific",
         "4.0",
         "5.0",
         "4.0",
         "92.0",
         "92",
         "f1000"
        ],
        [
         "26",
         "Palwinder Singh",
         "14 Jun 2022",
         "Not Approved",
         "333",
         "Anti-inflammatory activity and toxicity evaluation of 1,3-bis(p-hydroxyphenyl)urea",
         "Background: Inflammation is a normal protective response caused by an injury or tissue damage, through physical trauma, damaging chemicals, or invasion of pathogenic microorganisms. One of the modified p-aminophenol compounds is 1,3-bis(p-hydroxyphenyl)urea, which was estimated to have more potent analgesic activity and fewer hepatotoxic side effects than paracetamol. When the lipophilicity of this compound increases between 1.8 to 4.4, it is observed to serve as an anti-inflammatory agent. Therefore, the determination of safety precaution is very necessary while testing for the toxicity effect of 1,3-bis(p-hydroxyphenyl)urea. This is due to the effectiveness and safety of suitable drugs. Methods: An anti-inflammatory test was carried out by measuring the percentage of inflammation in rats, after the administration of 1,3-bis(p-hydroxyphenyl)urea was previously induced by the carrageenan solution intraplantar and the analysis of neutrophil values through a plethysmometer and Hematoxylin-Eosin method. Also, an acute toxicity test was performed by administering this p-aminophenol compound to female rats for 24 h and observed for 14 days. In addition, a subchronic toxicity test was conducted on male and female rats for 28 days, with continuous observations carried out for 42 days. Results: The doses of 1,3-bis(p-hydroxyphenyl)urea at 50, 100, and 200 mg/Kg BW, had anti-inflammatory activity compared to diclofenac sodium at 2.25 mg/Kg BW. Also, there is no toxicity and animal death symptoms were observed in the acute and subchronic tests. Conclusion: This 1,3-bis(p-hydroxyphenyl)urea compound had an anti-inflammatory activity and relatively low toxicity.",
         "62",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This reviewer read the manuscript with interest and rather several times to see what new science has been explored. To my surprise the subject is the compound 1,3-bis(p-hydroxyphenyl)urea. Some of the questions that arise are: Why did the authors choose this compound for the study?  What is the rationale for the selection of 1,3-bis(p-hydroxyphenyl)urea?  Endless data has been recorded by the authors. What reference drug/compound was used? Diclofenac is a COX-1/2 non-selective NSAID. In the first paragraph of ‘Results’ section, it is not clear whether the urea derivative is more potent than diclofenac or not.  Is it not possible to calculate IC50 for this urea derivative against COX-1 and COX-2?  Since this compound has already been studied for its analgesic effect, are  the results of the present study comparable to those already reported?  What exactly is the mode of action of this urea derivative? Does it act through COX-2 inhibition or some other pathway?  What about the COX-1, COX-2 selectivity?  In the light of above mentioned issues, this reviewer is not in favour of indexing this manuscript until the objectives are clear.  Is the work clearly and accurately presented and does it cite the current literature? No  Is the study design appropriate and is the work technically sound? No  Are sufficient details of methods and analysis provided to allow replication by others? No  If applicable, is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are all the source data underlying the results available to ensure full reproducibility? No  Are the conclusions drawn adequately supported by the results? No",
         "0.7545",
         "1",
         "0",
         "0.1541341991341991",
         "0.145",
         "0.7552205324172974",
         "39.84",
         "11.3",
         "12.53",
         "13.2",
         "11.6",
         "96",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "2.0",
         "11.0",
         "no",
         "neutral",
         "neutral",
         "Moderate",
         "3",
         "4.0",
         "2.0",
         "3.0",
         "25.0",
         "27",
         "f1000"
        ],
        [
         "27",
         "Neng Fisheri Kurniati",
         "07 Jul 2022",
         "Approved With Reservations",
         "317",
         "Anti-inflammatory activity and toxicity evaluation of 1,3-bis(p-hydroxyphenyl)urea",
         "Background: Inflammation is a normal protective response caused by an injury or tissue damage, through physical trauma, damaging chemicals, or invasion of pathogenic microorganisms. One of the modified p-aminophenol compounds is 1,3-bis(p-hydroxyphenyl)urea, which was estimated to have more potent analgesic activity and fewer hepatotoxic side effects than paracetamol. When the lipophilicity of this compound increases between 1.8 to 4.4, it is observed to serve as an anti-inflammatory agent. Therefore, the determination of safety precaution is very necessary while testing for the toxicity effect of 1,3-bis(p-hydroxyphenyl)urea. This is due to the effectiveness and safety of suitable drugs. Methods: An anti-inflammatory test was carried out by measuring the percentage of inflammation in rats, after the administration of 1,3-bis(p-hydroxyphenyl)urea was previously induced by the carrageenan solution intraplantar and the analysis of neutrophil values through a plethysmometer and Hematoxylin-Eosin method. Also, an acute toxicity test was performed by administering this p-aminophenol compound to female rats for 24 h and observed for 14 days. In addition, a subchronic toxicity test was conducted on male and female rats for 28 days, with continuous observations carried out for 42 days. Results: The doses of 1,3-bis(p-hydroxyphenyl)urea at 50, 100, and 200 mg/Kg BW, had anti-inflammatory activity compared to diclofenac sodium at 2.25 mg/Kg BW. Also, there is no toxicity and animal death symptoms were observed in the acute and subchronic tests. Conclusion: This 1,3-bis(p-hydroxyphenyl)urea compound had an anti-inflammatory activity and relatively low toxicity.",
         "85",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This article showed that 1,3-bis(p-hydroxyphenyl)urea had anti-inflammatory activity and safe to be used. However the results section in the abstract did not clearly show the efficacy and safety of the compound. Please provide the efficacy with number, percentage or else. Significance calculation should be shown in Figure 1 and 3 to make it easier for the reader to read the results. Legend of the figure and table should give more information, for example, the number of animals, magnification, etc. In Materials and Methods, many information have not been provided, such as the number of animal use for toxicity study, histology procedure, etc.  Please write a good introduction to the study. The first sentence of the paragraph should inform the primary information. Two or three next sentences should provide details information. Avoid repeated information. Furthermore, for the discussion section, please provide a more comprehensive discussion, such as comparing the data with the working hypotheses. Limitation of the study and future study should be mentioned as well.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? No",
         "0.7553",
         "2",
         "0",
         "0.2233870967741935",
         "0.378",
         "0.8138936161994934",
         "30.77",
         "12.7",
         "14.24",
         "14.3",
         "12.9",
         "85",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "3",
         "4.0",
         "3.0",
         "3.0",
         "60.0",
         "66",
         "f1000"
        ],
        [
         "28",
         "Sangeeta Saha",
         "16 Nov 2023",
         "Not Approved",
         "373",
         "Simulation model for the dynamics of dengue with asymptomatic transmission and the effect of temperature",
         "Background: One of the fastest spreading vector-borne diseases in tropical and subtropical regions is dengue, which generates cost overruns for public health entities. Several factors can influence the dynamics of dengue virus transmission: environmental and climatic (abundance of vectors), interactions between hosts (infections by asymptomatic individuals), and population immunological factors. Given these conditions, it is necessary to carry out theoretical studies based on meteorological factors and asymptomatic transmission that are associated with both the existence of the vector and its incidence, in order to provide a scientific basis for health entities in decision-making. Methods: A mathematical model based on nonlinear ordinary differential equations is proposed to interpret the dynamics of dengue transmission in humans coupled to the dynamics of the Aedes aegypti species, considering the population of symptomatic and asymptomatic infected humans and the effect of temperature variability. The basic reproduction number was found and some simulation results based on the Runge-Kutta numerical method were obtained. Results: The simulations showed that the temperature had a directly proportional relationship with the basic reproduction number. The cases of infected people and carrier mosquitoes increased when the temperature peaks increased drastically; in low temperatures the infection persisted with low morbidity due to the survival of asymptomatic people. Conclusions: High temperatures tolerable by mosquitoes increase their life expectancy and their numbers in the environment which, together with a reservoir of asymptomatic infected people, leads to a higher incidence of the dengue virus in certain seasons or maintains its circulation in seasons of low temperatures, despite lower vector survival rates.",
         "546",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors, in the manuscript, have proposed a compartmental epidemic model of dengue transmission where the mosquito biting rate and the transmission rates from host to vector as well as vector to host are assumed to be temperature dependent. The calculations are basic ones and seem to be ok, but there are few points which I need to mention. Firstly, whenever a model is proposed, it is very important to show the biological well-posedness of the system. So, proving the non-negativity and boundedness of the system variables make the base on which the rest of the analysis is performed. Secondly, I am unable to understand how the transmission from mosquito to human depends on the temperature with two types of conditions (noted in equations 15 and 16). It could have been analysed appropriately. Moreover, it is not demonstrated properly how the time variable is connected with the temperature. So, a proper analysis of the second subfigures of each of Figure 2- Figure 4 could improve the work. Also, as per the model assumption, the parameter denoting 'the increase in female mosquito population' should also depend on temperature, but it is chosen as a constant value only. The reason supporting it needs to be mentioned. Altogether I have found the concept interesting, but the mentioned points, if taken care of, will make the work more strong and presentable only.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7553",
         "1",
         "0",
         "0.143034188034188",
         "0.063",
         "0.8884497880935669",
         "33.54",
         "13.7",
         "15.25",
         "15.4",
         "14.1",
         "101",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "3.0",
         "80.0",
         "80",
         "f1000"
        ],
        [
         "29",
         "J H Arias-Castro",
         "16 Nov 2023",
         "Not Approved",
         "255",
         "Simulation model for the dynamics of dengue with asymptomatic transmission and the effect of temperature",
         "Background: One of the fastest spreading vector-borne diseases in tropical and subtropical regions is dengue, which generates cost overruns for public health entities. Several factors can influence the dynamics of dengue virus transmission: environmental and climatic (abundance of vectors), interactions between hosts (infections by asymptomatic individuals), and population immunological factors. Given these conditions, it is necessary to carry out theoretical studies based on meteorological factors and asymptomatic transmission that are associated with both the existence of the vector and its incidence, in order to provide a scientific basis for health entities in decision-making. Methods: A mathematical model based on nonlinear ordinary differential equations is proposed to interpret the dynamics of dengue transmission in humans coupled to the dynamics of the Aedes aegypti species, considering the population of symptomatic and asymptomatic infected humans and the effect of temperature variability. The basic reproduction number was found and some simulation results based on the Runge-Kutta numerical method were obtained. Results: The simulations showed that the temperature had a directly proportional relationship with the basic reproduction number. The cases of infected people and carrier mosquitoes increased when the temperature peaks increased drastically; in low temperatures the infection persisted with low morbidity due to the survival of asymptomatic people. Conclusions: High temperatures tolerable by mosquitoes increase their life expectancy and their numbers in the environment which, together with a reservoir of asymptomatic infected people, leads to a higher incidence of the dengue virus in certain seasons or maintains its circulation in seasons of low temperatures, despite lower vector survival rates.",
         "546",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The article aims to analyze the effects of temperature on dengue transmission considering the asymptomatic population. Initially, a model in which some temperature-dependent parameters are considered is presented. But then, the classical analysis of the model is performed without considering the dependence of the parameters on temperature, which simplifies the analysis of the model and puts it in the classical scheme, which practically makes the subject to be treated lose novelty. Additionally, some scenarios are presented in Figures 3 and 4, which turn out to be analogous because they model situations that have no differences, since the equations turn out to be equivalent, in the case of asymptomatic and infected humans.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7286",
         "1",
         "0",
         "0.1503623188405797",
         "0.0513",
         "0.8830835223197937",
         "22.55",
         "15.9",
         "18.22",
         "17.5",
         "17.0",
         "96",
         "0",
         "0",
         "1",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "no",
         "neutral",
         "neutral",
         "Moderate",
         "2",
         "4.0",
         "3.0",
         "5.0",
         "64.0",
         "66",
         "f1000"
        ],
        [
         "30",
         "Alison Kutywayo",
         "30 Nov 2023",
         "Approved With Reservations",
         "255",
         "A systematic review: Male engagement in adolescent and young adults’ sexual and reproductive health in the Americas",
         "Progress towards sexual and reproductive health (SRH) goals for adolescents across the Americas has stagnated. Of all the regions worldwide, Latin America has experienced the slowest decline in adolescent fertility rates. Reports published by the United Nations and multiple nongovernmental organizations demonstrate a growing consensus for a masculinities framework that engages men and boys in public health and social change. Male engagement acts as a complement - and not a replacement - of current SRH. Emerging evidence indicates that Coronavirus disease in 2019  has worsened SRH outcomes, especially related to gender-based violence; new evidence-based interventions are ever more urgent.  This systematic review includes a focus on education-based male engagement, a special consideration of gender equity, and systematic searches by fluent speakers in three most populous languages in the Americas (English, Spanish, and Portuguese). PubMed, EBSCO, SCOPUS, and Google Scholar databases were digitally searched. Publications were excluded if their focus did not align directly with sexual reproductive health, their location was outside the scope of study, its content derived from information collected before 2010, or its study’s population’s age of focus was not between 15-24 years of age. After abstract screening and full-text review, the original 10,721 articles identified were narrowed down to 13 articles whose references were further examined through hand searching, leading us to a total of 32 final articles chosen for analysis. The results were classified by geographic regions of the American continent. The literature emphasized that society often defines masculinity as a hegemonic role grounded in aggressive high-risk sexual behavior. Adolescent males internalize this and hold their peers to these expectations. These beliefs have detrimental SRH consequences that have yet to be fully understood among adolescent boys and males. The efficacy of future interventions will depend on further exploration of these topics, especially among minority populations.",
         "604",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Thank you for the opportunity to review this systematic review of male engagement in SRH in the Americas. It is an interesting piece of work.  Having reviewed this manuscript, my main comments are related to the structure of the Methods, Results and Discussion. The Results need to be thematically analyzed by theme, rather than by geographical area and there are many things in the Methods that need to be in the Results.  I suggest that the authors please carefully review the following manuscript  ( https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8005924/ ) for guidance on what to include in the respective sections. Table 1 in this PRISMA manuscript provides a clear guide that will help you strengthen your manuscript. In addition to these main comments, I have a 61 editorial comments throughout the manuscript for your consideration. (See attached PDF)  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Not applicable  Are the conclusions drawn adequately supported by the results presented in the review? Partly",
         "0.7795",
         "1",
         "1",
         "0.1264492753623188",
         "0.9417",
         "0.8444064855575562",
         "34.76",
         "13.3",
         "15.39",
         "15.2",
         "15.1",
         "102",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "3.0",
         "True",
         "neutral",
         "polite",
         "Moderate",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "82.0",
         "82",
         "f1000"
        ],
        [
         "31",
         "Hadina Habil",
         "21 Apr 2022",
         "Approved With Reservations",
         "317",
         "Role of English language in agricultural organisations",
         "Background – The importance placed on having good English language proficiency and skills to secure employment in Malaysia is a well-known fact. However, very little is known about the role of the English language in multilingual organisations within the agricultural industry in Malaysia. As such, this study aimed to examine the employees’ perception of the use of the English language in a professional context particularly in the Malaysian agricultural and agricultural related sectors.  Methods – A concurrent triangulation design was used to quantitatively evaluate the data. A total of 320 questionnaires from employees of 10 agriculture and agriculture related companies were analysed.  Additionally, interviews were also conducted with 10 employers from the human resources department as they provided deep insights into the language matters of the organisations.  Results – The employers and employees agree that English language proficiency has economic value and can play an important role at the workplace, as this skill can influence one’s career path in terms of employability and career progression.  Conclusions - From the standpoint of employees, a more insightful idea on the influence of English on career development in the agricultural industry has been obtained. These findings have implications for learning outcomes of students, education system, and policymakers aspiring for the human capital which is needed for Malaysia to become a high income and developed nation.",
         "50",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The findings from the survey questionnaire were not discussed in detail. Therefore, suggestions on how to improve the present situation were not mentioned, although it was stated in the conclusion section that the universities must ensure that the students develop English proficiency and good communication skills. For example, under Results: English language proficiency skills, information can be added to show what the skills are that the respondents can or cannot do with their English language proficiency. The same goes with the second result: Language use in the workplace: the role of English language. More details could be presented as to the role of English in the organisation. This is the same with the third finding: Employees' perception on importance of English. The present information does not provide much information for a detailed discussion of the findings.  The article will be more impactful if more details are provided about the data, the analysis, and the findings so that the discussion would be more precise and suggestions could be given to improve the situation.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? No",
         "0.7112",
         "1",
         "0",
         "0.1878205128205128",
         "0.0999",
         "0.8121065497398376",
         "33.14",
         "13.9",
         "14.88",
         "15.1",
         "15.3",
         "102",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "4.0",
         "3.0",
         "2.0",
         "80.0",
         "80",
         "f1000"
        ],
        [
         "32",
         "Mekala Sethuraman",
         "31 Mar 2023",
         "Approved With Reservations",
         "826",
         "Role of English language in agricultural organisations",
         "Background – The importance placed on having good English language proficiency and skills to secure employment in Malaysia is a well-known fact. However, very little is known about the role of the English language in multilingual organisations within the agricultural industry in Malaysia. As such, this study aimed to examine the employees’ perception of the use of the English language in a professional context particularly in the Malaysian agricultural and agricultural related sectors.  Methods – A concurrent triangulation design was used to quantitatively evaluate the data. A total of 320 questionnaires from employees of 10 agriculture and agriculture related companies were analysed.  Additionally, interviews were also conducted with 10 employers from the human resources department as they provided deep insights into the language matters of the organisations.  Results – The employers and employees agree that English language proficiency has economic value and can play an important role at the workplace, as this skill can influence one’s career path in terms of employability and career progression.  Conclusions - From the standpoint of employees, a more insightful idea on the influence of English on career development in the agricultural industry has been obtained. These findings have implications for learning outcomes of students, education system, and policymakers aspiring for the human capital which is needed for Malaysia to become a high income and developed nation.",
         "394",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Review of the Research Article: “Role of English Language in Agricultural Organisations” The article deals with the importance of English Language for the employees working in agricultural and agriculture-related organisations. It has employed concurrent triangulation design to analyse the data by quantitatively as well as qualitatively using questionnaires and interviews. The findings of the study reinstates the assumption of the authors on the pivotal role of English language for the employees to survive as well as to secure higher positions in the organisations. The authors suggest that the policymakers in Malaysia have to look into this need and modify the educational policy for enhancing the economic situation of Malaysia besides transforming it into a developed nation in the long run. Overall the article discusses the aim with clarity and suggests solution for the problem addressed. Abstract: Abstract is concise and clear. However, the authors have missed to mention the year of the study being conducted. It would give clear idea to the readers to relate with the educational policy of Malaysia at the time of the study as it plays a huge role in addressing the problem suggested in the article. Introduction: Introduction deals with the explanation on the Language proficiency level of employees in the agricultural and its related sectors. In addition, it discusses the role of agriculture in Malaysian economic growth. The authors should use the recent quote of Ministry of Education as this quote addresses the Proficiency level of graduates and employees. Recent report of graduates’ English language proficiency should be mentioned to explain the current situation in Malaysia. Marschan et al. (1977) quote should be rephrased for clarity. The authors have mentioned ‘previous studies’. However, they have not included the studies published in the year 2021. Methods: As mentioned in the earlier comment, the authors should include the period of the study. Profile of the respondent has not been given in detail but only mentioned that respondents vary at different background knowledge. At the end of the Methods section, the authors have mentioned that the data were categorized into themes. They have not elaborated on the themes they have mentioned. Results: Language Use in the Workplace: Sentence construction on the interpretation of the results should be modified for clarity of expression. Besides, the interpretation should be rechecked by the authors in line with the data presented in Figure 2. Further, in Figure 2, there is repetition of the variables, “Listening/Speaking (Malay)”, which should be revised. Employees’ perception on importance of English: The authors have mentioned that the employees are aware of the ‘importance of the role that language has in the workplace’. Do they have to stress the role of language in general or English language in particular? In the following paragraph, they have said, “it is imperative that they have the language competence”. This implies that the employees have the language competence. But the authors want to explain that the employees understand that they need to have the language competence. So, the authors have to rephrase the statement for clarity. At the end of the paragraph, they have used ‘As an employer explains’. The use of ‘As’ is inappropriate at the place used, as the authors neither have used a statement after the quote nor have merged with previous sentence. So, it is better to remove it. Discussion: The authors have discussed the significance of English language for employees in organisations in general and have not discussed in specific to the role of English language for the employees working in agricultural and its related sectors. How do the findings explain the influence of English language for the employees?. This question has been neglected to be discussed. It is good that the authors have used Piekkari et al.’s (2015) model of Language Barrier to support their theory, but they have not elaborated on its role in specific to the agriculture and its related sectors. Conclusion: The authors have stated conclusion very precisely with clarity. However, it would be good to add two or three sentences on the summary of what the article has dealt with so far.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7113",
         "2",
         "2",
         "0.1383080808080808",
         "0.038",
         "0.9129533767700196",
         "44.75",
         "11.5",
         "12.53",
         "14.2",
         "12.9",
         "99",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "1.0",
         "no",
         "neutral",
         "neutral",
         "Minimal",
         "3",
         "4.0",
         "4.0",
         "4.0",
         "85.0",
         "85",
         "f1000"
        ],
        [
         "33",
         "Slobodan M Janković",
         "21 Feb 2022",
         "Approved",
         "324",
         "Correlation between serum methotrexate-polyglutamate 3 (MTX-PG3) level and disease activity in rheumatoid arthritis patients: A prospective cohort study",
         "Background: Rheumatoid arthritis (RA) is one of the most common autoimmune diseases, characterized by systemic inflammation, joint destruction and disability. Methotrexate (MTX) is used as the primary treatment for RA patients. However, the response to MTX therapy is highly varied and difficult to predict. This study sought to determine the role of MTX by measuring the MTX polyglutamate 3 (MTX-PG3) levels and the disease activity score 28 based on C-reactive protein (DAS28-CRP) of RA patients. Method: A prospective cohort study was conducted at the Rheumatology Polyclinic of Dr. Cipto Mangunkusumo General Hospital. Thirty-four patients with RA were included and followed up to 12 weeks. The RA patients were treated with MTX 10 mg per week and an increased dose of 5 mg per week every month. DAS28-CRP and MTX-PG3 level were assessed at week 8 and 12. Multivariate logistic regression analysis was used to determine the correlation between MTX-PG3 and DAS28-CRP. Result: A total of 34 RA patients were followed and the MTX was well tolerated in which no increase of serum glutamic oxaloacetic transaminase (SGOT), serum glutamic pyruvic transaminase (SGPT) and glomerular filtration rate (GFR) were observed. The mean scores of DAS28-CRP decreased following the MTX-treatment: 3.93, 3.22 and 2.82 at week 0, 8 and 12, respectively. In contrast, the median concentration of MTX-PG3 increased from week 8 to week 12 followed by increasing the dose of MTX. Our analysis suggested there was a moderate positive correlation between MTX-PG3 levels and DAS28-CRP score at week 8 and week 12 post-MTX treatment. Conclusion: The level of MTX-PG3 is correlated with DAS28-CRP score suggesting that MTX-PG3 could be used as an indicator to assess the disease activity in RA patients. Nevertheless, a prospective study with a higher number of patients is needed to confirm this finding.",
         "6",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors made an observational study trying to correlate MTX PG levels with disease activity of RA (as measured by a clinical score). The topic is of general interest, and the study brings results with practical significance. The manuscript is well written, and merits acceptance for publication. However, there are a few issues that should be corrected: In the Methods section the authors should state precisely how they measures the MTX PG levels in erythrocytes. As it is written now, it is not clear whether the MTX PG levels were measured in erythrocytes or in full blood.  Number of patients is small, so it is critical that statistical methods were used properly. The authors should state whether assumptions of multivariate logistic regression were met. Also, what was the categorical outcome used as dependent variable of the regression? Finally, quality of the regression model should be stated (Hosmer Lemeshow test, Cox and Snellen...).  Something should be said about adherence of the patients to the therapy. Was there any method used to check for adherence? If not, mention this in the Limitation paragraph.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7684",
         "1",
         "0",
         "0.1401785714285714",
         "0.0999",
         "0.801764965057373",
         "37.2",
         "12.3",
         "14.25",
         "14.2",
         "12.8",
         "96",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "85.0",
         "80",
         "f1000"
        ],
        [
         "34",
         "Andri Frediansyah",
         "23 Feb 2022",
         "Approved With Reservations",
         "388",
         "Correlation between serum methotrexate-polyglutamate 3 (MTX-PG3) level and disease activity in rheumatoid arthritis patients: A prospective cohort study",
         "Background: Rheumatoid arthritis (RA) is one of the most common autoimmune diseases, characterized by systemic inflammation, joint destruction and disability. Methotrexate (MTX) is used as the primary treatment for RA patients. However, the response to MTX therapy is highly varied and difficult to predict. This study sought to determine the role of MTX by measuring the MTX polyglutamate 3 (MTX-PG3) levels and the disease activity score 28 based on C-reactive protein (DAS28-CRP) of RA patients. Method: A prospective cohort study was conducted at the Rheumatology Polyclinic of Dr. Cipto Mangunkusumo General Hospital. Thirty-four patients with RA were included and followed up to 12 weeks. The RA patients were treated with MTX 10 mg per week and an increased dose of 5 mg per week every month. DAS28-CRP and MTX-PG3 level were assessed at week 8 and 12. Multivariate logistic regression analysis was used to determine the correlation between MTX-PG3 and DAS28-CRP. Result: A total of 34 RA patients were followed and the MTX was well tolerated in which no increase of serum glutamic oxaloacetic transaminase (SGOT), serum glutamic pyruvic transaminase (SGPT) and glomerular filtration rate (GFR) were observed. The mean scores of DAS28-CRP decreased following the MTX-treatment: 3.93, 3.22 and 2.82 at week 0, 8 and 12, respectively. In contrast, the median concentration of MTX-PG3 increased from week 8 to week 12 followed by increasing the dose of MTX. Our analysis suggested there was a moderate positive correlation between MTX-PG3 levels and DAS28-CRP score at week 8 and week 12 post-MTX treatment. Conclusion: The level of MTX-PG3 is correlated with DAS28-CRP score suggesting that MTX-PG3 could be used as an indicator to assess the disease activity in RA patients. Nevertheless, a prospective study with a higher number of patients is needed to confirm this finding.",
         "8",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The researchers looked at 34 people with rheumatoid arthritis (RA) to see if there was a link between MTX-PG levels and how active their RA was. There were two women and 32 men in the study. The subject matter is of general interest, and the study yields useful information. There are, however, a few issues that should be addressed: 1) Please specify the date, duration, and months of the experiment. 2) Please verify the following statement: \"low disease activity, <3.2–5.1\". Is this correct? 3)The methods section is unclear. Please describe it in detail. Is there a particular type of blood (whole blood, red, or white blood cells) that you used in the study? Additionally, please provide detailed information about the centrifugation parameters, such as time, temperature, and g-force/RCF (g). Prior to analysis, is the blood subjected to any special treatment? 4) Please rewrite the section on chromatography measurement and analysis in detail. Include the HPLC specification and brand; column details (including particle size, pore size, inner diameter, and length); ammonium hydrochloride concentration and pH; solvent B composition (or A, if any); and the reference you cited. 5) Did you combine ammonium bicarbonate and ammonium chloride, and if so, in what proportion? Which detector (UV/CAD/MS) did you use? If UV/DAD, at what wavelength did you adjust the detector? 6) Please specify the brand of the MTX-PG3 standard and the R2 (nmol) value of the standard you used.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? I cannot comment. A qualified statistician is required.  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7661",
         "1",
         "0",
         "0.1242921492921493",
         "0.5077",
         "0.7883067727088928",
         "39.43",
         "11.5",
         "12.66",
         "13.1",
         "11.8",
         "91",
         "0",
         "1",
         "1",
         "0",
         "4.0",
         "5.0",
         "6.0",
         "True",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "3.0",
         "84.0",
         "84",
         "f1000"
        ],
        [
         "35",
         "Talha Bin Emran",
         "02 Mar 2022",
         "Approved With Reservations",
         "317",
         "Correlation between serum methotrexate-polyglutamate 3 (MTX-PG3) level and disease activity in rheumatoid arthritis patients: A prospective cohort study",
         "Background: Rheumatoid arthritis (RA) is one of the most common autoimmune diseases, characterized by systemic inflammation, joint destruction and disability. Methotrexate (MTX) is used as the primary treatment for RA patients. However, the response to MTX therapy is highly varied and difficult to predict. This study sought to determine the role of MTX by measuring the MTX polyglutamate 3 (MTX-PG3) levels and the disease activity score 28 based on C-reactive protein (DAS28-CRP) of RA patients. Method: A prospective cohort study was conducted at the Rheumatology Polyclinic of Dr. Cipto Mangunkusumo General Hospital. Thirty-four patients with RA were included and followed up to 12 weeks. The RA patients were treated with MTX 10 mg per week and an increased dose of 5 mg per week every month. DAS28-CRP and MTX-PG3 level were assessed at week 8 and 12. Multivariate logistic regression analysis was used to determine the correlation between MTX-PG3 and DAS28-CRP. Result: A total of 34 RA patients were followed and the MTX was well tolerated in which no increase of serum glutamic oxaloacetic transaminase (SGOT), serum glutamic pyruvic transaminase (SGPT) and glomerular filtration rate (GFR) were observed. The mean scores of DAS28-CRP decreased following the MTX-treatment: 3.93, 3.22 and 2.82 at week 0, 8 and 12, respectively. In contrast, the median concentration of MTX-PG3 increased from week 8 to week 12 followed by increasing the dose of MTX. Our analysis suggested there was a moderate positive correlation between MTX-PG3 levels and DAS28-CRP score at week 8 and week 12 post-MTX treatment. Conclusion: The level of MTX-PG3 is correlated with DAS28-CRP score suggesting that MTX-PG3 could be used as an indicator to assess the disease activity in RA patients. Nevertheless, a prospective study with a higher number of patients is needed to confirm this finding.",
         "15",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Title: Correlation between serum methotrexate-polyglutamate 3 (MTX-PG3) level and disease activity in rheumatoid arthritis patients: A prospective cohort study Minor comments: Although the article has scientific rigor, several minor flows need to be improved before publication: 1. The abstract section is unsuitable—no focus point in the abstract section. 2. \"Nevertheless, a prospective study with a higher number of patients is needed to confirm this finding.\" Is this necessary? 3. Authors are suggested to use the full form when used for the first time throughout the manuscript. 4. The aim of the study should be written as the last paragraph of the introduction. 7. MTX treatment and follow-up: How was this selected? 8. Receiver Operating Characteristics (ROC) analysis: Please describe in further detail. 9. \"Further analysis using the ROC curve showed that MTX-PG3 level…\" needs more insights with relevant references. 10. Presentation of figures is good. 11. Figure legends are appropriate and self-explanatory. 12. The conclusion needs to address future perspectives. 13. Spacing, punctuation marks, grammar, and spelling errors should be reviewed thoroughly.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7843",
         "11",
         "0",
         "0.1904411764705882",
         "0.1939",
         "0.8207837343215942",
         "29.96",
         "13.0",
         "14.06",
         "13.9",
         "13.8",
         "81",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "5.0",
         "7.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "4.0",
         "92.0",
         "92",
         "f1000"
        ],
        [
         "36",
         "Setya Haksama",
         "14 Jan 2022",
         "Approved With Reservations",
         "214",
         "Globalization and life lost due to tuberculosis: evidence from a multi-country study",
         "Background: Tuberculosis affects around 30% of the population of the world. Tuberculosis causes an increase in early mortality and thus has the potential to increase the number of years of life lost. Globalization directly or indirectly by affecting the factors that increase the susceptibility for tuberculosis infection has the potential to increase the spread and mortality due to tuberculosis. This study assessed the causal link between globalization and the years of life lost due to tuberculosis. Methods: Data from the Demographic and Health Survey (DHS) and World Bank for 2004 and 2005 were used for a number of covariates and possible mediators. Data from the Institute of Health Metrics and Evaluation (IHME) were used for the outcome variable and important globalization indicators. The primary health outcome that was studied is tuberculosis and the measure that was used to quantify tuberculosis mortality is the years of life lost (YLL). Path analysis was used. Results: The main independent variables of economic and social integration were not statistically significant. For every unit increase in the proportion of people that were using treated drinking water, there was a -0.0002 decrease in the YLL due to tuberculosis. For every unit increase in the proportion of people with earth floor, there was a 0.0002 units increase in YLL due to tuberculosis. For every unit increase in the proportion of people living using clean fuel, there was a 0.0004 decrease in the YLL due to tuberculosis. Conclusions: Social and economic globalization have no effect on the years of life lost due to tuberculosis, highlighting that globalization actually does not contribute to tuberculosis mortality. However, improving other important determinants such as sanitation, providing safe drinking water and clean households will reduce the mortality due to tuberculosis, highlighting the need to invest in them.",
         "38",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  1. All variables should be written clearly and systematically, first the independent variables should be described, then the dependent variables should be described. 2. Resources of data from World Bank was too old. 3. No data was obtained from 40 countries measured in relation to this research, there should be a ranking for each country that can indicate which countries have good scores and which countries have low scores.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7434",
         "3",
         "0",
         "0.1909999999999999",
         "0.1041",
         "0.7335164546966553",
         "34.76",
         "13.3",
         "15.46",
         "14.9",
         "14.8",
         "101",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "3.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "4.0",
         "3.0",
         "4.0",
         "82.0",
         "82",
         "f1000"
        ],
        [
         "37",
         "Mohamed Adil AA",
         "17 Jan 2022",
         "Approved",
         "251",
         "Globalization and life lost due to tuberculosis: evidence from a multi-country study",
         "Background: Tuberculosis affects around 30% of the population of the world. Tuberculosis causes an increase in early mortality and thus has the potential to increase the number of years of life lost. Globalization directly or indirectly by affecting the factors that increase the susceptibility for tuberculosis infection has the potential to increase the spread and mortality due to tuberculosis. This study assessed the causal link between globalization and the years of life lost due to tuberculosis. Methods: Data from the Demographic and Health Survey (DHS) and World Bank for 2004 and 2005 were used for a number of covariates and possible mediators. Data from the Institute of Health Metrics and Evaluation (IHME) were used for the outcome variable and important globalization indicators. The primary health outcome that was studied is tuberculosis and the measure that was used to quantify tuberculosis mortality is the years of life lost (YLL). Path analysis was used. Results: The main independent variables of economic and social integration were not statistically significant. For every unit increase in the proportion of people that were using treated drinking water, there was a -0.0002 decrease in the YLL due to tuberculosis. For every unit increase in the proportion of people with earth floor, there was a 0.0002 units increase in YLL due to tuberculosis. For every unit increase in the proportion of people living using clean fuel, there was a 0.0004 decrease in the YLL due to tuberculosis. Conclusions: Social and economic globalization have no effect on the years of life lost due to tuberculosis, highlighting that globalization actually does not contribute to tuberculosis mortality. However, improving other important determinants such as sanitation, providing safe drinking water and clean households will reduce the mortality due to tuberculosis, highlighting the need to invest in them.",
         "41",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The article highlights important areas in the arena of globalization and the spread of infectious diseases. The article particularly looks into data from a number of countries globally, thus increasing the validity and reliability of the study across continents and also globally.  Could this study be replicated by using longitudinal data to establish causality and stronger inferences? Do the path regression results provide more robust results than OLS analysis? What was the main logic in choosing only a specific set of covariates and not all the possible covariates for tuberculosis?  This a good study and will help in addressing many lacunae in the area of global health research.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7655",
         "1",
         "0",
         "0.1954301075268817",
         "0.072",
         "0.8643754720687866",
         "26.51",
         "14.4",
         "16.64",
         "16.1",
         "14.5",
         "103",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "95.0",
         "True",
         "f1000"
        ],
        [
         "38",
         "Arutselvi Devarajan",
         "18 Jan 2022",
         "Approved",
         "297",
         "Globalization and life lost due to tuberculosis: evidence from a multi-country study",
         "Background: Tuberculosis affects around 30% of the population of the world. Tuberculosis causes an increase in early mortality and thus has the potential to increase the number of years of life lost. Globalization directly or indirectly by affecting the factors that increase the susceptibility for tuberculosis infection has the potential to increase the spread and mortality due to tuberculosis. This study assessed the causal link between globalization and the years of life lost due to tuberculosis. Methods: Data from the Demographic and Health Survey (DHS) and World Bank for 2004 and 2005 were used for a number of covariates and possible mediators. Data from the Institute of Health Metrics and Evaluation (IHME) were used for the outcome variable and important globalization indicators. The primary health outcome that was studied is tuberculosis and the measure that was used to quantify tuberculosis mortality is the years of life lost (YLL). Path analysis was used. Results: The main independent variables of economic and social integration were not statistically significant. For every unit increase in the proportion of people that were using treated drinking water, there was a -0.0002 decrease in the YLL due to tuberculosis. For every unit increase in the proportion of people with earth floor, there was a 0.0002 units increase in YLL due to tuberculosis. For every unit increase in the proportion of people living using clean fuel, there was a 0.0004 decrease in the YLL due to tuberculosis. Conclusions: Social and economic globalization have no effect on the years of life lost due to tuberculosis, highlighting that globalization actually does not contribute to tuberculosis mortality. However, improving other important determinants such as sanitation, providing safe drinking water and clean households will reduce the mortality due to tuberculosis, highlighting the need to invest in them.",
         "42",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This paper explored an important aspect of the public health issue of TB and its association with globalization. I have some suggestions for the authors: The nature of data was cited as the reason for not being able to completely explain the causal link, I suggest the authors mention only association (as the data may exhibit some correlation but not causation) instead of the \"causal link\" in the objective.  Although the current introduction is good, it would be better if there are more indirect indicators or covariates that affect tuberculosis incidence.  The methods section is good and elaborate. The aspects of globalization - economic and social, and other aspects of globalization could also be considered in this research or for future research.  The main outcome variable is Years of Life Lost due to tuberculosis. It would be much better if disability-adjusted life years could have been used in future papers to expand this research.  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.765",
         "1",
         "0",
         "0.2096153846153846",
         "0.2025",
         "0.8910351991653442",
         "33.14",
         "13.9",
         "15.74",
         "15.1",
         "14.8",
         "102",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "1.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "3.0",
         "4.0",
         "5.0",
         "90.0",
         "90",
         "f1000"
        ],
        [
         "39",
         "Elizabeth A. Stokes",
         "21 Sep 2021",
         "Approved",
         "457",
         "Cost-effectiveness of hydroxychloroquine versus placebo for hand osteoarthritis: economic evaluation of the HERO trial",
         "Background: An economic evaluation alongside the Hydroxychloroquine Effectiveness in Reducing symptoms of hand Osteoarthritis (HERO) trial was undertaken to assess the cost-effectiveness of hydroxychloroquine compared with placebo for symptomatic treatment of hand osteoarthritis for patients with at least moderate hand pain and inadequate response to current therapies. Methods: A trial-based cost–utility analysis was undertaken from the perspective of the UK National Health Service and Personal Social Services over a 12-month time horizon, using evidence from 248 participants included in the HERO trial, conducted in England. Patient-level data were collected prospectively over a 12-month period, using participant-completed questionnaires and investigator forms, to collect healthcare utilisation, costs and quality-adjusted life years (QALYs) using the EQ-5D-5L. The base-case analysis was conducted on an intention-to-treat basis and used multiple imputation methods to deal with missing data. Results were presented in terms of incremental cost-effectiveness ratios (incremental cost per QALY) and net health benefit, with uncertainty surrounding the findings explored using cost-effectiveness acceptability curves. Results: The base-case analysis estimated slightly lower costs on average (−£11.80; 95% confidence interval (CI) −£15.60 to −£8.00) and marginally fewer QALYs (−0.0052; 95% CI −0.0057 to −0.0047) for participants in the hydroxychloroquine group versus placebo group at 12 months. The resulting incremental cost-effectiveness ratio of £2,267 per QALY lost indicated that although costs were saved, health-related quality of life was lost. Even assuming symmetrical preferences regarding losses and gains for health benefits, the findings do not fall within the cost-effective region. Similar findings arose for analyses conducted from the societal perspective and using complete cases only. Conclusions: This economic evaluation indicates that hydroxychloroquine is unlikely to provide a cost-effective pain relief option for improving health-related quality of life in adult patients with moderate-to-severe hand osteoarthritis.",
         "35",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This paper reports a within-trial cost-utility analysis (CUA) and cost-effectiveness analysis (CEA). The paper is clearly written, and appropriate methods have been used to conduct analyses. The text around interventions being cost-effective where findings are reported in terms of cost per QALY lost is very well explained. I have the following comments: A CUA and a CEA were planned, did you pre-specify which was the primary analysis?  Introduction – first sentence – who is at-risk?  Resource use was captured at baseline, 6 and 12 months. Did the questionnaires at each of these time points ask participants to recall their resource use over the previous 6 months? Was resource use captured at baseline solely for the purpose of including baseline costs in the multiple imputation models?  Did you explore the missing at random assumption?  Costs – resource use was captured on day cases, but no unit cost for this is reported in Table 1. Were there no participants who reported a day case admission? Were hospital admissions not captured as there is no chance that this patient group would be admitted for hand OA? In the introduction, surgery is cited as one of the high costs in this patient group.  The mean difference between groups and 95% CI is presented in Table 3 for costs and Table 5 for EQ-5D utilities, but not in Table 2 for resource use? It would help the reader to include this.  Table 3 – did you consider separating medication costs into HCQ and other medications?  The time horizon for the CUA was 12 months but for the CEA was 6 months? While the primary clinical outcome of hand pain severity was measured at 6 months, this was also captured at 12 months. Why was your analysis for this outcome based on a shorter time horizon than the CUA analysis? Was a CEA over 12 months a pre-planned sensitivity analysis?  Is the work clearly and accurately presented and does it cite the current literature? Yes  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7362",
         "1",
         "0",
         "0.1312373737373737",
         "0.1879",
         "0.8965256214141846",
         "45.96",
         "11.0",
         "12.46",
         "13.5",
         "11.2",
         "92",
         "0",
         "0",
         "0",
         "0",
         "4.0",
         "5.0",
         "9.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "4.0",
         "84.0",
         "84",
         "f1000"
        ],
        [
         "40",
         "David Mark Epstein",
         "10 Dec 2021",
         "Approved",
         "274",
         "Cost-effectiveness of hydroxychloroquine versus placebo for hand osteoarthritis: economic evaluation of the HERO trial",
         "Background: An economic evaluation alongside the Hydroxychloroquine Effectiveness in Reducing symptoms of hand Osteoarthritis (HERO) trial was undertaken to assess the cost-effectiveness of hydroxychloroquine compared with placebo for symptomatic treatment of hand osteoarthritis for patients with at least moderate hand pain and inadequate response to current therapies. Methods: A trial-based cost–utility analysis was undertaken from the perspective of the UK National Health Service and Personal Social Services over a 12-month time horizon, using evidence from 248 participants included in the HERO trial, conducted in England. Patient-level data were collected prospectively over a 12-month period, using participant-completed questionnaires and investigator forms, to collect healthcare utilisation, costs and quality-adjusted life years (QALYs) using the EQ-5D-5L. The base-case analysis was conducted on an intention-to-treat basis and used multiple imputation methods to deal with missing data. Results were presented in terms of incremental cost-effectiveness ratios (incremental cost per QALY) and net health benefit, with uncertainty surrounding the findings explored using cost-effectiveness acceptability curves. Results: The base-case analysis estimated slightly lower costs on average (−£11.80; 95% confidence interval (CI) −£15.60 to −£8.00) and marginally fewer QALYs (−0.0052; 95% CI −0.0057 to −0.0047) for participants in the hydroxychloroquine group versus placebo group at 12 months. The resulting incremental cost-effectiveness ratio of £2,267 per QALY lost indicated that although costs were saved, health-related quality of life was lost. Even assuming symmetrical preferences regarding losses and gains for health benefits, the findings do not fall within the cost-effective region. Similar findings arose for analyses conducted from the societal perspective and using complete cases only. Conclusions: This economic evaluation indicates that hydroxychloroquine is unlikely to provide a cost-effective pain relief option for improving health-related quality of life in adult patients with moderate-to-severe hand osteoarthritis.",
         "115",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors conduct an economic evaluation alongside the RCT. There were no differences found between the groups in terms of hand pain or quality-of-life and no significant differences in costs.  Although there were no differences, it is nevertheless worthwhile publishing these results, in order to avoid \"publication bias\" and guide future research in this area. The study, in general, is well conducted and I have no comments on technical matters.  Rather than calculate an ICER, which implies some measurable difference in outcomes and costs, personally, I would interpret the results in the abstract and conclusions that there were no meaningful or statistically significant differences in any outcomes or costs at 1 year.  The authors do not discuss other therapies or research in this area and this contextual comparison would be useful.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Yes",
         "0.7818",
         "1",
         "0",
         "0.1495833333333333",
         "0.1213",
         "0.8935310244560242",
         "24.68",
         "15.1",
         "16.18",
         "16.0",
         "15.5",
         "99",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "3.0",
         "4.0",
         "4.0",
         "80.0",
         "80",
         "f1000"
        ],
        [
         "41",
         "Rita Margaretha Setianingsih",
         "02 Aug 2021",
         "Approved With Reservations",
         "536",
         "Cultural heritage buildings for urban tourism destinations: portraits of Siantar, Indonesia, in the past",
         "Background: This study was motivated by the failure to use historic buildings, plantations heritage, and modernization of Siantar. The problem is focused on the optimization of historic buildings, icons for urban tourism destinations. The study contribution is useful for the protection, utilization, and development of cultural heritage buildings into a tourist destination in urban areas. More specifically, the study aims to explore and discuss the optimization of urban tourism to support economic and territorial growth. Methods: The study was carried out qualitatively with a pragmatic methodological approach according to the tourism paradigm. The study departs from the colonial archives: photographs, maps, notes, and field research focused on the identification, significance, and contribution to urban history. The data were transcribed verbatim and analyzed thematically. Raw information was reduced and coded according to the relevance of the study. Data are combined into categories and themes reflecting descriptive analysis, classification, and interpretation. Data validation was done through triangulation strategies, member checking, rich descriptions, and saturation.  Results:The Historic Tours of Siantar and Its Surroundings, the findings of this study were carried out in three stages; development based on national consensus in law, utilization into public space, appreciation for managers, and management incentives, and determining urban tourism designs. Conclusions: Utilization of cultural heritage buildings for urban tourism destinations reflects the urban with plantation characteristics, portraits of cities in the past, packed into urban tourism experiences.",
         "24",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  There are no other resources or activities located in urban areas and providing entertainment. For example, what is in the Simbolon area or in the China area around Jalan Dr. Cipto, or in the Simalungun area? More discussion on matters related to The Historic Tours of Siantar and its Surroundings. So the discussion talks about Geopark and others - we recommend discussing the potential that exists in Pematang Siantar urban area.  Cultural heritage is indeed a primary element in urban tourism in Siantar City, but it must also be supported by secondary elements related to the combination of attractiveness that is felt to be unique and becomes a motivation for tourists. Secondary elements describe urban facilities that support and complement the tourist experience. For example, Pematang Siantar has old transportation facilities (such as: BSA = Birmingham Small Arms Company, Java, and others) which may be accessible by tourists for short distances.  There is less description of what tourists should do in Siantar City – something to see, something to do, and something to buy. Something to see – cultural heritage. Something to buy – culinary at Cipto Street, Ganda Bakery, Horas Market. Something to do – walk in the garden, city park walks, Goddess Kwam Im Statue (Vihara Avalokitesvara), Maha Vihara Vidya Maitreya.  In the abstract section, it is mentioned about the research results, one of which is the determination of urban tourism design. But there is nothing in the conclusion and discussion section. It is better to discuss this, especially based on locality and it is better to focus on Siantar City (limited research).  For urban tourism, an itinerary should be made, so that tourists know the list of activities and budget estimates (this is for management incentives). It has been listed, but it extends outside the city of Siantar, for example to the areas of Sarbelawan and Tanohdjawa. This is not in accordance with the title of urban tourism. Maybe the title should be The Historic Tours of Siantar and its Surroundings.  As stated in the abstract on the results of research on the use of public space, the appreciation of managers and incentives for managers has not been discussed and is not included in the conclusions.  It is better to use a library about the city of Siantar, not a library about the Simalungun area or plantations. .  Is the work clearly and accurately presented and does it cite the current literature? No  Is the study design appropriate and is the work technically sound? No  Are sufficient details of methods and analysis provided to allow replication by others? Yes  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? No  Are the conclusions drawn adequately supported by the results? No",
         "0.744",
         "2",
         "0",
         "0.114139712488769",
         "0.1136",
         "0.8740142583847046",
         "35.37",
         "13.0",
         "13.84",
         "14.8",
         "13.0",
         "100",
         "0",
         "0",
         "0",
         "0",
         "3.0",
         "4.0",
         "8.0",
         "no",
         "neutral",
         "neutral",
         "Moderate",
         "2",
         "3.0",
         "4.0",
         "3.0",
         "42.0",
         "42",
         "f1000"
        ],
        [
         "42",
         "Michael Hitchcock",
         "18 Aug 2021",
         "Not Approved",
         "364",
         "Cultural heritage buildings for urban tourism destinations: portraits of Siantar, Indonesia, in the past",
         "Background: This study was motivated by the failure to use historic buildings, plantations heritage, and modernization of Siantar. The problem is focused on the optimization of historic buildings, icons for urban tourism destinations. The study contribution is useful for the protection, utilization, and development of cultural heritage buildings into a tourist destination in urban areas. More specifically, the study aims to explore and discuss the optimization of urban tourism to support economic and territorial growth. Methods: The study was carried out qualitatively with a pragmatic methodological approach according to the tourism paradigm. The study departs from the colonial archives: photographs, maps, notes, and field research focused on the identification, significance, and contribution to urban history. The data were transcribed verbatim and analyzed thematically. Raw information was reduced and coded according to the relevance of the study. Data are combined into categories and themes reflecting descriptive analysis, classification, and interpretation. Data validation was done through triangulation strategies, member checking, rich descriptions, and saturation.  Results:The Historic Tours of Siantar and Its Surroundings, the findings of this study were carried out in three stages; development based on national consensus in law, utilization into public space, appreciation for managers, and management incentives, and determining urban tourism designs. Conclusions: Utilization of cultural heritage buildings for urban tourism destinations reflects the urban with plantation characteristics, portraits of cities in the past, packed into urban tourism experiences.",
         "40",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  Generally, the paper is descriptive, and it is not clear what the contribution is to debates about urban heritage and tourism. This is partly a consequence of a lack of an adequate literature review. For example, the paper mentions the World Heritage Site issue, but overlooks some critical texts such as (some I have been involved in): Harrison and Hitchcock (2005)1; Hitchcock, King and Parnwell (2010)2, and King (2016)3. The methodology is a bit disorganised and there is no explanation as to why this one and not another one was selected. It also does not engage sufficiently with other papers on research methods. The name of the approach needs to be stated clearly and close to the beginning of the section. It takes a while to work out what is being done. The results are written in a largely descriptive manner and there is a curious lack of critical engagement. It was not quite clear what the aim of the paper is. It is also inconclusive even though there is an attempt at a Conclusion. In its current form the paper is not indexable, and the authors would need to thoroughly re-write it for it to be accepted. It needs to be thoroughly rewritten with much more development of its analytical purpose and more critical engagement with the existing literature.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? No  Are sufficient details of methods and analysis provided to allow replication by others? No  If applicable, is the statistical analysis and its interpretation appropriate? Partly  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7495",
         "1",
         "3",
         "0.1470748299319728",
         "0.1213",
         "0.861151933670044",
         "43.53",
         "12.0",
         "14.38",
         "14.4",
         "12.5",
         "101",
         "0",
         "2",
         "0",
         "0",
         "2.0",
         "4.0",
         "5.0",
         "no",
         "negative",
         "neutral",
         "3",
         "2",
         "3.0",
         "4.0",
         "4.0",
         "44.0",
         "50",
         "f1000"
        ],
        [
         "43",
         "Milena Ivanovic",
         "31 Aug 2021",
         "Not Approved",
         "708",
         "Cultural heritage buildings for urban tourism destinations: portraits of Siantar, Indonesia, in the past",
         "Background: This study was motivated by the failure to use historic buildings, plantations heritage, and modernization of Siantar. The problem is focused on the optimization of historic buildings, icons for urban tourism destinations. The study contribution is useful for the protection, utilization, and development of cultural heritage buildings into a tourist destination in urban areas. More specifically, the study aims to explore and discuss the optimization of urban tourism to support economic and territorial growth. Methods: The study was carried out qualitatively with a pragmatic methodological approach according to the tourism paradigm. The study departs from the colonial archives: photographs, maps, notes, and field research focused on the identification, significance, and contribution to urban history. The data were transcribed verbatim and analyzed thematically. Raw information was reduced and coded according to the relevance of the study. Data are combined into categories and themes reflecting descriptive analysis, classification, and interpretation. Data validation was done through triangulation strategies, member checking, rich descriptions, and saturation.  Results:The Historic Tours of Siantar and Its Surroundings, the findings of this study were carried out in three stages; development based on national consensus in law, utilization into public space, appreciation for managers, and management incentives, and determining urban tourism designs. Conclusions: Utilization of cultural heritage buildings for urban tourism destinations reflects the urban with plantation characteristics, portraits of cities in the past, packed into urban tourism experiences.",
         "53",
         "Not Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The article presents an overview of the heritage buildings in Siantar from the plantation period, the need for their conservation and possible utilisation as attractions in urban tourism, and the development of the heritage tours through the Historic Tours of Siantar and its Surroundings. It could have been an interesting article, but the argument put forward by the researcher falls short of expectations. The article lacks focus, organisation, and constructive argument. Sections presenting the study results and discussion of the findings are intertwined with the literature. Since the aim of the article is not clearly stated, the literature review is misguided and too generalised. In addition, the site description should not be discussed in the literature. Statistical data meant to highlight the growth of urban tourism is confusing, and none is referring to Sumatra and Siantar. The authors cannot use a percentage of urban tourism growth in Europe to argue the potential growth of urban tourism in Sumatra. Europe is the most visited continent globally, the continuous cultural heritage destination with the most famous cities in the world. What exactly are the points for comparison with Sumatra or Siantar? The study is well designed, especially because historical records of historical buildings were checked, compared, and verified on the ground. This approach gives credibility to a study. In addition, the study design follows a strict procedure of the inventory phase of the cultural attractions selection process. The clustering of attractions into four districts is the result of this process. Still, the primary historical significance of each cluster, the linkage corridors and the relationship between the clusters are not explained. The geographical map should be presented showing each cluster and how they are linked. The unique selling point is an offering of European, Chinese, and local heritage clusters surviving in a medium-sized city. The study is not designed to be replicated because it implements the well-known selection process of determining cultural attractions. The sources of data are submitted. General comments: The aim of the article is not clear. Also, the reason for the conservation of cultural heritage is misinterpreted and cannot be for tourism. The main reason should be for education and in building national identity and pride. Tourism is just one of the uses of cultural heritage, but when heritage is negatively impacted by tourism numbers, it should be conserved and protected. Another way of conserving cultural heritage through tourism use is by creating clusters and possibly by theming the areas and, in turn, creating functional tourism precincts. This should be better explained, given the richness of the data obtained on the ground. The inventory is just a starting point -  the first phase of the selection process in turning historic buildings into a tourist attractions. See chapter 7 of [ref 1]. The conceptual framework is too broad. Urban tourism destination is not synonymous with historical heritage destination. It is unclear how nostalgia fits in; it was not well integrated. It is not clear the link between Siantar as a student-friendly city and the further development and inclusion of tourism clusters into urban tours. The size and population of the city and its main urban functions are not explained. If the article is completely rewritten and restructured, it can present a valuable contribution to applying the selection process in creating viable tourism attractions. In its current form, the article is not suitable for indexing.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Yes  Are sufficient details of methods and analysis provided to allow replication by others? No  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? Partly  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7227",
         "2",
         "0",
         "0.1059272300469483",
         "0.072",
         "0.918596625328064",
         "37.1",
         "12.4",
         "13.5",
         "15.3",
         "13.1",
         "100",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "3.0",
         "6.0",
         "no",
         "neutral",
         "neutral",
         "Moderate",
         "2",
         "4.0",
         "3.0",
         "4.0",
         "52.0",
         "80",
         "f1000"
        ],
        [
         "44",
         "Akira Endo",
         "04 May 2021",
         "Approved With Reservations",
         "1775",
         "The feasibility of targeted test-trace-isolate for the control of SARS-CoV-2 variants",
         "The SARS-CoV-2 variant B.1.1.7 reportedly exhibits substantially higher transmission than the ancestral strain and may generate a major surge of cases before vaccines become widely available, while the P.1 and B.1.351 variants may be equally transmissible and also resist vaccines. All three variants can be sensitively detected by RT-PCR due to an otherwise rare del11288-11296 mutation in orf1ab; B.1.1.7 can also be detected using the common TaqPath kit. Testing, contact tracing, and isolation programs overwhelmed by SARS-CoV-2 could slow the spread of the new variants, which are still outnumbered by tracers in most countries. However, past failures and high rates of mistrust may lead health agencies to conclude that tracing is futile, dissuading them from redirecting existing tracers to focus on the new variants. Here we apply a branching-process model to estimate the effectiveness of implementing a variant-focused testing, contact tracing, and isolation strategy with realistic levels of performance. Our model indicates that bidirectional contact tracing can substantially slow the spread of SARS-CoV-2 variants even in regions where a large fraction of the population refuses to cooperate with contact tracers or to abide by quarantine and isolation requests.",
         "18",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study considers the effectiveness of contact tracing focused on variants in reducing the reproduction number. Focusing contact tracing efforts on variants is an interesting approach and may be relevant to the current situation of variant circulations worldwide. The model and the analysis themselves seem well constructed and implemented. However, the authors’ analysis only focuses on a single variant essentially, and does not account for some important aspects that need to be considered to estimate the effect of real-world contact tracing in the presence of multiple variants. As a result, I am not sure if this study provides new insights that are distinct from existing studies on contact tracing for a single-pathogen outbreak. In addition, it should be noted that given a fixed capacity for contact tracing, the reduction in the reproduction number would not be permanent if the outbreak continues to grow. I believe these issues, along with other comments detailed below, need to be addressed for this study to be truly of epidemiological and public health interest. Major comments: Please clarify how this study is distinct from existing studies on contact tracing considering a single-pathogen outbreak (including the authors’ own study cited here).  There seems to be a mismatch between the study motivation/context and the modelling approach. One of the points the authors are trying to make is that the contact tracing efforts should be focused on variants because they are of more epidemiological importance (due to potentially higher transmission or immunoescape). I do not disagree with this point, but there are several major issues regarding how it was handled in the manuscript.  The reproduction number R is used as an objective variable to measure the effect of contact tracing. This is useful to connect interventions and the dynamic evolution of the epidemic, but essentially assumes that the same level of tracing can continue everywhere long-term, regardless of the epidemic size. This is obviously not true as the authors also state in the manuscript. In conditions where R is above 1, transmission of variants would continue and overwhelms the tracing capacity at some point, pushing R back to the original value eventually. Focusing on R may be useful in identifying conditions required to control the outbreak (i.e. R<1), but it is unrealistic to consider that the tracing can keep R lower than the original value in a long term if the resulting value exceeds 1.  Variants are no longer minor in many places now (see for example: https://covid.cdc.gov/covid-data-tracker/#variant-proportions), and I am not sure how much this assumption of ‘minor variants’ is relevant to the actual situation. Moreover, even in places where the variants are still minor, if the (effective) transmissibility of the variants is higher than the existing virus, they would rapidly replace the existing viruses, potentially in a few weeks/months. Exclusion of existing strains. The main argument regarding the tracing capacity is that the variants account for a small proportion of cases and thus can be handled if tracing focuses on these variants. However, even if such focused intervention is possible by tests that can distinguish variants, existing non-variant viruses may continue spreading if their R is above 1. Although such a situation may still have some benefit, e.g. if preventing the spread of immunoescaping variants would ensure the success of the vaccination program, such contexts should be clarified and discussed.  Cost and capacity. As discussed above, contact tracing would work as estimated here only until the capacity is reached. However, I feel efforts associated with tracing is not seriously considered in the analysis. For example, if all contacts of cases within the tracing period are traced, extending the tracing period from 2 days to 6 days would incur substantial additional effort for tracing. I believe it is important to discuss to what extent contact tracing might be sustainable for each setting because the presented results become invalid once the capacity is reached.  Given the points above, I would recommend the authors reconsider what outcome measure to use and how to present them; e.g. consideration of the growth of \"non-targeted\" viruses, conditions required to keep R below 1, whether tracing can “buy time” until achieving a sufficient level of vaccination before reaching the capacity, optimising the intensity of other NPIs (e.g. lockdowns) in the presence of contact tracing, etc., such that the results are relevant to what may actually happen. The Introduction looks lightweight and lacking necessary details or contexts. There are a lot of concepts that may not be familiar enough to every reader but are not sufficiently explained (e.g. TTI, backward contact tracing, bidirectional tracing, why TaqPath test can distinguish B.1.1.7… etc.) and thus may require a succinct clarification. Please also note that this paper may be read in 20 years from now, when the reader may not have the same level of recognition of the current situation. In this light, for example, I feel the first paragraph of Introduction may sound a bit abrupt to the reader who is less aware of the overall timeline of the pandemic. Also see some of the specific comments in the Minor comments section.  The Methods section is too simple and does not contain sufficient information for the reader to comprehend the overall structure of the analysis. Although it does not need to contain every technical detail of the model and analysis as the supplementary methods can be found in the repository (but please include a link and description in the paper so that the reader can easily find it), I feel more information from the supplementary methods should be extracted and summarised in the main text. For example, from the current Methods section I cannot interpret how the course of transmission was characterised, what is the assumed procedure of tracing (Is it always bidirectional tracing? I feel 2-day window is too short for backward tracing), how environmental transmission was assumed to work, how R was calculated, etc.  I believe additional sensitivity analysis would be necessary. For example, the overdispersion parameter (0.11 used in the current analysis) is estimated to be slightly higher (0.3-0.5) in some studies where interventions were in place (Adam et al., 20201). As the authors assume that interventions may be affecting R during contact tracing, possible changes in overdispersion should also be considered. Delay from secondary transmission to quarantine of contacts (defined as a sum of various delay distribution) would also affect the effectiveness of contact tracing in a nontrivial manner.  Is the effect of vaccines not considered, although as in Introduction it was one of the major motivation for considering controlling variants? Vaccines may affect different viruses similarly or differently, depending on the type of variants.  Supplementary Methods, “Identified contacts are quarantined, …isolated, tested, and traced as described above”: what is the difference between quarantining and isolation of traced contacts? Does this mean all traced contacts of a case are put under quarantine regardless of their true infection status, but only tested if they are symptomatic (which changes the label from quarantine to isolation)? If so, it is expected that as the epidemic grows there would be a substantial number of quarantined individuals, and at some point this might be impossible (e.g. due to depletion of essential workers) and the Reff control could collapse.  Minor comments: Throughout: please spell out acronyms at their first appearance, including SARS-CoV-2 and COVID-19.  Introduction, protection against B.1.351 and P.1: now the evidence is not limited to in-vitro studies (e.g. Madhi et al., 20212 and Kustin et al., 20213). Please update and include clinical findings. Also summarise what we know about protection against B.1.1.7.  “All three variants share…; B.1.1.7 can also be…”: I would suggest that the authors first describe B.1.1.7 that can be detected by TaqPath tests (with some more background context, as this is primarily happening in UK and not necessarily recognized by the wider audience) and then go on to a discussion of potential detectability of other variants (because this is only a hypothetical scenario so far in my understanding, as opposed to detection of B.1.1.7). Also, would there be any data on the rollout of these variant-distinguishable tests worldwide?  “Samples testing positive…”: This needs more context. Why is authorisation going to be an issue and why can re-screening bypass it?  “as is true for SARS-CoV-2 – but not yet the variants – in many regions”: I feel this is unclear. TTI capacity would be overwhelmed when the overall caseloads are high, even if the variants account for a very small fraction of them. It should be made clear if this indicates contact tracing would only target variants distinguished by the (variant-specific) tests.  Method, “child cases” may be interpreted as cases that are children. Secondary transmissions?  Results, “In the absence of contact tracing, identification and isolation of symptomatic cases alone reduced Reff by 0.2 to 0.3…”: I couldn’t read this from the top rows of Figure 1. This may correspond to 0% of cases sharing data or 0% trace success probability, but Reff for such a scenario cannot be read from the figure because there is no colour scales or numbers.  “When identification and isolation…substantial effects.”: I am not sure how “moderate levels” and “substantial effects” are defined.  “Due to the exponential growth of uncontrolled epidemics…over a given timespan”: As stated above, this is only the case if contact tracing can continue without hitting the capacity. If R goes back to the original level after tracing is overwhelmed, there may be only a marginal difference in the final epidemic size.  Discussion, “Higher rates of cooperation…quarantine and isolation”: related to the first major comment, these efforts would make tracing more effective but require a substantial amount of effort and cost, and warrant discussion.  Please update references. Many of the preprints cited here have now been published in peer-reviewed journals, which might include more up-to-date information.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Not applicable  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? No",
         "0.8027",
         "3",
         "1",
         "0.1066198131137155",
         "0.2522",
         "0.8703778982162476",
         "35.17",
         "13.1",
         "12.42",
         "14.5",
         "13.6",
         "103",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "3.0",
         "11.0",
         "True",
         "negative",
         "neutral",
         "Moderate",
         "somewhat specific",
         "2.0",
         "3.0",
         "2.0",
         "22.0",
         "78",
         "f1000"
        ],
        [
         "45",
         "Tim C. D. Lucas",
         "14 May 2021",
         "Approved With Reservations",
         "828",
         "The feasibility of targeted test-trace-isolate for the control of SARS-CoV-2 variants",
         "The SARS-CoV-2 variant B.1.1.7 reportedly exhibits substantially higher transmission than the ancestral strain and may generate a major surge of cases before vaccines become widely available, while the P.1 and B.1.351 variants may be equally transmissible and also resist vaccines. All three variants can be sensitively detected by RT-PCR due to an otherwise rare del11288-11296 mutation in orf1ab; B.1.1.7 can also be detected using the common TaqPath kit. Testing, contact tracing, and isolation programs overwhelmed by SARS-CoV-2 could slow the spread of the new variants, which are still outnumbered by tracers in most countries. However, past failures and high rates of mistrust may lead health agencies to conclude that tracing is futile, dissuading them from redirecting existing tracers to focus on the new variants. Here we apply a branching-process model to estimate the effectiveness of implementing a variant-focused testing, contact tracing, and isolation strategy with realistic levels of performance. Our model indicates that bidirectional contact tracing can substantially slow the spread of SARS-CoV-2 variants even in regions where a large fraction of the population refuses to cooperate with contact tracers or to abide by quarantine and isolation requests.",
         "28",
         "Approved With Reservations  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  In this study the authors use established and previously published models of contact tracing to examine whether targeted test and trace systems could suppress novel variants. The premise is sound; contact tracing scales poorly, so while it is not necessarily effective at control SARS-CoV-2 at large once national prevalence is high, the numbers of certain variants are still low in a number of countries and therefore contact tracing might be able to control those new variants as they are seeded into a country. Whether this approach would work or not is not trivially obvious and so this study is asking an important question with policy implications globally. The analytical approach taken is quite simple in that the authors assume (and back up with some literature) that the variants can be identified easily and that therefore contact tracing of a new variant can continue without any reference to the dominant variant.  Comments: Most of my comments relate to this assumption that contact tracing of new variants can be modelled by simply ignoring the dominant variant.  First, I would like to see this assumption explicitly stated in the methods just to make it completely clear to the reader.  There are a number of further considerations with this assumption that I think should be discussed.  Given the high rate of vaccination and previous infection with the original SARS-CoV-2 strain, many countries are now in a state where immunity cannot be ignored. This is all handled by Reff, but I think it needs to be mentioned that Reff is combining NPIs, immunity or partial immunity from vaccination (depending on whether there's vaccine escape in the variant)  and partial immunity from previous infection with other strains.  The authors state that new variants can be detected with RT-PCR and TaqPath. However, does this extra step create no extra delay in the process? I imagine this would depend on the specific organisation but might be worth considering and mentioning.  Furthermore, is this identification of variants 100% accurate? The false negative rate (someone is infected with a new variant but the test says they are infected with the original variant) can be just included as part of the test sensitivity and I wouldn't be surprised if the difference is fairly small. More worrying for me is the false positive rate (someone is infected with the original variant but the tests says they are infected with a new variant). This is important because the rationale for the study relies entirely on the fact that there are not many cases with the new variant in a country but if, say, the false positive rate (as defined above) is even 1% then the large number of original variant cases in a country will quickly lead to the targeted test-trace-isolate system being swamped. This effect will obviously vary with the prevalence of original variant SARS-CoV-2.  I only know the literature for the UK, but even the lowest compliance rates used here are much higher than those measured (I wouldn't be surprised if some countries have much high compliance rates though). I am taking my values from the reference below (Smith et al., 20201),  but there might be more up-to-date surveys in the UK and I don't know at all about other countries.  From self-reported behaviour (past behaviour, not intentions) in the UK, about 12% of people with symptoms requested a test. This relates to the 50% of symptomatic cases identified without tracing parameter. Some details of how you selected 50% from ref 32 would be useful, as the values in that paper range from 5% to 100% depending on the country and time. In the UK, of those contacted by track and trace, 11% of people fully complied with 2 weeks self isolation (this relates to the 50%-90% comply with isolation parameter). So at the very least I think it might be useful to state that these values might be quite optimistic in some settings.  Finally, a minor and subjective point, but it might be useful to present Figure 1 with a diverging colour palette that clearly distinguishes Reff < 1 and Reff > 1.  Is the work clearly and accurately presented and does it cite the current literature? Partly  Is the study design appropriate and is the work technically sound? Partly  Are sufficient details of methods and analysis provided to allow replication by others? Partly  If applicable, is the statistical analysis and its interpretation appropriate? Yes  Are all the source data underlying the results available to ensure full reproducibility? Yes  Are the conclusions drawn adequately supported by the results? Partly",
         "0.7912",
         "1",
         "0",
         "0.114608760415212",
         "0.1733",
         "0.926215410232544",
         "37.64",
         "14.2",
         "14.79",
         "15.5",
         "15.2",
         "101",
         "0",
         "0",
         "2",
         "0",
         "4.0",
         "5.0",
         "8.0",
         "yes",
         "neutral",
         "neutral",
         "Moderate",
         "somewhat specific",
         "4.0",
         "5.0",
         "5.0",
         "82.0",
         "82",
         "f1000"
        ],
        [
         "46",
         "Prajwal Ghimire",
         "05 Mar 2021",
         "Approved",
         "249",
         "Case Report: Ziprasidone induced neuroleptic malignant syndrome",
         "Neuroleptic malignant syndrome (NMS) is a well-recognized neurologic emergency. It presents with classic features including hyperthermia, autonomic instability, muscle hypertonia, and mental status changes. The syndrome is potentially fatal and is associated with significant morbidity due to complications such as rhabdomyolysis, acute kidney injury, and ventricular arrhythmias due to the trans-cellular electrolyte shift. NMS is conventionally associated with the first-generation antipsychotic agents, however, has been described with the use of atypical and novel antipsychotics including Ziprasidone. A case of NMS with Ziprasidone use at the therapeutic dose is reported here.",
         "16",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The authors have presented a rare case report of a well recognised drug induced neurologic emergency of Neuroleptic malignant syndrome due to Ziprasidone. Sedhai et al. have highlighted major challenges and salient points during management of these conditions including the current knowledge regarding its pathophysiology. The case report raises the awareness regarding this potentially life-threatening condition during use of an emerging drug which is now more commonly used for neuro-psychiatric conditions of schizophrenia and bipolar disorders. The case report is well written and highlights the current knowledge and brief literature review in the discussion section with relevant references. It certainly adds a vital information regarding the drug to the current available knowledge in the literature.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Yes  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Yes  Is the case presented with sufficient detail to be useful for other practitioners? Yes",
         "0.7907",
         "2",
         "0",
         "0.0816707717569786",
         "0.0999",
         "0.8509092926979065",
         "23.16",
         "15.6",
         "18.68",
         "17.5",
         "17.9",
         "91",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "yes",
         "positive",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "5.0",
         "5.0",
         "90.0",
         "95",
         "f1000"
        ],
        [
         "47",
         "Ashish Saraf",
         "09 Mar 2021",
         "Approved",
         "209",
         "Case Report: Ziprasidone induced neuroleptic malignant syndrome",
         "Neuroleptic malignant syndrome (NMS) is a well-recognized neurologic emergency. It presents with classic features including hyperthermia, autonomic instability, muscle hypertonia, and mental status changes. The syndrome is potentially fatal and is associated with significant morbidity due to complications such as rhabdomyolysis, acute kidney injury, and ventricular arrhythmias due to the trans-cellular electrolyte shift. NMS is conventionally associated with the first-generation antipsychotic agents, however, has been described with the use of atypical and novel antipsychotics including Ziprasidone. A case of NMS with Ziprasidone use at the therapeutic dose is reported here.",
         "20",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  The case report is well written. The authors have given detailed description of the case mentioning the clinical features, the diagnostic workup and treatment given. The other causes of the rigidity have been ruled out during the diagnostic workup. The discussion is also well written and highlighted the importance of this case report.  This case report will definitely make the clinicians aware of the fact of NMS in newer drugs and hence making them vigilant.  Is the background of the case’s history and progression described in sufficient detail? Yes  Are enough details provided of any physical examination and diagnostic tests, treatment given and outcomes? Yes  Is sufficient discussion included of the importance of the findings and their relevance to future understanding of disease processes, diagnosis or treatment? Yes  Is the case presented with sufficient detail to be useful for other practitioners? Yes",
         "0.7103",
         "1",
         "0",
         "0.0706140350877193",
         "0.0999",
         "0.6933223009109497",
         "33.34",
         "13.8",
         "16.02",
         "15.5",
         "15.4",
         "101",
         "0",
         "1",
         "0",
         "0",
         "5.0",
         "4.0",
         "0.0",
         "yes",
         "neutral",
         "polite",
         "No Hedging",
         "very specific",
         "5.0",
         "4.0",
         "3.0",
         "80.0",
         "83",
         "f1000"
        ],
        [
         "48",
         "Joseph philipraj",
         "22 Mar 2021",
         "Approved",
         "292",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "39",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This systematic review is appropriate for the journal with a global problem of Mets and Urolithiasis. The introduction part clearly explains the motivation. The manuscript is clear and balanced. The manuscript stays focused on the subject. Authors have gone through the process of searching relevant articles from all websites and of sufficient duration. The inclusion and exclusion criteria in the analysis have been clearly stated. The impact of the analysis is clearly stated. The statistical analysis supports the paper well. The interpretation of the results, visualisation are well presented. The tables and figures are clear, relevant and correct. The authors demonstrate the knowledge of basic composition skills, including word choice, sentence structure, paragraph development and grammar. Limitations:  The studies included in the meta-analysis have cross-sectional nature and hence ascertainment of temporal association is not possible which also dictates need for further prospective studies. The specific type of stone formation is not correlated with studies. Despite these limitations all studies included in the meta-analysis showed the same directionality in the association between urolithiasis and Mets.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         "0.7415",
         "1",
         "0",
         "0.1145833333333333",
         "0.0999",
         "0.8487246632575989",
         "30.46",
         "12.8",
         "13.83",
         "14.6",
         "14.3",
         "99",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "4.0",
         "2.0",
         "yes",
         "neutral",
         "polite",
         "Minimal",
         "somewhat specific",
         "4.0",
         "4.0",
         "4.0",
         "92.0",
         "92",
         "f1000"
        ],
        [
         "49",
         "Muhammad Faruk",
         "08 Nov 2021",
         "Approved",
         "422",
         "Association between metabolic syndrome components and the risk of developing nephrolithiasis: A systematic review and bayesian meta-analysis",
         "Background: There is increasing evidence that nephrolithiasis is a systemic disease, as opposed to an isolated urinary metabolic problem, after considerable links were found between nephrolithiasis and systemic diseases such as hypertension, obesity, dyslipidemia, and insulin resistance. The interplay between these four factors defines metabolic syndrome (MetS). In this review we aim to clarify the associations of MetS and its components to kidney stone incident. Methods: Online databases of EMBASE, MEDLINE, and Google Scholar were searched from January 1998 up to October 2020 to identify observational studies examining the association between metabolic syndrome components and kidney stone incident. Bayesian random-effects meta-analysis and meta-regression were performed to observe the association. Linear dose-response analysis was conducted to shape the direction of the association. Data analysis was performed using STATA, and R statistics. Results: A total of 25 potentially relevant studies (n = 934,588 participants) were eventually identified. The pooled results suggested that metabolic syndrome was associated with an increased risk of nephrolithiasis with an odds ratio (OR) of 1.769 (95% CI: 1.386 – 2.309).  The summary OR of hypertension and dyslipidemia for developing nephrolithiasis were 1.613 (95% CI: 1.213 – 2.169) and 1.586 (95% CI: 1.007 – 2.502) respectively. The presence of diabetes mellitus and obesity had an OR of 1.552 (95% CI: 1.027 – 2.344) and 1.531 (95% CI: 1.099 – 2.109) respectively. Our results revealed that the increasing number of MetS traits will increase the risk of developing nephrolithiasis, the higher the fasting plasma glucose, and body mass index, the higher the risk of kidney stones incident. Conclusions: Our results suggest that hypertension, diabetes, obesity and dyslipidemia are associated with increased risk of developing nephrolithiasis. Linear significant association between MetS components and nephrolithiasis were revealed in our study which reinforced the notion that should be considered a systemic disorder.",
         "270",
         "Approved  info_outline Alongside their report, reviewers assign a status to the article:  Approved The paper is scientifically sound in its current form and only minor, if any, improvements are suggested  Approved with reservations A number of small changes, sometimes more significant revisions are required to address specific details and improve the papers academic merit.  Not approved Fundamental flaws in the paper seriously undermine the findings and conclusions  This study assessed the association between metabolic syndrome and its components with the risk of developing nephrolithiasis by conducting systematic review, Bayesian random-effects meta-analysis, meta-regression and dose-response analysis. This study was done appropriately based on PRISMA flowchart. Risk of bias was also conducted of the included studies. This study has successfully presented the proper meta-analysis for this design. However, to complete this study for indexing, I personally recommended several revisions: 1. Abstract: Introduction section: It is better to address meta-regression as the analysis to assess the correlation of association along with dose-response analysis  Conclusion section: In reporting the association between predictors and nephrolithiasis, state only the predictors in which its coefficient was statistically significant 2. R language was not considered as a statistical software for data analysis. The software for data analysis should be written as \"R\" (Please refer to methods section in statistical analysis subsection). 3. Please update the PRISMA flowchart (refer to PRISMA guideline 2009). 4. Give the numbering of each Forrest plot in Figure 3 and numbering of each meta-regression plot in Figure 4. Design these figures so that it could be well presented. 5. Uniformly decide the word choice of \"traits\" or \"components\", choose whether to use traits or components in the whole text, use one of these words consistently to avoid any misunderstanding. 6. It is better to provide the meta-regression of hypertension in systolic blood pressure and diastolic blood pressure as it is important to explain the relationship to nephrolithiasis in differentiation for these two types of blood pressure. 7. Meta-regression of body mass index  was sufficient in this study thus waist circumference meta-regression was not necessary to be included. 8. Provide the value of coefficient and confidence interval of each meta-regression analysis in the result section so that better understanding of predictors-outcome relationship could be reached clearly.  Are the rationale for, and objectives of, the Systematic Review clearly stated? Yes  Are sufficient details of the methods and analysis provided to allow replication by others? Yes  Is the statistical analysis and its interpretation appropriate? Yes  Are the conclusions drawn adequately supported by the results presented in the review? Yes",
         "0.7554",
         "7",
         "0",
         "0.1982758620689655",
         "0.2302",
         "0.9299524426460266",
         "24.68",
         "15.1",
         "14.79",
         "16.3",
         "16.8",
         "91",
         "0",
         "1",
         "0",
         "0",
         "4.0",
         "4.0",
         "3.0",
         "True",
         "neutral",
         "neutral",
         "Minimal",
         "somewhat specific",
         "5.0",
         "4.0",
         "3.0",
         "90.0",
         "90",
         "f1000"
        ]
       ],
       "shape": {
        "columns": 38,
        "rows": 241
       }
      },
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviewer</th>\n",
       "      <th>review_date</th>\n",
       "      <th>review_suggestion</th>\n",
       "      <th>length_words</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>days_to_submit</th>\n",
       "      <th>review_text</th>\n",
       "      <th>mattr</th>\n",
       "      <th>question_count</th>\n",
       "      <th>...</th>\n",
       "      <th>llm_sentiment_polarity</th>\n",
       "      <th>llm_politeness</th>\n",
       "      <th>llm_hedging</th>\n",
       "      <th>llm_specificity</th>\n",
       "      <th>llm_domain_terms</th>\n",
       "      <th>llm_relevance_alignment</th>\n",
       "      <th>llm_readability</th>\n",
       "      <th>llm_overall_quality</th>\n",
       "      <th>llm_overall_score_100</th>\n",
       "      <th>venue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>shaimaa Mohamed Amin</td>\n",
       "      <td>29 Jul 2024</td>\n",
       "      <td>Approved With Reservations</td>\n",
       "      <td>1557</td>\n",
       "      <td>Estimating the efficacy of Newborn-Communicati...</td>\n",
       "      <td>Background Primiparous mothers face diverse ch...</td>\n",
       "      <td>20</td>\n",
       "      <td>Approved With Reservations  info_outline Along...</td>\n",
       "      <td>0.7872</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>83.0</td>\n",
       "      <td>83</td>\n",
       "      <td>f1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Amogh Verma</td>\n",
       "      <td>03 Sep 2024</td>\n",
       "      <td>Approved With Reservations</td>\n",
       "      <td>653</td>\n",
       "      <td>Estimating the efficacy of Newborn-Communicati...</td>\n",
       "      <td>Background Primiparous mothers face diverse ch...</td>\n",
       "      <td>56</td>\n",
       "      <td>Approved With Reservations  info_outline Along...</td>\n",
       "      <td>0.7955</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>84.0</td>\n",
       "      <td>f1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Selmy Awad</td>\n",
       "      <td>28 Dec 2024</td>\n",
       "      <td>Approved With Reservations</td>\n",
       "      <td>174</td>\n",
       "      <td>Case Report: A giant ruptured splenic hydatic ...</td>\n",
       "      <td>The splenic localization of hydatid cysts is e...</td>\n",
       "      <td>24</td>\n",
       "      <td>Approved With Reservations  info_outline Along...</td>\n",
       "      <td>0.7693</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>60</td>\n",
       "      <td>f1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Silvio Buscemi</td>\n",
       "      <td>07 Jan 2025</td>\n",
       "      <td>Approved</td>\n",
       "      <td>280</td>\n",
       "      <td>Case Report: A giant ruptured splenic hydatic ...</td>\n",
       "      <td>The splenic localization of hydatid cysts is e...</td>\n",
       "      <td>34</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.7857</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>polite</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92</td>\n",
       "      <td>f1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nitin Liladhar Rane</td>\n",
       "      <td>17 Oct 2024</td>\n",
       "      <td>Approved</td>\n",
       "      <td>239</td>\n",
       "      <td>What we know and what should we know about the...</td>\n",
       "      <td>Background In response to the transformative i...</td>\n",
       "      <td>35</td>\n",
       "      <td>Approved  info_outline Alongside their report,...</td>\n",
       "      <td>0.7630</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>positive</td>\n",
       "      <td>polite</td>\n",
       "      <td>No Hedging</td>\n",
       "      <td>very specific</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>92</td>\n",
       "      <td>f1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>236</th>\n",
       "      <td>Anonymous</td>\n",
       "      <td>03/May/2014</td>\n",
       "      <td>Reject</td>\n",
       "      <td>804</td>\n",
       "      <td>Module Extraction for Efficient Object Query o...</td>\n",
       "      <td>The extraction of logically-independent fragme...</td>\n",
       "      <td>100</td>\n",
       "      <td>The submission addresses the problem of partit...</td>\n",
       "      <td>0.7587</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>negative</td>\n",
       "      <td>impolite</td>\n",
       "      <td>Heavy</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>20</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>Natasha Noy</td>\n",
       "      <td>22/Jul/2013</td>\n",
       "      <td>Accept</td>\n",
       "      <td>26</td>\n",
       "      <td>EARTh: an Environmental Application Reference ...</td>\n",
       "      <td>The paper aims at providing a description of E...</td>\n",
       "      <td>3</td>\n",
       "      <td>This revision addresses my concerns. I am part...</td>\n",
       "      <td>0.9600</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>85.0</td>\n",
       "      <td>85</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>Anonymous</td>\n",
       "      <td>15/Jun/2013</td>\n",
       "      <td>Reject</td>\n",
       "      <td>368</td>\n",
       "      <td>Facilitating Data Discovery by Connecting Rela...</td>\n",
       "      <td>In this study, we investigate two approaches t...</td>\n",
       "      <td>31</td>\n",
       "      <td>The paper presents and compares RDF/XML (in th...</td>\n",
       "      <td>0.7586</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>72</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>Ghislain Hachey</td>\n",
       "      <td>17/Jun/2013</td>\n",
       "      <td>Reject</td>\n",
       "      <td>665</td>\n",
       "      <td>Facilitating Data Discovery by Connecting Rela...</td>\n",
       "      <td>In this study, we investigate two approaches t...</td>\n",
       "      <td>33</td>\n",
       "      <td>This paper investigates two different approach...</td>\n",
       "      <td>0.8030</td>\n",
       "      <td>9</td>\n",
       "      <td>...</td>\n",
       "      <td>neutral</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Minimal</td>\n",
       "      <td>somewhat specific</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>74</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>240</th>\n",
       "      <td>Ian Dickinson</td>\n",
       "      <td>18/Jun/2013</td>\n",
       "      <td>Reject</td>\n",
       "      <td>640</td>\n",
       "      <td>Facilitating Data Discovery by Connecting Rela...</td>\n",
       "      <td>In this study, we investigate two approaches t...</td>\n",
       "      <td>34</td>\n",
       "      <td>This paper has a number of minor flaws, but my...</td>\n",
       "      <td>0.7908</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>negative</td>\n",
       "      <td>neutral</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>neutral</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>44</td>\n",
       "      <td>semanticweb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>241 rows × 38 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 reviewer  review_date           review_suggestion  \\\n",
       "0    shaimaa Mohamed Amin  29 Jul 2024  Approved With Reservations   \n",
       "1             Amogh Verma  03 Sep 2024  Approved With Reservations   \n",
       "2              Selmy Awad  28 Dec 2024  Approved With Reservations   \n",
       "3          Silvio Buscemi  07 Jan 2025                    Approved   \n",
       "4     Nitin Liladhar Rane  17 Oct 2024                    Approved   \n",
       "..                    ...          ...                         ...   \n",
       "236             Anonymous  03/May/2014                      Reject   \n",
       "237           Natasha Noy  22/Jul/2013                      Accept   \n",
       "238             Anonymous  15/Jun/2013                      Reject   \n",
       "239       Ghislain Hachey  17/Jun/2013                      Reject   \n",
       "240         Ian Dickinson  18/Jun/2013                      Reject   \n",
       "\n",
       "     length_words                                              title  \\\n",
       "0            1557  Estimating the efficacy of Newborn-Communicati...   \n",
       "1             653  Estimating the efficacy of Newborn-Communicati...   \n",
       "2             174  Case Report: A giant ruptured splenic hydatic ...   \n",
       "3             280  Case Report: A giant ruptured splenic hydatic ...   \n",
       "4             239  What we know and what should we know about the...   \n",
       "..            ...                                                ...   \n",
       "236           804  Module Extraction for Efficient Object Query o...   \n",
       "237            26  EARTh: an Environmental Application Reference ...   \n",
       "238           368  Facilitating Data Discovery by Connecting Rela...   \n",
       "239           665  Facilitating Data Discovery by Connecting Rela...   \n",
       "240           640  Facilitating Data Discovery by Connecting Rela...   \n",
       "\n",
       "                                              abstract  days_to_submit  \\\n",
       "0    Background Primiparous mothers face diverse ch...              20   \n",
       "1    Background Primiparous mothers face diverse ch...              56   \n",
       "2    The splenic localization of hydatid cysts is e...              24   \n",
       "3    The splenic localization of hydatid cysts is e...              34   \n",
       "4    Background In response to the transformative i...              35   \n",
       "..                                                 ...             ...   \n",
       "236  The extraction of logically-independent fragme...             100   \n",
       "237  The paper aims at providing a description of E...               3   \n",
       "238  In this study, we investigate two approaches t...              31   \n",
       "239  In this study, we investigate two approaches t...              33   \n",
       "240  In this study, we investigate two approaches t...              34   \n",
       "\n",
       "                                           review_text   mattr  \\\n",
       "0    Approved With Reservations  info_outline Along...  0.7872   \n",
       "1    Approved With Reservations  info_outline Along...  0.7955   \n",
       "2    Approved With Reservations  info_outline Along...  0.7693   \n",
       "3    Approved  info_outline Alongside their report,...  0.7857   \n",
       "4    Approved  info_outline Alongside their report,...  0.7630   \n",
       "..                                                 ...     ...   \n",
       "236  The submission addresses the problem of partit...  0.7587   \n",
       "237  This revision addresses my concerns. I am part...  0.9600   \n",
       "238  The paper presents and compares RDF/XML (in th...  0.7586   \n",
       "239  This paper investigates two different approach...  0.8030   \n",
       "240  This paper has a number of minor flaws, but my...  0.7908   \n",
       "\n",
       "     question_count  ...  llm_sentiment_polarity  llm_politeness  llm_hedging  \\\n",
       "0                 1  ...                 neutral          polite      Minimal   \n",
       "1                 1  ...                positive          polite      Minimal   \n",
       "2                 1  ...                 neutral         neutral      Minimal   \n",
       "3                 1  ...                 neutral          polite      Minimal   \n",
       "4                 1  ...                positive          polite   No Hedging   \n",
       "..              ...  ...                     ...             ...          ...   \n",
       "236               2  ...                negative        impolite        Heavy   \n",
       "237               0  ...                 neutral         neutral      Minimal   \n",
       "238               0  ...                 neutral         neutral     Moderate   \n",
       "239               9  ...                 neutral         neutral      Minimal   \n",
       "240               2  ...                negative         neutral     Moderate   \n",
       "\n",
       "       llm_specificity  llm_domain_terms  llm_relevance_alignment  \\\n",
       "0    somewhat specific               4.0                      4.0   \n",
       "1    somewhat specific               3.0                      4.0   \n",
       "2    somewhat specific               3.0                      4.0   \n",
       "3    somewhat specific               3.0                      4.0   \n",
       "4        very specific               5.0                      4.0   \n",
       "..                 ...               ...                      ...   \n",
       "236                  5               2.0                      1.0   \n",
       "237  somewhat specific               4.0                      3.0   \n",
       "238  somewhat specific               2.0                      4.0   \n",
       "239  somewhat specific               3.0                      4.0   \n",
       "240            neutral               3.0                      4.0   \n",
       "\n",
       "     llm_readability  llm_overall_quality  llm_overall_score_100        venue  \n",
       "0                3.0                 83.0                     83        f1000  \n",
       "1                4.0                 84.0                   84.0        f1000  \n",
       "2                3.0                 60.0                     60        f1000  \n",
       "3                5.0                 92.0                     92        f1000  \n",
       "4                3.0                 92.0                     92        f1000  \n",
       "..               ...                  ...                    ...          ...  \n",
       "236              3.0                 40.0                     20  semanticweb  \n",
       "237              5.0                 85.0                     85  semanticweb  \n",
       "238              3.0                 64.0                     72  semanticweb  \n",
       "239              5.0                 68.0                     74  semanticweb  \n",
       "240              4.0                 42.0                     44  semanticweb  \n",
       "\n",
       "[241 rows x 38 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Add the 'venue' column to both sample dataframes\n",
    "df_50_sample_file1['venue'] = 'f1000'\n",
    "df_50_sample_file2['venue'] = 'semanticweb'\n",
    "\n",
    "# Rename columns to remove '_llamaV3-2' from their names for each dataframe\n",
    "df_50_sample_file1.columns = [col.replace('_llamaV3-2', '') for col in df_50_sample_file1.columns]\n",
    "df_50_sample_file2.columns = [col.replace('_llamaV3-2', '') for col in df_50_sample_file2.columns]\n",
    "\n",
    "# Drop the 'paper_id' column from the second dataframe\n",
    "df_50_sample_file2 = df_50_sample_file2.drop(columns=['paper_id'])\n",
    "\n",
    "# Merge the two dataframes\n",
    "merged_df = pd.concat([df_50_sample_file1, df_50_sample_file2], ignore_index=True)\n",
    "\n",
    "# Display the merged dataframe\n",
    "display(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the merged dataframe to a CSV file named sw_f1000_merged.csv\n",
    "merged_df.to_csv('sw_f1000_merged.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
